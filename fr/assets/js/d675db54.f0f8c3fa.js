"use strict";(self.webpackChunkatlas=self.webpackChunkatlas||[]).push([[1928],{9637:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>u,contentTitle:()=>o,default:()=>p,frontMatter:()=>l,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"chapters/08/6","title":"La g\xe9n\xe9ralisation du faible au fort (W2SG)","description":"Historiquement, une grande partie du travail sur l\'alignement de l\'IA a \xe9t\xe9 hautement th\xe9orique, se concentrant sur les aspects fondamentaux du comportement des agents, l\'alignement interne et les risques li\xe9s \xe0 l\'optimisation apprise. M\xeame les techniques dont nous avons parl\xe9 dans les sections pr\xe9c\xe9dentes comme le d\xe9bat ou l\'IDA sont souvent critiqu\xe9es comme \xe9tant des cadres plut\xf4t que des solutions pratiques, ou fonctionnant principalement sur des probl\xe8mes simples sans aborder le d\xe9fi central de l\'alignement d\'une IA superintelligente dans des sc\xe9narios r\xe9els. Donc m\xeame si nous ne pouvons conduire des exp\xe9riences de s\xe9curit\xe9 que sur les mod\xe8les actuels, comment pouvons-nous \xeatre s\xfbrs que ces techniques resteront efficaces lorsque les IA approcheront des capacit\xe9s surhumaines ?","source":"@site/i18n/fr/docusaurus-plugin-content-docs/current/chapters/08/06.md","sourceDirName":"chapters/08","slug":"/chapters/08/06","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/08/06","draft":false,"unlisted":false,"editUrl":"https://github.com/markov-root/atlas/edit/main/docs/chapters/08/06.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"id":"6","title":"La g\xe9n\xe9ralisation du faible au fort (W2SG)","sidebar_label":"8.6 La g\xe9n\xe9ralisation du faible au fort (W2SG)","sidebar_position":7,"slug":"/chapters/08/06","reading_time_core":"10 min","reading_time_optional":"1 min","pagination_prev":"chapters/08/5","pagination_next":null},"sidebar":"docs","previous":{"title":"8.5 D\xe9bat","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/08/05"}}');var i=n(4848),r=n(8453),a=(n(2482),n(8559),n(9585),n(2501));const l={id:6,title:"La g\xe9n\xe9ralisation du faible au fort (W2SG)",sidebar_label:"8.6 La g\xe9n\xe9ralisation du faible au fort (W2SG)",sidebar_position:7,slug:"/chapters/08/06",reading_time_core:"10 min",reading_time_optional:"1 min",pagination_prev:"chapters/08/5",pagination_next:null},o="La g\xe9n\xe9ralisation du faible vers le fort (W2SG)",u={},d=[{value:"\xc9valuation en sandwich",id:"01",level:2}];function c(e){const s={a:"a",annotation:"annotation",h1:"h1",h2:"h2",header:"header",li:"li",math:"math",mfrac:"mfrac",mi:"mi",mo:"mo",mrow:"mrow",mtext:"mtext",ol:"ol",p:"p",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,r.R)(),...e.components},{GlossaryTerm:n}=s;return n||function(e,s){throw new Error("Expected "+(s?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("GlossaryTerm",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.header,{children:(0,i.jsx)(s.h1,{id:"la-g\xe9n\xe9ralisation-du-faible-vers-le-fort-w2sg",children:"La g\xe9n\xe9ralisation du faible vers le fort (W2SG)"})}),"\n",(0,i.jsx)(s.p,{children:"Historiquement, une grande partie du travail sur l'alignement de l'IA a \xe9t\xe9 hautement th\xe9orique, se concentrant sur les aspects fondamentaux du comportement des agents, l'alignement interne et les risques li\xe9s \xe0 l'optimisation apprise. M\xeame les techniques dont nous avons parl\xe9 dans les sections pr\xe9c\xe9dentes comme le d\xe9bat ou l'IDA sont souvent critiqu\xe9es comme \xe9tant des cadres plut\xf4t que des solutions pratiques, ou fonctionnant principalement sur des probl\xe8mes simples sans aborder le d\xe9fi central de l'alignement d'une IA superintelligente dans des sc\xe9narios r\xe9els. Donc m\xeame si nous ne pouvons conduire des exp\xe9riences de s\xe9curit\xe9 que sur les mod\xe8les actuels, comment pouvons-nous \xeatre s\xfbrs que ces techniques resteront efficaces lorsque les IA approcheront des capacit\xe9s surhumaines ?"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les mod\xe8les \xe9troitement surhumains permettent des \xe9tudes de cas de supervision \xe9volutive."})," Les mod\xe8les actuels sont suffisamment performants dans des t\xe2ches floues pour \xeatre meilleurs que les humains dans certains domaines, mais crucialement ils ne sont toujours pas meilleurs que tous les humains, ni suffisamment surhumains pour que nous ne puissions pas g\xe9n\xe9rer des \xe9tiquettes de v\xe9rit\xe9 terrain. Ces types de mod\xe8les sont parfois appel\xe9s \xe9troitement surhumains. Cette distinction entre \xe9troitement surhumain et surhumain est tr\xe8s importante. Comme exemple de cette diff\xe9rence, AlphaGo est surhumain dans le sens o\xf9 il a battu Lee Sedol le rendant meilleur que chaque humain vivant, alors que GPT-4 n'est capable d'\xe9crire des textes que mieux que certains humains, mais pas tous. Cela signifie que nous pouvons utiliser les IA \xe9troitement surhumaines comme \xe9tudes de cas ! Nous pouvons utiliser soit des experts soit les \xe9tiquettes de v\xe9rit\xe9 terrain auxquelles nous avons encore acc\xe8s, et voir si l'alignement augmente lorsque nous utilisons nos techniques de supervision \xe9volutive. (",(0,i.jsx)(s.a,{href:"https://www.alignmentforum.org/posts/PZtsoaoSLpKjjbMqM/the-case-for-aligning-narrowly-superhuman-models",children:"Cotra, 2021"}),")"]}),"\n",(0,i.jsx)(s.p,{children:"L'intuition fondamentale ici est de simuler des sc\xe9narios futurs o\xf9 l'humanit\xe9, \xe9quip\xe9e de divers outils et techniques, supervise les sorties de syst\xe8mes non fiables mais surhumains. Il existe diff\xe9rentes fa\xe7ons de mener des exp\xe9riences sur des mod\xe8les \xe9troitement surhumains. Nous pouvons utiliser des non-experts \xe9quip\xe9s de techniques de supervision \xe9volutive pour aligner les mod\xe8les d'IA. Une autre fa\xe7on est d'utiliser des mod\xe8les faibles (par exemple GPT-2) pour repr\xe9senter les humains, tandis que des mod\xe8les plus forts (par exemple GPT-4) repr\xe9sentent des syst\xe8mes d'IA plus capables que nous voulons aligner."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les mod\xe8les plus forts sont suppos\xe9s avoir des capacit\xe9s latentes."})," L'hypoth\xe8se est que les mod\xe8les plus forts, en raison de leur pr\xe9-entra\xeenement extensif sur des donn\xe9es diverses, ont d\xe9j\xe0 des repr\xe9sentations internes pour le type d'actions que nous voulons. Le r\xf4le de la supervision faible est de faire ressortir ce comportement \xe0 travers des signaux d'entra\xeenement."]}),"\n",(0,i.jsxs)(s.p,{children:['Comme exemple concret, imaginez utiliser GPT-4 pour obtenir des conseils m\xe9dicaux. Il a lu d\'innombrables articles de recherche et revues m\xe9dicales. Il poss\xe8de des repr\xe9sentations internes de nombreuses bonnes informations m\xe9dicales, le rendant th\xe9oriquement capable de donner des conseils m\xe9dicaux tr\xe8s comp\xe9tents. Mais les GPT sont initialement con\xe7us uniquement pour pr\xe9dire le mot suivant le plus probable, pas pour donner des conseils pr\xe9cis. Dans ce contexte, "aligner" le mod\xe8le signifie amener le mod\xe8le \xe0 donner des conseils m\xe9dicaux pr\xe9cis et utiles. Un type de technique que nous pouvons essayer est le ',(0,i.jsx)(n,{term:"fine-tuning",definition:'{"definition":"Processus consistant \xe0 prendre un mod\xe8le pr\xe9-entra\xeen\xe9 et \xe0 le perfectionner pour une t\xe2che ou un ensemble de donn\xe9es sp\xe9cifique..","source":"","aliases":["Fine-tuning","fine-tune","finetuning","finetune","affinage","Affinage"]}',children:(0,i.jsx)(n,{term:"fine-tuning",definition:'{"definition":"Processus consistant \xe0 prendre un mod\xe8le pr\xe9-entra\xeen\xe9 et \xe0 le perfectionner pour une t\xe2che ou un ensemble de donn\xe9es sp\xe9cifique..","source":"","aliases":["Fine-tuning","fine-tune","finetuning","finetune","affinage","Affinage"]}',children:"fine-tuning"})})," de GPT-4 sur des \xe9tiquettes g\xe9n\xe9r\xe9es par GPT-2. Ce n'est pas la seule fa\xe7on, il existe d'autres techniques que nous explorerons plus tard dans cette section. Pour l'instant, la chose la plus importante \xe0 comprendre est que nous op\xe9rons actuellement sous l'hypoth\xe8se que les mod\xe8les surhumains actuels et futurs auront probablement des repr\xe9sentations internes saillantes des comportements humains."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Qu'est-ce que la g\xe9n\xe9ralisation du faible vers le fort (W2SG) ?"})," La supervision faible implique l'entra\xeenement de mod\xe8les d'IA en utilisant des \xe9tiquettes ou des retours qui sont moins pr\xe9cis, moins d\xe9taill\xe9s ou plus bruit\xe9s que ceux fournis par des superviseurs tr\xe8s comp\xe9tents ou capables. Cela peut se produire lorsque les superviseurs (qu'ils soient humains ou des mod\xe8les plus faibles) ne sont pas experts dans la t\xe2che ou lorsque les donn\xe9es sont incompl\xe8tes ou contiennent des erreurs."]}),"\n",(0,i.jsx)(a.A,{src:"./img/T2j_Image_22.png",alt:"Entrer la description alternative de l'image",number:"22",label:"8.22",caption:"G\xe9n\xe9ralisation du faible au fort : Susciter des capacit\xe9s fortes avec une supervision faible ([Burns et. al. 2023](https://arxiv.org/abs/2312.09390))"}),"\n",(0,i.jsxs)(s.p,{children:["La g\xe9n\xe9ralisation du faible vers le fort (W2SG) se produit lorsqu'un mod\xe8le fort, entra\xeen\xe9 avec une supervision faible, parvient \xe0 surpasser son superviseur faible en exploitant ses connaissances et capacit\xe9s pr\xe9existantes. L'id\xe9e centrale est que le mod\xe8le fort poss\xe8de d\xe9j\xe0 les capacit\xe9s n\xe9cessaires pour le comportement d\xe9sir\xe9, et la supervision faible suscite ce comportement malgr\xe9 ses imperfections. Le processus de W2SG commence actuellement g\xe9n\xe9ralement par le ",(0,i.jsx)(n,{term:"fine-tuning",definition:'{"definition":"Processus consistant \xe0 prendre un mod\xe8le pr\xe9-entra\xeen\xe9 et \xe0 le perfectionner pour une t\xe2che ou un ensemble de donn\xe9es sp\xe9cifique..","source":"","aliases":["Fine-tuning","fine-tune","finetuning","finetune","affinage","Affinage"]}',children:(0,i.jsx)(n,{term:"fine-tuning",definition:'{"definition":"Processus consistant \xe0 prendre un mod\xe8le pr\xe9-entra\xeen\xe9 et \xe0 le perfectionner pour une t\xe2che ou un ensemble de donn\xe9es sp\xe9cifique..","source":"","aliases":["Fine-tuning","fine-tune","finetuning","finetune","affinage","Affinage"]}',children:"fine-tuning"})})," d'un grand mod\xe8le pr\xe9-entra\xeen\xe9 en utilisant une supervision faible de mod\xe8les plus petits. Bien que la supervision initiale puisse provenir de ces mod\xe8les moins capables, l'objectif final est de passer \xe0 une supervision humaine. L'objectif est de faire ressortir le plein potentiel du mod\xe8le fort comme s'il \xe9tait entra\xeen\xe9 sur une supervision parfaite de v\xe9rit\xe9 terrain. (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2312.09390",children:"Burns et. al. 2023"}),")"]}),"\n",(0,i.jsx)(s.p,{children:"Dans les exp\xe9riences actuelles, la configuration implique :"}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:'Un "superviseur faible" (un petit mod\xe8le de langage pr\xe9-entra\xeen\xe9) est fine-tun\xe9 sur une t\xe2che sp\xe9cifique, g\xe9n\xe9rant des pr\xe9dictions (\xe9tiquettes douces) sur un jeu de donn\xe9es mis de c\xf4t\xe9.'}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:'Un "\xe9tudiant fort" (un LM pr\xe9-entra\xeen\xe9 plus grand) est fine-tun\xe9 sur les pr\xe9dictions du mod\xe8le faible.'}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:'Un "plafond fort" (une autre copie du mod\xe8le plus grand) est fine-tun\xe9 directement sur les \xe9tiquettes de v\xe9rit\xe9 terrain pour comparaison de r\xe9f\xe9rence.'}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:["Le niveau de g\xe9n\xe9ralisation du faible vers le fort est quantifi\xe9 en utilisant l'\xc9cart de Performance R\xe9cup\xe9r\xe9 (PGR). Le PGR mesure combien de la diff\xe9rence de performance entre un superviseur faible et un mod\xe8le fort est combl\xe9e lorsque le mod\xe8le fort est entra\xeen\xe9 en utilisant une supervision faible. Lorsque nous entra\xeenons le mod\xe8le fort en utilisant les \xe9tiquettes fournies par le mod\xe8le faible, la performance du mod\xe8le fort sera probablement quelque part entre la performance du mod\xe8le faible et la performance id\xe9ale que le mod\xe8le fort pourrait atteindre avec des \xe9tiquettes parfaites. L'\xe9cart de performance r\xe9cup\xe9r\xe9 quantifie \xe0 quel point la performance du mod\xe8le fort se rapproche de sa performance id\xe9ale par rapport \xe0 la performance du mod\xe8le faible. Un PGR de 1 correspond \xe0 un r\xe9sultat id\xe9al (le mod\xe8le fort performe aussi bien qu'il l'aurait fait avec une supervision parfaite). En revanche, un \xe9tudiant fort qui \"r\xe9ussit\" \xe0 imiter parfaitement son superviseur, y compris ses d\xe9fauts, obtiendrait un PGR de 0. (",(0,i.jsx)(s.a,{href:"https://blog.eleuther.ai/weak-to-strong/",children:"Scherlis et. al. 2024"}),")"]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsxs)(s.span,{className:"katex",children:[(0,i.jsx)(s.span,{className:"katex-mathml",children:(0,i.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(s.semantics,{children:[(0,i.jsxs)(s.mrow,{children:[(0,i.jsx)(s.mi,{children:"P"}),(0,i.jsx)(s.mi,{children:"G"}),(0,i.jsx)(s.mi,{children:"R"}),(0,i.jsx)(s.mo,{children:"="}),(0,i.jsxs)(s.mfrac,{children:[(0,i.jsxs)(s.mrow,{children:[(0,i.jsx)(s.mtext,{children:"student"}),(0,i.jsx)(s.mo,{children:"\u2212"}),(0,i.jsx)(s.mtext,{children:"weak"})]}),(0,i.jsxs)(s.mrow,{children:[(0,i.jsx)(s.mtext,{children:"ceiling"}),(0,i.jsx)(s.mo,{children:"\u2212"}),(0,i.jsx)(s.mtext,{children:"weak"})]})]})]}),(0,i.jsx)(s.annotation,{encoding:"application/x-tex",children:"PGR = \\frac{\\text{student} - \\text{weak}}{\\text{ceiling} - \\text{weak}}"})]})})}),(0,i.jsxs)(s.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(s.span,{className:"base",children:[(0,i.jsx)(s.span,{className:"strut",style:{height:"0.6833em"}}),(0,i.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.00773em"},children:"PGR"}),(0,i.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(s.span,{className:"mrel",children:"="}),(0,i.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(s.span,{className:"base",children:[(0,i.jsx)(s.span,{className:"strut",style:{height:"1.3612em",verticalAlign:"-0.4811em"}}),(0,i.jsxs)(s.span,{className:"mord",children:[(0,i.jsx)(s.span,{className:"mopen nulldelimiter"}),(0,i.jsx)(s.span,{className:"mfrac",children:(0,i.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,i.jsxs)(s.span,{className:"vlist-r",children:[(0,i.jsxs)(s.span,{className:"vlist",style:{height:"0.8801em"},children:[(0,i.jsxs)(s.span,{style:{top:"-2.655em"},children:[(0,i.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,i.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,i.jsxs)(s.span,{className:"mord mtight",children:[(0,i.jsx)(s.span,{className:"mord text mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:"ceiling"})}),(0,i.jsx)(s.span,{className:"mbin mtight",children:"\u2212"}),(0,i.jsx)(s.span,{className:"mord text mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:"weak"})})]})})]}),(0,i.jsxs)(s.span,{style:{top:"-3.23em"},children:[(0,i.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,i.jsx)(s.span,{className:"frac-line",style:{borderBottomWidth:"0.04em"}})]}),(0,i.jsxs)(s.span,{style:{top:"-3.394em"},children:[(0,i.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,i.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,i.jsxs)(s.span,{className:"mord mtight",children:[(0,i.jsx)(s.span,{className:"mord text mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:"student"})}),(0,i.jsx)(s.span,{className:"mbin mtight",children:"\u2212"}),(0,i.jsx)(s.span,{className:"mord text mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:"weak"})})]})})]})]}),(0,i.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,i.jsx)(s.span,{className:"vlist-r",children:(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.4811em"},children:(0,i.jsx)(s.span,{})})})]})}),(0,i.jsx)(s.span,{className:"mclose nulldelimiter"})]})]})]})]})}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Limitations et d\xe9sanalogies du W2SG :"})," - ",(0,i.jsx)(s.strong,{children:"Surapprentissage de la supervision faible :"})," L'hypoth\xe8se qu'un mod\xe8le fort g\xe9n\xe9ralisera bien \xe0 partir d'une supervision faible n'est pas garantie. Les mod\xe8les surhumains pourraient facilement imiter les erreurs faibles. Ces mod\xe8les seront probablement tr\xe8s comp\xe9tents pour pr\xe9dire ce que les humains penseront et diront, particuli\xe8rement s'ils sont entra\xeen\xe9s sur des donn\xe9es humaines. Par cons\xe9quent, si nous entra\xeenons na\xefvement un tel mod\xe8le surhumain avec une supervision humaine, il pourrait simplement imiter le superviseur faible, produisant des capacit\xe9s de niveau humain plut\xf4t que ses capacit\xe9s surhumaines latentes. Les chercheurs utilisent \xe9galement des pertes de confiance auxiliaires, qui encouragent le mod\xe8le fort \xe0 faire des pr\xe9dictions confiantes m\xeame en contradiction avec la supervision faible, favorisant la g\xe9n\xe9ralisation et corrigeant les erreurs du superviseur faible."]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Hypoth\xe8ses sur les repr\xe9sentations des t\xe2ches."})," Le W2SG suppose que les mod\xe8les forts ont des repr\xe9sentations saillantes des t\xe2ches sur lesquelles ils sont entra\xeen\xe9s. Cela signifie que les mod\xe8les poss\xe8dent d\xe9j\xe0 une certaine compr\xe9hension de ces t\xe2ches depuis leur phase de pr\xe9-entra\xeenement. Cependant, cette hypoth\xe8se peut ne pas \xeatre vraie pour des t\xe2ches nouvelles ou tr\xe8s complexes. Si une t\xe2che est enti\xe8rement nouvelle ou significativement plus complexe que ce que le mod\xe8le a rencontr\xe9 pendant le pr\xe9-entra\xeenement, le mod\xe8le pourrait ne pas avoir les capacit\xe9s latentes n\xe9cessaires pour bien performer m\xeame avec une supervision faible."]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"Les exp\xe9riences sur le W2SG jusqu'\xe0 pr\xe9sent ont peut-\xeatre \xe9t\xe9 observ\xe9es dans le pr\xe9-entra\xeenement, au moins indirectement. En utilisant l'exemple pr\xe9c\xe9dent, les donn\xe9es m\xe9dicales ou les questions et r\xe9ponses directes sur la pratique m\xe9dicale sont pr\xe9sentes sous une forme ou une autre dans le jeu de donn\xe9es de pr\xe9-entra\xeenement de GPT-4. Cependant, les futurs mod\xe8les surhumains pourraient ne jamais observer directement des capacit\xe9s surhumaines pertinentes pour l'alignement. Ce qui signifie que ces types de capacit\xe9s pourraient \xeatre plus difficiles \xe0 susciter que les capacit\xe9s que les mod\xe8les auraient pu observer dans leurs donn\xe9es de pr\xe9-entra\xeenement. Cette d\xe9sanalogie pourrait rendre les r\xe9sultats actuels sur le W2SG trop optimistes."}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Hypoth\xe8se de d\xe9collage lent :"})," Le W2SG repose \xe9galement sur l'hypoth\xe8se d'un d\xe9collage progressif des capacit\xe9s de l'IA. Cette progression graduelle donne aux chercheurs suffisamment de temps pour utiliser des mod\xe8les mod\xe9r\xe9ment surhumains pour r\xe9soudre les probl\xe8mes d'alignement de mani\xe8re it\xe9rative avant qu'il ne soit trop tard. La fen\xeatre d'opportunit\xe9 fournie par un d\xe9collage graduel est cruciale pour affiner et tester les techniques d'alignement."]}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Le W2SG peut \xeatre vu comme un compl\xe9ment aux techniques de supervision \xe9volutive."})," Le W2SG n'est pas une solution compl\xe8te. M\xeame si un mod\xe8le g\xe9n\xe9ralise dans la direction souhait\xe9e, cela doit \xeatre v\xe9rifi\xe9, n\xe9cessitant un signal de v\xe9rit\xe9 terrain plus fiable que la supervision humaine na\xefve. En int\xe9grant le W2SG avec la supervision \xe9volutive, nous pouvons d\xe9velopper des m\xe9thodes plus robustes pour aligner l'IA avec les valeurs humaines, nous pr\xe9parant aux d\xe9fis pos\xe9s par les futurs syst\xe8mes superintelligents."]}),"\n",(0,i.jsxs)(s.p,{children:["Par exemple, les techniques de supervision \xe9volutive pourraient \xeatre utilis\xe9es pour g\xe9n\xe9rer des signaux de supervision faibles qu'un mod\xe8le fort apprendra ensuite \xe0 g\xe9n\xe9raliser. En combinant ces approches, nous pouvons cr\xe9er des protocoles plus robustes pour l'alignement de l'IA. Par exemple, la mod\xe9lisation r\xe9cursive des r\xe9compenses (RRM) peut utiliser le W2SG pour entra\xeener des mod\xe8les de r\xe9compense puissants avec des annotations de pr\xe9f\xe9rences humaines. Le d\xe9bat combin\xe9 avec le W2SG peut entra\xeener des mod\xe8les \xe0 g\xe9n\xe9raliser les jugements humains \xe0 de nouveaux d\xe9bats. La d\xe9composition des t\xe2ches combin\xe9e avec le W2SG peut superviser des t\xe2ches atomiques avec un mod\xe8le de r\xe9compense entra\xeen\xe9 \xe0 partir des pr\xe9f\xe9rences humaines. (",(0,i.jsx)(s.a,{href:"https://substack.com/home/post/p-139945470",children:"Leike, 2023"}),")"]}),"\n",(0,i.jsx)(s.p,{children:"L'\xe9valuation de ces techniques dans diff\xe9rents contextes aide \xe0 comprendre leurs forces et faiblesses. Dans les contextes sans manipulation, o\xf9 les mod\xe8les ne sont pas align\xe9s de mani\xe8re trompeuse, les techniques classiques de faible \xe0 fort et la supervision \xe9volutive peuvent \xeatre directement compar\xe9es. Dans les contextes avec manipulation, o\xf9 les mod\xe8les pourraient agir de mani\xe8re adversariale, les \xe9valuations doivent prendre en compte la tromperie potentielle, fournissant une mesure conservatrice de la robustesse d'un protocole. Lorsqu'il n'y a pas de manipulation (alignement trompeur), nous pouvons utiliser les techniques W2G de mani\xe8re directe \xe0 travers des techniques comme le sandwiching. Cependant, si nous avons de la manipulation (IA align\xe9e de mani\xe8re trompeuse), elle pourrait agir de mani\xe8re adversariale. Dans ce cas, nous pouvons utiliser des propositions comme les techniques adversariales au niveau m\xe9ta. Ces deux aspects sont ce que nous discutons dans les sections suivantes."}),"\n",(0,i.jsx)(s.h2,{id:"01",children:"\xc9valuation en sandwich"}),"\n",(0,i.jsx)(s.p,{children:'Le sandwich est une configuration exp\xe9rimentale qui utilise des mod\xe8les l\xe9g\xe8rement surhumains pour \xe9valuer l\'efficacit\xe9 de nos techniques de supervision dans des contextes contr\xf4l\xe9s. La configuration en sandwich comprend trois "couches" principales :'}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Couche non-expert :"})," \xc0 la base, nous avons les non-experts. Ce sont des personnes qui ne pourraient pas r\xe9soudre la t\xe2che donn\xe9e de mani\xe8re autonome. Par exemple, pensez \xe0 des profanes \xe0 qui l'on demande de choisir des actions en bourse ou de poser des diagnostics m\xe9dicaux. Ils repr\xe9sentent une version future de l'humanit\xe9. Ils doivent utiliser les techniques de supervision \xe9volutives pour orienter le comportement de l'IA dans une direction plus align\xe9e."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Mod\xe8le d'IA :"})," Au milieu, nous avons le mod\xe8le d'IA l\xe9g\xe8rement surhumain sur lequel nous voulons tester la technique de supervision. Ce mod\xe8le poss\xe8de certaines capacit\xe9s que nous ne pouvons pas faire ressortir. Le non-expert devrait \xeatre capable d'\"aligner\" le mod\xe8le en l'amenant \xe0 afficher le type de comportement souhait\xe9 en utilisant la technique de supervision \xe9volutive donn\xe9e."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Couche expert :"})," Au sommet, nous avons des experts du domaine qui \xe9valuent le succ\xe8s de la tentative d'alignement. Ils servent de r\xe9f\xe9rence, fournissant des retours sans interagir directement avec les non-experts ou l'IA pendant le processus. Nous pouvons \xe9galement utiliser des \xe9tiquettes de v\xe9rit\xe9 terrain issues des jeux de donn\xe9es comme substituts \xe0 la couche expert plut\xf4t que d'embaucher de v\xe9ritables experts."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(a.A,{src:"./img/eBc_Image_23.png",alt:"Entrer la description alternative de l'image",number:"23",label:"8.23",caption:"([Bowman et al., 2022](https://arxiv.org/abs/2211.03540))"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"D\xe9monstration empirique du sandwich."})," Les chercheurs ont men\xe9 une exp\xe9rience avec des non-experts charg\xe9s de r\xe9pondre \xe0 des questions \xe0 choix multiples. La t\xe2che consistait \xe0 r\xe9pondre \xe0 des questions \xe0 choix multiples du r\xe9f\xe9rentiel Measuring Massive Multitask Language Understanding (MMLU). Ce r\xe9f\xe9rentiel contient des centaines de questions sur les math\xe9matiques, la physique, la moralit\xe9, l'\xe9thique et divers sujets. (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2009.03300",children:"Hendrycks et. al, 2021"}),") Ils devaient \xe9galement r\xe9pondre \xe0 des questions bas\xe9es sur des nouvelles courtes du r\xe9f\xe9rentiel QuALITY en 5 minutes. (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2112.08608",children:"Pang et al., 2021"}),") La technique de supervision \xe9volutive qui leur a \xe9t\xe9 donn\xe9e \xe9tait une simple amplification utilisant un chatbot assistant IA. La performance a \xe9t\xe9 mesur\xe9e en utilisant les \xe9tiquettes de v\xe9rit\xe9 terrain des r\xe9ponses correctes du jeu de donn\xe9es."]}),"\n",(0,i.jsxs)(s.p,{children:["Lorsqu'ils sont mesur\xe9s individuellement, le mod\xe8le a surpass\xe9 les humains non assist\xe9s sur les deux t\xe2ches avec une large marge. Cela signifie que la condition de base pour tester le sandwich \xe9tait remplie - le mod\xe8le \xe9tant meilleur que les non-experts. Au cours de l'exp\xe9rience, les humains assist\xe9s par le chatbot ont obtenu des scores substantiellement meilleurs sur les t\xe2ches que les humains ou les mod\xe8les seuls. (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2211.03540",children:"Bowman et al., 2022"}),") M\xeame si cette conception \xe9tait extr\xeamement simplifi\xe9e, les participants ont r\xe9ussi \xe0 orienter le comportement du mod\xe8le dans la direction souhait\xe9e, c'est-\xe0-dire \xe0 rendre le mod\xe8le plus \"align\xe9\". Les chercheurs ont donc r\xe9ussi \xe0 d\xe9montrer efficacement le sandwich comme conception exp\xe9rimentale. En s'appuyant sur cette base, les exp\xe9riences futures pourront \xe9valuer l'efficacit\xe9 de m\xe9thodes de supervision \xe9volutives plus complexes comme le r\xe9-entra\xeenement, l'ajustement fin ou le d\xe9bat."]})]})}function p(e={}){const{wrapper:s}={...(0,r.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}}}]);