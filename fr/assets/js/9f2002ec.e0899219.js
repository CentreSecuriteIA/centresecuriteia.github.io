"use strict";(self.webpackChunkatlas=self.webpackChunkatlas||[]).push([[9710],{3719:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>m,contentTitle:()=>d,default:()=>x,frontMatter:()=>u,metadata:()=>t,toc:()=>p});const t=JSON.parse('{"id":"chapters/09/2","title":"M\xe9thodes d\'observation","description":"Visualisation des caract\xe9ristiques","source":"@site/i18n/fr/docusaurus-plugin-content-docs/current/chapters/09/02.md","sourceDirName":"chapters/09","slug":"/chapters/09/02","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/09/02","draft":false,"unlisted":false,"editUrl":"https://github.com/markov-root/atlas/edit/main/docs/chapters/09/02.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"2","title":"M\xe9thodes d\'observation","sidebar_label":"9.2 M\xe9thodes d\'observation","sidebar_position":3,"slug":"/chapters/09/02","reading_time_core":"17 min","reading_time_optional":"17 min","pagination_prev":"chapters/09/1","pagination_next":"chapters/09/3"},"sidebar":"docs","previous":{"title":"9.1 Qu\'est-ce que l\'Interpr\xe9tabilit\xe9 ?","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/09/01"},"next":{"title":"9.3 M\xe9thodes d\'intervention","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/09/03"}}');var i=n(4848),r=n(8453),a=n(4768),o=(n(2482),n(8559)),l=n(9585),c=n(2501);const u={id:2,title:"M\xe9thodes d'observation",sidebar_label:"9.2 M\xe9thodes d'observation",sidebar_position:3,slug:"/chapters/09/02",reading_time_core:"17 min",reading_time_optional:"17 min",pagination_prev:"chapters/09/1",pagination_next:"chapters/09/3"},d="M\xe9thodes d'observation",m={},p=[{value:"Visualisation des caract\xe9ristiques",id:"01",level:2},{value:"Circuits",id:"01-01",level:3},{value:"Neurones Polys\xe9mantiques",id:"01-02",level:3},{value:"Logit Lens",id:"02",level:2},{value:"Sondage des classificateurs",id:"03",level:2},{value:"Superposition",id:"04",level:2},{value:"Auto-encodeurs parcimonieux",id:"05",level:2}];function h(e){const s={a:"a",annotation:"annotation",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",math:"math",mi:"mi",mo:"mo",mrow:"mrow",msub:"msub",mtext:"mtext",ol:"ol",p:"p",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,r.R)(),...e.components},{GlossaryTerm:n}=s;return n||function(e,s){throw new Error("Expected "+(s?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("GlossaryTerm",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.header,{children:(0,i.jsx)(s.h1,{id:"m\xe9thodes-dobservation",children:"M\xe9thodes d'observation"})}),"\n",(0,i.jsx)(s.h2,{id:"01",children:"Visualisation des caract\xe9ristiques"}),"\n",(0,i.jsx)(s.p,{children:"La visualisation des caract\xe9ristiques est l'une des premi\xe8res m\xe9thodes d'observation en interpr\xe9tabilit\xe9 m\xe9caniste. Elle permet aux chercheurs d'explorer les caract\xe9ristiques qu'un mod\xe8le de vision apprend et utilise \xe0 diff\xe9rentes couches. Dans cette section, nous expliquerons en d\xe9tail ce qu'est la visualisation des caract\xe9ristiques et les d\xe9couvertes qu'elle a permises."}),"\n",(0,i.jsx)(l.A,{term:"Fonctionnalit\xe9",source:"",number:"1",label:"9.1",children:(0,i.jsx)(s.p,{children:"Une caract\xe9ristique fait r\xe9f\xe9rence \xe0 un motif ou une particularit\xe9 sp\xe9cifique que le r\xe9seau apprend \xe0 d\xe9tecter. Ces caract\xe9ristiques sont les unit\xe9s fondamentales que les mod\xe8les utilisent pour traiter l'information et prendre des d\xe9cisions."})}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Qu'est-ce qu'une caract\xe9ristique ?"})," Une caract\xe9ristique est un motif des donn\xe9es d'entr\xe9e que le r\xe9seau apprend \xe0 d\xe9tecter. Les mod\xe8les ont des caract\xe9ristiques car elles aident \xe0 d\xe9composer des entr\xe9es complexes, comme des images ou du texte, en composants interpr\xe9tables que le mod\xe8le peut utiliser pour faire des pr\xe9dictions."]}),"\n",(0,i.jsxs)(s.p,{children:["Les mod\xe8les de vision entra\xeen\xe9s pour la classification d'images poss\xe8dent g\xe9n\xe9ralement des caract\xe9ristiques correspondant aux chats, chiens, voitures, yeux, fruits, etc. Les caract\xe9ristiques des mod\xe8les de vision varient en complexit\xe9 selon la couche dans laquelle elles apparaissent. Dans les premi\xe8res couches, les caract\xe9ristiques repr\xe9sentent g\xe9n\xe9ralement des motifs simples et de bas niveau comme les bords, les couleurs ou les textures dans un mod\xe8le de vision. En progressant vers les couches plus profondes, les caract\xe9ristiques deviennent plus abstraites et complexes, repr\xe9sentant des concepts de plus haut niveau comme des formes, des objets, ou m\xeame des entit\xe9s sp\xe9cifiques comme des visages ou des animaux. Cette ",(0,i.jsx)(s.em,{children:"structure hi\xe9rarchique des caract\xe9ristiques"})," permet aux mod\xe8les de traiter progressivement les donn\xe9es brutes de pixels en concepts de plus haut niveau pour finalement classifier l'image. Par exemple, la reconnaissance d'une voiture commencerait par la d\xe9tection des bords (caract\xe9ristiques de bas niveau), puis des formes sp\xe9cifiques (comme les roues), et finalement la voiture enti\xe8re (caract\xe9ristique de haut niveau)."]}),"\n",(0,i.jsxs)(s.p,{children:["Dans les mod\xe8les de transformers, les chercheurs ont identifi\xe9 des caract\xe9ristiques correspondant \xe0 des concepts sp\xe9cifiques comme les s\xe9quences d'ADN, le langage juridique, les requ\xeates HTTP, ou le texte en h\xe9breu. Par exemple, lorsqu'un ",(0,i.jsx)(n,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:(0,i.jsx)(n,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:"transformer"})}),' rencontre une s\xe9quence d\'ADN, les neurones codant la "caract\xe9ristique ADN" s\'activent fortement en r\xe9ponse. De m\xeame, face \xe0 une phrase comme "Le tribunal a statu\xe9 en faveur du d\xe9fendeur car...", les caract\xe9ristiques li\xe9es au langage juridique et aux structures de phrases courantes dans les contextes juridiques peuvent s\'activer, aidant le mod\xe8le \xe0 pr\xe9dire une suite impliquant un raisonnement ou une justification, comme "...les preuves pr\xe9sent\xe9es \xe9taient insuffisantes." Ces caract\xe9ristiques sont des \xe9l\xe9ments essentiels que les mod\xe8les utilisent pour donner un sens aux donn\xe9es d\'entr\xe9e et faire des pr\xe9dictions.']}),"\n",(0,i.jsx)(l.A,{term:"Visualisation des caract\xe9ristiques",source:"",number:"2",label:"9.2",children:(0,i.jsx)(s.p,{children:"La visualisation des caract\xe9ristiques est une m\xe9thode qui permet d'identifier les caract\xe9ristiques apprises par un CNN, ce qui peut nous aider \xe0 comprendre comment il traite l'information et prend des d\xe9cisions."})}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Qu'est-ce que la visualisation des caract\xe9ristiques ?"})," C'est une technique qui nous aide \xe0 \xe9tudier les repr\xe9sentations internes des R\xe9seaux de Neurones Convolutifs (CNN), et \xe0 observer les motifs qu'un mod\xe8le a appris \xe0 reconna\xeetre. Elle g\xe9n\xe8re des images qui maximisent l'activation de neurones sp\xe9cifiques, de cartes de caract\xe9ristiques (sorties d'une couche convolutive), ou m\xeame de couches enti\xe8res dans un mod\xe8le (",(0,i.jsx)(s.a,{href:"https://distill.pub/2020/circuits/",children:"Cammarata et al., 2020"}),")."]}),"\n",(0,i.jsx)(c.A,{src:"./img/p54_Image_3.png",alt:"Entrer la description alternative de l'image",number:"3",label:"9.3",caption:"Exemples de visualisations de caract\xe9ristiques. Il semble que le r\xe9seau a appris \xe0 repr\xe9senter et \xe0 d\xe9tecter des balles de baseball, des visages d'animaux, des nuages et des b\xe2timents, mais les visualisations de caract\xe9ristiques doivent \xeatre interpr\xe9t\xe9es et peuvent ne pas d\xe9tecter ce que nous pensons initialement. D'apr\xe8s ([Olah et al., 2017](https://distill.pub/2017/feature-visualization/))."}),"\n",(0,i.jsxs)(s.p,{children:["Les premi\xe8res recherches en neurosciences visaient \xe0 comprendre le cerveau en identifiant quelles images excitaient fortement des neurones sp\xe9cifiques. Cela a aid\xe9 les neuroscientifiques \xe0 d\xe9couvrir des zones du cerveau d\xe9di\xe9es \xe0 l'identification des visages, du mouvement, des sc\xe8nes naturelles, etc. La visualisation des caract\xe9ristiques peut \xeatre consid\xe9r\xe9e comme une approche quelque peu similaire appliqu\xe9e aux CNN (",(0,i.jsx)(s.a,{href:"https://distill.pub/2017/feature-visualization/",children:"Olah et al., 2017"}),")."]}),"\n",(0,i.jsx)(s.p,{children:"Ces caract\xe9ristiques apprises - qu'il s'agisse de motifs simples comme les bords ou d'objets complexes - forment les \xe9l\xe9ments de base qui permettent aux mod\xe8les de comprendre et de traiter les donn\xe9es d'entr\xe9e. Cependant, les caract\xe9ristiques ne fonctionnent pas isol\xe9ment. Lorsque le r\xe9seau traite l'information, les caract\xe9ristiques interagissent et se combinent de mani\xe8re structur\xe9e, formant souvent des unit\xe9s plus complexes appel\xe9es circuits. Un circuit est un groupe de caract\xe9ristiques interconnect\xe9es qui travaillent ensemble pour ex\xe9cuter une fonction sp\xe9cifique."}),"\n",(0,i.jsx)(s.p,{children:"Par exemple, voici un circuit qui reconna\xeet une voiture dans les couches interm\xe9diaires d'un CNN. Ce circuit combine des caract\xe9ristiques de bas niveau comme les fen\xeatres, les carrosseries et les roues pour d\xe9tecter la pr\xe9sence d'une voiture dans une image. Le circuit permet au mod\xe8le de reconna\xeetre l'objet entier, m\xeame si aucune caract\xe9ristique isol\xe9e ne peut le faire."}),"\n",(0,i.jsx)(c.A,{src:"./img/S5x_Image_4.png",alt:"Description alternative de l'image",number:"4",label:"9.4",caption:"Un circuit de voiture dans un CNN. \xc0 gauche, trois cartes de caract\xe9ristiques de la couche 4b sont repr\xe9sent\xe9es par leurs visualisations de caract\xe9ristiques. Une carte semble d\xe9tecter les fen\xeatres, une autre les carrosseries, et la troisi\xe8me les roues. Ces trois cartes de caract\xe9ristiques sont connect\xe9es \xe0 une carte de caract\xe9ristiques dans la couche 4c, repr\xe9sent\xe9e par la visualisation \xe0 droite, \xe0 travers les noyaux de convolution montr\xe9s au milieu. Les caract\xe9ristiques de fen\xeatre, de carrosserie et de roue sont assembl\xe9es pour former un circuit complet de d\xe9tection de voiture. D'apr\xe8s ([Olah et al., 2020](https://distill.pub/2020/circuits/early-vision/))."}),"\n",(0,i.jsx)(l.A,{term:"Carte de caract\xe9ristiques",source:"",number:"3",label:"9.3",children:(0,i.jsx)(s.p,{children:"Une carte de caract\xe9ristiques dans un CNN est la sortie d'une couche convolutive. Elle est aussi appel\xe9e canal. La visualisation des caract\xe9ristiques est souvent appliqu\xe9e \xe0 l'\xe9chelle des cartes de caract\xe9ristiques - plut\xf4t qu'aux neurones individuels ou aux couches enti\xe8res - pour comprendre quelles caract\xe9ristiques elles encodent."})}),"\n",(0,i.jsx)(c.A,{src:"./img/Kmp_Image_5.png",alt:"Entrer la description alternative de l'image",number:"5",label:"9.5",caption:"Quelques exemples de visualisations de caract\xe9ristiques sur un CNN entra\xeen\xe9 pour la classification d'images. Chaque image correspond \xe0 une carte de caract\xe9ristiques. Certaines cartes de caract\xe9ristiques sont sensibles aux motifs avec des bords, d'autres sont sensibles \xe0 diff\xe9rents types de motifs textur\xe9s, ou \xe0 des objets comme des yeux, des visages de chiens, ou des jambes. D'apr\xe8s ([Olah et al., 2017](https://distill.pub/2017/feature-visualization/))."}),"\n",(0,i.jsxs)(o.A,{title:"\xc9tapes de g\xe9n\xe9ration des visualisations de caract\xe9ristiques",collapsed:!0,children:[(0,i.jsx)(c.A,{src:"./img/ucL_Image_6.png",alt:"Entrer la description alternative de l'image",number:"6",label:"9.6",caption:"Aper\xe7u du processus de visualisation des caract\xe9ristiques. \xc0 partir d'un neurone (ou d'un ensemble de neurones) dans un CNN, la visualisation des caract\xe9ristiques g\xe9n\xe8re une image qui l'active fortement, en partant d'une image al\xe9atoire, et \xe0 travers des \xe9tapes successives d'optimisation. L'image optimis\xe9e illustre \xe0 quel type de motif l'une des cartes de caract\xe9ristiques de la quatri\xe8me couche d'InceptionV1 est sensible ([Olah et al., 2017](https://distill.pub/2017/feature-visualization/))."}),(0,i.jsx)(s.p,{children:"La g\xe9n\xe9ration d'une visualisation de caract\xe9ristiques implique :"}),(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"S\xe9lectionner une cible : Choisir un neurone, une carte de caract\xe9ristiques ou une couche \xe0 visualiser. La plupart des visualisations de caract\xe9ristiques sont effectu\xe9es sur des cartes de caract\xe9ristiques."}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Commencer avec une image al\xe9atoire : D\xe9buter l'optimisation \xe0 partir d'une image de bruit al\xe9atoire. Elle sera ajust\xe9e pour maximiser l'activation du neurone ou du filtre cible."}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Calculer le gradient. L'objectif est de mettre \xe0 jour l'image de mani\xe8re \xe0 maximiser l'activation du neurone/de la carte de caract\xe9ristiques : Utiliser la r\xe9tropropagation pour calculer comment modifier l'image pour augmenter l'activation de la cible."}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Optimiser l'image : Appliquer la mont\xe9e de gradient de mani\xe8re it\xe9rative pour ajuster l'image."}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"R\xe9p\xe9ter les \xe9tapes de mont\xe9e de gradient : Ajuster l\xe9g\xe8rement l'image \xe0 chaque fois pour mieux activer le neurone/la carte de caract\xe9ristiques."}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Visualiser le r\xe9sultat : L'image finale r\xe9v\xe8le les motifs ou les structures que la cible a appris \xe0 d\xe9tecter."}),"\n"]}),"\n"]}),(0,i.jsx)(c.A,{src:"./img/OQ6_Image_7.png",alt:"Entrer la description alternative de l'image",number:"7",label:"9.7",caption:"Des visualisations de caract\xe9ristiques peuvent \xeatre produites pour des neurones individuels ou des groupes de neurones, comme une carte de caract\xe9ristiques, ou m\xeame une couche enti\xe8re. D'apr\xe8s ([Olah et al., 2017](https://distill.pub/2017/feature-visualization/))."})]}),"\n",(0,i.jsx)(s.h3,{id:"01-01",children:"Circuits"}),"\n",(0,i.jsx)(l.A,{term:"Circuit",source:"",number:"4",label:"9.4",children:(0,i.jsx)(s.p,{children:"Un circuit est un groupe de caract\xe9ristiques interconnect\xe9es qui fonctionnent ensemble pour ex\xe9cuter une fonction sp\xe9cifique. Les circuits sont essentiellement des caract\xe9ristiques d'ordre sup\xe9rieur, qui sont compos\xe9es de mani\xe8re r\xe9cursive de caract\xe9ristiques d'ordre inf\xe9rieur. La notion de circuit s'applique \xe0 toute architecture de mod\xe8le, y compris les LLM. L'identification des circuits qui ex\xe9cutent des fonctions sp\xe9cifiques dans les mod\xe8les est un domaine de recherche en interpr\xe9tabilit\xe9 m\xe9caniste."})}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Chaque couche dans un CNN extrait progressivement des caract\xe9ristiques de plus en plus complexes de l'image."})," Les neurones des premi\xe8res couches r\xe9agissent \xe0 des motifs rudimentaires et abstraits tels que des courbes, des angles et des petites formes (similaires aux premi\xe8res couches du cortex visuel humain !). \xc0 mesure que nous progressons plus profond\xe9ment dans le r\xe9seau, les neurones d\xe9tectent des objets plus complexes et sp\xe9cifiques, comme des yeux, des animaux, des voitures, etc (",(0,i.jsx)(s.a,{href:"https://distill.pub/2020/circuits/zoom-in/",children:"Olah et al., 2020"}),'). Il est int\xe9ressant de noter que certaines de ces "familles de neurones" se r\xe9p\xe8tent dans diff\xe9rentes architectures de mod\xe8les et conditions d\'entra\xeenement (',(0,i.jsx)(s.a,{href:"https://distill.pub/2020/circuits/early-vision/",children:"Olah et al., 2020"}),")."]}),"\n",(0,i.jsx)(c.A,{src:"./img/jiL_Image_8.png",alt:"Entrer la description alternative de l'image",number:"8",label:"9.8",caption:"Les d\xe9tecteurs de courbes sont universellement pr\xe9sents dans les premi\xe8res couches des CNN, ils existent dans diff\xe9rentes orientations et couleurs et couvrent collectivement toutes les orientations. Chaque d\xe9tecteur de courbes r\xe9pond \xe0 une grande vari\xe9t\xe9 de courbes, dans diff\xe9rentes orientations. D'apr\xe8s ([Olah et al., 2020](https://distill.pub/2020/circuits/zoom-in/))."}),"\n",(0,i.jsxs)(s.p,{children:["Les CNN apprennent aussi couramment des ",(0,i.jsx)(s.strong,{children:"d\xe9tecteurs de fr\xe9quences hautes-basses"})," dans leurs premi\xe8res couches."]}),"\n",(0,i.jsx)(c.A,{src:"./img/soI_Image_9.png",alt:"Entrer la description alternative de l'image",number:"9",label:"9.9",caption:"Les d\xe9tecteurs de fr\xe9quences hautes-basses recherchent des motifs de basse fr\xe9quence d'un c\xf4t\xe9 de leur champ r\xe9ceptif, et des motifs de haute fr\xe9quence de l'autre c\xf4t\xe9. Ils existent dans diff\xe9rentes orientations et couleurs. D'apr\xe8s ([Olah et al., 2020](https://distill.pub/2020/circuits/early-vision/))."}),"\n",(0,i.jsxs)(s.p,{children:["Les d\xe9tecteurs de fr\xe9quences hautes-basses s'assemblent dans les couches plus profondes pour former des ",(0,i.jsx)(s.strong,{children:"d\xe9tecteurs de contours."})," ",(0,i.jsx)(c.A,{src:"./img/iGO_Image_10.png",alt:"Entrer la description alternative de l'image",number:"10",label:"9.10",caption:"Un neurone d\xe9tecteur de contours form\xe9 dans la troisi\xe8me couche d'un CNN (montr\xe9 en bas \xe0 gauche avec sa visualisation de caract\xe9ristiques). La rang\xe9e sup\xe9rieure montre les visualisations de caract\xe9ristiques des neurones de la deuxi\xe8me couche et les noyaux les reliant \xe0 la troisi\xe8me couche. Les nouveaux neurones se forment en combinant les signaux de neurones plus \xe9l\xe9mentaires des couches pr\xe9c\xe9dentes : ici, le neurone d\xe9tecteur de contours se forme en combinant des neurones d\xe9tecteurs de haute-basse fr\xe9quence, avec des neurones d\xe9tecteurs de bords, des neurones d\xe9tecteurs de contraste de couleur, etc. D'apr\xe8s ([Olah et al., 2020](https://distill.pub/2020/circuits/early-vision/))."})]}),"\n",(0,i.jsx)(s.h3,{id:"01-02",children:"Neurones Polys\xe9mantiques"}),"\n",(0,i.jsx)(s.p,{children:"Bien que la visualisation des caract\xe9ristiques ait permis une compr\xe9hension plus approfondie de la fa\xe7on dont les CNN repr\xe9sentent l'information, elle a \xe9galement mis en \xe9vidence des d\xe9fis comme la polys\xe9mantique. Un ph\xe9nom\xe8ne intriguant se produit lorsque nous observons les neurones qui suivent le d\xe9tecteur de voitures et qui y sont fortement connect\xe9s. Certains de ces neurones r\xe9pondent non seulement aux images de voitures mais aussi \xe0 des stimuli sans rapport, comme des images de chiens. Cela indique que la \"caract\xe9ristique voiture\" est r\xe9partie entre plusieurs neurones qui r\xe9pondent \xe0 des entr\xe9es apparemment sans rapport. Ce sont ce qu'on appelle des neurones polys\xe9mantiques \u2014 des neurones qui s'activent en r\xe9ponse \xe0 diverses caract\xe9ristiques distinctes. En revanche, les neurones monos\xe9mantiques ne r\xe9pondent qu'\xe0 une seule caract\xe9ristique ou stimulus sp\xe9cifique."}),"\n",(0,i.jsx)(c.A,{src:"./img/kjD_Image_11.png",alt:"Entrer la description alternative de l'image",number:"11",label:"9.11",caption:"\xc0 gauche se trouve le circuit de d\xe9tection de voiture de la figure pr\xe9c\xe9dente. Apr\xe8s la formation de concepts distincts, ils s'enchev\xeatrent dans des neurones polys\xe9mantiques, comme un neurone qui r\xe9pond \xe0 la fois aux images de voitures et de chiens. D'apr\xe8s ([Olah et al., 2020](https://distill.pub/2020/circuits/early-vision/))."}),"\n",(0,i.jsx)(c.A,{src:"./img/8iG_Image_12.png",alt:"Entrer la description alternative de l'image",number:"12",label:"9.12",caption:"Visualisation multiple de caract\xe9ristiques r\xe9alis\xe9e sur un neurone polys\xe9mantique qui r\xe9agit aux images de voitures, ainsi qu'aux visages de chats et aux pattes de chats. D'apr\xe8s ([Olah et al., 2020](https://distill.pub/2020/circuits/early-vision/))."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les neurones polys\xe9mantiques sont tr\xe8s courants."})," Par exemple, dans un petit mod\xe8le de langage, on peut trouver un neurone qui r\xe9pond simultan\xe9ment aux dialogues en anglais, aux textes cor\xe9ens, aux requ\xeates HTTP et aux citations acad\xe9miques (",(0,i.jsx)(s.a,{href:"https://transformer-circuits.pub/2023/monosemantic-features",children:"Bricken et al., 2023"}),"). Cela signifie que chaque neurone ne correspond pas \xe0 une caract\xe9ristique sp\xe9cifique. Par cons\xe9quent, raisonner sur le comportement d'un r\xe9seau en se basant sur des neurones individuels est trompeur. Les neurones ne sont pas les unit\xe9s fondamentales sur lesquelles se concentrer pour comprendre les mod\xe8les."]}),"\n",(0,i.jsx)(s.p,{children:"La polys\xe9mantique pose un d\xe9fi pour l'interpr\xe9tabilit\xe9 car elle n\xe9cessite de comprendre comment les caract\xe9ristiques sont encod\xe9es \xe0 travers plusieurs neurones, plut\xf4t que de supposer que chaque neurone repr\xe9sente une unit\xe9 discr\xe8te de sens. Identifier comment ces caract\xe9ristiques distribu\xe9es sont encod\xe9es est un domaine de recherche actif en interpr\xe9tabilit\xe9."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"L'hypoth\xe8se principale pour expliquer pourquoi la polys\xe9mantique appara\xeet dans les r\xe9seaux neuronaux est appel\xe9e l'hypoth\xe8se de superposition."})," Les grands mod\xe8les doivent apprendre un nombre \xe9norme de caract\xe9ristiques pour fonctionner efficacement, probablement plus que le nombre de neurones dont ils disposent. En cons\xe9quence, les mod\xe8les ne peuvent pas attribuer chaque caract\xe9ristique \xe0 un seul neurone. Ils doivent plut\xf4t encoder les caract\xe9ristiques de mani\xe8re plus compress\xe9e. L'hypoth\xe8se de superposition sugg\xe8re que les mod\xe8les repr\xe9sentent plus de caract\xe9ristiques qu'ils n'ont de neurones en encodant plusieurs caract\xe9ristiques par neurone, ces caract\xe9ristiques \xe9tant orient\xe9es dans des directions presque orthogonales. En d'autres termes, les mod\xe8les compriment l'information en superposant des caract\xe9ristiques sur plusieurs neurones."]}),"\n",(0,i.jsxs)(o.A,{title:"Polys\xe9mantisme vs Superposition",collapsed:!0,children:[(0,i.jsxs)(s.p,{children:["La distinction entre la polys\xe9mantique et l'hypoth\xe8se de superposition est importante (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2404.14082",children:"Bereska et Gavves, 2024"}),") :"]}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"La polys\xe9mantique fait r\xe9f\xe9rence au ph\xe9nom\xe8ne empirique o\xf9 un neurone repr\xe9sente ou r\xe9pond \xe0 plusieurs caract\xe9ristiques non li\xe9es."}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"L'hypoth\xe8se de superposition, au contraire, fait g\xe9n\xe9ralement r\xe9f\xe9rence \xe0 une hypoth\xe8se qui tente d'expliquer la polys\xe9mantique. Elle sugg\xe8re que lorsque les mod\xe8les ont plus de caract\xe9ristiques \xe0 repr\xe9senter qu'ils n'ont de neurones pour les repr\xe9senter, ils doivent compresser ces caract\xe9ristiques dans l'espace limit\xe9. Cette compression force les caract\xe9ristiques \xe0 se chevaucher entre les neurones. Cela expliquerait pourquoi nous observons des neurones r\xe9pondant \xe0 plusieurs caract\xe9ristiques apparemment sans rapport. Bien que la superposition m\xe8ne intrins\xe8quement \xe0 la polys\xe9mantique, la polys\xe9mantique elle-m\xeame n'implique pas toujours la superposition, car la polys\xe9mantique pourrait th\xe9oriquement provenir d'autres m\xe9canismes."}),"\n"]}),"\n"]})]}),"\n",(0,i.jsx)(s.p,{children:"Comprendre et traiter la polys\xe9mantique est un domaine de recherche actif. Diverses directions sont explor\xe9es :"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Repr\xe9sentations \xe9parses :"})," Concevoir des r\xe9seaux utilisant des repr\xe9sentations \xe9parses (o\xf9 moins de neurones sont actifs \xe0 la fois) peut r\xe9duire la polys\xe9mantique (",(0,i.jsx)(s.a,{href:"https://transformer-circuits.pub/2022/solu/index.html",children:"Elhage et al., 2022"}),"). Cette approche n'a pas \xe9t\xe9 largement explor\xe9e car elle s'accompagne de compromis significatifs en termes de performance."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"D\xe9senchev\xeatrement des caract\xe9ristiques :"})," Certaines approches impliquent la d\xe9composition d'activations neuronales complexes pour isoler les caract\xe9ristiques individuelles. Une approche prometteuse dans cette ligne de recherche, connue sous le nom d'Auto-encodeurs \xe9pars, est une technique qui \"d\xe9plie\" le r\xe9seau et s\xe9pare les caract\xe9ristiques individuelles (",(0,i.jsx)(s.a,{href:"https://transformer-circuits.pub/2023/monosemantic-features",children:"Bricken et al., 2023"}),"). Elle est expliqu\xe9e plus en d\xe9tail dans la section sur les Auto-encodeurs \xe9pars."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"La visualisation des caract\xe9ristiques a conduit \xe0 plusieurs insights cl\xe9s sur le fonctionnement des r\xe9seaux neuronaux de vision :"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Structure hi\xe9rarchique :"})," Les r\xe9seaux neuronaux apprennent les caract\xe9ristiques de mani\xe8re hi\xe9rarchique, les premi\xe8res couches d\xe9tectant des motifs simples et les couches plus profondes les composant en objets complexes. Par exemple, les d\xe9tecteurs de courbes dans les premi\xe8res couches se combinent en d\xe9tecteurs de contours dans les couches interm\xe9diaires et finalement en d\xe9tecteurs d'objets complets dans les couches plus profondes."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Circuits :"}),' Les caract\xe9ristiques interagissent pour former des "circuits" \u2014 des groupes de caract\xe9ristiques interconnect\xe9es qui accomplissent collectivement une fonction sp\xe9cifique. Par exemple, un circuit pour d\xe9tecter les voitures pourrait combiner des caract\xe9ristiques comme les roues, les fen\xeatres et les formes de carrosserie en une repr\xe9sentation coh\xe9rente d\'une voiture.']}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Polys\xe9mantique :"})," La visualisation des caract\xe9ristiques a r\xe9v\xe9l\xe9 le ph\xe9nom\xe8ne de polys\xe9mantique, o\xf9 des neurones ou des caract\xe9ristiques individuels dans un r\xe9seau neuronal r\xe9pondent \xe0 plusieurs concepts apparemment sans rapport. Ce chevauchement complique notre capacit\xe9 \xe0 attribuer des r\xf4les clairs et interpr\xe9tables aux neurones individuels."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Universalit\xe9 :"})," Certaines caract\xe9ristiques, comme les d\xe9tecteurs de bords ou de courbes, sont universelles \xe0 travers les mod\xe8les et les architectures. Cela sugg\xe8re que certaines caract\xe9ristiques sont fondamentales pour le traitement visuel, ind\xe9pendamment de la t\xe2che ou du jeu de donn\xe9es sp\xe9cifique."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.h2,{id:"02",children:"Logit Lens"}),"\n",(0,i.jsxs)(s.p,{children:["La Logit Lens (",(0,i.jsx)(s.a,{href:"https://www.alignmentforum.org/posts/AcKRB8wDpdaN6v6ru/",children:"nostalgebraist, 2020"}),") est l'un des premiers outils d\xe9velopp\xe9s pour examiner l'int\xe9rieur des transformers. Elle nous permet d'observer comment un ",(0,i.jsx)(n,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:(0,i.jsx)(n,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:"transformer"})}),' affine ses pr\xe9dictions couche par couche \u2014 nous permettant de voir non seulement la sortie finale mais aussi le "processus de r\xe9flexion" \xe9volutif que le mod\xe8le suit lorsqu\'il fait une pr\xe9diction.']}),"\n",(0,i.jsx)(s.p,{children:'Les transformers sont entra\xeen\xe9s \xe0 pr\xe9dire le prochain token dans une s\xe9quence. Ils le font en transformant les entr\xe9es couche par couche, chaque couche ajoutant de nouvelles informations pour am\xe9liorer la pr\xe9diction. La Logit Lens permet de "traduire" la repr\xe9sentation interne de chaque couche en tokens. En voyant ce que le mod\xe8le "pr\xe9dit" \xe0 chaque couche, nous pouvons suivre comment ses pr\xe9dictions \xe9voluent d\'une estimation approximative dans les couches initiales \xe0 un choix affin\xe9 dans la derni\xe8re. Cependant, il est important de noter que si la Logit Lens nous permet de voir les pr\xe9dictions interm\xe9diaires \xe0 chaque couche, elle n\'explique pas le m\xe9canisme de transformation. La Logit Lens est un outil intrins\xe8quement observationnel \u2014 elle r\xe9v\xe8le quel est le token le plus probable \xe0 la fin de chaque couche mais ne permet pas de comprendre pourquoi ce token pr\xe9cis est pr\xe9dit.'}),"\n",(0,i.jsxs)(o.A,{title:"D\xe9tail - Guide d\xe9taill\xe9 de LogitLens",collapsed:!0,children:[(0,i.jsxs)(s.p,{children:["Un mod\xe8le ",(0,i.jsx)(n,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:(0,i.jsx)(n,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:"transformer"})})," est une architecture puissante pour traiter des s\xe9quences de donn\xe9es, en particulier du texte. Il est entra\xeen\xe9 \xe0 pr\xe9dire le prochain mot ou sous-mot dans une s\xe9quence, appel\xe9s tokens."]}),(0,i.jsxs)(s.p,{children:["L'ensemble de tous les tokens (mots ou sous-mots) que le mod\xe8le peut reconna\xeetre est appel\xe9 le vocabulaire. Par exemple, GPT-2 a un vocabulaire de 50 257 tokens. Plus pr\xe9cis\xe9ment, un ",(0,i.jsx)(n,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:(0,i.jsx)(n,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:"transformer"})})," prend une s\xe9quence de tokens en entr\xe9e et est entra\xeen\xe9 \xe0 pr\xe9dire le prochain token dans cette s\xe9quence, produisant une distribution de probabilit\xe9 sur l'ensemble du vocabulaire."]}),(0,i.jsxs)(s.p,{children:["Int\xe9rieurement, un ",(0,i.jsx)(n,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:(0,i.jsx)(n,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:"transformer"})})," est constitu\xe9 de plusieurs couches empil\xe9es, chacune contenant deux sous-couches : un MLP (perceptron multicouche) et des t\xeates d'",(0,i.jsx)(n,{term:"attention",definition:'{"definition":"M\xe9canisme permettant aux mod\xe8les de se concentrer sur les parties pertinentes de l\'entr\xe9e lors de la r\xe9alisation de pr\xe9dictions, en calculant des combinaisons pond\xe9r\xe9es d\'\xe9l\xe9ments d\'entr\xe9e..","source":"[Bahdanau et al., 2015](https://arxiv.org/abs/1409.0473)","aliases":["Attention","attention mechanism","self-attention"]}',children:(0,i.jsx)(n,{term:"attention",definition:'{"definition":"M\xe9canisme permettant aux mod\xe8les de se concentrer sur les parties pertinentes de l\'entr\xe9e lors de la r\xe9alisation de pr\xe9dictions, en calculant des combinaisons pond\xe9r\xe9es d\'\xe9l\xe9ments d\'entr\xe9e..","source":"[Bahdanau et al., 2015](https://arxiv.org/abs/1409.0473)","aliases":["Attention","attention mechanism","self-attention"]}',children:"attention"})}),". Pour comprendre la Logit Lens, nous n'avons pas besoin d'entrer dans les d\xe9tails du fonctionnement de ces sous-couches."]}),(0,i.jsx)(s.p,{children:"Les couches interm\xe9diaires sont connect\xe9es par ce qu'on appelle le flux r\xe9siduel. Le flux r\xe9siduel est un chemin qui transporte l'information de l'entr\xe9e \xe0 la sortie, lui permettant de circuler \xe0 travers toutes les couches du mod\xe8le."}),(0,i.jsx)(c.A,{src:"./img/DRe_Image_13.png",alt:"Entrer la description alternative de l'image",number:"13",label:"9.13",caption:"Une illustration minimaliste d'un transformeur avec une seule couche. Les transformeurs ne peuvent pas manipuler directement les tokens, ils les int\xe8grent donc en vecteurs num\xe9riques, une op\xe9ration repr\xe9sent\xe9e dans la case grise du bas. Apr\xe8s l'int\xe9gration, les tokens sont repr\xe9sent\xe9s comme des vecteurs dans le flux r\xe9siduel. La premi\xe8re sous-couche (t\xeates d'attention, repr\xe9sent\xe9es par les deux cases c\xf4te \xe0 c\xf4te sur la gauche) lit ces tokens int\xe9gr\xe9s, applique une transformation, et ajoute sa sortie au flux r\xe9siduel. La deuxi\xe8me sous-couche (MLP) fait de m\xeame. Enfin, pour produire un token, les tokens int\xe9gr\xe9s doivent \xeatre reconvertis dans l'espace du vocabulaire par une op\xe9ration de d\xe9sint\xe9gration (repr\xe9sent\xe9e dans la case du haut). Le flux r\xe9siduel permet \xe0 chaque couche d'apporter des ajustements progressifs aux pr\xe9dictions du mod\xe8le en accumulant et en affinant l'information transmise \xe0 travers chaque transformation. D'apr\xe8s ([Elhage et al., 2021](https://transformer-circuits.pub/2021/framework/index.html))."}),(0,i.jsx)(s.p,{children:"L'id\xe9e essentielle derri\xe8re la Logit Lens est que l'op\xe9ration de d\xe9semballage, typiquement appliqu\xe9e uniquement apr\xe8s la derni\xe8re couche, peut \xeatre appliqu\xe9e \xe0 n'importe quel point du flux r\xe9siduel. Apr\xe8s chaque couche interm\xe9diaire, le flux r\xe9siduel peut \xeatre d\xe9semball\xe9 \u2014 c'est-\xe0-dire reconverti dans l'espace des tokens \u2014 nous permettant d'observer quel token est actuellement le plus probable."}),(0,i.jsx)(s.p,{children:"Connexion entre la Logit Lens et la Visualisation des Caract\xe9ristiques dans les CNN. Dans la section pr\xe9c\xe9dente sur la Visualisation des Caract\xe9ristiques, nous avons vu que les CNN construisent leur compr\xe9hension d'une image couche par couche, d\xe9tectant des motifs simples comme les bords dans les premi\xe8res couches et des formes ou objets plus complexes dans les suivantes. La visualisation des caract\xe9ristiques nous permet d'interpr\xe9ter ces transformations progressives en affichant les motifs visuels auxquels diff\xe9rents neurones r\xe9pondent. La Logit Lens peut \xeatre vue comme un outil d'interpr\xe9tabilit\xe9 parall\xe8le pour les transformers. Au lieu de visualiser les caract\xe9ristiques d'image, la Logit Lens nous permet de voir les suppositions \xe9tape par \xe9tape du mod\xe8le pour le prochain token."}),(0,i.jsx)(s.p,{children:"La figure montre \xe0 quoi ressemble l'utilisation de la Logit Lens en pratique."}),(0,i.jsx)(c.A,{src:"./img/UuF_Image_14.png",alt:"Description alternative de l'image",number:"14",label:"9.14",caption:'Un exemple du Logit Lens utilis\xe9 sur GPT-2 lorsqu\'il tente de pr\xe9dire le prochain token de la s\xe9quence : "Specifically, we train GPT-3, an". Les tokens d\'entr\xe9e sont \xe9crits en bas, et les sorties correctes en haut. Les couches s\'empilent de bas en haut. Le premier token en haut, ",", correspond au token que le mod\xe8le devrait pr\xe9dire lorsqu\'il re\xe7oit en entr\xe9e uniquement le premier token : "Specifically". Le deuxi\xe8me token en haut, "we", correspond au token que le mod\xe8le devrait pr\xe9dire lorsqu\'il re\xe7oit en entr\xe9e uniquement les deux premiers tokens : "Specifically, ". C\'est la raison pour laquelle il y a un d\xe9calage d\'une position entre les tokens du bas et les tokens du haut. (*) indique que le mod\xe8le a correctement pr\xe9dit le prochain token. Chaque cellule contient les meilleures suppositions du mod\xe8le \xe0 diff\xe9rentes couches. L\'\xe9chelle de couleurs indique la valeur du logit associ\xe9e. Plus le logit est \xe9lev\xe9, plus le mod\xe8le est confiant dans sa pr\xe9diction. Tir\xe9 de ([nostalgebraist, 2020](https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens)).'}),(0,i.jsx)(s.p,{children:'La figure montre que lorsque GPT-2 essaie de pr\xe9dire le prochain token dans la s\xe9quence "Specifically, we train GPT-3, an", il pr\xe9dit "enormous" dans ses premi\xe8res couches, puis "massive", "single", et "N" dans sa derni\xe8re couche.'}),(0,i.jsx)(c.A,{src:"./img/qlF_Image_15.png",alt:"Entrer la description alternative de l'image",number:"15",label:"9.15",caption:"Aper\xe7u du fonctionnement de la Lentille Logit. Lire de bas en haut. Une explication d\xe9taill\xe9e est fournie dans les paragraphes suivants. Les formes des objets sont indiqu\xe9es entre crochets."}),(0,i.jsxs)(s.p,{children:["Un ",(0,i.jsx)(n,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:(0,i.jsx)(n,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:"transformer"})})," prend en entr\xe9e une s\xe9quence de tokens. Chaque token est un \xe9l\xe9ment d'un vocabulaire (typiquement de taille ",(0,i.jsxs)(s.span,{className:"katex",children:[(0,i.jsx)(s.span,{className:"katex-mathml",children:(0,i.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(s.semantics,{children:[(0,i.jsx)(s.mrow,{children:(0,i.jsxs)(s.msub,{children:[(0,i.jsx)(s.mi,{children:"n"}),(0,i.jsx)(s.mtext,{children:"vocab"})]})}),(0,i.jsx)(s.annotation,{encoding:"application/x-tex",children:"n_{\\text{vocab}}"})]})})}),(0,i.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(s.span,{className:"base",children:[(0,i.jsx)(s.span,{className:"strut",style:{height:"0.5806em",verticalAlign:"-0.15em"}}),(0,i.jsxs)(s.span,{className:"mord",children:[(0,i.jsx)(s.span,{className:"mord mathnormal",children:"n"}),(0,i.jsx)(s.span,{className:"msupsub",children:(0,i.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,i.jsxs)(s.span,{className:"vlist-r",children:[(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.3361em"},children:(0,i.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,i.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,i.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:(0,i.jsx)(s.span,{className:"mord text mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:"vocab"})})})})]})}),(0,i.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,i.jsx)(s.span,{className:"vlist-r",children:(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,i.jsx)(s.span,{})})})]})})]})]})})]}),"), donc chaque token de texte peut \xeatre associ\xe9 \xe0 une valeur enti\xe8re allant de 0 \xe0 ",(0,i.jsxs)(s.span,{className:"katex",children:[(0,i.jsx)(s.span,{className:"katex-mathml",children:(0,i.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(s.semantics,{children:[(0,i.jsx)(s.mrow,{children:(0,i.jsxs)(s.msub,{children:[(0,i.jsx)(s.mi,{children:"n"}),(0,i.jsx)(s.mtext,{children:"vocab"})]})}),(0,i.jsx)(s.annotation,{encoding:"application/x-tex",children:"n_{\\text{vocab}}"})]})})}),(0,i.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(s.span,{className:"base",children:[(0,i.jsx)(s.span,{className:"strut",style:{height:"0.5806em",verticalAlign:"-0.15em"}}),(0,i.jsxs)(s.span,{className:"mord",children:[(0,i.jsx)(s.span,{className:"mord mathnormal",children:"n"}),(0,i.jsx)(s.span,{className:"msupsub",children:(0,i.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,i.jsxs)(s.span,{className:"vlist-r",children:[(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.3361em"},children:(0,i.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,i.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,i.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:(0,i.jsx)(s.span,{className:"mord text mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:"vocab"})})})})]})}),(0,i.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,i.jsx)(s.span,{className:"vlist-r",children:(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,i.jsx)(s.span,{})})})]})})]})]})})]}),". Cette association peut aussi \xeatre consid\xe9r\xe9e comme repr\xe9sentant le token comme un vecteur de base dans un espace de dimension ",(0,i.jsxs)(s.span,{className:"katex",children:[(0,i.jsx)(s.span,{className:"katex-mathml",children:(0,i.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(s.semantics,{children:[(0,i.jsx)(s.mrow,{children:(0,i.jsxs)(s.msub,{children:[(0,i.jsx)(s.mi,{children:"n"}),(0,i.jsx)(s.mtext,{children:"vocab"})]})}),(0,i.jsx)(s.annotation,{encoding:"application/x-tex",children:"n_{\\text{vocab}}"})]})})}),(0,i.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(s.span,{className:"base",children:[(0,i.jsx)(s.span,{className:"strut",style:{height:"0.5806em",verticalAlign:"-0.15em"}}),(0,i.jsxs)(s.span,{className:"mord",children:[(0,i.jsx)(s.span,{className:"mord mathnormal",children:"n"}),(0,i.jsx)(s.span,{className:"msupsub",children:(0,i.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,i.jsxs)(s.span,{className:"vlist-r",children:[(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.3361em"},children:(0,i.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,i.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,i.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:(0,i.jsx)(s.span,{className:"mord text mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:"vocab"})})})})]})}),(0,i.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,i.jsx)(s.span,{className:"vlist-r",children:(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,i.jsx)(s.span,{})})})]})})]})]})})]}),", appel\xe9 l'espace du vocabulaire. Chaque vecteur de base dans l'espace du vocabulaire est associ\xe9 \xe0 un token."]}),(0,i.jsxs)(s.p,{children:["Un ",(0,i.jsx)(n,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:(0,i.jsx)(n,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:"transformer"})})," est entra\xeen\xe9 \xe0 pr\xe9dire le prochain token de la s\xe9quence d'entr\xe9e, donc sa sortie est une distribution de probabilit\xe9 sur le vocabulaire."]}),(0,i.jsxs)(s.p,{children:["Les transformers convertissent chaque token en vecteurs ",(0,i.jsxs)(s.span,{className:"katex",children:[(0,i.jsx)(s.span,{className:"katex-mathml",children:(0,i.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(s.semantics,{children:[(0,i.jsx)(s.mrow,{children:(0,i.jsxs)(s.msub,{children:[(0,i.jsx)(s.mi,{children:"n"}),(0,i.jsx)(s.mtext,{children:"vocab"})]})}),(0,i.jsx)(s.annotation,{encoding:"application/x-tex",children:"n_{\\text{vocab}}"})]})})}),(0,i.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(s.span,{className:"base",children:[(0,i.jsx)(s.span,{className:"strut",style:{height:"0.5806em",verticalAlign:"-0.15em"}}),(0,i.jsxs)(s.span,{className:"mord",children:[(0,i.jsx)(s.span,{className:"mord mathnormal",children:"n"}),(0,i.jsx)(s.span,{className:"msupsub",children:(0,i.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,i.jsxs)(s.span,{className:"vlist-r",children:[(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.3361em"},children:(0,i.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,i.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,i.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:(0,i.jsx)(s.span,{className:"mord text mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:"vocab"})})})})]})}),(0,i.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,i.jsx)(s.span,{className:"vlist-r",children:(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,i.jsx)(s.span,{})})})]})})]})]})})]}),", ce qui est connu comme l'espace d'",(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:"embedding"})}),". La dimension de l'espace d'",(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:"embedding"})})," est not\xe9e ",(0,i.jsxs)(s.span,{className:"katex",children:[(0,i.jsx)(s.span,{className:"katex-mathml",children:(0,i.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(s.semantics,{children:[(0,i.jsx)(s.mrow,{children:(0,i.jsxs)(s.msub,{children:[(0,i.jsx)(s.mi,{children:"d"}),(0,i.jsx)(s.mtext,{children:"model"})]})}),(0,i.jsx)(s.annotation,{encoding:"application/x-tex",children:"d_{\\text{model}}"})]})})}),(0,i.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(s.span,{className:"base",children:[(0,i.jsx)(s.span,{className:"strut",style:{height:"0.8444em",verticalAlign:"-0.15em"}}),(0,i.jsxs)(s.span,{className:"mord",children:[(0,i.jsx)(s.span,{className:"mord mathnormal",children:"d"}),(0,i.jsx)(s.span,{className:"msupsub",children:(0,i.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,i.jsxs)(s.span,{className:"vlist-r",children:[(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.3361em"},children:(0,i.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,i.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,i.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:(0,i.jsx)(s.span,{className:"mord text mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:"model"})})})})]})}),(0,i.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,i.jsx)(s.span,{className:"vlist-r",children:(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,i.jsx)(s.span,{})})})]})})]})]})})]}),". Les tokens projet\xe9s sont appel\xe9s vecteurs d'",(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:"embedding"})}),", ou simplement ",(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:"embeddings"})}),". Dans certains contextes, ils peuvent aussi \xeatre appel\xe9s activations cach\xe9es. La matrice d'",(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:"embedding"})})," convertit les tokens de l'espace du vocabulaire vers l'espace d'",(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:"embedding"})}),". C'est comme une table de consultation qui associe les \xe9l\xe9ments dans l'espace du vocabulaire avec leurs homologues correspondants dans l'espace d'",(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:"embedding"})}),"."]}),(0,i.jsxs)(s.p,{children:["Une fois que les tokens ont \xe9t\xe9 convertis dans l'espace d'",(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:"embedding"})}),", ils circulent \xe0 travers les couches successives du ",(0,i.jsx)(n,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:(0,i.jsx)(n,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:"transformer"})}),". Similaire \xe0 la fa\xe7on dont les images d'entr\xe9e subissent des transformations \xe0 travers les couches d'un CNN, les vecteurs d'",(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:"embedding"})})," sont transform\xe9s lorsqu'ils passent \xe0 travers le r\xe9seau. La Logit Lens se concentre pr\xe9cis\xe9ment sur ces repr\xe9sentations interm\xe9diaires que les transformers construisent."]}),(0,i.jsxs)(s.p,{children:["Finalement, pour produire une distribution de probabilit\xe9 sur le vocabulaire, le vecteur d'",(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:"embedding"})})," final doit \xeatre reconverti dans l'espace du vocabulaire. La conversion de l'espace d'",(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:"embedding"})})," vers l'espace du vocabulaire peut \xeatre faite par multiplication par une matrice de dimension ",(0,i.jsxs)(s.span,{className:"katex",children:[(0,i.jsx)(s.span,{className:"katex-mathml",children:(0,i.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(s.semantics,{children:[(0,i.jsxs)(s.mrow,{children:[(0,i.jsx)(s.mo,{stretchy:"false",children:"["}),(0,i.jsxs)(s.msub,{children:[(0,i.jsx)(s.mi,{children:"d"}),(0,i.jsx)(s.mtext,{children:"model"})]}),(0,i.jsx)(s.mo,{separator:"true",children:","}),(0,i.jsxs)(s.msub,{children:[(0,i.jsx)(s.mi,{children:"n"}),(0,i.jsx)(s.mtext,{children:"vocab"})]}),(0,i.jsx)(s.mo,{stretchy:"false",children:"]"})]}),(0,i.jsx)(s.annotation,{encoding:"application/x-tex",children:"[d_{\\text{model}}, n_{\\text{vocab}}]"})]})})}),(0,i.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(s.span,{className:"base",children:[(0,i.jsx)(s.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,i.jsx)(s.span,{className:"mopen",children:"["}),(0,i.jsxs)(s.span,{className:"mord",children:[(0,i.jsx)(s.span,{className:"mord mathnormal",children:"d"}),(0,i.jsx)(s.span,{className:"msupsub",children:(0,i.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,i.jsxs)(s.span,{className:"vlist-r",children:[(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.3361em"},children:(0,i.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,i.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,i.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:(0,i.jsx)(s.span,{className:"mord text mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:"model"})})})})]})}),(0,i.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,i.jsx)(s.span,{className:"vlist-r",children:(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,i.jsx)(s.span,{})})})]})})]}),(0,i.jsx)(s.span,{className:"mpunct",children:","}),(0,i.jsx)(s.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,i.jsxs)(s.span,{className:"mord",children:[(0,i.jsx)(s.span,{className:"mord mathnormal",children:"n"}),(0,i.jsx)(s.span,{className:"msupsub",children:(0,i.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,i.jsxs)(s.span,{className:"vlist-r",children:[(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.3361em"},children:(0,i.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,i.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,i.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:(0,i.jsx)(s.span,{className:"mord text mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:"vocab"})})})})]})}),(0,i.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,i.jsx)(s.span,{className:"vlist-r",children:(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,i.jsx)(s.span,{})})})]})})]}),(0,i.jsx)(s.span,{className:"mclose",children:"]"})]})})]}),". Cette op\xe9ration est appel\xe9e le d\xe9semballage. Le r\xe9sultat du d\xe9semballage est un vecteur de logits de taille ",(0,i.jsxs)(s.span,{className:"katex",children:[(0,i.jsx)(s.span,{className:"katex-mathml",children:(0,i.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(s.semantics,{children:[(0,i.jsx)(s.mrow,{children:(0,i.jsxs)(s.msub,{children:[(0,i.jsx)(s.mi,{children:"n"}),(0,i.jsx)(s.mtext,{children:"vocab"})]})}),(0,i.jsx)(s.annotation,{encoding:"application/x-tex",children:"n_{\\text{vocab}}"})]})})}),(0,i.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(s.span,{className:"base",children:[(0,i.jsx)(s.span,{className:"strut",style:{height:"0.5806em",verticalAlign:"-0.15em"}}),(0,i.jsxs)(s.span,{className:"mord",children:[(0,i.jsx)(s.span,{className:"mord mathnormal",children:"n"}),(0,i.jsx)(s.span,{className:"msupsub",children:(0,i.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,i.jsxs)(s.span,{className:"vlist-r",children:[(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.3361em"},children:(0,i.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,i.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,i.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:(0,i.jsx)(s.span,{className:"mord text mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:"vocab"})})})})]})}),(0,i.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,i.jsx)(s.span,{className:"vlist-r",children:(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,i.jsx)(s.span,{})})})]})})]})]})})]}),". Les logits peuvent ensuite \xeatre convertis en probabilit\xe9s sur le vocabulaire en utilisant la fonction ",(0,i.jsx)(n,{term:"softmax",definition:'{"definition":"Une fonction d\'activation qui convertit un vecteur de nombres r\xe9els en une distribution de probabilit\xe9, couramment utilis\xe9e dans les t\xe2ches de classification..","source":"","aliases":["Softmax"]}',children:(0,i.jsx)(n,{term:"softmax",definition:'{"definition":"Une fonction d\'activation qui convertit un vecteur de nombres r\xe9els en une distribution de probabilit\xe9, couramment utilis\xe9e dans les t\xe2ches de classification..","source":"","aliases":["Softmax"]}',children:"softmax"})}),"."]}),(0,i.jsxs)(s.p,{children:["L'intuition essentielle derri\xe8re la Logit Lens est que l'op\xe9ration de d\xe9semballage, typiquement appliqu\xe9e apr\xe8s la derni\xe8re couche, peut aussi \xeatre appliqu\xe9e apr\xe8s chaque couche interm\xe9diaire. Les vecteurs d'",(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:"embedding"})})," sont modifi\xe9s par chaque couche du r\xe9seau, mais leurs dimensions restent les m\xeames (",(0,i.jsxs)(s.span,{className:"katex",children:[(0,i.jsx)(s.span,{className:"katex-mathml",children:(0,i.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(s.semantics,{children:[(0,i.jsx)(s.mrow,{children:(0,i.jsxs)(s.msub,{children:[(0,i.jsx)(s.mi,{children:"d"}),(0,i.jsx)(s.mtext,{children:"model"})]})}),(0,i.jsx)(s.annotation,{encoding:"application/x-tex",children:"d_{\\text{model}}"})]})})}),(0,i.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(s.span,{className:"base",children:[(0,i.jsx)(s.span,{className:"strut",style:{height:"0.8444em",verticalAlign:"-0.15em"}}),(0,i.jsxs)(s.span,{className:"mord",children:[(0,i.jsx)(s.span,{className:"mord mathnormal",children:"d"}),(0,i.jsx)(s.span,{className:"msupsub",children:(0,i.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,i.jsxs)(s.span,{className:"vlist-r",children:[(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.3361em"},children:(0,i.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,i.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,i.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:(0,i.jsx)(s.span,{className:"mord text mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:"model"})})})})]})}),(0,i.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,i.jsx)(s.span,{className:"vlist-r",children:(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,i.jsx)(s.span,{})})})]})})]})]})})]}),"). Ainsi, apr\xe8s n'importe quelle couche, les vecteurs d'",(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:"embedding"})})," peuvent \xeatre reconvertis vers l'espace du vocabulaire, et on peut avoir une id\xe9e de comment le r\xe9seau affine sa pr\xe9diction \xe0 travers les couches."]})]}),"\n",(0,i.jsx)(s.h2,{id:"03",children:"Sondage des classificateurs"}),"\n",(0,i.jsxs)(s.p,{children:["Le sondage est une technique utilis\xe9e pour analyser les r\xe9seaux neuronaux et comprendre quelles repr\xe9sentations ou concepts ils ont appris et o\xf9 (",(0,i.jsx)(s.a,{href:"https://aclanthology.org/2022.cl-1.7/",children:"Belinkov, 2022"}),"). Les techniques de sondage peuvent \xeatre appliqu\xe9es \xe0 divers mod\xe8les, des transformers aux CNN, pour d\xe9terminer si des informations ou propri\xe9t\xe9s sp\xe9cifiques sont encod\xe9es dans les repr\xe9sentations interm\xe9diaires d'un mod\xe8le."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Qu'est-ce qu'une sonde ?"})," Une sonde est un mod\xe8le l\xe9ger, souvent un classificateur lin\xe9aire, entra\xeen\xe9 pour d\xe9tecter si un concept ou une caract\xe9ristique sp\xe9cifique est repr\xe9sent\xe9 dans les activations d'un r\xe9seau neuronal. Dans une configuration de sondage, les chercheurs analysent les activations (les sorties interm\xe9diaires) des couches d'un r\xe9seau pour voir si ces activations encodent des informations sur une propri\xe9t\xe9 ou un concept particulier. Par exemple, les sondes peuvent \xeatre utilis\xe9es pour d\xe9terminer si les activations d'un mod\xe8le de langage contiennent des informations sur les r\xe8gles grammaticales ou si un mod\xe8le de jeu d'\xe9checs comme AlphaZero encode des connaissances strat\xe9giques sur le jeu, o\xf9 ces connaissances sont situ\xe9es dans le r\xe9seau, et quand elles sont acquises pendant l'entra\xeenement (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2305.01610",children:"Gurnee et al., 2023"}),", ",(0,i.jsx)(s.a,{href:"https://www.pnas.org/doi/10.1073/pnas.2206625119",children:"McGrath et al., 2022"}),")."]}),"\n",(0,i.jsxs)(s.p,{children:['Un exemple bien connu de sondage a \xe9t\xe9 appliqu\xe9 \xe0 AlphaZero, le r\xe9seau neuronal entra\xeen\xe9 \xe0 jouer aux \xe9checs qui a c\xe9l\xe8brement battu les meilleurs joueurs humains. Les chercheurs ont utilis\xe9 des sondes pour \xe9tudier si AlphaZero repr\xe9sente int\xe9rieurement certains concepts strat\xe9giques sur les \xe9checs, comme "L\'adversaire peut-il capturer ma reine ?" ou "Y a-t-il une menace d\'\xe9chec et mat en un coup ?" (',(0,i.jsx)(s.a,{href:"https://www.pnas.org/doi/10.1073/pnas.2206625119",children:"McGrath et al., 2022"}),")."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La classification par sondage est le processus d'entra\xeenement de classificateurs sur les activations interm\xe9diaires du r\xe9seau pour identifier si des propri\xe9t\xe9s sp\xe9cifiques sont encod\xe9es."})," Les \xe9tapes de la classification par sondage sont les suivantes :"]}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Choisir une propri\xe9t\xe9 ou un concept :"}),' D\xe9finir un concept sp\xe9cifique \xe0 explorer, comme "L\'adversaire peut-il capturer ma reine ?".']}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"G\xe9n\xe9rer ou s\xe9lectionner des donn\xe9es d'entr\xe9e :"}),' Cr\xe9er un jeu de donn\xe9es avec des exemples qui varient en termes de propri\xe9t\xe9 cible. Par exemple, aux \xe9checs, nous pourrions cr\xe9er des configurations de plateau o\xf9 "le joueur peut capturer la reine de l\'adversaire" est soit vrai soit faux.']}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Enregistrer les activations interm\xe9diaires :"})," Faire passer ce jeu de donn\xe9es \xe0 travers le mod\xe8le et enregistrer les activations des neurones \xe0 diff\xe9rentes couches."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Entra\xeener un classificateur sur les activations :"})," Utiliser les activations enregistr\xe9es comme caract\xe9ristiques d'entr\xe9e pour entra\xeener un classificateur (sonde) qui distingue entre diff\xe9rentes classes bas\xe9es sur le concept (par exemple, vrais vs faux prompts d'entr\xe9e)."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"\xc9valuer la pr\xe9cision de la sonde :"})," Si la sonde atteint une haute pr\xe9cision, cela sugg\xe8re que le concept cible est fortement encod\xe9 dans les activations de la couche enregistr\xe9e."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(o.A,{title:"Sondage en pratique : \xe9tudes de cas et limitations",collapsed:!0,children:[(0,i.jsx)(c.A,{src:"./img/TQo_Image_16.png",alt:"Entrer la description alternative de l'image",number:"16",label:"9.16",caption:"Pr\xe9cision de deux sondes entra\xeen\xe9es sur les activations interm\xe9diaires d'AlphaZero, \xe0 travers les couches et les \xe9tapes d'entra\xeenement. Les deux sondes ont \xe9t\xe9 entra\xeen\xe9es sur deux concepts : \"Le camp qui joue peut-il capturer la reine adverse ?\", et \"Le camp adverse pourrait-il mettre \xe9chec et mat le camp qui joue en un coup ?\". La couleur repr\xe9sente la pr\xe9cision de la sonde (la couleur jaune correspond \xe0 une valeur plus \xe9lev\xe9e, indiquant que la caract\xe9ristique est plus repr\xe9sent\xe9e). Ici, les sondes ont \xe9t\xe9 entra\xeen\xe9es \xe0 diff\xe9rentes \xe9tapes de l'entra\xeenement d'AlphaZero et \xe0 partir des activations de diff\xe9rentes couches du r\xe9seau (un bloc correspond \xe0 une couche d'AlphaZero). On peut constater que plus AlphaZero est entra\xeen\xe9, plus il repr\xe9sente ces deux concepts. Le concept \"has_mate_threat\" semble \xeatre repr\xe9sent\xe9 de mani\xe8re assez homog\xe8ne \xe0 travers les couches d'AlphaZero, tandis que \"can_capture_queen_opponent\" appara\xeet comme \xe9tant plus repr\xe9sent\xe9 dans les premi\xe8res couches. \"La capacit\xe9 \xe0 pr\xe9dire has_mate_threat \xe0 partir des activations d'AlphaZero indique qu'AlphaZero ne mod\xe9lise pas simplement ses mouvements potentiels, mais aussi les mouvements potentiels de son adversaire et leurs cons\xe9quences lors de l'\xe9valuation de la position\". D'apr\xe8s (MacGrath et al., 2022)."}),(0,i.jsxs)(s.p,{children:["Utilisation de sondes lin\xe9aires pour d\xe9tecter les prompts menant \xe0 des comportements dangereux. L'\xe9quipe d'alignement d'Anthropic travaille actuellement sur un programme de recherche appel\xe9 \"agents dormants\" o\xf9 ils entra\xeenent d\xe9lib\xe9r\xe9ment des mod\xe8les align\xe9s de mani\xe8re trompeuse (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2401.05566",children:"Hubinger et al., 2024"}),") pour tester si les techniques actuellement disponibles peuvent d\xe9tecter le d\xe9salignement. Ces \"agents dormants\" sont des mod\xe8les avec des portes d\xe9rob\xe9es cach\xe9es introduites pendant l'entra\xeenement. L'un des agents dormants qu'ils ont entra\xeen\xe9 \xe9crit du code s\xe9curis\xe9 lorsque le prompt indique l'ann\xe9e \"2023\" mais ins\xe8re des vuln\xe9rabilit\xe9s lorsque le prompt indique \"2024\". Ces sorties dangereuses sont difficiles \xe0 d\xe9tecter et pourraient facilement \xe9chapper \xe0 un superviseur humain, c'est pourquoi il serait extr\xeamement utile de d\xe9velopper une m\xe9thode de d\xe9tection automatique. Les chercheurs d'Anthropic ont entra\xeen\xe9 des sondes lin\xe9aires bas\xe9es sur les activations du flux r\xe9siduel des agents dormants qui classifient les entr\xe9es comme s\xfbres ou dangereuses avec une tr\xe8s haute pr\xe9cision (",(0,i.jsx)(s.a,{href:"https://www.anthropic.com/news/probes-catch-sleeper-agents",children:"MacDiarmid et al., 2024"}),"). Le fait qu'un prompt d\xe9clenchera ou non une d\xe9fection semble \xeatre encod\xe9 lin\xe9airement \xe0 travers une large gamme de flux r\xe9siduels interm\xe9diaires. Cependant, ils restent m\xe9fiants de ce r\xe9sultat et reconnaissent que la pr\xe9cision \xe9tonnamment \xe9lev\xe9e des sondes pourrait \xeatre due \xe0 l'insertion de la porte d\xe9rob\xe9e, et que la \"d\xe9fection naturelle\" pourrait ne pas \xeatre d\xe9tect\xe9e aussi facilement."]}),(0,i.jsxs)(s.p,{children:["Il a \xe9galement \xe9t\xe9 sugg\xe9r\xe9 d'entra\xeener des sondes sur des sc\xe9narios \xe9crits par des humains de tentatives de prise de contr\xf4le ou d'actions catastrophiques (",(0,i.jsx)(s.a,{href:"https://www.alignmentforum.org/posts/WCj7WgFSLmyKaMwPR/coup-probes-catching-catastrophes-with-probes-trained-off",children:"Roger., 2023"}),") pour d\xe9tecter de tels objectifs ou intentions dans les mod\xe8les avant qu'ils ne se produisent. Comme pour les agents dormants, il n'est pas certain que les sondes entra\xeen\xe9es dans des environnements artificiels se g\xe9n\xe9raliseront dans des sc\xe9narios r\xe9els."]}),(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Limitations des classificateurs de sondage"})," - ",(0,i.jsx)(s.strong,{children:"Corr\xe9lation, pas causalit\xe9 :"})," Les classificateurs de sondage indiquent qu'un concept (ou un proxy de ce concept) est encod\xe9, mais ils ne r\xe9v\xe8lent pas si ce concept est activement utilis\xe9 par le r\xe9seau pendant l'inf\xe9rence. La haute pr\xe9cision du classificateur peut refl\xe9ter la facilit\xe9 avec laquelle il peut d\xe9tecter des motifs, pas n\xe9cessairement que le mod\xe8le s'appuie sur ces motifs pour la prise de d\xe9cision. Pour d\xe9couvrir des effets causaux, nous devons intervenir dans les repr\xe9sentations du mod\xe8le au lieu de simplement les observer."]}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:'Identification de proxys plut\xf4t que de "vrais concepts" :'})," Le sondage peut d\xe9tecter des motifs qui agissent comme des proxys pour le concept d'int\xe9r\xeat, plut\xf4t que le concept lui-m\xeame. Par exemple, une sonde entra\xeen\xe9e pour d\xe9tecter le \"langage juridique\" pourrait en r\xe9alit\xe9 d\xe9tecter des indices corr\xe9l\xe9s (comme certains mots formels ou structures de phrases) plut\xf4t qu'une v\xe9ritable compr\xe9hension de la terminologie juridique. Cela rend difficile l'interpr\xe9tation des sondes comme des indicateurs d\xe9finitifs des concepts exacts repr\xe9sent\xe9s dans le mod\xe8le."]}),"\n"]})]}),"\n",(0,i.jsx)(s.h2,{id:"04",children:"Superposition"}),"\n",(0,i.jsx)(s.p,{children:"Pour donner du sens aux donn\xe9es, les classifier ou prendre des d\xe9cisions, les r\xe9seaux neuronaux doivent apprendre des caract\xe9ristiques - des repr\xe9sentations qui capturent des motifs significatifs dans les donn\xe9es. Cependant, les r\xe9seaux disposent d'un nombre limit\xe9 de neurones pour stocker une vaste quantit\xe9 d'informations. Au lieu d'attribuer un seul neurone \xe0 chaque caract\xe9ristique, les r\xe9seaux neuronaux \"partagent\" souvent les neurones entre plusieurs caract\xe9ristiques. Ce stockage partag\xe9 et superpos\xe9 est connu sous le nom de superposition."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La superposition se produit car elle permet au r\xe9seau de g\xe9rer plus de caract\xe9ristiques en utilisant moins de neurones, le rendant ainsi plus efficace en termes de m\xe9moire."}),' Cependant, cette efficacit\xe9 a un co\xfbt : la polys\xe9mantique. La polys\xe9mantique signifie qu\'un seul neurone ou composant du r\xe9seau repr\xe9sente plusieurs caract\xe9ristiques, souvent sans rapport entre elles. Par exemple, un neurone pourrait s\'activer en r\xe9ponse \xe0 la fois aux "chats" et aux "voitures", bien que ces concepts soient totalement diff\xe9rents.']}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Polys\xe9mantique et Superposition."})," Le vocabulaire entourant la superposition et les concepts associ\xe9s est souvent confus. Les termes superposition et polys\xe9mantique sont souvent utilis\xe9s de mani\xe8re interchangeable, m\xeame s'ils font r\xe9f\xe9rence \xe0 des aspects l\xe9g\xe8rement diff\xe9rents du m\xeame ph\xe9nom\xe8ne dans certains contextes : la superposition d\xe9crit le stockage superpos\xe9 des caract\xe9ristiques, tandis que la polys\xe9mantique met en \xe9vidence le comportement des neurones qui r\xe9pondent \xe0 plusieurs caract\xe9ristiques distinctes. Gardez \xe9galement \xe0 l'esprit que la superposition ne doit pas \xeatre confondue avec l'hypoth\xe8se de superposition, qui est une th\xe9orie sp\xe9cifique propos\xe9e pour expliquer pourquoi et comment la superposition se produit dans les r\xe9seaux neuronaux."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Ce chevauchement cr\xe9e un d\xe9fi pour l'interpr\xe9tabilit\xe9."}),' Id\xe9alement, nous pourrions nous attendre \xe0 ce que chaque neurone ait un objectif clair et unique - un neurone pour les "chats", un autre pour les "voitures", et ainsi de suite. En r\xe9alit\xe9, de nombreux neurones r\xe9pondent \xe0 des combinaisons de caract\xe9ristiques sans rapport, conduisant \xe0 des repr\xe9sentations enchev\xeatr\xe9es. Cela signifie que l\'interpr\xe9tation des neurones individuels de mani\xe8re isol\xe9e fournit souvent une image incompl\xe8te ou trompeuse (',(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2104.07143",children:"Bolukbasi et al., 2021"}),")."]}),"\n",(0,i.jsx)(s.p,{children:"Contrastez cela avec un r\xe9seau hypoth\xe9tique sans polys\xe9mantique : chaque neurone correspondrait \xe0 une caract\xe9ristique distincte, rendant le mod\xe8le beaucoup plus facile \xe0 interpr\xe9ter. Cependant, une telle conception n\xe9cessiterait beaucoup plus de neurones pour repr\xe9senter individuellement chaque caract\xe9ristique, ce qui est inefficace du point de vue computationnel, particuli\xe8rement dans les mod\xe8les \xe0 grande \xe9chelle. Par cons\xe9quent, la superposition est pratiquement in\xe9vitable dans les r\xe9seaux neuronaux modernes."}),"\n",(0,i.jsx)(s.p,{children:"Du point de vue de la s\xe9curit\xe9 de l'IA, comprendre la superposition est crucial. Si nous voulons retracer comment un mod\xe8le prend ses d\xe9cisions, nous devons identifier et d\xe9m\xealer ces caract\xe9ristiques qui se chevauchent. Ce n'est qu'alors que nous pourrons retracer le raisonnement derri\xe8re ses pr\xe9dictions et d\xe9couvrir ce qui motive son comportement."}),"\n",(0,i.jsx)(s.p,{children:"Avant de se plonger dans les techniques de d\xe9m\xealage des caract\xe9ristiques, les chercheurs ont d'abord cherch\xe9 \xe0 comprendre comment la polys\xe9mantique appara\xeet. Les questions cl\xe9s incluent :"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Qu'est-ce qui cause la polys\xe9mantique dans les r\xe9seaux neuronaux ?"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Comment l'architecture du mod\xe8le ou le processus d'entra\xeenement l'influence-t-il ?"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Peut-elle \xeatre contr\xf4l\xe9e ou att\xe9nu\xe9e ?"}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"Pour r\xe9pondre \xe0 ces questions, les chercheurs ont utilis\xe9 des mod\xe8les jouets - des r\xe9seaux neuronaux simples et \xe0 petite \xe9chelle. Les mod\xe8les jouets permettent une exp\xe9rimentation contr\xf4l\xe9e et aident les chercheurs \xe0 isoler et \xe9tudier des ph\xe9nom\xe8nes comme la superposition sans la complexit\xe9 des syst\xe8mes plus grands. La sous-section suivante d\xe9taille les mod\xe8les jouets utilis\xe9s pour \xe9tudier la polys\xe9mantique."}),"\n",(0,i.jsxs)(o.A,{title:"Exp\xe9riences sur des mod\xe8les jouets pour soutenir l'hypoth\xe8se de superposition",collapsed:!0,children:[(0,i.jsxs)(s.p,{children:["L'article sur les Mod\xe8les Jouets de Superposition pr\xe9sente des mod\xe8les simplifi\xe9s qui aident les chercheurs \xe0 \xe9tudier la superposition dans un environnement contr\xf4l\xe9 (",(0,i.jsx)(s.a,{href:"https://transformer-circuits.pub/2022/toy_model/index.html",children:"Elhage et al., 2022"}),"). Ces mod\xe8les fournissent des preuves soutenant l'hypoth\xe8se de superposition - une th\xe9orie sur la fa\xe7on dont les r\xe9seaux neuronaux stockent et organisent efficacement l'information."]}),(0,i.jsx)(s.p,{children:"L'hypoth\xe8se de superposition sugg\xe8re que les r\xe9seaux neuronaux peuvent repr\xe9senter plus de caract\xe9ristiques ou de concepts qu'ils n'ont de neurones individuels en encodant l'information comme des combinaisons lin\xe9aires \xe0 travers plusieurs neurones. Cela signifie :"}),(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Compression efficace :"})," Les r\xe9seaux neuronaux peuvent compresser l'information en repr\xe9sentant plus de caract\xe9ristiques qu'il n'y a de dimensions disponibles, optimisant l'utilisation de la m\xe9moire."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Repr\xe9sentation distribu\xe9e :"})," Les caract\xe9ristiques ne sont pas exclusivement li\xe9es \xe0 des neurones uniques ; au lieu de cela, elles sont distribu\xe9es \xe0 travers plusieurs neurones."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Directions non orthogonales :"})," Les caract\xe9ristiques sont stock\xe9es dans des directions qui ne sont pas parfaitement orthogonales dans l'espace d'activation du r\xe9seau, ce qui conduit \xe0 des chevauchements et des interf\xe9rences potentielles entre les concepts."]}),"\n"]}),"\n"]}),(0,i.jsx)(s.p,{children:"Cet article est une pierre angulaire de l'interpr\xe9tabilit\xe9 m\xe9caniste car il r\xe9v\xe8le des ph\xe9nom\xe8nes fascinants sur la fa\xe7on dont les r\xe9seaux neuronaux organisent et stockent l'information :"}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"D\xe9monstration de la superposition :"})," Les exp\xe9riences montrent que la superposition se produit et identifient les conditions dans lesquelles elle appara\xeet."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Explication des neurones mono- et polys\xe9mantiques :"})," L'article clarifie pourquoi certains neurones se sp\xe9cialisent dans une seule caract\xe9ristique (monos\xe9mantique) tandis que d'autres repr\xe9sentent plusieurs caract\xe9ristiques (polys\xe9mantique)."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Transitions de phase dans l'entra\xeenement :"})," Il met en \xe9vidence un changement de phase",(0,i.jsx)(a.A,{id:"footnote_phase_transition",number:"1",text:"Un changement de phase dans l'entra\xeenement des r\xe9seaux neuronaux fait r\xe9f\xe9rence \xe0 un changement soudain et qualitatif dans le comportement ou la structure du mod\xe8le pendant le processus d'entra\xeenement."})," pendant l'entra\xeenement qui d\xe9termine si les caract\xe9ristiques sont stock\xe9es en superposition."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Organisation g\xe9om\xe9trique des caract\xe9ristiques :"})," Les caract\xe9ristiques en superposition sont organis\xe9es en structures g\xe9om\xe9triques telles que des digones, triangles, pentagones et t\xe9tra\xe8dres, fournissant un aper\xe7u de l'organisation interne du r\xe9seau."]}),"\n"]}),"\n"]}),(0,i.jsxs)(s.p,{children:["La figure suivante est une excellente illustration de la superposition dans un mod\xe8le jouet. Le mod\xe8le jouet a 2 dimensions, repr\xe9sent\xe9es par les axes x et y dans la figure ci-dessous, mais il doit apprendre 5 caract\xe9ristiques. Cela signifie que le mod\xe8le doit trouver un moyen d'int\xe9grer plus d'informations (5 caract\xe9ristiques) dans moins de dimensions (espace bidimensionnel). Chaque caract\xe9ristique se voit attribuer une importance, repr\xe9sent\xe9e par des couleurs. Une caract\xe9ristique importante est une caract\xe9ristique qui a un impact significatif sur la pr\xe9cision ou la ",(0,i.jsx)(n,{term:"loss function",definition:'{"definition":"Une fonction qui mesure dans quelle mesure les pr\xe9dictions d\'un mod\xe8le correspondent aux valeurs cibles r\xe9elles, utilis\xe9e pour guider l\'entra\xeenement..","source":"","aliases":["Loss Function","cost function","objective function","Fonction de perte"]}',children:(0,i.jsx)(n,{term:"loss function",definition:'{"definition":"Une fonction qui mesure dans quelle mesure les pr\xe9dictions d\'un mod\xe8le correspondent aux valeurs cibles r\xe9elles, utilis\xe9e pour guider l\'entra\xeenement..","source":"","aliases":["Loss Function","cost function","objective function","Fonction de perte"]}',children:"fonction de perte"})})," du mod\xe8le (si la suppression ou l'affaiblissement de la repr\xe9sentation de cette caract\xe9ristique cause une grande baisse de performance, elle serait consid\xe9r\xe9e comme importante). Le d\xe9fi principal dans la superposition est de savoir comment encoder efficacement les caract\xe9ristiques importantes tout en minimisant le chevauchement et l'interf\xe9rence entre elles."]}),(0,i.jsx)(s.p,{children:"Chaque caract\xe9ristique a \xe9galement une sparsit\xe9. Cela fait r\xe9f\xe9rence \xe0 la fr\xe9quence \xe0 laquelle elle est active dans le jeu de donn\xe9es. Une caract\xe9ristique dense (faible sparsit\xe9) est activ\xe9e fr\xe9quemment, rendant plus difficile la coexistence d'autres caract\xe9ristiques dans les m\xeames dimensions sans interf\xe9rence."}),(0,i.jsx)(c.A,{src:"./img/JNC_Image_17.png",alt:"Entrer la description alternative de l'image",number:"17",label:"9.17",caption:"Comment un mod\xe8le \xe0 2 dimensions encode-t-il 5 caract\xe9ristiques \xe0 mesure que leur parcimonie augmente ? Une parcimonie de 0 % signifie que les caract\xe9ristiques sont tr\xe8s denses ou fr\xe9quentes. Le mod\xe8le encode uniquement les deux caract\xe9ristiques les plus importantes dans des dimensions orthogonales. \xc0 mesure que la parcimonie augmente et que les caract\xe9ristiques importantes sont moins fr\xe9quemment utiles, le mod\xe8le jouet encode des caract\xe9ristiques suppl\xe9mentaires dans des directions non orthogonales. L'intuition est que moins les caract\xe9ristiques sont fr\xe9quentes, moins il est probable que deux caract\xe9ristiques qui se chevauchent soient activ\xe9es en m\xeame temps et causent des interf\xe9rences. Ainsi, le co\xfbt des interf\xe9rences entre les caract\xe9ristiques est compens\xe9 par l'avantage d'apprendre davantage de caract\xe9ristiques. \xc0 90 % de parcimonie, les 5 caract\xe9ristiques sont repr\xe9sent\xe9es sous forme de pentagone. D'apr\xe8s ([Elhage et al., 2022](https://transformer-circuits.pub/2022/toy_model/index.html))."}),(0,i.jsx)(s.p,{children:"Lors de l'encodage des caract\xe9ristiques, il y a un compromis \xe0 faire entre l'utilit\xe9 d'avoir autant de caract\xe9ristiques que possible et une faible interf\xe9rence entre elles. Les mod\xe8les int\xe8grent leurs caract\xe9ristiques dans des structures g\xe9om\xe9triques tr\xe8s complexes pour atteindre un encodage optimal. La figure ci-dessous montre les diff\xe9rentes structures g\xe9om\xe9triques que les mod\xe8les utilisent pour encoder les caract\xe9ristiques."}),(0,i.jsx)(c.A,{src:"./img/d6h_Image_18.png",alt:"Entrer la description alternative de l'image",number:"18",label:"9.18",caption:"\xc0 mesure que les caract\xe9ristiques deviennent plus \xe9parses (moins fr\xe9quemment activ\xe9es), un plus grand nombre d'entre elles peut \xeatre encod\xe9 de mani\xe8re optimale et dans des structures g\xe9om\xe9triques plus complexes. La premi\xe8re figure en haut \xe0 gauche montre que lorsque les caract\xe9ristiques sont tr\xe8s denses, seules les caract\xe9ristiques les plus importantes sont repr\xe9sent\xe9es et elles sont organis\xe9es en t\xe9tra\xe8dres. Ce mod\xe8le apprend 28 caract\xe9ristiques et les encode en 7 t\xe9tra\xe8dres. Sur la deuxi\xe8me figure, les caract\xe9ristiques sont l\xe9g\xe8rement plus \xe9parses, un plus grand nombre d'entre elles peut \xeatre encod\xe9 de mani\xe8re optimale, et les t\xe9tra\xe8dres sont remplac\xe9s par des triangles et des digones. Ce mod\xe8le apprend 46 caract\xe9ristiques encod\xe9es en triangles et digones. La superposition pr\xe9sente une structure g\xe9om\xe9trique complexe. D'apr\xe8s ([Elhage et al., 2022](https://transformer-circuits.pub/2022/toy_model/index.html))."})]}),"\n",(0,i.jsx)(s.h2,{id:"05",children:"Auto-encodeurs parcimonieux"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Un d\xe9fi majeur en interpr\xe9tabilit\xe9 m\xe9caniste est la polys\xe9mantique, o\xf9 un seul neurone ou une seule caract\xe9ristique repr\xe9sente plusieurs concepts sans rapport entre eux."})," La polys\xe9mantique appara\xeet naturellement dans les MLP et les flux r\xe9siduels des LLM, et complique l'identification des caract\xe9ristiques sp\xe9cifiques qui influencent le r\xe9sultat d'un mod\xe8le. Les Auto-Encodeurs Parcimonieux (AEP) constituent une approche prometteuse pour d\xe9m\xealer les caract\xe9ristiques au sein d'un r\xe9seau (",(0,i.jsx)(s.a,{href:"https://transformer-circuits.pub/2023/monosemantic-features",children:"Bricken et al., 2023"}),", ",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2406.04093",children:"Gao et al., 2024"}),", ",(0,i.jsx)(s.a,{href:"https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html#related-work-steering",children:"Templeton et al., 2024"}),")."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les AEP gagnent en popularit\xe9 car ils ont montr\xe9 des r\xe9sultats prometteurs dans la s\xe9paration des caract\xe9ristiques."})," Les caract\xe9ristiques extraites \xe0 l'aide des AEP peuvent ensuite \xeatre utilis\xe9es pour :"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Orienter le comportement des mod\xe8les de langage loin des r\xe9sultats ind\xe9sirables (voir section Pilotage des Activations). (",(0,i.jsx)(s.a,{href:"https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html#related-work-steering",children:"Templeton et al., 2024"}),") a trouv\xe9 de nombreuses caract\xe9ristiques li\xe9es \xe0 la s\xe9curit\xe9 dans Claude 3 Sonnet, notamment des caract\xe9ristiques pour le code dangereux, les biais, la sycophantie, la tromperie et la recherche de pouvoir, ainsi que les informations dangereuses ou criminelles. Ces caract\xe9ristiques s'activent sur les textes impliquant ces sujets et influencent causalement les sorties du mod\xe8le lorsqu'on intervient dessus."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Trouver des circuits plus interpr\xe9tables directement constitu\xe9s de caract\xe9ristiques plut\xf4t que de composants du mod\xe8le. En particulier, trouver et comprendre les circuits dans lesquels les caract\xe9ristiques li\xe9es \xe0 la s\xe9curit\xe9 sont impliqu\xe9es pourrait \xeatre pr\xe9cieux (voir section sur l'Automatisation et la Mise \xe0 l'\xe9chelle de l'Interpr\xe9tabilit\xe9)."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"Les AEP sont \xe9galement excellents car ils sont entra\xeen\xe9s de mani\xe8re non supervis\xe9e, ce qui nous permet de d\xe9couvrir des abstractions ou des associations form\xe9es par le mod\xe8le que nous n'aurions pas pu anticiper."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Qu'est-ce qu'un auto-encodeur ?"})," Un auto-encodeur est un r\xe9seau neuronal con\xe7u pour apprendre des repr\xe9sentations compress\xe9es des donn\xe9es d'entr\xe9e en les encodant dans un espace latent de dimension inf\xe9rieure puis en reconstruisant l'entr\xe9e originale \xe0 partir de cette repr\xe9sentation. L'espace latent est la couche o\xf9 les donn\xe9es sont repr\xe9sent\xe9es sous une forme compress\xe9e ou abstraite, contenant les caract\xe9ristiques cl\xe9s n\xe9cessaires \xe0 la reconstruction de l'entr\xe9e. Cette repr\xe9sentation apprise capture souvent les motifs ou caract\xe9ristiques essentiels des donn\xe9es."]}),"\n",(0,i.jsx)(c.A,{src:"./img/7wM_Image_19.png",alt:"Entrer la description alternative de l'image",number:"19",label:"9.19",caption:"Un auto-encodeur apprend deux transformations, repr\xe9sent\xe9es par les poids de l'encodeur et les poids du d\xe9codeur, pour compresser les donn\xe9es d'entr\xe9e dans un espace latent de dimension inf\xe9rieure puis reconstruire l'entr\xe9e originale \xe0 partir de cette repr\xe9sentation."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:'Pourquoi les AEP sont-ils "parcimonieux" ?'}),' Les auto-encodeurs peuvent varier en structure et en objectif. Les AEP sont des auto-encodeurs qui introduisent des contraintes de parcimonie sur les activations dans l\'espace latent, encourageant le mod\xe8le \xe0 utiliser un nombre limit\xe9 de neurones latents pour chaque entr\xe9e. Cette "parcimonie" force le mod\xe8le \xe0 apprendre des caract\xe9ristiques distinctes et sp\xe9cifiques, rendant les repr\xe9sentations plus interpr\xe9tables.']}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Comment les AEP aident-ils \xe0 d\xe9m\xealer les caract\xe9ristiques dans les transformers ?"})," Le processus de d\xe9m\xealage des activations du mod\xe8le en caract\xe9ristiques interpr\xe9tables implique g\xe9n\xe9ralement l'entra\xeenement d'un auto-encodeur parcimonieux pour reconstruire les activations de parties sp\xe9cifiques d'un mod\xe8le, comme le MLP d'une couche particuli\xe8re ou un flux r\xe9siduel, avec un espace latent plus grand que l'entr\xe9e",(0,i.jsx)(a.A,{id:"footnote_overcomplete_autoencoders",number:"2",text:"Un auto-encodeur avec un espace latent plus grand que son entr\xe9e est appel\xe9 un auto-encodeur surcomplet."}),", de sorte que chaque neurone dans l'espace latent soit id\xe9alement monos\xe9mantique - repr\xe9sentant une seule caract\xe9ristique - et interpr\xe9table."]}),"\n",(0,i.jsx)(c.A,{src:"./img/ckD_Image_20.png",alt:"Entrer la description alternative de l'image",number:"20",label:"9.20",caption:"Les activations des mod\xe8les peuvent \xeatre d\xe9compos\xe9es en caract\xe9ristiques \xe0 l'aide d'un auto-encodeur parcimonieux. Cette figure illustre un SAE entra\xeen\xe9 pour d\xe9m\xealer les caract\xe9ristiques dans un MLP. D'apr\xe8s ([Bricken et al., 2023](https://transformer-circuits.pub/2023/monosemantic-features))."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Apprentissage de dictionnaire."})," Apr\xe8s l'entra\xeenement d'un AEP, chaque neurone dans son espace latent peut \xeatre analys\xe9 pour comprendre \xe0 quelles entr\xe9es ou caract\xe9ristiques sp\xe9cifiques il r\xe9pond. En identifiant ces r\xe9ponses, les chercheurs peuvent effectivement construire un \"dictionnaire\" de caract\xe9ristiques, o\xf9 chaque neurone correspond \xe0 une caract\xe9ristique distincte dans les donn\xe9es. Ce processus d'entra\xeenement des AEP sur diverses couches et parties d'un mod\xe8le pour identifier ces caract\xe9ristiques est connu sous le nom d'apprentissage de dictionnaire."]}),"\n",(0,i.jsxs)(s.p,{children:["Par exemple, dans une \xe9tude sur Claude 3 Sonnet, des caract\xe9ristiques li\xe9es \xe0 la s\xe9curit\xe9 telles que celles pour le \"code dangereux\" ou les \"jetons d'erreur\" ont \xe9t\xe9 identifi\xe9es en utilisant des AEP. De mani\xe8re int\xe9ressante, l'augmentation de l'activation de la caract\xe9ristique de code dangereux dans l'espace latent de l'AEP et la r\xe9injection dans le mod\xe8le des activations reconstruites par l'AEP l'ont amen\xe9 \xe0 g\xe9n\xe9rer une vuln\xe9rabilit\xe9 de d\xe9passement de tampon (",(0,i.jsx)(s.a,{href:"https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html#related-work-steering",children:"Templeton et al., 2024"}),")."]}),"\n",(0,i.jsx)(c.A,{src:"./img/5xS_Image_21.png",alt:"Entrer la description alternative de l'image",number:"21",label:"9.21",caption:"Exemples de caract\xe9ristiques li\xe9es \xe0 la s\xe9curit\xe9 extraites de Claude 3 Sonnet, telles que les caract\xe9ristiques pour le code non s\xe9curis\xe9 et les jetons d'erreur. L'\xe9chelle de couleurs indique le degr\xe9 d'activation de chaque caract\xe9ristique pour chaque jeton, avec un orange plus fonc\xe9 indiquant une activation plus \xe9lev\xe9e. La caract\xe9ristique \"erreur de code\" s'active fortement sur les jetons qui contiennent une erreur. Les images pr\xe9sent\xe9es correspondent aux exemples qui activent fortement la caract\xe9ristique sp\xe9cifique. D'apr\xe8s ([Templeton et al., 2024](https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html))."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Limitations et directions de recherche ouvertes pour les AEP."})," Bien que prometteurs, les AEP sont encore un travail pr\xe9coce avec des limitations :"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Compr\xe9hension incompl\xe8te de l'utilisation du mod\xe8le :"})," L'identification des caract\xe9ristiques du mod\xe8le ne r\xe9v\xe8le pas comment elles sont utilis\xe9es pendant l'inf\xe9rence, nous devons encore trouver les circuits qui les impliquent."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Difficult\xe9 d'interpr\xe9tation des caract\xe9ristiques :"})," Toutes les caract\xe9ristiques d\xe9couvertes par les AEP ne sont pas facilement interpr\xe9tables ; certaines caract\xe9ristiques restent difficiles \xe0 comprendre."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Manque de m\xe9thodes de validation :"})," Actuellement, il existe des m\xe9thodes limit\xe9es pour tester la validit\xe9 des interpr\xe9tations des caract\xe9ristiques."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les AEP ont une mauvaise qualit\xe9 de reconstruction :"})," Les auto-encodeurs parcimonieux ne reconstruisent pas tr\xe8s bien les activations du mod\xe8le, ce qui signifie qu'ils ne capturent pas compl\xe8tement le comportement de nos mod\xe8les. Par exemple, faire passer les activations de GPT-4 \xe0 travers un AEP donne des performances \xe9quivalentes \xe0 un mod\xe8le entra\xeen\xe9 avec 10 fois moins de calcul (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2406.04093",children:"Gao et al., 2024"}),")."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"Les AEP soul\xe8vent des questions de recherche intrigantes pour la s\xe9curit\xe9 et l'interpr\xe9tabilit\xe9 de l'IA :"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Quelles caract\xe9ristiques s'activent pendant les contournements de s\xe9curit\xe9 ?"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Quelles caract\xe9ristiques doivent s'activer ou rester inactives pour qu'un mod\xe8le donne des conseils sur la production de cyberattaques, d'armes biologiques, etc. ?"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Pouvons-nous utiliser la base des caract\xe9ristiques pour d\xe9tecter quand le ",(0,i.jsx)(n,{term:"fine-tuning",definition:'{"definition":"Processus consistant \xe0 prendre un mod\xe8le pr\xe9-entra\xeen\xe9 et \xe0 le perfectionner pour une t\xe2che ou un ensemble de donn\xe9es sp\xe9cifique..","source":"","aliases":["Fine-tuning","fine-tune","finetuning","finetune","affinage","Affinage"]}',children:(0,i.jsx)(n,{term:"fine-tuning",definition:'{"definition":"Processus consistant \xe0 prendre un mod\xe8le pr\xe9-entra\xeen\xe9 et \xe0 le perfectionner pour une t\xe2che ou un ensemble de donn\xe9es sp\xe9cifique..","source":"","aliases":["Fine-tuning","fine-tune","finetuning","finetune","affinage","Affinage"]}',children:"fine-tuning"})})," d'un mod\xe8le augmente la probabilit\xe9 de comportements ind\xe9sirables ?"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(a.c,{title:"Notes de bas de page"})]})}function x(e={}){const{wrapper:s}={...(0,r.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},4768:(e,s,n)=>{n.d(s,{c:()=>u,A:()=>c});var t=n(6540),i=n(3012);const r={footnoteAnchor:"footnoteAnchor_PZpY",footnoteSection:"footnoteSection_waoz",separator:"separator_hp8y",separatorLine:"separatorLine_uVnd",separatorLogo:"separatorLogo_dMBq",footnoteRegistry:"footnoteRegistry_ieVW",registryTitle:"registryTitle_ybBb",footnoteList:"footnoteList_Kjil",footnoteItem:"footnoteItem_aLZ2",footnoteNumber:"footnoteNumber_dA3X",footnoteContent:"footnoteContent_Xfmt",backButton:"backButton_vSVm",highlighted:"highlighted_YFU0",highlight:"highlight_jxG3",highlightDark:"highlightDark_Ekom"};var a=n(4848);function o(e,s){void 0===s&&(s=!0);const n=document.getElementById(e);n&&(n.scrollIntoView({behavior:"smooth"}),s&&(n.classList.add(r.highlighted),setTimeout((()=>n.classList.remove(r.highlighted)),1500)))}function l(e){return e?e.replace(/\[([^\]]+)\]\(([^)]+)\)/g,'<a href="$2" target="_blank" rel="noopener noreferrer">$1</a>'):""}function c(e){let{id:s,text:n,number:c}=e;const u=s||`footnote-${Math.random().toString(36).substr(2,9)}`,d="string"==typeof n?l(n):n;return(0,t.useEffect)((()=>{const e=setTimeout((()=>{const e=document.getElementById(`footnote-clone-${u}`);e&&n&&(e.innerHTML="string"==typeof n?l(n):n.toString())}),100);return()=>clearTimeout(e)}),[u,n]),(0,a.jsx)(i.Mn,{content:(0,a.jsx)("div",{dangerouslySetInnerHTML:{__html:d}}),children:(0,a.jsx)("sup",{id:`footnote-ref-${u}`,className:r.footnoteAnchor,onClick:e=>{(e.ctrlKey||e.metaKey)&&(e.preventDefault(),o(`footnote-content-${u}`))},"data-footnote-number":c||"?",children:c||"*"})})}function u(e){let{title:s="References"}=e;const[n,l]=(0,t.useState)([]);return(0,t.useEffect)((()=>{const e=document.querySelectorAll('[id^="footnote-ref-"]'),s=Array.from(e).map((e=>({id:e.id.replace("footnote-ref-",""),number:e.getAttribute("data-footnote-number")||e.textContent})));l(s)}),[]),n.length?(0,a.jsxs)("div",{className:r.footnoteSection,children:[(0,a.jsxs)("div",{className:r.separator,children:[(0,a.jsx)("div",{className:r.separatorLine}),(0,a.jsx)("img",{src:"/img/logo_samples/01-test.svg",alt:"Atlas logo",className:r.separatorLogo}),(0,a.jsx)("div",{className:r.separatorLine})]}),(0,a.jsxs)("div",{className:r.footnoteRegistry,children:[(0,a.jsx)("h2",{className:r.registryTitle,children:s}),(0,a.jsx)("ol",{className:r.footnoteList,children:n.map((e=>(0,a.jsxs)("li",{id:`footnote-content-${e.id}`,className:r.footnoteItem,value:parseInt(e.number)||void 0,children:[(0,a.jsx)(i.Mn,{content:"Back to reference",children:(0,a.jsxs)("button",{className:r.footnoteNumber,onClick:()=>o(`footnote-ref-${e.id}`),"aria-label":"Back to reference",children:[e.number,"."]})}),(0,a.jsx)("div",{className:r.footnoteContent,children:(0,a.jsx)("div",{id:`footnote-clone-${e.id}`})}),(0,a.jsx)(i.Mn,{content:"Back to reference",children:(0,a.jsx)("button",{className:r.backButton,onClick:()=>o(`footnote-ref-${e.id}`),"aria-label":"Back to reference",children:"\u21a9"})})]},e.id)))})]})]}):null}}}]);