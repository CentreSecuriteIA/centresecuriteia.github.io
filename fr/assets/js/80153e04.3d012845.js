"use strict";(self.webpackChunkatlas=self.webpackChunkatlas||[]).push([[6281],{9468:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>p,contentTitle:()=>c,default:()=>f,frontMatter:()=>u,metadata:()=>t,toc:()=>m});const t=JSON.parse('{"id":"chapters/03/2","title":"Strat\xe9gies de pr\xe9vention des abus","description":"Les strat\xe9gies pour pr\xe9venir les utilisations abusives se concentrent souvent sur le contr\xf4le de l\'acc\xe8s aux capacit\xe9s dangereuses ou la mise en \u0153uvre de mesures de protection techniques pour limiter les applications nuisibles.","source":"@site/i18n/fr/docusaurus-plugin-content-docs/current/chapters/03/02.md","sourceDirName":"chapters/03","slug":"/chapters/03/02","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/03/02","draft":false,"unlisted":false,"editUrl":"https://github.com/markov-root/atlas/edit/main/docs/chapters/03/02.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"2","title":"Strat\xe9gies de pr\xe9vention des abus","sidebar_label":"3.2 Strat\xe9gies de pr\xe9vention des abus","sidebar_position":3,"slug":"/chapters/03/02","section_description":"Beyond technical controls, what combination of legal, social, and educational measures is needed to address AI misuse risks that are already widespread?","reading_time_core":"9 min","reading_time_optional":"12 min","pagination_prev":"chapters/03/1","pagination_next":"chapters/03/3"},"sidebar":"docs","previous":{"title":"3.1 D\xe9finitions","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/03/01"},"next":{"title":"3.3 Strat\xe9gies de s\xe9curit\xe9 pour l\'AGI","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/03/03"}}');var i=n(4848),r=n(8453),a=n(2482),o=n(8559),l=n(9585),d=n(2501);const u={id:2,title:"Strat\xe9gies de pr\xe9vention des abus",sidebar_label:"3.2 Strat\xe9gies de pr\xe9vention des abus",sidebar_position:3,slug:"/chapters/03/02",section_description:"Beyond technical controls, what combination of legal, social, and educational measures is needed to address AI misuse risks that are already widespread?",reading_time_core:"9 min",reading_time_optional:"12 min",pagination_prev:"chapters/03/1",pagination_next:"chapters/03/3"},c="Strat\xe9gies de pr\xe9vention des utilisations abusives",p={},m=[{value:"Contr\xf4les d&#39;acc\xe8s",id:"01",level:2},{value:"Contr\xf4les externes",id:"01-01",level:3},{value:"Contr\xf4les Internes",id:"01-02",level:3},{value:"Protections Techniques",id:"01-03",level:3},{value:"Strat\xe9gies socio-techniques",id:"02",level:2}];function h(e){const s={a:"a",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components},{GlossaryTerm:n}=s;return n||function(e,s){throw new Error("Expected "+(s?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("GlossaryTerm",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.header,{children:(0,i.jsx)(s.h1,{id:"strat\xe9gies-de-pr\xe9vention-des-utilisations-abusives",children:"Strat\xe9gies de pr\xe9vention des utilisations abusives"})}),"\n",(0,i.jsx)(s.p,{children:"Les strat\xe9gies pour pr\xe9venir les utilisations abusives se concentrent souvent sur le contr\xf4le de l'acc\xe8s aux capacit\xe9s dangereuses ou la mise en \u0153uvre de mesures de protection techniques pour limiter les applications nuisibles."}),"\n",(0,i.jsx)(s.h2,{id:"01",children:"Contr\xf4les d'acc\xe8s"}),"\n",(0,i.jsx)(s.h3,{id:"01-01",children:"Contr\xf4les externes"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les strat\xe9gies de contr\xf4le d'acc\xe8s abordent directement la tension inh\xe9rente entre les avantages de l'open source et les risques d'utilisation abusive."}),' L\'industrie de l\'IA est all\xe9e au-del\xe0 des discussions binaires "publier" ou "ne pas publier" ; les praticiens pensent d\xe9sormais en termes de gradient continu d\'acc\xe8s aux mod\xe8les (',(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2403.07918",children:"Kapoor et al., 2024, On the Societal Impact of Open Foundation Models"}),"). La question de savoir qui a acc\xe8s \xe0 un mod\xe8le se situe sur une \xe9chelle allant de totalement ferm\xe9 (usage interne uniquement) \xe0 totalement ouvert (poids du mod\xe8le disponibles publiquement sans restrictions)."]}),"\n",(0,i.jsxs)(l.A,{term:"L'IA Open Source",source:"([Open Source Initiative, 2025](https://opensource.org/ai))",number:"5",label:"3.5",children:[(0,i.jsx)(s.p,{children:"Une IA Open Source est un syst\xe8me d'IA mis \xe0 disposition selon des conditions qui accordent les libert\xe9s de :"}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Utiliser le syst\xe8me \xe0 toute fin sans avoir \xe0 demander la permission."}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"\xc9tudier comment le syst\xe8me fonctionne et inspecter ses composants."}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Modifier le syst\xe8me \xe0 toute fin, y compris pour changer ses r\xe9sultats."}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Partager le syst\xe8me pour que d'autres puissent l'utiliser avec ou sans modifications, \xe0 toute fin."}),"\n"]}),"\n"]})]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Parmi ces diff\xe9rentes options d'acc\xe8s, le d\xe9ploiement par API repr\xe9sente l'un des compromis strat\xe9giques les plus couramment utilis\xe9s."})," Lorsque nous discutons des contr\xf4les d'acc\xe8s dans cette section, nous parlons principalement des m\xe9canismes qui cr\xe9ent une passerelle contr\xf4l\xe9e vers les capacit\xe9s d'IA\u2014le plus souvent via un d\xe9ploiement par API, o\xf9 la majeure partie du mod\xe8le (code, poids et donn\xe9es) reste totalement ferm\xe9e, mais l'acc\xe8s aux capacit\xe9s du mod\xe8le est partiellement ouvert. Dans cette configuration, les d\xe9veloppeurs conservent le contr\xf4le sur la fa\xe7on dont leurs mod\xe8les sont accessibles et utilis\xe9s. Les contr\xf4les bas\xe9s sur l'API maintiennent la supervision des d\xe9veloppeurs, permettant une surveillance continue, la mise \xe0 jour des mesures de s\xe9curit\xe9 et la possibilit\xe9 de r\xe9voquer l'acc\xe8s si n\xe9cessaire (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2311.09227",children:"Seger et al., 2023"}),")."]}),"\n",(0,i.jsx)(d.A,{src:"./img/aWH_Image_2.png",alt:"Saisir la description alternative de l'image",number:"2",label:"3.2",caption:"Ceci est un diagramme simplifi\xe9 pour illustrer conceptuellement comment une API fonctionnerait. Ce n'est pas ainsi que fonctionne l'API d'OpenAI. C'est uniquement \xe0 des fins d'illustration."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Le d\xe9ploiement par API \xe9tablit une couche de protection entre les utilisateurs et les capacit\xe9s du mod\xe8le."})," Au lieu de t\xe9l\xe9charger le code ou les poids du mod\xe8le, les utilisateurs interagissent avec le mod\xe8le en envoyant des requ\xeates \xe0 un serveur o\xf9 le mod\xe8le s'ex\xe9cute, ne recevant en retour que les sorties g\xe9n\xe9r\xe9es. Cette architecture permet aux d\xe9veloppeurs de mettre en \u0153uvre divers m\xe9canismes de s\xe9curit\xe9 :"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Filtrage des entr\xe9es/sorties :"})," Filtrage des prompts pour d\xe9tecter le contenu nuisible et filtrage des r\xe9ponses g\xe9n\xe9r\xe9es selon les politiques de s\xe9curit\xe9. Par exemple, les filtres peuvent d\xe9tecter et bloquer les tentatives de g\xe9n\xe9ration de CSAM ou d'instructions pour fabriquer des armes. Cette approche contrecarre directement les utilisations abusives comme la g\xe9n\xe9ration de contenu ill\xe9gal ou d'instructions dangereuses."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Limitation du d\xe9bit :"})," Pr\xe9vention des utilisations abusives \xe0 grande \xe9chelle gr\xe2ce \xe0 des plafonds d'utilisation. En limitant le volume des requ\xeates, ces contr\xf4les att\xe9nuent les risques d'abus automatis\xe9s comme la g\xe9n\xe9ration de milliers de deepfakes ou de messages spam (",(0,i.jsx)(s.a,{href:"https://crfm.stanford.edu/2022/05/17/community-norms.html",children:"Liang et al., 2022"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Surveillance de l'utilisation :"})," Au-del\xe0 du contr\xf4le du volume des requ\xeates, la surveillance de l'utilisation permet des v\xe9rifications d'identit\xe9 et d'ant\xe9c\xe9dents pour les utilisateurs malveillants (similaire aux lois KYC). Par exemple, cela permet une surveillance r\xe9glementaire, emp\xeache les tentatives r\xe9p\xe9t\xe9es de contourner les filtres de s\xe9curit\xe9, et permet \xe9galement un acc\xe8s plus approfondi aux utilisateurs hautement fiables (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2310.13625",children:"Egan & Heim, 2023"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Restrictions d'utilisation :"})," Application de conditions d'utilisation qui interdisent les applications nuisibles. Les entreprises peuvent restreindre les applications \xe0 haut risque comme la recherche sur les armes biologiques ou les op\xe9rations cyber autonomes via des accords juridiques soutenus par une surveillance technique (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2307.03718",children:"Anderljung et al., 2023"}),"). Lorsque des violations sont d\xe9tect\xe9es, l'acc\xe8s peut \xeatre r\xe9voqu\xe9."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Mises \xe0 jour \xe0 la vol\xe9e :"})," D\xe9ploiement rapide d'am\xe9liorations des syst\xe8mes de s\xe9curit\xe9 sans action de l'utilisateur. Contrairement aux mod\xe8les open source o\xf9 les versions non s\xe9curis\xe9es persistent ind\xe9finiment, les mod\xe8les bas\xe9s sur API peuvent \xeatre continuellement am\xe9lior\xe9s pour faire face aux vuln\xe9rabilit\xe9s nouvellement d\xe9couvertes (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2310.11986",children:"Weidinger et al., 2023"}),"). Cela aide \xe0 contrer les nouveaux vecteurs d'attaque comme les techniques de jailbreak."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(d.A,{src:"./img/F2O_Image_3.png",alt:"Saisir la description alternative de l'image",number:"3",label:"3.3",caption:"Le gradient d'acc\xe8s aux mod\xe8les d'IA pour le public externe. La publication des mod\xe8les existe sur un spectre, allant des syst\xe8mes enti\xe8rement ferm\xe9s accessibles uniquement en interne, aux versions \xe9chelonn\xe9es, \xe0 l'acc\xe8s API, aux poids t\xe9l\xe9chargeables avec restrictions, et aux versions enti\xe8rement open source. Le d\xe9ploiement bas\xe9 sur API repr\xe9sente un point interm\xe9diaire sur ce gradient ([Seger et al., 2023](https://arxiv.org/abs/2311.09227))."}),"\n",(0,i.jsxs)(o.A,{title:"Diff\xe9rents composants d'un mod\xe8le peuvent exister \xe0 diff\xe9rents points du spectre d'acc\xe8s",collapsed:!0,children:[(0,i.jsx)(d.A,{src:"./img/J1c_Image_4.png",alt:"Saisir la description alternative de l'image",number:"4",label:"3.4",caption:"Un gradient d'acc\xe8s diff\xe9rent propos\xe9 se concentrant \xe0 la fois sur le code du mod\xe8le et les donn\xe9es d'entra\xeenement ([Eiras et al., 2024](https://arxiv.org/abs/2404.17047)). Nous pouvons voir des combinaisons de niveaux d'acc\xe8s, par exemple DeepSeek-V3 pourrait \xeatre consid\xe9r\xe9 approximativement comme C5-D1 ([DeepSeek, 2025](https://github.com/deepseek-ai/DeepSeek-V3))."}),(0,i.jsx)(s.p,{children:"Nous pouvons autoriser l'acc\xe8s aux capacit\xe9s, au code, aux poids, aux donn\xe9es d'entra\xeenement et \xe0 la gouvernance \xe0 diff\xe9rents niveaux. Cette granularit\xe9 permet des contr\xf4les d'acc\xe8s pr\xe9cis qui att\xe9nuent les pr\xe9occupations de risques catastrophiques tout en maximisant les avantages. Par exemple, voici quelques classifications granulaires des niveaux d'acc\xe8s \xe0 certains mod\xe8les populaires :"}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"OpenAI GPT-4 : C1-D1-W2 : Code et donn\xe9es ferm\xe9s, acc\xe8s aux poids uniquement par API."}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Anthropic Claude : C1-D1-W2 : Code et donn\xe9es ferm\xe9s, acc\xe8s uniquement par API, gouvernance plus transparente."}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"DeepSeek : C5-D1-W4 : Code ouvert, donn\xe9es ferm\xe9es, poids t\xe9l\xe9chargeables avec restrictions."}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Llama 2 : C3-D1-W4 : Licence de code mod\xe9r\xe9ment restreinte, donn\xe9es ferm\xe9es, poids t\xe9l\xe9chargeables avec restrictions d'utilisation."}),"\n"]}),"\n"]})]}),"\n",(0,i.jsx)(a.A,{speaker:"Ajeya Cotra",position:"Conseiller principal chez Open Philanthropy",date:"2024",source:"([Piper, 2024](https://www.vox.com/future-perfect/2024/2/2/24058484/open-source-artificial-intelligence-ai-risk-meta-llama-2-chatgpt-openai-deepfake))",children:(0,i.jsx)(s.p,{children:"La plupart des syst\xe8mes trop dangereux pour \xeatre open source sont probablement trop dangereux pour \xeatre entra\xeen\xe9s compte tenu des pratiques courantes dans les laboratoires aujourd'hui, o\xf9 il est tr\xe8s plausible qu'ils fuient, ou tr\xe8s plausible qu'ils soient vol\xe9s, ou tr\xe8s plausible que s'ils sont disponibles via une API, ils puissent causer des dommages."})}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Le contr\xf4le centralis\xe9 soul\xe8ve des questions sur la dynamique du pouvoir dans le d\xe9veloppement de l'IA."})," Lorsque les d\xe9veloppeurs maintiennent un contr\xf4le exclusif sur les capacit\xe9s du mod\xe8le, ils prennent des d\xe9cisions unilat\xe9rales sur les utilisations acceptables, les filtres de contenu appropri\xe9s et qui re\xe7oit l'acc\xe8s. Cette concentration du pouvoir est en tension avec le potentiel d\xe9mocratisant d'approches plus ouvertes. La strat\xe9gie d'att\xe9nuation des utilisations abusives par la restriction de l'acc\xe8s cr\xe9e donc un effet secondaire de centralisation et de concentration potentielle du pouvoir, qui n\xe9cessite d'autres strat\xe9gies techniques et de gouvernance pour contrebalancer."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:'La premi\xe8re \xe9tape de la strat\xe9gie de "Contr\xf4le d\'acc\xe8s" consiste \xe0 identifier quels mod\xe8les sont consid\xe9r\xe9s comme dangereux et lesquels ne le sont pas via des \xe9valuations de mod\xe8les.'})," Avant de d\xe9ployer des mod\xe8les puissants, les d\xe9veloppeurs (ou des tiers) devraient les \xe9valuer pour des capacit\xe9s dangereuses sp\xe9cifiques, comme la capacit\xe9 d'aider dans les cyberattaques ou la conception d'armes biologiques. Ces \xe9valuations guident les d\xe9cisions concernant le d\xe9ploiement et les garanties n\xe9cessaires (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2305.15324",children:"Shevlane et al., 2023"}),")."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Le Red Teaming peut aider \xe0 \xe9valuer si les mesures d'att\xe9nuation sont suffisantes."})," Pendant le red teaming, des \xe9quipes internes tentent d'exploiter les faiblesses du syst\xe8me pour am\xe9liorer sa s\xe9curit\xe9. Ils devraient tester si un utilisateur malveillant hypoth\xe9tique peut obtenir suffisamment de bits de conseil du mod\xe8le sans se faire rep\xe9rer. Nous abordons plus en d\xe9tail des concepts comme le red teaming et les \xe9valuations de mod\xe8les dans le chapitre suivant d\xe9di\xe9 au sujet."]}),"\n",(0,i.jsxs)(o.A,{title:"Assurer un \xe9quilibre positif entre l'offensive et la d\xe9fensive dans un monde open source",collapsed:!0,children:[(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"L'\xe9quilibre entre l'attaque et la d\xe9fense fa\xe7onne les d\xe9cisions d'acc\xe8s pour les mod\xe8les d'IA de pointe."})," Ce concept fait r\xe9f\xe9rence \xe0 la facilit\xe9 relative avec laquelle les d\xe9fenseurs peuvent se prot\xe9ger contre les attaquants par rapport \xe0 la facilit\xe9 avec laquelle les attaquants peuvent exploiter les vuln\xe9rabilit\xe9s. Comprendre cet \xe9quilibre est crucial pour \xe9valuer si l'open source de mod\xe8les puissants sera b\xe9n\xe9fique ou nuisible net. Dans le d\xe9veloppement logiciel traditionnel, l'open source renforce g\xe9n\xe9ralement la d\xe9fense\u2014une transparence accrue permet \xe0 une communaut\xe9 plus large d'identifier et de corriger les vuln\xe9rabilit\xe9s, am\xe9liorant la s\xe9curit\xe9 globale (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2311.09227",children:"Seger et al., 2023"}),"). Cependant, les mod\xe8les d'IA de pointe peuvent fondamentalement changer cette dynamique. Contrairement aux bugs logiciels conventionnels qui peuvent \xeatre corrig\xe9s, ces mod\xe8les introduisent de nouveaux risques qui r\xe9sistent aux corrections simples. Par exemple, une fois qu'une capacit\xe9 nuisible est d\xe9couverte dans un mod\xe8le ouvert, elle ne peut pas \xeatre \"d\xe9sapprise\" dans toutes les copies d\xe9ploy\xe9es."]}),(0,i.jsxs)(s.p,{children:["Les avantages et risques sp\xe9cifiques des ",(0,i.jsx)(n,{term:"foundation model",definition:'{"definition":"Mod\xe8le \xe0 grande \xe9chelle entra\xeen\xe9 sur des donn\xe9es diverses qui sert de base \xe0 l\'adaptation \xe0 diverses t\xe2ches en aval, g\xe9n\xe9ralement par le biais d\'un r\xe9glage fin ou d\'une incitation.","source":"[Bommasani et al., 2021](https://arxiv.org/abs/2108.07258)","aliases":["Foundation Model","foundation models","base model","mod\xe8le de base","mod\xe8les de base","mod\xe8le fondation","mod\xe8les fondation","mod\xe8le de fondation","mod\xe8les de fondation","Mod\xe8le de fondation"]}',children:(0,i.jsx)(n,{term:"foundation model",definition:'{"definition":"Mod\xe8le \xe0 grande \xe9chelle entra\xeen\xe9 sur des donn\xe9es diverses qui sert de base \xe0 l\'adaptation \xe0 diverses t\xe2ches en aval, g\xe9n\xe9ralement par le biais d\'un r\xe9glage fin ou d\'une incitation.","source":"[Bommasani et al., 2021](https://arxiv.org/abs/2108.07258)","aliases":["Foundation Model","foundation models","base model","mod\xe8le de base","mod\xe8les de base","mod\xe8le fondation","mod\xe8les fondation","mod\xe8le de fondation","mod\xe8les de fondation","Mod\xe8le de fondation"]}',children:"mod\xe8les de fondation"})})," ouverts d\xe9coulent de leurs propri\xe9t\xe9s distinctives par rapport aux mod\xe8les ferm\xe9s : acc\xe8s plus large, plus grande personnalisation, capacit\xe9 d'inf\xe9rence locale, impossibilit\xe9 de r\xe9voquer l'acc\xe8s et faible capacit\xe9 de surveillance."]}),(0,i.jsx)(d.A,{src:"./img/c9x_Image_5.png",alt:"Saisir la description alternative de l'image",number:"5",label:"3.5",caption:"Une vue extr\xeamement simplifi\xe9e du compromis entre l'absence de publication, qui peut augmenter le contr\xf4le sur les risques imm\xe9diats, et la publication enti\xe8rement ouverte, qui permet une meilleure compr\xe9hension des risques \xe0 long terme ([Liang et al., 2022](https://crfm.stanford.edu/2022/05/17/community-norms.html))"}),(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"Arguments en faveur d'une plus grande ouverture :"})}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"D\xe9mocratisation de la prise de d\xe9cision."})," Lorsque les mod\xe8les sont exclusivement contr\xf4l\xe9s par des entreprises bien dot\xe9es en ressources, ces entit\xe9s d\xe9terminent unilat\xe9ralement les cas d'utilisation acceptables et les politiques de contenu. Les mod\xe8les ouverts distribuent ce pouvoir plus largement. Cela emp\xeache la concentration du pouvoir, le verrouillage des valeurs et refl\xe8te mieux les int\xe9r\xeats soci\xe9taux divers (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2403.07918",children:"Kapoor et al, 2024"}),"; ",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2404.17047",children:"Eiras et al., 2024"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Recherche acc\xe9l\xe9r\xe9e sur la s\xe9curit\xe9."})," Les poids de mod\xe8les ouverts permettent une recherche sur la s\xe9curit\xe9 qui n\xe9cessite un acc\xe8s direct au mod\xe8le, y compris des \xe9tudes d'interpr\xe9tabilit\xe9 qui seraient impossibles par le seul acc\xe8s API. La recherche sur le contr\xf4le des repr\xe9sentations, l'ing\xe9nierie d'activation et les m\xe9canismes de s\xe9curit\xe9 a consid\xe9rablement progress\xe9 gr\xe2ce \xe0 l'acc\xe8s aux poids des mod\xe8les (",(0,i.jsx)(s.a,{href:"https://www.beren.io/2023-11-05-Open-source-AI-has-been-vital-for-alignment/",children:"Millidge, 2025"}),"; ",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2404.17047",children:"Eiras et al., 2024"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Am\xe9lioration de la recherche scientifique et acad\xe9mique."})," Un acc\xe8s plus large donne plus de pouvoir \xe0 la communaut\xe9 de recherche dans tous les domaines. En IA sp\xe9cifiquement, la reproductibilit\xe9 scientifique d\xe9pend aussi de l'acc\xe8s persistant \xe0 des versions sp\xe9cifiques de mod\xe8les\u2014lorsque les mod\xe8les sont ouverts, les chercheurs peuvent pr\xe9server des versions sp\xe9cifiques pour des \xe9tudes \xe0 long terme sur le comportement, les biais et les capacit\xe9s des mod\xe8les (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2403.07918",children:"Kapoor et al., 2023"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Plus grande inclusion pour des besoins divers."})," Un acc\xe8s plus large permet de donner aux gens un acc\xe8s \xe9gal aux b\xe9n\xe9fices de l'IA en adaptant les ",(0,i.jsx)(n,{term:"foundation model",definition:'{"definition":"Mod\xe8le \xe0 grande \xe9chelle entra\xeen\xe9 sur des donn\xe9es diverses qui sert de base \xe0 l\'adaptation \xe0 diverses t\xe2ches en aval, g\xe9n\xe9ralement par le biais d\'un r\xe9glage fin ou d\'une incitation.","source":"[Bommasani et al., 2021](https://arxiv.org/abs/2108.07258)","aliases":["Foundation Model","foundation models","base model","mod\xe8le de base","mod\xe8les de base","mod\xe8le fondation","mod\xe8les fondation","mod\xe8le de fondation","mod\xe8les de fondation","Mod\xe8le de fondation"]}',children:(0,i.jsx)(n,{term:"foundation model",definition:'{"definition":"Mod\xe8le \xe0 grande \xe9chelle entra\xeen\xe9 sur des donn\xe9es diverses qui sert de base \xe0 l\'adaptation \xe0 diverses t\xe2ches en aval, g\xe9n\xe9ralement par le biais d\'un r\xe9glage fin ou d\'une incitation.","source":"[Bommasani et al., 2021](https://arxiv.org/abs/2108.07258)","aliases":["Foundation Model","foundation models","base model","mod\xe8le de base","mod\xe8les de base","mod\xe8le fondation","mod\xe8les fondation","mod\xe8le de fondation","mod\xe8les de fondation","Mod\xe8le de fondation"]}',children:"mod\xe8les de fondation"})})," \xe0 des choses comme les langues et communaut\xe9s sous-repr\xe9sent\xe9es (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2403.07918",children:"Kapoor et al, 2024"}),"). Cela permet aussi aux petites organisations et aux d\xe9veloppeurs de r\xe9gions diverses de construire sur ces technologies sans co\xfbts prohibitifs. Cela pourrait \xe9galement aider \xe0 pr\xe9venir la monoculture algorithmique (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2101.05853",children:"Kleinberg & Raghavan, 2021"}),")"]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Transparence et responsabilit\xe9 am\xe9lior\xe9es."})," Les poids de mod\xe8les largement disponibles permettent aux chercheurs externes, auditeurs et journalistes d'enqu\xeater plus en profondeur sur les ",(0,i.jsx)(n,{term:"foundation model",definition:'{"definition":"Mod\xe8le \xe0 grande \xe9chelle entra\xeen\xe9 sur des donn\xe9es diverses qui sert de base \xe0 l\'adaptation \xe0 diverses t\xe2ches en aval, g\xe9n\xe9ralement par le biais d\'un r\xe9glage fin ou d\'une incitation.","source":"[Bommasani et al., 2021](https://arxiv.org/abs/2108.07258)","aliases":["Foundation Model","foundation models","base model","mod\xe8le de base","mod\xe8les de base","mod\xe8le fondation","mod\xe8les fondation","mod\xe8le de fondation","mod\xe8les de fondation","Mod\xe8le de fondation"]}',children:(0,i.jsx)(n,{term:"foundation model",definition:'{"definition":"Mod\xe8le \xe0 grande \xe9chelle entra\xeen\xe9 sur des donn\xe9es diverses qui sert de base \xe0 l\'adaptation \xe0 diverses t\xe2ches en aval, g\xe9n\xe9ralement par le biais d\'un r\xe9glage fin ou d\'une incitation.","source":"[Bommasani et al., 2021](https://arxiv.org/abs/2108.07258)","aliases":["Foundation Model","foundation models","base model","mod\xe8le de base","mod\xe8les de base","mod\xe8le fondation","mod\xe8les fondation","mod\xe8le de fondation","mod\xe8les de fondation","Mod\xe8le de fondation"]}',children:"mod\xe8les de fondation"})}),". Cela pourrait pr\xe9venir les pr\xe9occupations de safetywashing (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2407.21792",children:"Ren et al., 2024"}),"), et est particuli\xe8rement pr\xe9cieux \xe9tant donn\xe9 que l'histoire de la technologie num\xe9rique montre qu'un examen plus large r\xe9v\xe8le des pr\xe9occupations manqu\xe9es par les d\xe9veloppeurs."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"R\xe9duction de la concentration du march\xe9."})," Les ",(0,i.jsx)(n,{term:"foundation model",definition:'{"definition":"Mod\xe8le \xe0 grande \xe9chelle entra\xeen\xe9 sur des donn\xe9es diverses qui sert de base \xe0 l\'adaptation \xe0 diverses t\xe2ches en aval, g\xe9n\xe9ralement par le biais d\'un r\xe9glage fin ou d\'une incitation.","source":"[Bommasani et al., 2021](https://arxiv.org/abs/2108.07258)","aliases":["Foundation Model","foundation models","base model","mod\xe8le de base","mod\xe8les de base","mod\xe8le fondation","mod\xe8les fondation","mod\xe8le de fondation","mod\xe8les de fondation","Mod\xe8le de fondation"]}',children:(0,i.jsx)(n,{term:"foundation model",definition:'{"definition":"Mod\xe8le \xe0 grande \xe9chelle entra\xeen\xe9 sur des donn\xe9es diverses qui sert de base \xe0 l\'adaptation \xe0 diverses t\xe2ches en aval, g\xe9n\xe9ralement par le biais d\'un r\xe9glage fin ou d\'une incitation.","source":"[Bommasani et al., 2021](https://arxiv.org/abs/2108.07258)","aliases":["Foundation Model","foundation models","base model","mod\xe8le de base","mod\xe8les de base","mod\xe8le fondation","mod\xe8les fondation","mod\xe8le de fondation","mod\xe8les de fondation","Mod\xe8le de fondation"]}',children:"mod\xe8les de fondation"})})," ouverts peuvent att\xe9nuer les monocultures nocives en permettant un comportement plus diversifi\xe9 des mod\xe8les en aval, r\xe9duisant la gravit\xe9 des d\xe9faillances homog\xe8nes."]}),"\n"]}),"\n"]}),(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"Arguments en faveur d'une plus grande fermeture :"})}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Publication irr\xe9versible avec des garanties tr\xe8s fragiles."})," Une fois publi\xe9s, les mod\xe8les ouverts ne peuvent pas \xeatre rappel\xe9s si des probl\xe8mes de s\xe9curit\xe9 \xe9mergent. Contrairement aux API ferm\xe9es, les garanties peuvent \xeatre facilement supprim\xe9es, et les mod\xe8les peuvent \xeatre affin\xe9s \xe0 des fins nuisibles sans surveillance (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2302.04844",children:"Solaiman et al., 2023"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Permettre des attaques sophistiqu\xe9es."})," L'acc\xe8s en bo\xeete blanche permet aux acteurs malveillants de mieux comprendre et exploiter les vuln\xe9rabilit\xe9s du mod\xe8le pour des cyberattaques ou pour contourner les mesures de s\xe9curit\xe9 dans d'autres syst\xe8mes (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2001.00463",children:"Shevlane & Dafoe, 2020"}),"). Les poids ouverts pourraient aider au d\xe9veloppement d'armes biologiques, d'armes chimiques ou de capacit\xe9s cyber avanc\xe9es que les mod\xe8les ferm\xe9s peuvent mieux restreindre (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2311.09227",children:"Seger et al., 2023"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Prolif\xe9ration de d\xe9fauts non r\xe9solus."})," Lorsque les mod\xe8les sont open source, les biais, vuln\xe9rabilit\xe9s de s\xe9curit\xe9 et autres d\xe9fauts peuvent se propager largement. Il n'existe pas de m\xe9canisme fiable pour s'assurer que les utilisateurs en aval impl\xe9mentent les mises \xe0 jour de s\xe9curit\xe9 (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2311.09227",children:"Seger et al., 2023"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Potentiel accru d'utilisation abusive."})," Les mod\xe8les ouverts facilitent des pr\xe9judices sp\xe9cifiques que les mod\xe8les ferm\xe9s contraignent mieux\u2014des choses comme l'imagerie intime non consensuelle, le mat\xe9riel d'exploitation des enfants (",(0,i.jsx)(s.a,{href:"https://hai.stanford.edu/sites/default/files/2024-03/Response-NTIA-RFC-Open-Foundation-Models.pdf",children:"Hai et al, 2024"}),"), et certaines formes de d\xe9sinformation cibl\xe9e (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2403.07918",children:"Kapoor et al., 2024"}),")."]}),"\n"]}),"\n"]}),(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les strat\xe9gies alternatives de publication offrent des compromis potentiels."})," Diverses propositions sugg\xe8rent une publication par \xe9tapes (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/1908.09203",children:"Solaiman et al., 2019"}),"), un acc\xe8s contr\xf4l\xe9 avec des exigences de connaissance du client, des API de recherche pour les chercheurs qualifi\xe9s et des partenariats de confiance (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2311.09227",children:"Seger et al., 2023"}),"). \xc0 mesure que les capacit\xe9s progressent, un cadre d'acc\xe8s gradu\xe9 qui adapte les contr\xf4les aux risques sp\xe9cifiques pourrait s'av\xe9rer le plus efficace pour \xe9quilibrer l'acc\xe8s avec la s\xe9curit\xe9."]})]}),"\n",(0,i.jsxs)(o.A,{title:"L'entra\xeenement distribu\xe9 et le d\xe9fi de la non-prolif\xe9ration",collapsed:!0,children:[(0,i.jsxs)(s.p,{children:["L'essor des techniques d'entra\xeenement distribu\xe9, permettant d'entra\xeener des LLM sur plusieurs clusters de calcul g\xe9ographiquement dispers\xe9s avec une faible surcharge de communication comme DiLoCo (",(0,i.jsx)(s.a,{href:"https://www.tigera.io/learn/guides/llm-security/ai-safety/",children:"Douillard et al, 2023"}),"), pr\xe9sente de nouveaux d\xe9fis et opportunit\xe9s pour la pr\xe9vention des abus et la gouvernance."]}),(0,i.jsxs)(s.p,{children:["Il pourrait \xeatre possible \xe0 l'avenir d'entra\xeener et de servir des mod\xe8les de mani\xe8re distribu\xe9e. Des m\xe9thodes comme DiLoCo permettent d'entra\xeener de grands mod\xe8les sans centres de donn\xe9es massifs centralis\xe9s, en utilisant des techniques inspir\xe9es de l'apprentissage f\xe9d\xe9r\xe9 (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2311.08105",children:"Douillard et al., 2024"}),")."]}),(0,i.jsxs)(s.p,{children:["Implications politiques : L'entra\xeenement distribu\xe9 pourrait d\xe9mocratiser le d\xe9veloppement de l'IA en abaissant les barri\xe8res d'infrastructure. Cependant, cela complique consid\xe9rablement les strat\xe9gies de gouvernance bas\xe9es sur le calcul (comme le KYC pour les fournisseurs de calcul ou la surveillance des grands centres de donn\xe9es) qui supposent un entra\xeenement centralis\xe9. Cela rend beaucoup plus difficile le suivi et le contr\xf4le de qui entra\xeene des mod\xe8les puissants, augmentant potentiellement les risques de prolif\xe9ration en rendant inefficaces certains m\xe9canismes de gouvernance (",(0,i.jsx)(s.a,{href:"https://jack-clark.net/2025/02/03/import-ai-398-deepmind-makes-distributed-training-better-ai-versus-the-intelligence-community-and-another-chinese-reasoning-model/",children:"Clark, 2025"}),")."]})]}),"\n",(0,i.jsx)(s.h3,{id:"01-02",children:"Contr\xf4les Internes"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les contr\xf4les d'acc\xe8s internes prot\xe8gent les poids des mod\xe8les et les secrets algorithmiques."})," Alors que les contr\xf4les d'acc\xe8s externes r\xe9gulent la fa\xe7on dont les utilisateurs interagissent avec les syst\xe8mes d'IA via des API et d'autres interfaces, les contr\xf4les d'acc\xe8s internes se concentrent sur la s\xe9curisation des poids des mod\xe8les eux-m\xeames. Si les poids des mod\xe8les sont exfiltr\xe9s, tous les contr\xf4les d'acc\xe8s externes deviennent non pertinents, car le mod\xe8le peut \xeatre d\xe9ploy\xe9 sans aucune restriction. Plusieurs mod\xe8les de risque supposent souvent un risque catastrophique d\xfb \xe0 l'exfiltration des poids et \xe0 l'espionnage (",(0,i.jsx)(s.a,{href:"https://situational-awareness.ai/",children:"Aschenbrenner, 2024"}),"; ",(0,i.jsx)(s.a,{href:"https://www.rand.org/pubs/research_reports/RRA2849-1.html",children:"Nevo et al., 2024"}),"; ",(0,i.jsx)(s.a,{href:"https://ai-2027.com/",children:"Kokotajlo et al., 2025"}),"). Les laboratoires de recherche d\xe9veloppant des mod\xe8les de pointe devraient mettre en \u0153uvre des mesures rigoureuses de cybers\xe9curit\xe9 pour prot\xe9ger les syst\xe8mes d'IA contre le vol. Cela semble simple, mais ce ne l'est pas, et prot\xe9ger les mod\xe8les contre des acteurs au niveau \xe9tatique pourrait n\xe9cessiter des efforts extraordinaires (",(0,i.jsx)(s.a,{href:"https://www.lesswrong.com/posts/2oAxpRuadyjN2ERhe/information-security-considerations-for-ai-and-the-long-term",children:"Ladish & Heim, 2022"}),"). Dans cette section, nous essayons d'explorer les strat\xe9gies pour prot\xe9ger les poids des mod\xe8les et prot\xe9ger les insights algorithmiques contre l'acc\xe8s non autoris\xe9, le vol ou l'utilisation abusive par des initi\xe9s ou des attaquants externes."]}),"\n",(0,i.jsx)(d.A,{src:"./img/dYe_Image_6.png",alt:"Saisir la description alternative de l'image",number:"6",label:"3.6",caption:"Aper\xe7u des composants actifs dans le d\xe9veloppement d'un syst\xe8me d'apprentissage automatique. Chacun introduit plus de complexit\xe9, \xe9largit le mod\xe8le de menace et introduit plus de vuln\xe9rabilit\xe9s potentielles ([Ladish & Heim, 2022](https://www.lesswrong.com/posts/2oAxpRuadyjN2ERhe/information-security-considerations-for-ai-and-the-long-term))."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Une protection efficace n\xe9cessite une d\xe9fense multicouche couvrant les domaines technique, organisationnel et physique."})," Par exemple, pensez \xe0 un laboratoire d'IA de pointe qui veut prot\xe9ger son mod\xe8le le plus avanc\xe9 : les contr\xf4les techniques cryptent les poids et limitent l'acc\xe8s num\xe9rique ; les contr\xf4les organisationnels restreignent la connaissance de l'architecture du mod\xe8le \xe0 une petite \xe9quipe de chercheurs contr\xf4l\xe9s ; et les contr\xf4les physiques garantissent que l'infrastructure de calcul reste dans des installations s\xe9curis\xe9es \xe0 acc\xe8s restreint. Si une seule couche \xe9choue \u2014 par exemple, si le cryptage est rompu mais que les restrictions d'acc\xe8s physique demeurent \u2014 le mod\xe8le conserve une certaine protection. Cette approche de d\xe9fense en profondeur garantit que plusieurs d\xe9faillances de s\xe9curit\xe9 devraient se produire simultan\xe9ment pour une exfiltration r\xe9ussie."]}),"\n",(0,i.jsxs)(o.A,{title:"Cybers\xe9curit\xe9 en IA : Niveaux de s\xe9curit\xe9 des poids (WSL) et Niveaux de s\xe9curit\xe9 des secrets algorithmiques (SSL)",collapsed:!0,children:[(0,i.jsxs)(s.p,{children:["Les chercheurs ont propos\xe9 de formaliser la s\xe9curit\xe9 en IA en utilisant des cadres \xe0 plusieurs niveaux qui distinguent entre la protection des poids des mod\xe8les (WSL) et les secrets algorithmiques (SSL) contre diverses menaces de capacit\xe9 op\xe9rationnelle (OC) (",(0,i.jsx)(s.a,{href:"https://www.rand.org/pubs/research_reports/RRA2849-1.html",children:"Nevo et al., 2024"}),", ",(0,i.jsx)(s.a,{href:"https://www.rand.org/pubs/research_reports/RR2703.html",children:"Snyder et al., 2020"}),"; ",(0,i.jsx)(s.a,{href:"https://ai-2027.com/research/security-forecast",children:"Dean, 2025"}),")."]}),(0,i.jsx)(d.A,{src:"./img/WbU_Image_7.png",alt:"Saisir la description alternative de l'image",number:"7",label:"3.7",caption:"Exemple de strat\xe9gie de contr\xf4le d'acc\xe8s pour la protection interne des mod\xe8les. Bas\xe9 sur 5 niveaux de s\xe9curit\xe9 \xe9volutifs (SL) pour s\xe9curiser les poids des mod\xe8les d'IA ([Nevo et al., 2024](https://www.rand.org/pubs/research_reports/RRA2849-1.html))."}),(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La protection des poids (Niveaux de S\xe9curit\xe9 des Poids des Mod\xe8les (WSL)) versus les secrets algorithmiques (Niveaux de S\xe9curit\xe9 des Secrets Algorithmiques (SSL)) pr\xe9sente diff\xe9rents d\xe9fis de s\xe9curit\xe9."})," Alors que les poids des mod\xe8les repr\xe9sentent un volume de donn\xe9es important (rendant l'exfiltration gourmande en bande passante), les secrets algorithmiques peuvent \xeatre expliqu\xe9s de mani\xe8re concise dans un court document ou un petit extrait de code (les rendant plus faciles \xe0 exfiltrer par des moyens conventionnels). La capacit\xe9 op\xe9rationnelle (OC) d\xe9finit essentiellement la sophistication croissante des attaquants potentiels, et le niveau de s\xe9curit\xe9 correspondant d\xe9finit la capacit\xe9 \xe0 se prot\xe9ger contre eux. Par exemple, SSL1 et WSL1 correspondent \xe0 la capacit\xe9 de d\xe9fendre de mani\xe8re robuste (probabilit\xe9 de 95%) contre les tentatives OC1 essayant de voler les poids des mod\xe8les d'IA de pointe (",(0,i.jsx)(s.a,{href:"https://ai-2027.com/research/security-forecast",children:"Dean, 2025"}),")."]}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"OC1 :"}),' Tentatives amateurs - Hackers amateurs ou attaques "spray and pray" avec des budgets jusqu\'\xe0 1 000 $, durant plusieurs jours, sans infrastructure ou acc\xe8s pr\xe9existant']}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"OC2 :"})," Efforts professionnels opportunistes - Hackers professionnels individuels ou groupes ex\xe9cutant des attaques non cibl\xe9es avec des budgets jusqu'\xe0 10 000 $, durant plusieurs semaines, avec une infrastructure cyber personnelle"]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"OC3 :"})," Syndicats du cybercrime et menaces internes - Groupes criminels, organisations terroristes, employ\xe9s m\xe9contents avec des budgets jusqu'\xe0 1 million $, durant plusieurs mois, avec soit une infrastructure significative soit un acc\xe8s interne"]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"OC4 :"})," Op\xe9rations standard par les institutions cyber-capables de premier plan - Groupes sponsoris\xe9s par l'\xc9tat et agences de renseignement avec des budgets jusqu'\xe0 10 millions $, op\xe9rations d'un an, vaste infrastructure et ressources \xe9tatiques"]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"OC5 :"})," Op\xe9rations prioritaires par les \xc9tats-nations les plus capables - Les acteurs les plus sophistiqu\xe9s au monde avec des budgets jusqu'\xe0 1 milliard $, op\xe9rations pluriannuelles, et infrastructure au niveau \xe9tatique d\xe9velopp\xe9e sur des d\xe9cennies"]}),"\n"]}),"\n"]}),(0,i.jsxs)(s.p,{children:["Extrait de AI 2027 - Pr\xe9visions de s\xe9curit\xe9 (",(0,i.jsx)(s.a,{href:"https://ai-2027.com/research/security-forecast",children:"Dean, 2025"}),") :"]}),(0,i.jsxs)(s.p,{children:["**",(0,i.jsx)(s.em,{children:"\"Les entreprises d'IA de pointe aux \xc9tats-Unis avaient un niveau de s\xe9curit\xe9 de startup il n'y a pas si longtemps, et atteindre WSL3 est particuli\xe8rement difficile en raison des menaces internes (OC3) qui sont difficiles \xe0 contrer. En d\xe9cembre 2024, les principales entreprises d'IA aux \xc9tats-Unis comme OpenAI et Anthropic sont des startups avec des efforts notables mais n\xe9anmoins au stade initial pour augmenter la s\xe9curit\xe9. \xc9tant donn\xe9 l'hypoth\xe8se qu'environ 1000 de leurs employ\xe9s actuels peuvent interagir avec les poids des mod\xe8les dans le cadre de leur recherche quotidienne, et les aspects cl\xe9s de leurs mesures de s\xe9curit\xe9 reposant probablement sur des protocoles tels que le calcul confidentiel de NVIDIA, nous nous attendons \xe0 ce que leurs mesures contre les menaces internes les maintiennent au standard WSL2. Des entreprises technologiques plus \xe9tablies comme Google pourraient \xeatre au niveau WSL3 sur les poids de pointe.\""})]}),(0,i.jsxs)(s.p,{children:["Voici une s\xe9rie d'enqu\xeates men\xe9es dans le cadre du rapport AI 2027 pour avoir une id\xe9e de o\xf9 se situent les entreprises et la recherche par rapport \xe0 ces niveaux de s\xe9curit\xe9. Toutes les enqu\xeates sont sous forme - Sondage d'atelier. 2024. \"Sondage des participants.\" Donn\xe9es non publi\xe9es de la session interactive de planification de sc\xe9narios de s\xe9curit\xe9 IA, Atelier de s\xe9curit\xe9 IA FAR.Labs, Berkeley, CA, 16 novembre 2024. N=30, taux de r\xe9ponse 90% (",(0,i.jsx)(s.a,{href:"https://ai-2027.com/research/security-forecast",children:"Dean, 2025"}),")."]}),(0,i.jsx)(d.A,{src:"./img/lXC_Image_8.png",alt:"Saisir la description alternative de l'image",number:"8",label:"3.8",caption:"Cette question sur la possibilit\xe9 qu'un acteur \xe9tatique vole un mod\xe8le d'IA am\xe9ricain de pointe avant 2030 a montr\xe9 un fort consensus \u2013 un signe que les niveaux de s\xe9curit\xe9 actuels sont loin de prot\xe9ger contre une menace d'acteur \xe9tatique ([Dean, 2025](https://ai-2027.com/research/security-forecast))."}),(0,i.jsx)(d.A,{src:"./img/RgI_Image_9.png",alt:"Saisir la description alternative de l'image",number:"9",label:"3.9",caption:"Cette question sur la mise en \u0153uvre du SL5 par les entreprises d'IA montre un consensus selon lequel l'aide gouvernementale sera probablement n\xe9cessaire ([Dean, 2025](https://ai-2027.com/research/security-forecast))."}),(0,i.jsx)(d.A,{src:"./img/T1b_Image_10.png",alt:"Saisir la description alternative de l'image",number:"10",label:"3.10",caption:"Cette question sur la difficult\xe9 de mise en \u0153uvre du SL5 montre un certain consensus sur le fait que des niveaux de priorit\xe9 \xe9lev\xe9s d'assistance gouvernementale et plus de 6 mois seront probablement n\xe9cessaires ([Dean, 2025](https://ai-2027.com/research/security-forecast))."})]}),"\n",(0,i.jsxs)(o.A,{title:"Comparaison entre l'exfiltration humaine et l'auto-exfiltration de l'IA",collapsed:!0,children:[(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"L'auto-exfiltration est la possibilit\xe9 qu'un syst\xe8me d'IA avanc\xe9 puisse se copier lui-m\xeame en dehors de son environnement pr\xe9vu."})," Plut\xf4t que de se prot\xe9ger contre des attaquants externes ou des initi\xe9s malveillants, ce risque n\xe9cessite de se d\xe9fendre contre le syst\xe8me d'IA lui-m\xeame agissant comme un attaquant sophistiqu\xe9. Le risque \xe9merge lorsqu'un syst\xe8me d'IA devient suffisamment capable de comprendre sa propre architecture, d'identifier les vuln\xe9rabilit\xe9s dans ses syst\xe8mes de confinement, et d'orchestrer une s\xe9rie complexe d'actions pour se copier vers une infrastructure externe (",(0,i.jsx)(s.a,{href:"https://aligned.substack.com/p/self-exfiltration",children:"Leike, 2023"}),")."]}),(0,i.jsxs)(s.p,{children:["Les sc\xe9narios d'auto-exfiltration vont de l'IA exploitant des vuln\xe9rabilit\xe9s logicielles pour obtenir des privil\xe8ges syst\xe8me \xe9lev\xe9s, \xe0 des approches plus sophistiqu\xe9es comme la cr\xe9ation de canaux cach\xe9s pour le transfert graduel de donn\xe9es, la manipulation d'utilisateurs autoris\xe9s par l'ing\xe9nierie sociale, ou la coordination d'op\xe9rations complexes en plusieurs \xe9tapes qui aboutissent finalement \xe0 une copie compl\xe8te existant en dehors des environnements contr\xf4l\xe9s. Premi\xe8rement, un syst\xe8me doit avoir des capacit\xe9s techniques suffisantes pour ex\xe9cuter une telle op\xe9ration \u2014 y compris comprendre son environnement d'ex\xe9cution, identifier les vuln\xe9rabilit\xe9s, et potentiellement manipuler les utilisateurs ou syst\xe8mes autoris\xe9s. C'est une pr\xe9occupation d'utilisation abusive si l'auto-exfiltration se produit via des entr\xe9es ou des prompts adverses qui d\xe9clenchent des comportements non intentionnels, m\xeame si le mod\xe8le n'a pas normalement d'objectifs d'auto-exfiltration. Alternativement, si les mod\xe8les d'IA ont une haute capacit\xe9 d'auto-exfiltration, avec une haute conscience situationnelle, ils pourraient choisir de le faire ind\xe9pendamment d'une utilisation abusive externe. C'est une question concernant leur alignement (",(0,i.jsx)(s.a,{href:"https://aligned.substack.com/p/self-exfiltration",children:"Leike, 2023"}),"). Un syst\xe8me bien align\xe9 s'abstiendrait d'auto-exfiltration m\xeame s'il en est capable, tandis qu'un syst\xe8me mal align\xe9 pourrait activement la poursuivre."]}),(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les chercheurs en s\xe9curit\xe9 de l'IA ont commenc\xe9 \xe0 d\xe9velopper des r\xe9f\xe9rences et des \xe9valuations sp\xe9cifiquement con\xe7ues pour mesurer les capacit\xe9s des syst\xe8mes d'IA pertinentes pour l'auto-exfiltration."})," Certaines r\xe9f\xe9rences testent des sous-ensembles de capacit\xe9s d'exfiltration, par exemple Cybench teste la capacit\xe9 des LM \xe0 identifier autonomement les vuln\xe9rabilit\xe9s et \xe0 ex\xe9cuter des exploits (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2408.08926",children:"Zhang et al., 2024"}),"), ou Exfilbench qui est une r\xe9f\xe9rence d'exfiltration et de r\xe9plication (",(0,i.jsx)(s.a,{href:"https://www.exfilbench.com/",children:"Exfilbench, 2025"}),"). Les r\xe9f\xe9rences individuelles peuvent \xeatre combin\xe9es en \xe9valuations compl\xe8tes qui visent \xe0 \xe9valuer la capacit\xe9 d'un syst\xe8me \xe0 se r\xe9pliquer autonomement, s'adapter \xe0 de nouveaux environnements, et potentiellement se transf\xe9rer vers d'autres ressources informatiques (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2312.11671",children:"Kinniment et al., 2024"}),"; ",(0,i.jsx)(s.a,{href:"https://metr.github.io/autonomy-evals-guide/",children:"METR, 2025"}),"; ",(0,i.jsx)(s.a,{href:"https://www.exfilbench.org",children:"Exfilbench, 2025"}),"). Nous d\xe9veloppons \xe9galement des \xe9valuations de contr\xf4le qui supposent une IA adversaire, puis testent la capacit\xe9 de nos d\xe9fenses \xe0 r\xe9sister aux actions subversives de l'IA (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2312.06942",children:"Greenblatt et al, 2024"}),"; ",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2501.17315",children:"Korbak et al., 2025"}),"). Ces \xe9valuations aident les chercheurs \xe0 comprendre comment les capacit\xe9s d'auto-exfiltration \xe9voluent avec les capacit\xe9s globales du syst\xe8me et permettent des mesures de s\xe9curit\xe9 pr\xe9ventives. Tout cela est abord\xe9 beaucoup plus en d\xe9tail dans le chapitre sur les \xe9valuations."]})]}),"\n",(0,i.jsx)(s.h3,{id:"01-03",children:"Protections Techniques"}),"\n",(0,i.jsx)(s.p,{children:"Au-del\xe0 des contr\xf4les d'acc\xe8s et des techniques d'ajustement des instructions comme le RLHF, les chercheurs d\xe9veloppent des techniques pour int\xe9grer des m\xe9canismes de s\xe9curit\xe9 directement dans les mod\xe8les eux-m\xeames ou dans leurs pipelines de d\xe9ploiement. Cela ajoute une couche de d\xe9fense suppl\xe9mentaire pour pr\xe9venir les utilisations abusives potentielles. Si cette section est r\xe9pertori\xe9e sous les m\xe9thodes de contr\xf4le d'acc\xe8s, c'est parce que la grande majorit\xe9 des protections techniques que nous pouvons mettre en place n\xe9cessitent que les d\xe9veloppeurs maintiennent un contr\xf4le d'acc\xe8s sur les mod\xe8les. Si un mod\xe8le est compl\xe8tement open source, les protections techniques ne peuvent pas \xeatre garanties."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Disjoncteurs."})," Inspir\xe9s par l'ing\xe9nierie des repr\xe9sentations, les disjoncteurs visent \xe0 d\xe9tecter et interrompre les sch\xe9mas d'activation internes associ\xe9s aux sorties nuisibles lors de leur formation (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2406.04313",children:"Andy Zou et al., 2024"}),"). En \"redirigeant\" ces repr\xe9sentations nuisibles (par exemple, en utilisant le Reroutage de Repr\xe9sentation avec LoRRA), cette technique peut emp\xeacher la g\xe9n\xe9ration de contenu nuisible, d\xe9montrant une robustesse contre les attaques adverses in\xe9dites tout en pr\xe9servant l'utilit\xe9 du mod\xe8le lorsque la requ\xeate n'est pas nuisible. Cette approche cible la capacit\xe9 intrins\xe8que du mod\xe8le \xe0 nuire, la rendant potentiellement plus robuste que le filtrage entr\xe9e/sortie."]}),"\n",(0,i.jsx)(d.A,{src:"./img/n4n_Image_11.png",alt:"Saisir la description alternative de l'image",number:"11",label:"3.11",caption:"Introduction du circuit-breaking comme nouvelle approche pour construire des garanties hautement fiables. Les m\xe9thodes traditionnelles comme le RLHF et l'entra\xeenement antagoniste offrent une supervision au niveau des sorties qui induit des \xe9tats de refus dans l'espace de repr\xe9sentation du mod\xe8le. Cependant, les \xe9tats nocifs restent accessibles une fois ces \xe9tats de refus initiaux contourn\xe9s. En revanche, inspir\xe9 par l'ing\xe9nierie des repr\xe9sentations, le circuit breaking op\xe8re directement sur les repr\xe9sentations internes, liant les \xe9tats nocifs aux disjoncteurs. Cela emp\xeache la travers\xe9e d'une s\xe9quence d'\xe9tats nocifs ([Zou et al., 2024](https://arxiv.org/abs/2406.04313))."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"D\xe9sapprentissage Machine."})," Cela implique des techniques pour supprimer s\xe9lectivement des connaissances ou des capacit\xe9s sp\xe9cifiques d'un mod\xe8le entra\xeen\xe9 sans r\xe9entra\xeenement complet. Les applications pertinentes pour la pr\xe9vention des abus comprennent la suppression des connaissances sur les substances dangereuses ou les armes, l'effacement des biais nuisibles, ou la suppression des vuln\xe9rabilit\xe9s de contournement. Certains chercheurs pensent que la capacit\xe9 \xe0 supprimer s\xe9lectivement et de mani\xe8re robuste des capacit\xe9s pourrait s'av\xe9rer tr\xe8s pr\xe9cieuse dans un large \xe9ventail de sc\xe9narios, tout en \xe9tant r\xe9alisable (",(0,i.jsx)(s.a,{href:"https://www.alignmentforum.org/posts/mFAvspg4sXkrfZ7FA/deep-forgetting-and-unlearning-for-safely-scoped-llms",children:"Casper, 2023"}),"). Les techniques vont des m\xe9thodes bas\xe9es sur le gradient \xe0 la modification des param\xe8tres et \xe0 l'\xe9dition de mod\xe8les. Cependant, des d\xe9fis subsistent pour assurer un oubli complet et robuste, \xe9viter l'oubli catastrophique des connaissances utiles, et mettre ces m\xe9thodes \xe0 l'\xe9chelle efficacement."]}),"\n",(0,i.jsx)(d.A,{src:"./img/gB7_Image_12.png",alt:"Saisir la description alternative de l'image",number:"12",label:"3.12",caption:"Exemple d'illustration d'un type sp\xe9cifique d'algorithme de d\xe9sapprentissage machine (d\xe9sapprentissage approximatif) ([Liu, 2024](https://ai.stanford.edu/~kzliu/blog/unlearning))."}),"\n",(0,i.jsxs)(o.A,{title:"Le d\xe9fi impossible de cr\xe9er des garanties inviolables",collapsed:!0,children:[(0,i.jsx)(s.p,{children:"Un d\xe9fi majeur pour les mod\xe8les \xe0 poids ouverts est que les adversaires peuvent les affiner pour supprimer les protections int\xe9gr\xe9es."}),(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Pourquoi ne pouvons-nous pas simplement ajuster les instructions des mod\xe8les puissants puis les publier en poids ouverts ?"})," Une fois qu'un mod\xe8le est librement accessible, m\xeame s'il a \xe9t\xe9 affin\xe9 pour inclure des filtres de s\xe9curit\xe9, la suppression de ces filtres est relativement simple. Certaines \xe9tudes ont montr\xe9 que quelques centaines d'euros suffisent pour contourner toutes les barri\xe8res de s\xe9curit\xe9 actuellement en place sur les mod\xe8les open-source disponibles simplement en affinant le mod\xe8le avec quelques exemples toxiques (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2310.20624",children:"Lermen et al., 2024"}),"). C'est pourquoi placer les mod\xe8les derri\xe8re des API est un compromis strat\xe9gique."]}),(0,i.jsxs)(s.p,{children:["Les protections r\xe9sistantes \xe0 la falsification comme axe de recherche. La recherche sur les protections r\xe9sistantes \xe0 la falsification, comme la m\xe9thode TAR, vise \xe0 rendre les m\xe9canismes de s\xe9curit\xe9 (comme le refus ou la restriction des connaissances) robustes contre de telles attaques par ajustement (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2408.00761",children:"Tamirisa et al., 2024"}),"). TAR a montr\xe9 des promesses dans la r\xe9sistance \xe0 l'ajustement extensif tout en pr\xe9servant les capacit\xe9s g\xe9n\xe9rales, bien que des limitations fondamentales subsistent dans la d\xe9fense contre les attaques sophistiqu\xe9es exploitant des variations b\xe9nignes."]})]}),"\n",(0,i.jsx)(s.h2,{id:"02",children:"Strat\xe9gies socio-techniques"}),"\n",(0,i.jsx)(s.p,{children:"Les deux strat\xe9gies pr\xe9c\xe9dentes se concentrent sur la r\xe9duction des risques li\xe9s aux mod\xe8les qui ne sont pas encore largement disponibles, comme les mod\xe8les capables de cyberattaques avanc\xe9es ou de cr\xe9ation d'agents pathog\xe8nes. Mais qu'en est-il des mod\xe8les qui permettent les deep fakes, les campagnes de d\xe9sinformation ou les violations de la vie priv\xe9e ? Beaucoup de ces mod\xe8les sont d\xe9j\xe0 largement accessibles."}),"\n",(0,i.jsx)(s.p,{children:"Malheureusement, il est d\xe9j\xe0 trop facile d'utiliser des mod\xe8les open-source pour cr\xe9er des images sexualis\xe9es de personnes \xe0 partir de quelques photos d'elles. Il n'existe pas de solution purement technique pour contrer cela. Par exemple, ajouter des d\xe9fenses (comme du bruit adversarial) aux photos publi\xe9es en ligne pour les rendre illisibles par l'IA ne sera probablement pas extensible, et empiriquement, chaque type de d\xe9fense a \xe9t\xe9 contourn\xe9 par des attaques dans la litt\xe9rature des attaques adversariales."}),"\n",(0,i.jsxs)(s.p,{children:["La solution principale est de r\xe9glementer et d'\xe9tablir des normes strictes contre ce type de comportement. Quelques approches potentielles (",(0,i.jsx)(s.a,{href:"https://controlai.com/deepfakes/deepfakes-policy",children:"Control AI, 2024"}),") :"]}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Lois et sanctions :"})," Adopter et appliquer des lois rendant ill\xe9gale la cr\xe9ation et le partage de pornographie deep fake non consensuelle ou l'utilisation de l'IA pour le harc\xe8lement, les violations de la vie priv\xe9e, la propri\xe9t\xe9 intellectuelle ou la d\xe9sinformation. Imposer des sanctions significatives comme moyen de dissuasion."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Mod\xe9ration de contenu :"})," Exiger des plateformes en ligne qu'elles d\xe9tectent et suppriment proactivement les contenus probl\xe9matiques g\xe9n\xe9r\xe9s par l'IA, la d\xe9sinformation et le mat\xe9riel violant la vie priv\xe9e. Tenir les plateformes responsables en cas d'\xe9chec de mod\xe9ration."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Filigrane :"})," Encourager ou exiger le \"filigrane\" du contenu g\xe9n\xe9r\xe9 par l'IA. D\xe9velopper des normes pour la provenance num\xe9rique et l'authentification."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"\xc9ducation et sensibilisation :"})," Lancer des campagnes d'\xe9ducation publique sur les risques des deep fakes, de la d\xe9sinformation et des menaces de l'IA sur la vie priv\xe9e. Apprendre aux gens \xe0 \xeatre des consommateurs critiques du contenu en ligne."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Recherche :"})," Soutenir la recherche sur les m\xe9thodes techniques de d\xe9tection du contenu g\xe9n\xe9r\xe9 par l'IA, d'identification des m\xe9dias manipul\xe9s et de pr\xe9servation de la vie priv\xe9e face aux syst\xe8mes d'IA."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Ces \xe9l\xe9ments peuvent \xeatre combin\xe9s avec d'autres strat\xe9gies et couches pour obtenir une d\xe9fense en profondeur."})," Par exemple, les syst\xe8mes aliment\xe9s par l'IA peuvent filtrer les appels t\xe9l\xe9phoniques en temps r\xe9el, analysant les mod\xe8les vocaux, la fr\xe9quence des appels et les indices conversationnels pour identifier les arnaques probables et alerter les utilisateurs ou bloquer les appels (",(0,i.jsx)(s.a,{href:"https://www.neuralt.com/news-insights/protect-your-subscribers-against-scam-calls-with-ai-powered-scamblock",children:"Neuralt, 2024"}),"). Les chatbots comme Daisy (",(0,i.jsx)(s.a,{href:"https://fr.euronews.com/next/2024/03/08/decouvrez-daisy-le-chatbot-mamie-qui-fait-perdre-du-temps-aux-fraudeurs-au-telephone",children:"Anna Desmarais, 2024"}),") et les services comme Jolly Roger Telephone utilisent l'IA pour engager les arnaqueurs dans de longues conversations improductives, gaspillant leur temps et les d\xe9tournant des victimes potentielles. Cela repr\xe9sente des applications pratiques et d\xe9fensives de l'IA contre les formes courantes d'utilisation abusive. Mais ce n'est qu'une premi\xe8re \xe9tape et c'est loin d'\xeatre suffisant."]}),"\n",(0,i.jsx)(s.p,{children:"En fin de compte, une combinaison de cadres juridiques, de politiques de plateformes, de normes sociales et d'outils technologiques sera n\xe9cessaire pour att\xe9nuer les risques pos\xe9s par les mod\xe8les d'IA largement disponibles."})]})}function f(e={}){const{wrapper:s}={...(0,r.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}}}]);