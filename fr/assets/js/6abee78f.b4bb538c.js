"use strict";(self.webpackChunkatlas=self.webpackChunkatlas||[]).push([[9669],{8292:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>p,contentTitle:()=>c,default:()=>g,frontMatter:()=>d,metadata:()=>t,toc:()=>m});const t=JSON.parse('{"id":"chapters/04/3","title":"Architectures de gouvernance","description":"La gouvernance de l\'IA fronti\xe8re ne peut \xeatre confi\xe9e \xe0 une seule institution ou niveau d\'autorit\xe9. Les entreprises manquent d\'incitations pour pleinement tenir compte des impacts soci\xe9taux, les nations sont en comp\xe9tition pour l\'avantage technologique, et les organismes internationaux peinent \xe0 faire respecter les r\xe8gles. Chaque niveau de gouvernance \u2013 entreprise, national et international \u2013 apporte des forces uniques et fait face \xe0 des limitations distinctes. Comprendre comment ces niveaux interagissent et se renforcent mutuellement est important pour construire des syst\xe8mes de gouvernance efficaces de l\'IA.","source":"@site/i18n/fr/docusaurus-plugin-content-docs/current/chapters/04/03.md","sourceDirName":"chapters/04","slug":"/chapters/04/03","permalink":"/fr/chapters/04/03","draft":false,"unlisted":false,"editUrl":"https://github.com/markov-root/atlas/edit/main/docs/chapters/04/03.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"3","title":"Architectures de gouvernance","sidebar_label":"4.3 Architectures de gouvernance","sidebar_position":4,"slug":"/chapters/04/03","reading_time_core":"27 min","reading_time_optional":"3 min","pagination_prev":"chapters/04/2","pagination_next":"chapters/04/4"},"sidebar":"docs","previous":{"title":"4.2 D\xe9fis Syst\xe9miques","permalink":"/fr/chapters/04/02"},"next":{"title":"4.4 Mise en \u0153uvre","permalink":"/fr/chapters/04/04"}}');var i=n(4848),r=n(8453),a=n(3989),l=n(2482),o=n(8559),u=(n(9585),n(2501));const d={id:3,title:"Architectures de gouvernance",sidebar_label:"4.3 Architectures de gouvernance",sidebar_position:4,slug:"/chapters/04/03",reading_time_core:"27 min",reading_time_optional:"3 min",pagination_prev:"chapters/04/2",pagination_next:"chapters/04/4"},c="Architectures de gouvernance",p={},m=[{value:"Gouvernance d&#39;entreprise",id:"01",level:2},{value:"Cadres de S\xe9curit\xe9 Frontier",id:"01-01",level:3},{value:"Gouvernance Nationale",id:"02",level:2},{value:"Gouvernance Internationale",id:"03",level:2},{value:"Options Politiques",id:"03-00-01",level:4}];function h(e){const s={a:"a",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.header,{children:(0,i.jsx)(s.h1,{id:"architectures-de-gouvernance",children:"Architectures de gouvernance"})}),"\n",(0,i.jsx)(s.p,{children:"La gouvernance de l'IA fronti\xe8re ne peut \xeatre confi\xe9e \xe0 une seule institution ou niveau d'autorit\xe9. Les entreprises manquent d'incitations pour pleinement tenir compte des impacts soci\xe9taux, les nations sont en comp\xe9tition pour l'avantage technologique, et les organismes internationaux peinent \xe0 faire respecter les r\xe8gles. Chaque niveau de gouvernance \u2013 entreprise, national et international \u2013 apporte des forces uniques et fait face \xe0 des limitations distinctes. Comprendre comment ces niveaux interagissent et se renforcent mutuellement est important pour construire des syst\xe8mes de gouvernance efficaces de l'IA."}),"\n",(0,i.jsx)(u.A,{src:"./img/hj0_Image_22.png",alt:"Saisir la description alternative de l'image",number:"18",label:"4.18",caption:"Les trois niveaux de gouvernance de l'IA."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La gouvernance d'entreprise apporte rapidit\xe9 et expertise technique."})," Les entreprises d\xe9veloppant l'IA fronti\xe8re ont une visibilit\xe9 in\xe9gal\xe9e sur les capacit\xe9s \xe9mergentes et peuvent mettre en \u0153uvre des mesures de s\xe9curit\xe9 plus rapidement que tout r\xe9gulateur externe. Elles contr\xf4lent les points de d\xe9cision critiques : conception de l'architecture, protocoles d'entra\xeenement, \xe9valuations des capacit\xe9s et crit\xe8res de d\xe9ploiement. Quand OpenAI a d\xe9couvert que GPT-4 pouvait avoir un comportement trompeur, ils ont pu imm\xe9diatement modifier les proc\xe9dures d'entra\xeenement - ce qui prendrait des mois ou des ann\xe9es via les canaux r\xe9glementaires (",(0,i.jsx)(s.a,{href:"https://www.governance.ai/research-paper/risk-assessment-at-agi-companies-a-review-of-popular-risk-assessment-techniques-from-other-safety-critical-industries",children:"Koessler, 2023"}),")."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La gouvernance nationale \xe9tablit la l\xe9gitimit\xe9 d\xe9mocratique et le pouvoir d'application."})," Bien que les entreprises puissent agir rapidement, elles n'ont pas l'autorit\xe9 pour prendre des d\xe9cisions affectant des populations enti\xe8res. Les gouvernements nationaux fournissent le mandat d\xe9mocratique et les m\xe9canismes d'application n\xe9cessaires pour des r\xe9glementations contraignantes. L'AI Act de l'UE le d\xe9montre en \xe9tablissant des exigences l\xe9gales assorties d'amendes allant jusqu'\xe0 3% du chiffre d'affaires mondial, cr\xe9ant de r\xe9elles cons\xe9quences pour la non-conformit\xe9 que les mesures volontaires des entreprises ne peuvent \xe9galer (",(0,i.jsx)(s.a,{href:"https://www.governance.ai/research-paper/from-principles-to-rules-a-regulatory-approach-for-frontier-ai",children:"Schuett et al., 2024"}),")."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La gouvernance internationale traite les externalit\xe9s mondiales et les \xe9checs de coordination."})," Les risques de l'IA ne respectent pas les fronti\xe8res. Un mod\xe8le dangereux d\xe9velopp\xe9 dans un pays peut affecter le monde entier par la prolif\xe9ration num\xe9rique. Les m\xe9canismes internationaux aident \xe0 aligner les incitations entre les nations, emp\xeachant les courses vers le bas et assurant des normes de s\xe9curit\xe9 coh\xe9rentes. Le R\xe9seau International des Instituts de S\xe9curit\xe9 de l'IA, lanc\xe9 en 2024, illustre comment les pays peuvent partager les meilleures pratiques et coordonner les normes malgr\xe9 les pressions concurrentielles (",(0,i.jsx)(s.a,{href:"https://www.ceris.be/wp-content/uploads/2024/03/International-Institutions-for-Advanced-AI-Robert-Trager.pdf",children:"Ho et al., 2023"}),")."]}),"\n",(0,i.jsx)(u.A,{src:"./img/Aka_Image_23.png",alt:"Saisir la description alternative de l'image",number:"19",label:"4.19",caption:"Comment les niveaux interagissent et se renforcent."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les niveaux de gouvernance cr\xe9ent des boucles de retours qui se renforcent."})," Les cadres de s\xe9curit\xe9 des entreprises informent les r\xe9glementations nationales, qui fa\xe7onnent les normes internationales, qui \xe0 leur tour influencent les pratiques des entreprises mondialement. Quand Anthropic a introduit sa Politique de Mise \xe0 l'\xc9chelle Responsable en 2023, cela a fourni un mod\xe8le qui a influenc\xe9 \xe0 la fois les seuils de calcul de l'Ordre Ex\xe9cutif am\xe9ricain et les discussions lors des sommets internationaux sur l'IA. Cette pollinisation crois\xe9e acc\xe9l\xe8re le d\xe9veloppement d'approches de gouvernance efficaces (",(0,i.jsx)(s.a,{href:"https://www.governance.ai/research-paper/three-lines-of-defense-against-risks-from-ai#:~:text=Organizations%20that%20develop%20and%20deploy,%2C%20legal%2C%20and%20ethical%20reasons.",children:"Schuett, 2023"}),")."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les lacunes \xe0 un niveau cr\xe9ent de la pression sur les autres."})," Quand l'auto-gouvernance des entreprises s'av\xe8re insuffisante, la pression augmente pour une r\xe9glementation nationale. Quand les approches nationales divergent trop fortement, cr\xe9ant un arbitrage r\xe9glementaire, la demande cro\xeet pour une coordination internationale. Cette tension dynamique fait \xe9voluer la gouvernance, bien qu'elle puisse aussi cr\xe9er des lacunes dangereuses pendant les p\xe9riodes de transition."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les diff\xe9rents niveaux g\xe8rent diff\xe9rentes \xe9chelles de temps et incertitudes."})," La gouvernance d'entreprise excelle dans la r\xe9ponse rapide aux d\xe9veloppements techniques mais peine avec la planification \xe0 long terme sous pression concurrentielle. La gouvernance nationale peut \xe9tablir des cadres stables mais avance lentement. La gouvernance internationale fournit une coordination \xe0 long terme mais fait face aux plus grands d\xe9fis de mise en \u0153uvre. Ensemble, ils cr\xe9ent un portefeuille temporel abordant \xe0 la fois les risques imm\xe9diats et syst\xe9miques."]}),"\n",(0,i.jsx)(s.h2,{id:"01",children:"Gouvernance d'entreprise"}),"\n",(0,i.jsx)(l.A,{speaker:"Elon Musk",position:"Fondateur/Co-Fondateur d'OpenAI, Neuralink, SpaceX, xAI, PayPal, PDG de Tesla, Directeur technique de X/Twitter",date:"",source:"",children:(0,i.jsx)(s.p,{children:"L'IA est un cas rare o\xf9 je pense que nous devons \xeatre proactifs dans la r\xe9glementation plut\xf4t que r\xe9actifs [...] Je pense que [la super intelligence num\xe9rique] est la plus grande crise existentielle \xe0 laquelle nous sommes confront\xe9s et la plus urgente. Il faut un organisme public qui ait une vision et une supervision pour confirmer que tout le monde d\xe9veloppe l'IA de mani\xe8re s\xfbre [...] Et retenez bien mes paroles, l'IA est beaucoup plus dangereuse que les armes nucl\xe9aires. Beaucoup plus. Alors pourquoi n'avons-nous aucune surveillance r\xe9glementaire ? C'est insens\xe9."})}),"\n",(0,i.jsx)(l.A,{speaker:"Dario Amodei",position:"Co-Fondateur/PDG d'Anthropic, ex-pr\xe9sident de la recherche chez OpenAI",date:"",source:"",children:(0,i.jsx)(s.p,{children:"Presque chaque d\xe9cision que je prends semble \xeatre en \xe9quilibre sur le fil d'un rasoir. Si nous ne construisons pas assez vite, les pays autoritaires pourraient gagner. Si nous construisons trop vite, les types de risques dont nous avons parl\xe9 pourraient l'emporter."})}),"\n",(0,i.jsx)(s.p,{children:"Dans cette section, nous examinerons comment les entreprises d'IA abordent la gouvernance en pratique. Nous verrons ce qui fonctionne, ce qui ne fonctionne pas et o\xf9 subsistent les lacunes. Cela nous aidera \xe0 comprendre pourquoi la gouvernance d'entreprise seule n'est pas suffisante et pr\xe9parera le terrain pour les discussions ult\xe9rieures sur la gouvernance nationale et internationale. \xc0 la fin de cette section, nous \xe9tablirons \xe0 la fois le r\xf4le essentiel de la gouvernance au niveau de l'entreprise et la raison pour laquelle elle doit \xeatre compl\xe9t\xe9e par des cadres r\xe9glementaires plus larges."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Qu'est-ce que la gouvernance d'entreprise et pourquoi est-elle importante ?"})," La gouvernance d'entreprise fait r\xe9f\xe9rence aux structures internes, aux pratiques et aux processus qui d\xe9terminent comment les entreprises d'IA prennent des d\xe9cisions pertinentes en mati\xe8re de s\xe9curit\xe9. Les entreprises d\xe9veloppant l'IA fronti\xe8re ont une visibilit\xe9 unique sur les capacit\xe9s \xe9mergentes et peuvent mettre en \u0153uvre des mesures de s\xe9curit\xe9 plus rapidement que les r\xe9gulateurs externes (",(0,i.jsx)(s.a,{href:"http://arxiv.org/abs/2307.03718",children:"(Anderljung et al., 2023)"})," ; ",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2402.08797",children:"Sastry et al., 2024"}),"). Elles disposent des connaissances techniques et du contr\xf4le direct n\xe9cessaires pour mettre en \u0153uvre des garanties efficaces, mais elles font \xe9galement face \xe0 d'immenses pressions du march\xe9 qui peuvent s'opposer \xe0 la prise de temps pour les mesures de s\xe9curit\xe9 (",(0,i.jsx)(s.a,{href:"https://doi.org/10.1007/978-3-540-70818-6_14",children:"Friedman et al., 2007"}),"). Cela inclut les politiques, les structures de surveillance, les protocoles techniques et les normes organisationnelles que les entreprises utilisent pour assurer la s\xe9curit\xe9 tout au long du processus de d\xe9veloppement de l'IA. Ces m\xe9canismes traduisent des principes de haut niveau en d\xe9cisions op\xe9rationnelles au sein des laboratoires et des \xe9quipes de d\xe9veloppement (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2105.02117",children:"Zhang et al., 2021"})," ; ",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2012.06505",children:"Cihon et al., 2021"}),")."]}),"\n",(0,i.jsxs)(s.p,{children:["Les m\xe9canismes de gouvernance interne sont importants car les entreprises d'IA fronti\xe8re disposent actuellement d'une libert\xe9 significative dans la gouvernance de leurs propres syst\xe8mes. Leur proximit\xe9 avec le d\xe9veloppement leur permet d'identifier et de traiter les risques plus t\xf4t et plus efficacement que ne pourrait le faire la seule surveillance externe (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2105.02117",children:"Zhang et al., 2021"}),"). Cependant, la gouvernance interne seule ne peut pas traiter les risques syst\xe9miques ; ceux-ci n\xe9cessitent une surveillance publique, que nous explorons plus loin dans ce chapitre."]}),"\n",(0,i.jsx)(a.A,{src:"https://ourworldindata.org/grapher/affiliation-researchers-building-artificial-intelligence-systems-all?tab=chart",width:"100%",height:"600px",loading:"lazy",allow:"web-share; clipboard-write",frameBorder:"0",number:"5",label:"4.5",caption:"Affiliation des \xe9quipes de recherche d\xe9veloppant des syst\xe8mes d'IA notables, par ann\xe9e de publication. D\xe9crit le secteur o\xf9 les auteurs d'un syst\xe8me d'IA notable ont leurs affiliations principales ([Giattino et al., 2023](https://ourworldindata.org/artificial-intelligence))."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Pourquoi la gouvernance interne est-elle importante en pratique ?"})," Les entreprises d'IA contr\xf4lent les \xe9tapes les plus sensibles du d\xe9veloppement des mod\xe8les : la conception de l'architecture, les sessions d'entra\xeenement, les \xe9valuations des capacit\xe9s, les crit\xe8res de d\xe9ploiement et les protocoles de s\xe9curit\xe9. Une gouvernance interne bien con\xe7ue peut r\xe9duire les risques en alignant les priorit\xe9s de s\xe9curit\xe9 avec la prise de d\xe9cision quotidienne, en int\xe9grant des proc\xe9dures d'escalade et en appliquant des contraintes avant le d\xe9ploiement (",(0,i.jsx)(s.a,{href:"https://www.aisafetybook.com/textbook/corporate-governance",children:"Hendrycks et al., 2024"}),"). Elle inclut des mesures proactives comme la pause des sessions d'entra\xeenement, la restriction d'acc\xe8s aux capacit\xe9s \xe0 haut risque et l'audit de l'utilisation interne des mod\xe8les. Parce que les acteurs externes n'ont souvent pas acc\xe8s aux informations propri\xe9taires, la gouvernance interne est la premi\xe8re ligne de d\xe9fense, en particulier pour les mod\xe8les qui n'ont pas encore \xe9t\xe9 publi\xe9s (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2212.08364",children:"Schuett, 2023"})," ; ",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2012.06505",children:"Cihon et al., 2021"}),")."]}),"\n",(0,i.jsx)(l.A,{speaker:"International AI Safety Report",position:"",date:"",source:"([Bengio et al. 2025](https://arxiv.org/abs/2501.17805))",children:(0,i.jsx)(s.p,{children:"Le d\xe9ploiement peut prendre plusieurs formes : d\xe9ploiement interne pour utilisation par le d\xe9veloppeur du syst\xe8me, ou d\xe9ploiement externe soit publiquement soit pour des clients priv\xe9s. On sait tr\xe8s peu de choses sur les d\xe9ploiements internes. Cependant, on sait que les entreprises adoptent diff\xe9rents types de strat\xe9gies pour le d\xe9ploiement externe."})}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Quel r\xf4le joue le d\xe9ploiement interne dans la gouvernance interne ?"})," Les syst\xe8mes d'IA les plus avanc\xe9s sont g\xe9n\xe9ralement d'abord d\xe9ploy\xe9s en interne au sein des entreprises d'IA avant toute publication publique. Ces d\xe9ploiements internes manquent souvent de l'examen minutieux appliqu\xe9 aux lancements externes et peuvent fonctionner avec des privil\xe8ges \xe9lev\xe9s, contourner les \xe9valuations formelles et faire \xe9voluer les capacit\xe9s par une utilisation it\xe9rative avant m\xeame que les parties prenantes externes ne soient au courant de leur existence (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2504.12170",children:"Stix, 2025"}),"). Sans politiques couvrant explicitement l'utilisation interne, comme les contr\xf4les d'acc\xe8s, les approbations de d\xe9ploiement interne ou les garanties contre l'utilisation r\xe9cursive des mod\xe8les, les syst\xe8mes \xe0 haut risque peuvent progresser sans contr\xf4le (Voir Figure B.). Pourtant, la connaissance publique de ces d\xe9ploiements est limit\xe9e, et la plupart des efforts de gouvernance se concentrent encore sur les versions publiques (",(0,i.jsx)(s.a,{href:"https://assets.publishing.service.gov.uk/media/679a0c48a77d250007d313ee/International_AI_Safety_Report_2025_accessible_f.pdf",children:"Bengio et al., 2025"}),"). Renforcer la gouvernance interne autour du d\xe9ploiement interne est crucial pour garantir que les cas d'utilisation pr\xe9coces et potentiellement dangereux sont correctement supervis\xe9s."]}),"\n",(0,i.jsx)(u.A,{src:"./img/alC_Image_25.png",alt:"Saisir la description alternative de l'image",number:"20",label:"4.20",caption:"La figure illustre une boucle auto-renfor\xe7ante dans laquelle les syst\xe8mes d'IA automatisent progressivement la recherche en IA, menant \xe0 une IA de plus en plus capable qui acc\xe9l\xe8re davantage son propre d\xe9veloppement ([Stix, 2025](https://arxiv.org/abs/2504.12170))."}),"\n",(0,i.jsx)(s.p,{children:"Les structures organisationnelles \xe9tablissent qui prend les d\xe9cisions et qui est responsable de la s\xe9curit\xe9 dans les entreprises d'IA. Les sections suivantes couvrent des m\xe9canismes de s\xe9curit\xe9 sp\xe9cifiques, ici, nous nous concentrons sur la question de la gouvernance : qui a l'autorit\xe9 au sein des entreprises pour prioriser la s\xe9curit\xe9 par rapport aux autres objectifs ?"}),"\n",(0,i.jsx)(s.p,{children:"Par exemple, une structure de gouvernance efficace d\xe9termine si une \xe9quipe de s\xe9curit\xe9 peut retarder la sortie d'un mod\xe8le si elle identifie des pr\xe9occupations, si les dirigeants peuvent passer outre les d\xe9cisions de s\xe9curit\xe9, et si le conseil d'administration a l'autorit\xe9 finale sur les d\xe9ploiements \xe0 haut risque. Ces relations d'autorit\xe9 affectent directement la fa\xe7on dont les consid\xe9rations de s\xe9curit\xe9 sont prises en compte dans les d\xe9cisions de d\xe9veloppement."}),"\n",(0,i.jsx)(u.A,{src:"./img/J3d_Image_26.png",alt:"Saisir la description alternative de l'image",number:"21",label:"4.21",caption:"([Kahney, 2011](https://www.cultofmac.com/news/apple-ms-google-etc-imagined-as-fun-org-charts))"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Quels r\xf4les de gouvernance sont critiques pour la s\xe9curit\xe9 de l'IA ?"})," Une gouvernance efficace de l'IA n\xe9cessite trois niveaux interconnect\xe9s de surveillance interne (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2402.01691",children:"Hadley et al., 2024"})," ; ",(0,i.jsx)(s.a,{href:"https://www.governance.ai/research-paper/three-lines-of-defense-against-risks-from-ai#:~:text=Organizations%20that%20develop%20and%20deploy,%2C%20legal%2C%20and%20ethical%20reasons.",children:"Schuett, 2023"}),") :"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Les structures de surveillance au niveau du conseil d'administration allouant les ressources et appliquant les politiques de s\xe9curit\xe9 telles que les Comit\xe9s de Revue des Algorithmes (CRA) et les comit\xe9s d'\xe9thique pour les \xe9valuations des risques techniques et soci\xe9taux, guidant les d\xe9cisions go/no-go sur les d\xe9ploiements, et \xe9tablissant une surveillance avec des lignes claires de responsabilit\xe9 (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2402.01691",children:"Hadley et al., 2024"})," ; ",(0,i.jsx)(s.a,{href:"https://www.governance.ai/research-paper/three-lines-of-defense-against-risks-from-ai#:~:text=Organizations%20that%20develop%20and%20deploy,%2C%20legal%2C%20and%20ethical%20reasons.",children:"Schuett, 2023"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Les dirigeants allouant les ressources et appliquant les politiques de s\xe9curit\xe9. Des r\xf4les comme le Directeur de l'Intelligence Artificielle (DIA), le Directeur des Risques (DR), et les postes connexes pour coordonner les efforts de gestion des risques dans l'organisation, et aider \xe0 traduire les principes \xe9thiques en pratique (",(0,i.jsx)(s.a,{href:"https://www.researchgate.net/publication/360644155_AI_GOVERNANCE_ARE_CHIEF_AI_OFFICERS_AND_AI_RISK_OFFICERS_NEEDED",children:"Sch\xe4fer et al., 2022"})," ; ",(0,i.jsx)(s.a,{href:"https://academic.oup.com/policyandsociety/article/44/1/38/7965776",children:"Janssen et al., 2025"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Les \xe9quipes techniques de s\xe9curit\xe9 conduisant des \xe9valuations et recommandant des mesures d'att\xe9nuation. Des \xe9quipes comprenant des auditeurs internes, des responsables des risques et des comit\xe9s d'audit sp\xe9cialis\xe9s pour assurer une identification rigoureuse des risques, maintenir l'int\xe9grit\xe9 des audits et fournir une assurance op\xe9rationnelle, avec des lignes de rapport directes au conseil d'administration pour l'ind\xe9pendance (",(0,i.jsx)(s.a,{href:"https://www.governance.ai/research-paper/three-lines-of-defense-against-risks-from-ai#:~:text=Organizations%20that%20develop%20and%20deploy,%2C%20legal%2C%20and%20ethical%20reasons.",children:"Schuett, 2023"})," ; ",(0,i.jsx)(s.a,{href:"https://dl.acm.org/doi/pdf/10.1145/3351095.3372873",children:"Raji et al., 2020"}),")."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"En mai 2025, OpenAI a annonc\xe9 une restructuration significative de son mod\xe8le de gouvernance."})," Tout en maintenant le contr\xf4le \xe0 but non lucratif, l'entreprise a fait passer sa filiale \xe0 but lucratif d'une LLC \xe0 une Public Benefit Corporation (PBC) : le m\xeame mod\xe8le utilis\xe9 par Anthropic et d'autres laboratoires d'IA. Ce changement repr\xe9sentait une reconnaissance que les structures ant\xe9rieures \"\xe0 profit plafonn\xe9\" \xe9taient con\xe7ues pour \"un monde o\xf9 il pourrait y avoir un effort dominant en mati\xe8re d'AGI\" mais \xe9taient moins adapt\xe9es \"dans un monde de nombreuses grandes entreprises d'AGI\" (",(0,i.jsx)(s.a,{href:"https://openai.com/index/evolving-our-structure/",children:"OpenAI, 2025"}),"). Les entreprises d'IA fronti\xe8re doivent simultan\xe9ment s\xe9curiser des milliards d'investissements en capital, maintenir la comp\xe9titivit\xe9 avec des rivaux bien dot\xe9s en ressources, et pr\xe9server les structures de gouvernance qui privil\xe9gient la s\xe9curit\xe9. Comme le note Daniel Colson de l'AI Policy Institute, cela cr\xe9e des compromis difficiles o\xf9 les conseils d'administration pourraient \xeatre forc\xe9s de \"peser l'effondrement total contre une forme de compromis afin d'atteindre ce qu'ils consid\xe8rent comme leur mission \xe0 long terme\" (",(0,i.jsx)(s.a,{href:"https://time.com/6983420/anthropic-structure-openai-incentives/",children:"TIME, 2024"}),")."]}),"\n",(0,i.jsx)(u.A,{src:"./img/Ogq_Image_27.png",alt:"Saisir la description alternative de l'image",number:"22",label:"4.22",caption:"([Stix, 2025](https://arxiv.org/abs/2504.12170))"}),"\n",(0,i.jsx)(s.h3,{id:"01-01",children:"Cadres de S\xe9curit\xe9 Frontier"}),"\n",(0,i.jsx)(s.p,{children:"Les Cadres de S\xe9curit\xe9 Frontier sont des politiques internes cr\xe9\xe9es par les entreprises d'IA pour guider leur processus de d\xe9veloppement et garantir qu'elles prennent les pr\xe9cautions appropri\xe9es \xe0 mesure que leurs syst\xe8mes deviennent plus performants. Ils sont l'\xe9quivalent des protocoles de s\xe9curit\xe9 utilis\xe9s dans les centrales nucl\xe9aires ou les laboratoires de haute s\xe9curit\xe9, et aident \xe0 faire le pont entre les m\xe9canismes de gouvernance d'entreprise internes et la surveillance r\xe9glementaire externe en mati\xe8re de s\xe9curit\xe9 de l'IA."}),"\n",(0,i.jsxs)(s.p,{children:["Introduits pour la premi\xe8re fois en 2023, les FSF ont gagn\xe9 en dynamisme lors du Sommet de l'IA de S\xe9oul en mai 2024, o\xf9 16 entreprises se sont engag\xe9es \xe0 mettre en \u0153uvre de telles politiques. En mars 2025, douze entreprises ont publi\xe9 des politiques compl\xe8tes de s\xe9curit\xe9 pour l'IA frontier : Anthropic, OpenAI, Google DeepMind, Magic, Naver, Meta, G42, Cohere, Microsoft, Amazon, xAI et Nvidia, d'autres entreprises leur embo\xeetant le pas (",(0,i.jsx)(s.a,{href:"https://metr.org/blog/2025-03-26-common-elements-of-frontier-ai-safety-policies/",children:"METR, 2025"}),")."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Quels \xe9l\xe9ments essentiels d\xe9finissent un FSF complet ?"})," Malgr\xe9 des variations dans leur mise en \u0153uvre, la plupart des FSF partagent plusieurs \xe9l\xe9ments fondamentaux :"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Seuils de Capacit\xe9 :"})," Les FSF \xe9tablissent des seuils sp\xe9cifiques auxquels les capacit\xe9s d'IA poseraient des risques graves n\xe9cessitant des garanties renforc\xe9es (",(0,i.jsx)(s.a,{href:"https://www.rand.org/pubs/research_reports/RRA2849-1.html",children:"Nevo et al., 2024"}),"). Les pr\xe9occupations courantes concernant les capacit\xe9s incluent : L'assistance aux armes biologiques (comme permettre la cr\xe9ation d'agents pathog\xe8nes dangereux), Les capacit\xe9s offensives cyber (comme l'automatisation de la d\xe9couverte de failles zero-day), La recherche et le d\xe9veloppement automatis\xe9s en IA (comme l'acc\xe9l\xe9ration des progr\xe8s de l'IA au-del\xe0 de la supervision humaine), La r\xe9plication et l'adaptation autonomes."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"S\xe9curit\xe9 des Poids des Mod\xe8les :"})," \xc0 mesure que les mod\xe8les approchent des seuils de capacit\xe9 dangereux, les entreprises mettent en \u0153uvre des mesures de s\xe9curit\xe9 de plus en plus sophistiqu\xe9es pour emp\xeacher l'acc\xe8s non autoris\xe9 aux poids des mod\xe8les. Celles-ci vont des protocoles standard de s\xe9curit\xe9 de l'information aux mesures avanc\xe9es comme les environnements \xe0 acc\xe8s restreint, le chiffrement et la s\xe9curit\xe9 mat\xe9rielle sp\xe9cialis\xe9e (",(0,i.jsx)(s.a,{href:"https://www.rand.org/pubs/research_reports/RRA2849-1.html",children:"Nevo et al., 2024"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Conditions d'Arr\xeat du D\xe9veloppement/D\xe9ploiement :"})," La plupart des cadres contiennent des engagements explicites \xe0 suspendre le d\xe9veloppement ou le d\xe9ploiement des mod\xe8les si les seuils de capacit\xe9 sont franchis avant que des garanties ad\xe9quates puissent \xeatre mises en \u0153uvre (",(0,i.jsx)(s.a,{href:"https://metr.org/blog/2025-03-26-common-elements-of-frontier-ai-safety-policies/",children:"METR, 2025"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"\xc9licitation Compl\xe8te des Capacit\xe9s :"})," \xc0 travers les FSF, les entreprises s'engagent \xe0 \xe9valuer les mod\xe8les de mani\xe8re \xe0 r\xe9v\xe9ler leurs capacit\xe9s compl\xe8tes plut\xf4t que de les sous-estimer (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2403.13793",children:"Phuong et al., 2024"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Fr\xe9quence et Calendrier des \xc9valuations :"})," Les FSF \xe9tablissent des calendriers sp\xe9cifiques pour le moment o\xf9 les \xe9valuations doivent avoir lieu (g\xe9n\xe9ralement avant le d\xe9ploiement, pendant l'entra\xeenement et apr\xe8s le d\xe9ploiement) avec des d\xe9clencheurs pour des \xe9valuations suppl\xe9mentaires lorsque les mod\xe8les montrent des augmentations significatives de capacit\xe9s (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2312.07413",children:"Davidson et al., 2023"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"M\xe9canismes de Responsabilisation :"})," Ceux-ci incluent : Des r\xf4les de gouvernance interne (par exemple, le \"Responsible Scaling Officer\" d'Anthropic), Des conseils consultatifs externes et des audits tiers, Des engagements de transparence sur les capacit\xe9s des mod\xe8les et les mesures de s\xe9curit\xe9, Des protections pour les lanceurs d'alerte signalant des pr\xe9occupations de s\xe9curit\xe9."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Mises \xe0 Jour des Politiques :"})," Tous les FSF reconnaissent la nature \xe9volutive des risques li\xe9s \xe0 l'IA et s'engagent \xe0 des examens et mises \xe0 jour r\xe9guliers des politiques \xe0 mesure que la compr\xe9hension des risques et des meilleures pratiques s'am\xe9liore (",(0,i.jsx)(s.a,{href:"https://metr.org/blog/2025-03-26-common-elements-of-frontier-ai-safety-policies/",children:"METR, 2025"}),")."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Comment les entreprises op\xe9rationnalisent-elles les cadres de s\xe9curit\xe9 en pratique ?"})," Une approche prometteuse qui gagne du terrain est le mod\xe8le des Trois Lignes de D\xe9fense (3LoD) adapt\xe9 d'autres industries critiques pour la s\xe9curit\xe9 (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2212.08364",children:"Schuett, 2023"}),") :"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Premi\xe8re Ligne de D\xe9fense :"})," Les chercheurs et d\xe9veloppeurs de premi\xe8re ligne mettent en \u0153uvre des mesures de s\xe9curit\xe9 dans le travail quotidien, effectuent des \xe9valuations initiales des risques et adh\xe8rent aux directives \xe9thiques et aux protocoles de s\xe9curit\xe9."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Deuxi\xe8me Ligne de D\xe9fense :"})," Des fonctions sp\xe9cialis\xe9es de gestion des risques et de conformit\xe9, y compris les comit\xe9s d'\xe9thique de l'IA, les \xe9quipes d\xe9di\xe9es \xe0 la s\xe9curit\xe9 et les unit\xe9s de conformit\xe9 fournissent une surveillance et des orientations."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Troisi\xe8me Ligne de D\xe9fense :"})," Les fonctions d'audit interne ind\xe9pendantes fournissent une assurance au conseil d'administration et \xe0 la direction g\xe9n\xe9rale par le biais d'audits r\xe9guliers des pratiques de s\xe9curit\xe9, d'\xe9valuations ind\xe9pendantes des mod\xe8les et d'\xe9valuations de la pr\xe9paration globale."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(u.A,{src:"./img/nmm_Image_28.png",alt:"Saisir la description alternative de l'image",number:"23",label:"4.23",caption:"Exemple d'organigramme d'une entreprise d'IA avec des responsabilit\xe9s \xe9quivalentes pour chacune des trois lignes."}),"\n",(0,i.jsxs)(s.p,{children:["Cette approche multicouche aide \xe0 garantir que les risques sont identifi\xe9s et g\xe9r\xe9s \xe0 plusieurs niveaux, r\xe9duisant les chances d'oublis dangereux. Par exemple, lorsque les chercheurs d\xe9veloppent un mod\xe8le avec des capacit\xe9s avanc\xe9es inattendues, les \xe9quipes de s\xe9curit\xe9 peuvent mener des \xe9valuations approfondies et mettre en \u0153uvre des garanties suppl\xe9mentaires, tandis que les \xe9quipes d'audit examinent les processus plus larges de gestion des capacit\xe9s \xe9mergentes (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2212.08364",children:"Schuett, 2023"}),")."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Comment \xe9valuer les risques pour des capacit\xe9s qui n'existent pas encore ?"})," Les capacit\xe9s de l'IA se d\xe9veloppent et changent rapidement. Les FSF int\xe8grent des techniques d'autres industries critiques pour la s\xe9curit\xe9 adapt\xe9es au d\xe9veloppement de l'IA (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2307.08823",children:"Koessler & Schuett, 2023"}),") :"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Analyse de Sc\xe9narios :"})," Explorer des sc\xe9narios futurs potentiels, comme un syst\xe8me d'IA d\xe9veloppant des comportements trompeurs ou des capacit\xe9s \xe9mergentes inattendues."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Analyse en Ar\xeate de Poisson :"})," Identifier les causes potentielles des \xe9checs d'alignement, comme une recherche de s\xe9curit\xe9 insuffisante, la pression du d\xe9ploiement ou des tests inad\xe9quats."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Cartographie Causale :"})," Visualiser comment les d\xe9cisions de recherche, les mesures de s\xe9curit\xe9 et les strat\xe9gies de d\xe9ploiement interagissent pour influencer le risque global."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Technique Delphi :"})," Recueillir des opinions d'experts \xe0 travers des s\xe9ries structur\xe9es de questionnaires pour synth\xe9tiser diverses perspectives sur les risques potentiels."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Analyse N\u0153ud Papillon :"})," Cartographier les voies entre les causes, les \xe9v\xe9nements dangereux et les cons\xe9quences, ainsi que les mesures de pr\xe9vention et d'att\xe9nuation."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Que se passe-t-il lorsque les garanties pr\xe9-d\xe9ploiement sont insuffisantes ?"})," M\xeame avec des garanties rigoureuses avant le d\xe9ploiement, des capacit\xe9s dangereuses peuvent \xe9merger apr\xe8s le d\xe9ploiement. Les FSF int\xe8grent de plus en plus des \"corrections de d\xe9ploiement\", qui sont des plans d'urgence complets pour les sc\xe9narios o\xf9 la gestion des risques pr\xe9-d\xe9ploiement s'av\xe8re insuffisante (",(0,i.jsx)(s.a,{href:"https://arxiv.org/pdf/2310.00328",children:"O'Brien et al., 2023"}),") :"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Contr\xf4les Techniques pour maintenir un contr\xf4le continu sur les mod\xe8les d\xe9ploy\xe9s gr\xe2ce aux capacit\xe9s de surveillance et de modification, soutenus par des m\xe9canismes de retour en arri\xe8re pr\xe9\xe9tablis."}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Pr\xe9paration Organisationnelle pour \xe9tablir des \xe9quipes d\xe9di\xe9es d'intervention en cas d'incident form\xe9es \xe0 l'\xe9valuation et \xe0 l'att\xe9nuation rapides des risques."}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Cadre Juridique pour cr\xe9er des accords utilisateurs clairs qui \xe9tablissent le cadre op\xe9rationnel pour les interventions d'urgence."}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Arr\xeat du Mod\xe8le comme le retrait complet du march\xe9 ou la destruction du mod\xe8le et des composants associ\xe9s."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Quels avantages offrent les FSF et o\xf9 sont leurs limites ?"})," Les FSF donnent aux entreprises un moyen de d\xe9montrer leur engagement envers une gestion proactive des risques. Leur nature publique permet un examen externe, tandis que leurs cadres de cat\xe9gorisation des risques montrent leur engagement vis-\xe0-vis des modes de d\xe9faillance potentiels. La structure d\xe9lib\xe9r\xe9ment flexible des cadres permet une adaptation \xe0 mesure que la compr\xe9hension des risques de l'IA \xe9volue (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2501.16500",children:"Pistillo, 2025"}),")."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Comment pouvons-nous garantir que les FSF sont efficacement mis en \u0153uvre ?"})," Bien que les FSF repr\xe9sentent des progr\xe8s dans la gouvernance de l'IA, leur efficacit\xe9 d\xe9pend en fin de compte de leur mise en \u0153uvre. Des entreprises comme Anthropic et OpenAI ont \xe9tabli des m\xe9canismes de gouvernance notables. Quelle que soit leur qualit\xe9 de conception, les politiques internes restent soumises aux int\xe9r\xeats strat\xe9giques des entreprises. Lorsque la s\xe9curit\xe9 entre en concurrence avec la vitesse, la rentabilit\xe9 ou la domination du march\xe9, m\xeame une gouvernance interne forte peut \xeatre compromise. Les mesures volontaires manquent de force ex\xe9cutoire, et les initi\xe9s font souvent face \xe0 des incitations mal align\xe9es lorsqu'ils soul\xe8vent des pr\xe9occupations (",(0,i.jsx)(s.a,{href:"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5241351",children:"Zhang et al., 2025"}),")."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"Limitations et Voie \xe0 Suivre"})}),"\n",(0,i.jsx)(l.A,{speaker:"Demis Hassabis",position:"PDG et Co-Fondateur de DeepMind, Laur\xe9at du Prix Nobel de Chimie",date:"",source:"",children:(0,i.jsx)(s.p,{children:"Ces types de d\xe9cisions sont trop importants pour une seule personne. Nous devons construire des structures de gouvernance plus robustes qui ne mettent pas cela entre les mains de quelques personnes seulement."})}),"\n",(0,i.jsxs)(s.p,{children:["\xc0 mesure que les capacit\xe9s de l'IA continuent de progresser, les cadres de gouvernance doivent \xe9voluer en cons\xe9quence. Il reste encore une marge d'am\xe9lioration significative. Certains sugg\xe8rent que les entreprises devraient d\xe9finir des seuils de risque plus pr\xe9cis et v\xe9rifiables, s'inspirant potentiellement des tol\xe9rances au risque soci\xe9tales d'autres industries (",(0,i.jsx)(s.a,{href:"https://arxiv.org/pdf/2501.16500",children:"Pistillo, 2025"}),"). Par exemple, les industries traitant des risques catastrophiques fixent g\xe9n\xe9ralement des niveaux de risque maximum tol\xe9rables allant de 1 sur 10 000 \xe0 1 sur 10 milliards par an - des seuils quantitatifs que les entreprises d'IA pourraient adopter avec des ajustements appropri\xe9s."]}),"\n",(0,i.jsx)(s.p,{children:"Pour les risques syst\xe9miques comme les dynamiques de course, le d\xe9tournement \xe0 double usage ou la d\xe9faillance catastrophique des mod\xe8les, aucune entreprise ne peut \xeatre seule garante de l'int\xe9r\xeat public. La gouvernance d'entreprise peut gagner du temps mais ne peut pas se substituer \xe0 la responsabilit\xe9 publique ou \xe0 l'architecture de s\xe9curit\xe9 \xe0 l'\xe9chelle du syst\xe8me. Dans le prochain chapitre, nous examinons comment les cadres de gouvernance nationaux peuvent fournir cette surveillance externe essentielle, \xe9tablissant des limites r\xe9glementaires qui s'appliquent \xe0 toutes les entreprises dans les juridictions."}),"\n",(0,i.jsx)(s.h2,{id:"02",children:"Gouvernance Nationale"}),"\n",(0,i.jsx)(l.A,{speaker:"Zhang Jun",position:"Ambassadeur de la Chine \xe0 l'ONU",date:"",source:"",children:(0,i.jsx)(s.p,{children:"L'impact potentiel de l'IA pourrait d\xe9passer les limites cognitives humaines. Pour garantir que cette technologie profite toujours \xe0 l'humanit\xe9, nous devons r\xe9guler le d\xe9veloppement de l'IA et emp\xeacher cette technologie de devenir un cheval sauvage incontr\xf4lable [...] Nous devons renforcer la d\xe9tection et l'\xe9valuation de tout le cycle de vie de l'IA, en nous assurant que l'humanit\xe9 a la capacit\xe9 d'appuyer sur le bouton pause dans les moments critiques."})}),"\n",(0,i.jsxs)(s.p,{children:["Nous avons \xe9tabli dans la section pr\xe9c\xe9dente que les entreprises manquent souvent d'incitations pour prendre pleinement en compte l'impact soci\xe9tal plus large, font face \xe0 des pressions concurrentielles qui peuvent compromettre la s\xe9curit\xe9, et manquent de l\xe9gitimit\xe9 pour prendre des d\xe9cisions affectant des populations enti\xe8res (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2307.04699",children:"Dafoe, 2023"}),"). Les cadres de gouvernance nationale servent donc de compl\xe9ment essentiel aux initiatives d'autor\xe9gulation, \xe9tablissant des normes r\xe9gionales que les entreprises peuvent int\xe9grer dans leurs pratiques internes."]}),"\n",(0,i.jsxs)(s.p,{children:["Contrairement aux d\xe9fis traditionnels de gouvernance technologique, les syst\xe8mes d'IA fronti\xe8re g\xe9n\xe8rent des externalit\xe9s qui couvrent plusieurs domaines : de la s\xe9curit\xe9 nationale \xe0 la stabilit\xe9 \xe9conomique, de l'\xe9quit\xe9 sociale au fonctionnement d\xe9mocratique. Les syst\xe8mes d'IA menacent la s\xe9curit\xe9 nationale en d\xe9mocratisant les capacit\xe9s utilisables par des acteurs malveillants, facilitent des r\xe9sultats \xe9conomiques in\xe9gaux en concentrant le pouvoir de march\xe9 dans des entreprises et pays sp\xe9cifiques tout en d\xe9pla\xe7ant les emplois ailleurs, et produisent des conditions soci\xe9tales n\xe9fastes \xe0 travers des pratiques extractives de donn\xe9es et des r\xe9sultats algorithmiques biais\xe9s (",(0,i.jsx)(s.a,{href:"https://academic.oup.com/ia/article/100/3/1275/7641064",children:"Roberts et al., 2024"}),"). Les organismes de r\xe9glementation traditionnels, con\xe7us pour des domaines technologiques plus \xe9troits, manquent g\xe9n\xe9ralement de comp\xe9tence spatiale, technique ou d'autorit\xe9 institutionnelle n\xe9cessaire pour gouverner efficacement ces syst\xe8mes (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2307.04699",children:"Dafoe, 2023"}),")."]}),"\n",(0,i.jsxs)(s.p,{children:["Consid\xe9rez le contraste avec les v\xe9hicules autonomes, o\xf9 les principales externalit\xe9s sont relativement bien d\xe9finies (s\xe9curit\xe9 des usagers de la route) et rel\xe8vent des cadres r\xe9glementaires existants (agences de s\xe9curit\xe9 routi\xe8re). Les syst\xe8mes d'IA fronti\xe8re, en revanche, g\xe9n\xe8rent des externalit\xe9s qui traversent les fronti\xe8res et juridictions r\xe9glementaires traditionnelles, n\xe9cessitant de nouvelles approches institutionnelles capables de combler le foss\xe9 d'expertise, le foss\xe9 de coordination et le foss\xe9 temporel dans les cadres r\xe9glementaires actuels ",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2307.04699",children:"(Dafoe, 2023"}),")."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les syst\xe8mes d'IA peuvent causer des dommages de mani\xe8res qui ne sont pas toujours transparentes ou pr\xe9visibles."})," Au-del\xe0 des bugs logiciels ou des inad\xe9quations entr\xe9e-sortie, les risques \xe9mergent de la fa\xe7on dont les syst\xe8mes d'IA repr\xe9sentent int\xe9rieurement les objectifs, font des compromis et g\xe9n\xe9ralisent \xe0 partir des donn\xe9es. Lorsque ces syst\xe8mes sont d\xe9ploy\xe9s \xe0 grande \xe9chelle, m\xeame de subtils d\xe9salignements entre le comportement du syst\xe8me et l'intention humaine peuvent avoir des cons\xe9quences \xe9tendues. La poursuite automatis\xe9e de sous-objectifs, par exemple, peut g\xe9n\xe9rer des r\xe9sultats techniquement corrects mais socialement catastrophiques s'ils ne sont pas soigneusement contraints (",(0,i.jsx)(s.a,{href:"https://www.nature.com/articles/s41599-024-03017-1",children:"Cha, 2024"}),"). Comme beaucoup de ces modes de d\xe9faillance sont int\xe9gr\xe9s dans des architectures de mod\xe8les opaques et des dynamiques d'entra\xeenement, ils r\xe9sistent \xe0 la d\xe9tection par des processus conventionnels d'audit ou de certification. La r\xe9glementation nationale fournit un ancrage pour la responsabilit\xe9 en exigeant des d\xe9veloppeurs qu'ils construisent, testent et d\xe9ploient des syst\xe8mes de mani\xe8re v\xe9rifiable externement, juridiquement applicable et publiquement l\xe9gitime."]}),"\n",(0,i.jsx)(s.p,{children:"Comme nous le verrons dans cette section, les grandes r\xe9gions ont d\xe9velopp\xe9 des philosophies r\xe9glementaires distinctement diff\xe9rentes qui refl\xe8tent leurs contextes institutionnels uniques et leurs priorit\xe9s politiques. Comprendre ces cadres nationaux fournira un contexte pour notre analyse ult\xe9rieure des m\xe9canismes de gouvernance internationale, qui doivent naviguer et harmoniser ces diff\xe9rences r\xe9gionales pour cr\xe9er des normes mondiales efficaces pour les syst\xe8mes d'IA dont les impacts transcendent les fronti\xe8res nationales."}),"\n",(0,i.jsxs)(s.p,{children:["Au cours de la derni\xe8re d\xe9cennie, plus de 30 pays ont publi\xe9 des strat\xe9gies nationales d'IA d\xe9crivant leur approche du d\xe9veloppement, de la r\xe9glementation et de l'adoption. Ces strat\xe9gies diff\xe8rent largement dans leur emphase, mais lorsqu'elles sont analys\xe9es syst\xe9matiquement, elles se regroupent en trois mod\xe8les de gouvernance r\xe9currents : d\xe9veloppement, contr\xf4le et promotion (",(0,i.jsx)(s.a,{href:"https://www.researchgate.net/publication/367010605_The_state's_role_in_governing_artificial_intelligence_development_control_and_promotion_through_national_strategies",children:"Papyshev et al., 2023"}),"). Dans les mod\xe8les ax\xe9s sur le d\xe9veloppement, comme ceux de la Chine, de la Cor\xe9e du Sud et de la Hongrie, l'\xc9tat agit comme un coordinateur strat\xe9gique, dirigeant les ressources publiques vers l'infrastructure d'IA, les programmes de recherche et les missions nationales. Les approches orient\xe9es vers le contr\xf4le, pr\xe9dominantes dans l'Union europ\xe9enne et des pays comme la Norv\xe8ge et le Mexique, mettent l'accent sur les normes juridiques, la surveillance \xe9thique et les cadres de surveillance des risques. Les mod\xe8les ax\xe9s sur la promotion, incluant les \xc9tats-Unis, le Royaume-Uni et Singapour, adoptent une approche plus d\xe9centralis\xe9e : l'\xc9tat agit principalement comme un facilitateur de l'innovation du secteur priv\xe9, avec relativement peu de contraintes r\xe9glementaires. Ces diff\xe9rences sont importantes. Toute tentative de construire des cadres de gouvernance internationale devra tenir compte des asym\xe9tries structurelles entre ces r\xe9gimes nationaux, particuli\xe8rement en ce qui concerne l'autorit\xe9 d'application, les m\xe9canismes de responsabilit\xe9 et la capacit\xe9 institutionnelle (",(0,i.jsx)(s.a,{href:"https://www.researchgate.net/publication/367010605_The_state's_role_in_governing_artificial_intelligence_development_control_and_promotion_through_national_strategies",children:"Papyshev et al., 2023"}),")."]}),"\n",(0,i.jsx)(u.A,{src:"./img/Knl_Image_29.png",alt:"Saisir la description alternative de l'image",number:"24",label:"4.24",caption:"Le r\xf4le de l'\xc9tat dans la gouvernance de l'intelligence artificielle : d\xe9veloppement, contr\xf4le et promotion \xe0 travers les strat\xe9gies nationales ([Papyshev et al., 2023](https://www.researchgate.net/publication/367010605_The_state's_role_in_governing_artificial_intelligence_development_control_and_promotion_through_national_strategies))."}),"\n",(0,i.jsx)(u.A,{src:"./img/0Dc_Image_30.png",alt:"Saisir la description alternative de l'image",number:"25",label:"4.25",caption:"([State of AI Report, 2023](https://www.stateof.ai/))"}),"\n",(0,i.jsx)(s.h2,{id:"03",children:"Gouvernance Internationale"}),"\n",(0,i.jsx)(l.A,{speaker:"Ant\xf3nio Guterres",position:"Secr\xe9taire g\xe9n\xe9ral de l'ONU",date:"",source:"",children:(0,i.jsx)(s.p,{children:"L'IA pose un risque mondial \xe0 long terme. M\xeame ses concepteurs n'ont aucune id\xe9e o\xf9 leur perc\xe9e peut mener. J'exhorte [le Conseil de s\xe9curit\xe9 de l'ONU] \xe0 aborder cette technologie avec un sentiment d'urgence [...] Ses cr\xe9ateurs eux-m\xeames ont averti que des risques bien plus importants, potentiellement catastrophiques et existentiels, nous attendent."})}),"\n",(0,i.jsx)(l.A,{speaker:"Kamala Harris",position:"Ancien Vice-Pr\xe9sident des \xc9tats-Unis",date:"",source:"",children:(0,i.jsx)(s.p,{children:"[...] tout comme l'IA a le potentiel de faire un bien profond, elle a aussi le potentiel de causer des dommages profonds. Des cyberattaques facilit\xe9es par l'IA \xe0 une \xe9chelle d\xe9passant tout ce que nous avons vu auparavant aux armes biologiques formul\xe9es par l'IA qui pourraient mettre en danger la vie de millions de personnes, ces menaces sont souvent appel\xe9es les \"menaces existentielles de l'IA\" car, bien s\xfbr, elles pourraient mettre en danger l'existence m\xeame de l'humanit\xe9. Ces menaces sont sans aucun doute profondes et exigent une action mondiale."})}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les pays individuels ne peuvent-ils pas simplement r\xe9glementer l'IA \xe0 l'int\xe9rieur de leurs fronti\xe8res ?"})," La r\xe9ponse courte est : non, pas efficacement. La gestion efficace des syst\xe8mes d'IA avanc\xe9s n\xe9cessite une coordination qui transcende les fronti\xe8res nationales. Cela d\xe9coule de trois probl\xe8mes fondamentaux (",(0,i.jsx)(s.a,{href:"https://www.ceris.be/wp-content/uploads/2024/03/International-Institutions-for-Advanced-AI-Robert-Trager.pdf#:~:text=International%20institutions%20may%20have%20an%20important%20role,to%20innovation%20and%20the%20spread%20of%20benefits.",children:"Ho et al., 2023"}),"):"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Aucun pays n'a le contr\xf4le exclusif sur le d\xe9veloppement de l'IA."})," M\xeame si une nation met en \u0153uvre des r\xe9glementations strictes, les d\xe9veloppeurs dans les pays aux normes plus souples pourraient toujours cr\xe9er et d\xe9ployer des syst\xe8mes d'IA potentiellement dangereux affectant le monde entier (",(0,i.jsx)(s.a,{href:"https://arxiv.org/pdf/2310.09217",children:"Hausenloy et al., 2023"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les risques de l'IA ont un impact mondial."})," La r\xe9gulation de ces risques n\xe9cessite une coop\xe9ration internationale (",(0,i.jsx)(s.a,{href:"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4424123",children:"Tallberg et al., 2023"}),"). Interrog\xe9 sur la participation de la Chine au sommet sur la s\xe9curit\xe9 de l'IA de Bletchley, James Cleverly, ancien ministre britannique des Affaires \xe9trang\xe8res, a justement not\xe9 : \"nous ne pouvons pas prot\xe9ger le public britannique des risques de l'IA si nous excluons l'une des nations leaders en technologie d'IA.\""]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Dynamiques de course vers le bas."})," Les pays craignent un d\xe9savantage concurrentiel dans la course \xe0 l'IA, ce qui cr\xe9e des incitations \xe0 l'arbitrage r\xe9glementaire et compromet les normes de s\xe9curit\xe9 au niveau mondial (",(0,i.jsx)(s.a,{href:"https://scholarship.law.georgetown.edu/facpub/2647/",children:"Lancieri et al., 2024"}),"). La gouvernance internationale peut aider \xe0 aligner les incitations entre les nations, encourageant le d\xe9veloppement responsable de l'IA sans forcer un pays \xe0 sacrifier son avantage concurrentiel (",(0,i.jsx)(s.a,{href:"https://digitalcommons.law.villanova.edu/cgi/viewcontent.cgi?article=3670&context=vlr",children:"Li, 2025"}),")."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(a.A,{src:"https://ourworldindata.org/grapher/cumulative-number-of-large-scale-ai-systems-by-country?tab=chart",width:"100%",height:"600px",loading:"lazy",allow:"web-share; clipboard-write",frameBorder:"0",number:"6",label:"4.6",caption:"Nombre cumul\xe9 de syst\xe8mes d'IA \xe0 grande \xe9chelle par pays depuis 2017. Se r\xe9f\xe8re \xe0 l'emplacement de l'organisation principale \xe0 laquelle les auteurs des syst\xe8mes d'IA \xe0 grande \xe9chelle sont affili\xe9s ([Giattino et al., 2023](https://ourworldindata.org/artificial-intelligence))."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Comment les politiques nationales affectent-elles le d\xe9veloppement mondial de l'IA ?"})," M\xeame des r\xe9glementations apparemment nationales (comme les politiques d'immigration, voir ci-dessous) peuvent remodeler le paysage mondial de l'IA \xe0 travers divers m\xe9canismes de d\xe9bordement."]}),"\n",(0,i.jsx)(u.A,{src:"./img/VMN_Image_32.jpeg",alt:"Saisir la description alternative de l'image",number:"26",label:"4.26",caption:"Quelles sont les trajectoires de carri\xe8re des chercheurs en IA de haut niveau ? ([MacroPolo](https://macropolo.org/digital-projects/the-global-ai-talent-tracker/))"}),"\n",(0,i.jsxs)(s.p,{children:["Les entreprises du monde entier, d\xe9sireuses de maintenir l'acc\xe8s au lucratif march\xe9 europ\xe9en, trouvent souvent plus rentable d'adopter les normes de l'UE dans l'ensemble de leurs op\xe9rations plut\xf4t que de maintenir des normes distinctes pour diff\xe9rentes r\xe9gions. Par exemple, une entreprise technologique am\xe9ricaine d\xe9veloppant un nouveau syst\xe8me de reconnaissance faciale aliment\xe9 par l'IA pour une utilisation dans les espaces publics pourrait voir ce syst\xe8me class\xe9 comme \"\xe0 haut risque\" selon la loi sur l'IA de l'UE. Cela le soumettrait \xe0 des exigences strictes concernant la qualit\xe9 des donn\xe9es, la documentation, la surveillance humaine, et plus encore. Les entreprises ont alors le choix de d\xe9velopper soit deux versions distinctes de leur produit, une pour le march\xe9 de l'UE et une pour partout ailleurs, soit simplement d'appliquer les normes de l'UE mondialement. Beaucoup seront tent\xe9es de choisir la deuxi\xe8me option, pour minimiser leur co\xfbt de conformit\xe9. C'est ce qu'on appelle \"l'effet Bruxelles\" (",(0,i.jsx)(s.a,{href:"https://scholarship.law.columbia.edu/books/232/",children:"Bradford, 2020"}),") : les r\xe9glementations de l'UE peuvent finir par fa\xe7onner les march\xe9s mondiaux, m\xeame dans les pays o\xf9 ces r\xe9glementations ne s'appliquent pas formellement."]}),"\n",(0,i.jsx)(s.p,{children:"L'effet Bruxelles peut se manifester de deux fa\xe7ons :"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Adoption de facto :"})," Les entreprises adoptent souvent volontairement les normes de l'UE mondialement pour \xe9viter la complexit\xe9 et le co\xfbt du maintien de diff\xe9rentes normes pour diff\xe9rents march\xe9s."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Influence de jure :"})," D'autres pays adoptent fr\xe9quemment des r\xe9glementations similaires \xe0 celles de l'UE, soit pour maintenir l'alignement r\xe9glementaire, soit parce qu'ils consid\xe8rent l'approche de l'UE comme un mod\xe8le \xe0 suivre."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:["Les r\xe9glementations de l'UE pourraient offrir la premi\xe8re op\xe9rationnalisation largement adopt\xe9e et mandat\xe9e de concepts comme la \"gestion des risques\" ou le \"risque syst\xe9mique\" dans le contexte de l'IA fronti\xe8re. Alors que d'autres pays s'efforcent de r\xe9glementer les syst\xe8mes d'IA avanc\xe9s, ils pourraient consid\xe9rer le cadre de l'UE comme point de d\xe9part (",(0,i.jsx)(s.a,{href:"https://www.governance.ai/research-paper/brussels-effect-ai",children:"Siegmann & Anderljung 2022"}),")."]}),"\n",(0,i.jsx)(l.A,{speaker:"Ursula von der Leyen",position:"Chef de l'ex\xe9cutif de l'UE",date:"",source:"",children:(0,i.jsx)(s.p,{children:"[Nous] ne devrions pas sous-estimer les menaces r\xe9elles venant de l'IA [...] Elle avance plus vite que ce que m\xeame ses d\xe9veloppeurs avaient anticip\xe9 [...] Nous avons une fen\xeatre d'opportunit\xe9 qui se r\xe9tr\xe9cit pour guider cette technologie de mani\xe8re responsable."})}),"\n",(0,i.jsx)(s.p,{children:"En 2023, les gouvernements am\xe9ricain et britannique ont tous deux annonc\xe9 de nouveaux instituts pour la s\xe9curit\xe9 de l'IA. En 2025, il existe au moins 12 Instituts nationaux de s\xe9curit\xe9 de l'IA (AISI) \xe9tablis dans le monde. Ceux-ci incluent des instituts des \xc9tats-Unis, du Royaume-Uni, du Canada, de France, d'Allemagne, d'Italie, du Japon, de Cor\xe9e du Sud, de Singapour, d'Australie, du Kenya et d'Inde. L'Union europ\xe9enne a \xe9tabli le Bureau europ\xe9en de l'IA, qui fonctionne de mani\xe8re similaire aux AISI nationaux. Ces instituts collaborent \xe0 travers le R\xe9seau international des instituts de s\xe9curit\xe9 de l'IA, lanc\xe9 en novembre 2024, pour coordonner la recherche, partager les meilleures pratiques et d\xe9velopper des normes de s\xe9curit\xe9 interop\xe9rables pour les syst\xe8mes d'IA avanc\xe9s."}),"\n",(0,i.jsx)(u.A,{src:"./img/X4s-countries-international-network-ai-safety.png",alt:"pays du r\xe9seau international pour la s\xe9curit\xe9 de l'IA",number:"27",label:"4.27",caption:"Ces pays font partie du r\xe9seau international pour la s\xe9curit\xe9 de l'IA, avec leurs organismes nationaux respectifs d\xe9di\xe9s \xe0 la s\xe9curit\xe9 de l'IA ([Variengien & Martinet, 2024](https://oecd.ai/en/wonk/ai-safety-institutes-challenge))."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les efforts de gouvernance mondiale font \xe9galement face \xe0 des obstacles majeurs."})," La comp\xe9tition strat\xe9gique entre les principales puissances, qui consid\xe8rent l'IA comme un atout pour la s\xe9curit\xe9 nationale et un moteur \xe9conomique, compromet souvent la coop\xe9ration. Les asym\xe9tries de pouvoir compliquent davantage les n\xe9gociations : les pays disposant de capacit\xe9s d'IA avanc\xe9es, comme les \xc9tats-Unis et la Chine, peuvent r\xe9sister aux contraintes internationales, tandis que d'autres peuvent exiger un transfert de technologie et un soutien au renforcement des capacit\xe9s en \xe9change de leur participation. Les syst\xe8mes politiques et les valeurs divergents posent \xe9galement des obstacles, avec des d\xe9saccords sur des questions telles que la vie priv\xe9e, la libre expression et l'autorit\xe9 de l'\xc9tat. Par exemple, l'Initiative mondiale de gouvernance de l'IA de la Chine met l'accent sur la souverainet\xe9 et la non-ing\xe9rence, contrastant avec les cadres occidentaux ancr\xe9s dans les droits individuels et la responsabilit\xe9 d\xe9mocratique (",(0,i.jsx)(s.a,{href:"https://www.researchgate.net/publication/387730260_Exploring_China's_cyber_sovereignty_concept_and_artificial_intelligence_governance_model_a_machine_learning_approach",children:"Hung, 2025"}),"; ",(0,i.jsx)(s.a,{href:"https://www.cartercenter.org/resources/pdfs/peace/china/finding-firmer-ground-the-role-of-high-technology-in-u.s.-china-relations.pdf",children:"Hsu et al., 2023"}),"). Plus significativement peut-\xeatre, les profonds d\xe9ficits de confiance entre les grandes puissances, aliment\xe9s par les tensions sur le commerce, la propri\xe9t\xe9 intellectuelle et les droits de l'homme, rendent difficile la conclusion d'accords cr\xe9dibles et applicables, s'ajoutant au paysage g\xe9opolitique complexe qui fa\xe7onne l'avenir de la gouvernance internationale de l'IA (",(0,i.jsx)(s.a,{href:"https://www.techpolicy.press/from-competition-to-cooperation-can-uschina-engagement-overcome-geopolitical-barriers-in-ai-governance/",children:"Mishra, 2024"}),")."]}),"\n",(0,i.jsx)(u.A,{src:"./img/IrH_Image_34.jpeg",alt:"Saisir la description alternative de l'image",number:"28",label:"4.28",caption:"Caricature soulignant un \xe9cart entre les d\xe9clarations des pays et leurs v\xe9ritables intentions dans le contexte du Sommet sur la s\xe9curit\xe9 de l'IA au Royaume-Uni en novembre 2023 ([The Economist](https://www.economist.com/the-world-this-week/2023/11/02/kals-cartoon))"}),"\n",(0,i.jsxs)(o.A,{title:"M\xe9canismes Internationaux Existants (2025)",collapsed:!0,children:[(0,i.jsx)(s.p,{children:"Malgr\xe9 ces d\xe9fis, un ensemble d'initiatives internationales a \xe9merg\xe9 pour aborder la gouvernance de l'IA :"}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La s\xe9rie de Sommets mondiaux sur l'IA :"})," Lanc\xe9s par le Royaume-Uni en 2023, les sommets ont \xe9t\xe9 une plateforme permettant aux principaux acteurs de l'\xe9cosyst\xe8me de l'IA de se r\xe9unir et de discuter des priorit\xe9s mondiales en mati\xe8re de s\xe9curit\xe9, d'innovation et de gouvernance de l'IA. Ils continuent d'avoir lieu tous les deux ans, chaque sommet \xe9tant organis\xe9 par un pays diff\xe9rent."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Le Processus IA d'Hiroshima :"})," Lanc\xe9 par les nations du G7, cette initiative vise \xe0 promouvoir le d\xe9veloppement et l'utilisation responsables de l'IA \xe0 travers des politiques coordonn\xe9es."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les efforts des Nations Unies :"})," Incluent les recommandations \xe9thiques de l'UNESCO sur l'IA, l'Organe consultatif de haut niveau, et le prochain Pacte num\xe9rique mondial, un cadre des Nations Unies pour la coop\xe9ration num\xe9rique internationale, ax\xe9 sur un avenir num\xe9rique commun avec une composante IA."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les directives de l'OCDE :"})," L'Organisation de coop\xe9ration et de d\xe9veloppement \xe9conomiques a \xe9t\xe9 particuli\xe8rement influente dans l'\xe9laboration des principes de gouvernance de l'IA qui informent les politiques nationales, et continue de guider les cadres r\xe9gionaux en mettant l'accent sur les droits, la transparence et la responsabilit\xe9."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Le trait\xe9 sur l'IA du Conseil de l'Europe :"})," Ce trait\xe9 propos\xe9 vise \xe0 prot\xe9ger les droits humains dans le contexte du d\xe9veloppement et de l'utilisation de l'IA, en se concentrant sur les limites \xe9thiques."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"L'Initiative mondiale de gouvernance de l'IA de la Chine :"})," D\xe9montrant que la gouvernance de l'IA est une priorit\xe9 m\xeame pour les nations souvent en d\xe9saccord avec les puissances occidentales, la Chine a pr\xe9sent\xe9 sa propre proposition pour la gouvernance internationale de l'IA."]}),"\n"]}),"\n"]})]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Comment \xe9volue typiquement la gouvernance internationale de la technologie ?"})," Comprendre la progression de l'\xe9laboration des politiques internationales aide \xe0 contextualiser les efforts actuels de gouvernance de l'IA et \xe0 identifier les voies potentielles \xe0 suivre. L'\xe9laboration des politiques internationales progresse typiquement \xe0 travers plusieurs \xe9tapes (",(0,i.jsx)(s.a,{href:"https://sk.sagepub.com/ency/edvol/intlpoliticalscience/chpt/stages-model-policy-making",children:"Badie et al., 2011"}),"):"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"D\xe9finition de l'agenda :"})," Identifier la question et la placer \xe0 l'agenda international."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Formulation des politiques :"})," D\xe9velopper des solutions et approches potentielles."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Prise de d\xe9cision :"})," Choisir des plans d'action sp\xe9cifiques."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Mise en \u0153uvre :"})," Mettre en pratique les politiques choisies."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"\xc9valuation :"})," \xc9valuer l'efficacit\xe9 et faire des ajustements."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"Pour la gouvernance de l'IA, nous en sommes encore largement aux premi\xe8res \xe9tapes de ce processus. La S\xe9rie des Sommets sur l'IA, le R\xe9seau des Instituts de s\xe9curit\xe9 de l'IA et d'autres cadres internationaux repr\xe9sentent tous des progr\xe8s dans la d\xe9finition de l'agenda et la formulation initiale des politiques. Mais le v\xe9ritable travail d'\xe9laboration d'accords internationaux contraignants et leur mise en \u0153uvre reste \xe0 venir."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les efforts pr\xe9c\xe9dents de gouvernance internationale fournissent des le\xe7ons pr\xe9cieuses pour l'IA."})," Alors, que pouvons-nous apprendre de d\xe9cennies d'efforts de contr\xf4le des armes nucl\xe9aires ? Consid\xe9rons trois le\xe7ons importantes (",(0,i.jsx)(s.a,{href:"https://www.tandfonline.com/doi/abs/10.1080/13523260.2019.1576464",children:"Maas, 2019"}),"):"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Le pouvoir des normes et des institutions."})," Malgr\xe9 les craintes initiales d'une prolif\xe9ration rapide, seuls neuf pays poss\xe8dent des armes nucl\xe9aires pr\xe8s de 80 ans apr\xe8s leur d\xe9veloppement, r\xe9sultat d'efforts concert\xe9s pour construire des normes mondiales contre la prolif\xe9ration et l'utilisation nucl\xe9aires. Le Trait\xe9 sur la non-prolif\xe9ration des armes nucl\xe9aires (TNP), sign\xe9 en 1968, a cr\xe9\xe9 un cadre pour emp\xeacher la propagation des armes nucl\xe9aires et a aid\xe9 \xe0 promouvoir les utilisations pacifiques de la technologie nucl\xe9aire."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Le r\xf4le des communaut\xe9s \xe9pist\xe9miques."})," Le d\xe9veloppement des accords de contr\xf4le des armes nucl\xe9aires n'\xe9tait pas uniquement l'\u0153uvre de diplomates et de politiciens. Il s'appuyait fortement sur les contributions de scientifiques, d'ing\xe9nieurs et d'autres experts techniques qui comprenaient la technologie et ses implications. Ces experts ont form\xe9 un r\xe9seau de professionnels avec une expertise reconnue dans un domaine particulier, ou ce que les politologues appellent une \"communaut\xe9 \xe9pist\xe9mique\". Ils ont jou\xe9 des r\xf4les importants dans la formation des d\xe9bats politiques, la fourniture de conseils techniques, et ont m\xeame servi de diplomates officieux pendant les p\xe9riodes tendues de la Guerre froide. Contrairement aux physiciens nucl\xe9aires, qui \xe9taient souvent employ\xe9s directement par les gouvernements, de nombreux experts en IA travaillent dans le secteur priv\xe9, donc un d\xe9fi pour former de tels r\xe9seaux pour la gouvernance mondiale de l'IA sera de s'assurer que les communaut\xe9s \xe9pist\xe9miques peuvent efficacement informer les d\xe9cisions politiques."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:'Le d\xe9fi persistant des "accidents normaux."'})," Malgr\xe9 des d\xe9cennies de gestion prudente, l'\xe8re nucl\xe9aire a connu plusieurs incidents o\xf9 l'erreur humaine, les dysfonctionnements techniques ou les malentendus ont failli mener \xe0 la catastrophe. Le sociologue Charles Perrow a qualifi\xe9 ces incidents d'\"accidents normaux\", soutenant que dans des syst\xe8mes complexes et \xe9troitement coupl\xe9s, de tels incidents sont in\xe9vitables (",(0,i.jsx)(s.a,{href:"https://doi.org/10.5465/amr.1985.4278477",children:"1985"}),"). En appliquant le concept \xe0 l'IA, nous pourrions voir des interactions inattendues et des d\xe9faillances en cascade augmenter \xe0 mesure que les syst\xe8mes d'IA deviennent plus complexes et interconnect\xe9s. La vitesse \xe0 laquelle les syst\xe8mes d'IA op\xe8rent pourrait signifier qu'un \"accident normal\" en IA pourrait se d\xe9rouler trop rapidement pour une intervention humaine, remettant en question la notion de \"contr\xf4le humain significatif\", souvent propos\xe9e comme garantie pour les syst\xe8mes d'IA (",(0,i.jsx)(s.a,{href:"https://www.tandfonline.com/doi/abs/10.1080/13523260.2019.1576464",children:"Maas, 2019"}),")."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.h4,{id:"03-00-01",children:"Options Politiques"}),"\n",(0,i.jsx)(l.A,{speaker:"Demis Hassabis",position:"Co-Fondateur et PDG de DeepMind",date:"",source:"",children:(0,i.jsx)(s.p,{children:"Nous devons prendre les risques de l'IA aussi s\xe9rieusement que d'autres d\xe9fis mondiaux majeurs, comme le changement climatique. La communaut\xe9 internationale a mis trop de temps \xe0 coordonner une r\xe9ponse mondiale efficace \xe0 cela, et nous vivons maintenant avec les cons\xe9quences de ce retard. Nous ne pouvons pas nous permettre le m\xeame d\xe9lai avec l'IA [...] alors peut-\xeatre qu'il y aura un jour l'\xe9quivalent de l'AIEA, qui audite effectivement ces choses."})}),"\n",(0,i.jsxs)(s.p,{children:["Plusieurs arrangements institutionnels pourraient soutenir la gouvernance internationale de l'IA (",(0,i.jsx)(s.a,{href:"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4579773",children:"Maas & Villalobos, 2024"}),"):"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Construction du consensus scientifique :"})," Similaire au Groupe d'experts intergouvernemental sur l'\xe9volution du climat (GIEC), un organisme d\xe9di\xe9 pourrait fournir des rapports r\xe9guliers sur les capacit\xe9s et les risques de l'IA pour informer les d\xe9cideurs politiques et le public. \xc9tant donn\xe9 le rythme rapide du d\xe9veloppement de l'IA, cet organisme devrait \xeatre plus agile que les organisations traditionnelles de construction du consensus scientifique."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Construction du consensus politique et \xe9tablissement de normes :"})," S'appuyant sur le consensus scientifique, un forum pour les dirigeants politiques pourrait d\xe9velopper des normes et principes partag\xe9s, peut-\xeatre structur\xe9 comme la Convention-cadre des Nations Unies sur les changements climatiques (CCNUCC). Un tel organisme pourrait faciliter le dialogue continu, n\xe9gocier des accords et adapter les approches de gouvernance \xe0 mesure que la technologie \xe9volue."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Coordination des politiques et de la r\xe9glementation :"})," Un organisme international ax\xe9 sur la coordination des politiques pourrait aider \xe0 harmoniser les r\xe9glementations de l'IA entre les pays, r\xe9duisant la fragmentation et pr\xe9venant les opportunit\xe9s d'arbitrage r\xe9glementaire."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Application des normes et restrictions :"})," Des m\xe9canismes de surveillance de la conformit\xe9 et d'application des normes convenues seraient n\xe9cessaires pour une gouvernance efficace."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Stabilisation et r\xe9ponse d'urgence :"})," Un r\xe9seau mondial d'entreprises, d'experts et de r\xe9gulateurs pr\xeats \xe0 aider en cas de d\xe9faillances majeures des syst\xe8mes d'IA pourrait aider \xe0 att\xe9nuer les risques. Ce groupe pourrait travailler de mani\xe8re proactive pour identifier les vuln\xe9rabilit\xe9s potentielles dans l'infrastructure mondiale de l'IA et d\xe9velopper des plans d'urgence, similaire au Centre des incidents et des urgences de l'Agence internationale de l'\xe9nergie atomique mais op\xe9rant sur des \xe9chelles de temps beaucoup plus rapides."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Recherche conjointe internationale :"})," La recherche collaborative pourrait aider \xe0 garantir que le d\xe9veloppement de l'IA fronti\xe8re priorise la s\xe9curit\xe9 et les r\xe9sultats b\xe9n\xe9fiques, similaire \xe0 la fa\xe7on dont le CERN facilite la coop\xe9ration scientifique internationale."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Distribution des b\xe9n\xe9fices et de l'acc\xe8s :"})," Une institution ax\xe9e sur l'assurance d'un acc\xe8s \xe9quitable aux b\xe9n\xe9fices de l'IA pourrait emp\xeacher une concentration nocive des capacit\xe9s et garantir que les b\xe9n\xe9fices de la technologie sont largement distribu\xe9s \xe0 travers des m\xe9canismes comme un fonds mondial pour l'aide au d\xe9veloppement de l'IA ou des transferts de technologie."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(u.A,{src:"./img/SRN_Image_35.png",alt:"Saisir la description alternative de l'image",number:"29",label:"4.29",caption:"Un tableau d'aper\xe7u des fonctions de gouvernance et de leur objectif."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Qu'est-ce que cela signifie pour la conception d'institutions efficaces ?"})," Il n'y a pas de solution unique qui convienne \xe0 tous. Les institutions pour la gouvernance mondiale de l'IA doivent \xeatre adapt\xe9es aux caract\xe9ristiques uniques de la technologie : cycles d'it\xe9ration rapides, contextes de d\xe9ploiement larges et trajectoires futures incertaines. Nous aurons probablement besoin d'un r\xe9seau d'institutions compl\xe9mentaires, chacune remplissant des fonctions de gouvernance sp\xe9cifiques list\xe9es ci-dessus. La cl\xe9 n'est pas seulement quelles institutions nous construisons, mais pourquoi et comment. Quels risques et b\xe9n\xe9fices sp\xe9cifiques n\xe9cessitent une coordination internationale ? Quelles fonctions sont essentielles pour les g\xe9rer ? Et quels designs correspondent le mieux \xe0 ces fonctions sous des contraintes du monde r\xe9el ? Sans r\xe9ponses claires, la conception institutionnelle risque de devenir un miroir des r\xe9gimes pass\xe9s plut\xf4t qu'une r\xe9ponse aux d\xe9fis de l'IA avanc\xe9e (",(0,i.jsx)(s.a,{href:"https://deepmind.google/discover/blog/exploring-institutions-for-global-ai-governance/",children:"DeepMind, 2024"}),")."]})]})}function g(e={}){const{wrapper:s}={...(0,r.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},3989:(e,s,n)=>{n.d(s,{A:()=>o});var t=n(6540),i=n(6347),r=n(8444);const a={iframeContainer:"iframeContainer_ixkI",loader:"loader_gjvK",spinner:"spinner_L1j2",spin:"spin_rtC2",iframeWrapper:"iframeWrapper_Tijy",iframe:"iframe_UAfa",caption:"caption_mDwB",captionLink:"captionLink_Ly4l"};var l=n(4848);function o(e){let{src:s,caption:n,title:o="Embedded content",height:u="500px",width:d="100%",chapter:c,number:p,label:m}=e;const[h,g]=(0,t.useState)(!0),v=(0,i.zy)(),f=c||(()=>{const e=v.pathname.match(/\/chapters\/(\d+)/);return e?parseInt(e[1]):null})(),x=u&&"100%"!==u&&"auto"!==u;return(0,l.jsxs)("figure",{className:a.iframeContainer,children:[h&&(0,l.jsxs)("div",{className:a.loader,children:[(0,l.jsx)("div",{className:a.spinner}),(0,l.jsx)("p",{children:"Loading content..."})]}),(0,l.jsx)("div",{className:a.iframeWrapper,style:{paddingBottom:x?"0":"56.25%",height:x?u:"auto"},children:(0,l.jsx)("iframe",{src:s,title:o,width:d,height:x?u:"100%",frameBorder:"0",allowFullScreen:!0,loading:"lazy",onLoad:()=>{g(!1)},className:a.iframe,style:{height:x?u:"100%",position:x?"static":"absolute"}})}),(0,l.jsx)(r.A,{caption:n,mediaType:"iframe",chapter:f,number:p,label:m})]})}}}]);