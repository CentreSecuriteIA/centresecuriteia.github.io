"use strict";(self.webpackChunkatlas=self.webpackChunkatlas||[]).push([[4040],{3297:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>c,contentTitle:()=>d,default:()=>h,frontMatter:()=>u,metadata:()=>t,toc:()=>p});const t=JSON.parse('{"id":"chapters/01/9","title":"Annexe : Discussion sur les LLMs","description":"Les LLMs actuels, bien qu\'entra\xeen\xe9s sur des donn\xe9es abondantes, sont encore loin d\'\xeatre parfaits.","source":"@site/i18n/fr/docusaurus-plugin-content-docs/current/chapters/01/09.md","sourceDirName":"chapters/01","slug":"/chapters/01/09","permalink":"/fr/chapters/01/09","draft":false,"unlisted":false,"editUrl":"https://github.com/markov-root/atlas/edit/main/docs/chapters/01/09.md","tags":[],"version":"current","sidebarPosition":10,"frontMatter":{"id":"9","title":"Annexe : Discussion sur les LLMs","sidebar_label":"1.9 Annexe : Discussion sur les LLMs","sidebar_position":10,"slug":"/chapters/01/09","reading_time_core":"18 min","reading_time_optional":"5 min","pagination_prev":"chapters/01/8","pagination_next":null},"sidebar":"docs","previous":{"title":"1.8 Annexe : Avis d\'experts","permalink":"/fr/chapters/01/08"}}');var i=n(4848),r=n(8453),a=n(2482),l=n(8559),o=(n(9585),n(2501));const u={id:9,title:"Annexe : Discussion sur les LLMs",sidebar_label:"1.9 Annexe : Discussion sur les LLMs",sidebar_position:10,slug:"/chapters/01/09",reading_time_core:"18 min",reading_time_optional:"5 min",pagination_prev:"chapters/01/8",pagination_next:null},d="Annexe : Discussion sur les LLMs",c={},p=[{value:"Insuffisance empirique ?",id:"01",level:2},{value:"Compr\xe9hension superficielle ?",id:"02",level:2},{value:"Inad\xe9quation structurelle ?",id:"03",level:2},{value:"Diff\xe9rences avec le cerveau",id:"04",level:2},{value:"Autres raisons de poursuivre le d\xe9veloppement des LLM",id:"05",level:2}];function m(e){const s={a:"a",em:"em",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components},{GlossaryTerm:n}=s;return n||function(e,s){throw new Error("Expected "+(s?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("GlossaryTerm",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.header,{children:(0,i.jsx)(s.h1,{id:"annexe--discussion-sur-les-llms",children:"Annexe : Discussion sur les LLMs"})}),"\n",(0,i.jsx)(s.p,{children:"Les LLMs actuels, bien qu'entra\xeen\xe9s sur des donn\xe9es abondantes, sont encore loin d'\xeatre parfaits."}),"\n",(0,i.jsx)(s.p,{children:"Ces probl\xe8mes persisteront-ils dans les futures it\xe9rations, ou dispara\xeetront-ils ? Cette section examine les principales critiques de ces mod\xe8les et tente de d\xe9terminer si elles sont valides m\xeame pour les futurs LLMs."}),"\n",(0,i.jsx)(s.p,{children:"Ce type d'\xe9valuation qualitative est important pour savoir si les LLMs repr\xe9sentent la voie la plus probable vers l'AGI ou non."}),"\n",(0,i.jsx)(s.h2,{id:"01",children:"Insuffisance empirique ?"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les LLM peuvent-ils \xeatre cr\xe9atifs ?"})," La cr\xe9ativit\xe9 des LLM est souvent d\xe9battue, mais il existe des indications claires que l'IA est, en principe, capable de processus cr\xe9atifs de diff\xe9rentes mani\xe8res :"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Recherche scientifique autonome :"})," Les avanc\xe9es r\xe9centes ont montr\xe9 que les LLM peuvent effectivement faire de nouvelles d\xe9couvertes. Par exemple, une \xe9tude de DeepMind a d\xe9montr\xe9 qu'un LLM \"",(0,i.jsx)(s.em,{children:"a d\xe9couvert de nouvelles solutions pour le probl\xe8me des ensembles cap\xe9s, un probl\xe8me math\xe9matique ouvert de longue date"}),'" (',(0,i.jsx)(s.a,{href:"https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/",children:"DeepMind, 2023"}),") qui \xe9tait un probl\xe8me ouvert favori de Terence Tao. Cela indique que l'IA peut non seulement comprendre les connaissances existantes mais aussi apporter de nouvelles perspectives dans des domaines complexes comme les math\xe9matiques."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"D\xe9couverte autonome :"})," L'IA a la capacit\xe9 de red\xe9couvrir ind\xe9pendamment des strat\xe9gies et des ouvertures humaines. AlphaGo, par exemple, a red\xe9couvert des strat\xe9gies et des ouvertures humaines du jeu de Go par auto-apprentissage (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2111.09259",children:"McGrath et al., 2021"}),"), sans aucune donn\xe9e humaine. Cela d\xe9montre la capacit\xe9 d'une IA \xe0 apprendre et innover de mani\xe8re ind\xe9pendante dans des domaines \xe9tablis."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Optimisation cr\xe9ative :"})," L'IA peut optimiser de mani\xe8re \xe9tonnamment cr\xe9ative. Les ph\xe9nom\xe8nes de d\xe9tournement des sp\xe9cifications, o\xf9 l'IA trouve des solutions non intentionnelles aux probl\xe8mes, l'illustrent. Bien que cette impr\xe9visibilit\xe9 pose ses d\xe9fis, elle montre \xe9galement que les syst\xe8mes d'IA peuvent proposer des solutions nouvelles et cr\xe9atives qui pourraient ne pas \xeatre imm\xe9diatement \xe9videntes ou intuitives pour les r\xe9solveurs de probl\xe8mes humains. Le billet de blog de DeepMind sur le d\xe9tournement des sp\xe9cifications illustre ce point de mani\xe8re vivante (",(0,i.jsx)(s.a,{href:"https://deepmind.google/discover/blog/specification-gaming-the-flip-side-of-ai-ingenuity/",children:"Krakovna et al., 2020"}),")."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les LLM ne sont-ils pas trop lents \xe0 apprendre ?"})," Les arguments contre les mod\xe8les de langage bas\xe9s sur les transformers affirment souvent qu'ils sont trop inefficaces en termes d'\xe9chantillons, et que les LLM sont extr\xeamement lents \xe0 apprendre de nouveaux concepts par rapport aux humains. Pour am\xe9liorer les performances dans de nouvelles t\xe2ches ou situations, on argue souvent que les LLM n\xe9cessitent un entra\xeenement sur d'\xe9normes quantit\xe9s de donn\xe9es \u2014 des millions de fois plus qu'un humain n'en aurait besoin. Cependant, il y a une tendance croissante vers l'efficacit\xe9 des donn\xe9es, et une conviction croissante que cela peut \xeatre consid\xe9rablement am\xe9lior\xe9 dans les futurs mod\xe8les."]}),"\n",(0,i.jsxs)(s.p,{children:["EfficientZero est un agent d'apprentissage par renforcement qui d\xe9passe la performance m\xe9diane humaine sur un ensemble de 26 jeux Atari apr\xe8s seulement deux heures d'exp\xe9rience en temps r\xe9el par jeu (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2111.00210",children:"Ye et al., 2021"}),"; ",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2403.00564",children:"Wang et al., 2024"}),"). C'est une am\xe9lioration consid\xe9rable par rapport aux algorithmes pr\xe9c\xe9dents, montrant les bonds potentiels en efficacit\xe9 des donn\xe9es. La promesse ici n'est pas seulement un apprentissage plus efficace mais aussi le potentiel d'adaptation rapide et de ma\xeetrise dans de nouvelles t\xe2ches, similaire \xe0 la vitesse d'apprentissage d'un enfant. EfficientZero n'est pas un LLM, mais il montre que l'",(0,i.jsx)(n,{term:"deep learning",definition:'{"definition":"Un sous-ensemble de l\'apprentissage automatique utilisant des r\xe9seaux neuronaux \xe0 plusieurs couches cach\xe9es pour apprendre des mod\xe8les complexes dans les donn\xe9es..","source":"","aliases":["Deep Learning","DL","apprentissage profond","Apprentissage Profond"]}',children:(0,i.jsx)(n,{term:"deep learning",definition:'{"definition":"Un sous-ensemble de l\'apprentissage automatique utilisant des r\xe9seaux neuronaux \xe0 plusieurs couches cach\xe9es pour apprendre des mod\xe8les complexes dans les donn\xe9es..","source":"","aliases":["Deep Learning","DL","apprentissage profond","Apprentissage Profond"]}',children:"apprentissage profond"})})," peut parfois \xeatre rendu efficace."]}),"\n",(0,i.jsxs)(s.p,{children:['Les lois d\'\xe9chelle indiquent que les IA plus grandes ont tendance \xe0 \xeatre plus efficaces en termes de donn\xe9es, n\xe9cessitant moins de donn\xe9es pour atteindre le m\xeame niveau de performance que leurs homologues plus petits. Des articles comme "Language Models are Few-Shot Learners" (',(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2005.14165",children:"Brown et al., 2020"}),") et les preuves que les mod\xe8les plus grands semblent n\xe9cessiter moins de donn\xe9es pour atteindre le m\xeame niveau de performance (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2001.08361",children:"Kaplan et al., 2020"}),"), sugg\xe8rent qu'\xe0 mesure que les mod\xe8les s'agrandissent, ils deviennent plus comp\xe9tents avec moins d'exemples. Cette tendance pointe vers un futur o\xf9 l'IA pourrait \xeatre capable de s'adapter rapidement et d'apprendre \xe0 partir de donn\xe9es limit\xe9es, remettant en question l'id\xe9e que les IA sont intrins\xe8quement des apprenants lents compar\xe9s aux humains."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les LLM sont-ils robustes aux changements de distribution ?"})," Bien qu'il soit vrai que l'IA n'ait pas encore atteint une robustesse maximale, par exemple \xeatre capable de performer parfaitement apr\xe8s un changement de distribution, il y a eu des progr\xe8s consid\xe9rables :"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La robustesse est corr\xe9l\xe9e aux capacit\xe9s :"})," La robustesse est \xe9troitement li\xe9e aux capacit\xe9s des mod\xe8les d'IA lorsque les IA sont entra\xeen\xe9es sur des t\xe2ches difficiles. Par exemple, il y a une am\xe9lioration significative de la robustesse et du transfert d'apprentissage de GPT-2 \xe0 GPT-4. En vision par ordinateur, les mod\xe8les r\xe9cents comme Segment Anything (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2304.02643",children:"Kirillov et al., 2023"}),") sont beaucoup plus robustes et capables de transfert d'apprentissage que leurs pr\xe9d\xe9cesseurs moins capables. Cette progression n'est pas due \xe0 des facteurs myst\xe9rieux mais plut\xf4t au r\xe9sultat de la mise \xe0 l'\xe9chelle et de l'am\xe9lioration des architectures existantes."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La robustesse est un continuum, et une robustesse parfaite n'est peut-\xeatre pas n\xe9cessaire :"})," La robustesse en IA ne devrait pas \xeatre vue comme un concept binaire, mais plut\xf4t comme existant sur un continuum. Ce continuum est \xe9vident dans la fa\xe7on dont les mod\xe8les d'IA, comme ceux de classification d'images, surpassent souvent la performance humaine en termes de capacit\xe9 et de robustesse (",(0,i.jsx)(s.a,{href:"https://aiimpacts.org/time-for-ai-to-cross-the-human-performance-range-in-imagenet-image-classification/",children:"Korzekwa, 2022"}),"). Cependant, il est important de reconna\xeetre qu'aucun syst\xe8me n'est compl\xe8tement immunis\xe9 contre les d\xe9fis tels que les attaques adverses. Ceci est illustr\xe9 par des IA avanc\xe9es comme Katago au Go qui, bien que vuln\xe9rables \xe0 de telles attaques (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2211.00241",children:"Wang et al., 2022"}),"), atteignent toujours un niveau de jeu surhumain. Cependant, la qu\xeate d'une robustesse parfaite pourrait ne pas \xeatre essentielle pour cr\xe9er une IA transformative capable, car m\xeame des syst\xe8mes avec certaines vuln\xe9rabilit\xe9s peuvent atteindre des niveaux de comp\xe9tence surhumains. Cependant, bien que la robustesse puisse ne pas \xeatre n\xe9cessaire pour cr\xe9er une IA capable, la cr\xe9ation d'une IA s\xfbre et align\xe9e devra r\xe9soudre le probl\xe8me de la mauvaise g\xe9n\xe9ralisation des objectifs."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.h2,{id:"02",children:"Compr\xe9hension superficielle ?"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Perroquets stochastiques : Les IA ne font-elles que m\xe9moriser l'information sans vraiment la comprimer ?"}),' Il existe deux mani\xe8res arch\xe9typales de repr\xe9senter l\'information dans un LLM : soit m\xe9moriser point par point, comme une table de consultation, soit comprimer l\'information en ne m\xe9morisant que les caract\xe9ristiques de haut niveau, ce que nous pouvons alors appeler "le mod\xe8le du monde". Ceci est expliqu\xe9 dans l\'important article "Superposition, Memorization, and Double Descent" (',(0,i.jsx)(s.a,{href:"https://transformer-circuits.pub/2023/toy-double-descent/index.html",children:"Anthropic, 2023"}),") : il s'av\xe8re que pour stocker des points, le mod\xe8le apprend initialement la position de tous les points (pure m\xe9morisation), puis, si nous augmentons le nombre de points, le mod\xe8le commence \xe0 comprimer cette connaissance, et le mod\xe8le est alors capable de g\xe9n\xe9ralisation (et impl\xe9mente un mod\xe8le simple des donn\xe9es)."]}),"\n",(0,i.jsx)(a.A,{speaker:"Francois Chollet",position:"\xc9minent chercheur en IA",date:"",source:"([Chollet, 2023](https://x.com/fchollet/status/1736079054313574578?s=20))",children:(0,i.jsx)(s.p,{children:"Malheureusement, trop peu de personnes comprennent la distinction entre m\xe9morisation et compr\xe9hension. Ce n'est pas une question abstraite comme 'le syst\xe8me a-t-il un mod\xe8le interne du monde ?', c'est une distinction tr\xe8s pragmatique de comportement : 'le syst\xe8me est-il capable de g\xe9n\xe9ralisation large, ou est-il limit\xe9 \xe0 une g\xe9n\xe9ralisation locale ?'"})}),"\n",(0,i.jsx)(o.A,{src:"./img/XcP_Image_30.png",alt:"Entrer la description alternative de l'image",number:"44",label:"1.44",caption:"De Superposition, M\xe9morisation et Double Descente ([Anthropic, 2023](https://transformer-circuits.pub/2023/toy-double-descent/index.html))"}),"\n",(0,i.jsxs)(s.p,{children:['L\'IA est capable de comprimer l\'information, souvent de mani\xe8re pertinente. Par exemple, en examinant les repr\xe9sentations des mots repr\xe9sentant les couleurs dans les LLM comme "rouge" et "bleu", la structure form\xe9e par tous les ',(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:(0,i.jsx)(n,{term:"embedding",definition:'{"definition":"Une repr\xe9sentation vectorielle dense d\'objets discrets (tels que des mots ou des tokens) dans un espace vectoriel continu qui capture les relations s\xe9mantiques..","source":"","aliases":["Embedding","word embedding","embeddings","vector representation","vector embeddings","Plongement"]}',children:"embeddings"})})," de ces couleurs cr\xe9e le cercle chromatique correct (Cela utilise une projection non lin\xe9aire comme le T-SNE pour projeter depuis l'espace de haute dimension vers le plan 2D). D'autres exemples de mod\xe8les du monde sont pr\xe9sent\xe9s dans un article intitul\xe9 \"Eight Things to Know about Large Language Models\" (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2304.00612",children:"Bowman, 2023"}),")."]}),"\n",(0,i.jsxs)(s.p,{children:["Bien s\xfbr, il existe d'autres domaines o\xf9 l'IA ressemble davantage \xe0 une table de consultation, mais c'est un spectre, et chaque cas doit \xeatre examin\xe9 individuellement. Par exemple, pour \"l'association factuelle\", l'article \"Locating and Editing Factual Associations in GPT\" montre que la structure de donn\xe9es sous-jacente pour GPT-2 est plus proche d'une table de consultation (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2202.05262",children:"Meng et al., 2023"}),"), mais l'article \"Emergent Linear Representations in World Models of Self-Supervised Sequence Models\" d\xe9montre qu'un petit GPT est capable d'apprendre un mod\xe8le du monde comprim\xe9 d'OthelloGpt. (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2309.00941",children:"Nanda et al., 2023"}),") Il y a plus d'exemples dans la section d\xe9di\xe9e aux mod\xe8les du monde dans l'article \"Eight Things to Know about Large Language Models\" (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2304.00612",children:"Bowman, 2023"}),")."]}),"\n",(0,i.jsxs)(s.p,{children:["Il est clair que les LLM compriment leurs repr\xe9sentations au moins un peu. De nombreux exemples de capacit\xe9s impressionnantes sont pr\xe9sent\xe9s dans le travail \"The Stochastic Parrot Hypothesis is debatable for the last generation of LLMs\", qui montre qu'il ne peut pas s'agir uniquement de m\xe9morisation. (",(0,i.jsx)(s.a,{href:"https://www.lesswrong.com/posts/HxRjHq3QG8vcYy4yy/the-stochastic-parrot-hypothesis-is-debatable-for-the-last",children:"Feuillade-Montixi & Peign\xe9, 2023"}),")"]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les LLM vont-ils in\xe9vitablement halluciner ?"}),' Les LLM sont enclins \xe0 "halluciner", un terme utilis\xe9 pour d\xe9crire la g\xe9n\xe9ration de contenu absurde ou factuellement incorrect en r\xe9ponse \xe0 certaines requ\xeates. Ce probl\xe8me, mis en \xe9vidence dans des \xe9tudes comme "On Faithfulness and Factuality in Abstractive Summarization" par Maynez et al. (',(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2005.00661",children:"Maynez et al., 2020"}),') et "TruthfulQA: Measuring How Models Mimic Human Falsehoods" par Lin et al. (',(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2109.07958",children:"Lin et al., 2022"}),"), pose un d\xe9fi important. Cependant, il est important de voir que ces d\xe9fis sont anticip\xe9s en raison de la configuration d'entra\xeenement et peuvent \xeatre att\xe9nu\xe9s :"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Biais inh\xe9rent aux textes sources :"})," Une des raisons fondamentales pour lesquelles les LLM peuvent produire du contenu faux est les donn\xe9es d'entra\xeenement, qui ne sont pas toujours enti\xe8rement factuelles ou impartiales. En essence, les LLM refl\xe8tent la nature diverse et parfois contradictoire de leurs donn\xe9es d'entra\xeenement. Dans ce contexte, les LLM 'hallucinent' constamment, mais occasionnellement, ces hallucinations s'alignent avec notre perception de la r\xe9alit\xe9."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Strat\xe9gies pour am\xe9liorer la pr\xe9cision factuelle :"})," La tendance des LLM \xe0 g\xe9n\xe9rer des hallucinations peut \xeatre significativement diminu\xe9e en utilisant diverses techniques. Voir l'encadr\xe9 ci-dessous pour une d\xe9composition de celles-ci."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les mod\xe8les plus grands peuvent \xeatre plus v\xe9ridiques que les plus petits."})," C'est le cas avec TruthfulQA. OpenAI rapporte que GPT-4 est 40% plus pr\xe9cis et factuellement coh\xe9rent que son pr\xe9d\xe9cesseur."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(l.A,{title:"De nombreuses techniques peuvent \xeatre utilis\xe9es pour am\xe9liorer la v\xe9racit\xe9 des LLM.",collapsed:!0,children:[(0,i.jsxs)(s.p,{children:[(0,i.jsxs)(s.strong,{children:[(0,i.jsx)(n,{term:"fine-tuning",definition:'{"definition":"Processus consistant \xe0 prendre un mod\xe8le pr\xe9-entra\xeen\xe9 et \xe0 le perfectionner pour une t\xe2che ou un ensemble de donn\xe9es sp\xe9cifique..","source":"","aliases":["Fine-tuning","fine-tune","finetuning","finetune","affinage","Affinage"]}',children:"Fine-tuning"})," des LLM pour la factualit\xe9 :"]})," Dans cet article (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2311.08401",children:"Tian et al., 2023"}),"), les auteurs recommandent des m\xe9thodes de ",(0,i.jsx)(n,{term:"fine-tuning",definition:'{"definition":"Processus consistant \xe0 prendre un mod\xe8le pr\xe9-entra\xeen\xe9 et \xe0 le perfectionner pour une t\xe2che ou un ensemble de donn\xe9es sp\xe9cifique..","source":"","aliases":["Fine-tuning","fine-tune","finetuning","finetune","affinage","Affinage"]}',children:(0,i.jsx)(n,{term:"fine-tuning",definition:'{"definition":"Processus consistant \xe0 prendre un mod\xe8le pr\xe9-entra\xeen\xe9 et \xe0 le perfectionner pour une t\xe2che ou un ensemble de donn\xe9es sp\xe9cifique..","source":"","aliases":["Fine-tuning","fine-tune","finetuning","finetune","affinage","Affinage"]}',children:"fine-tuning"})})," utilisant l'optimisation directe des pr\xe9f\xe9rences (DPO) pour diminuer le taux d'hallucinations. En appliquant ces techniques, un mod\xe8le Llama 2 7B a vu une r\xe9duction de 58% du taux d'erreurs factuelles par rapport \xe0 son mod\xe8le original."]}),(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"G\xe9n\xe9ration augment\xe9e par la recherche (RAG)."})," Cette m\xe9thode fonctionne en incorporant un processus de recherche d'informations du monde r\xe9el (recherche, comme une recherche Google) puis en utilisant ces informations pour guider les r\xe9ponses de l'IA (g\xe9n\xe9ration, bas\xe9e sur le document r\xe9cup\xe9r\xe9). Ce faisant, l'IA est mieux ancr\xe9e dans la r\xe9alit\xe9 factuelle, r\xe9duisant les chances de produire du contenu irr\xe9aliste ou incorrect. Essentiellement, c'est comme donner \xe0 l'IA une biblioth\xe8que de r\xe9f\xe9rence pour v\xe9rifier les faits pendant qu'elle apprend et r\xe9pond, assurant que sa sortie est plus ancr\xe9e dans la r\xe9alit\xe9. Cette approche est particuli\xe8rement utile dans le contexte de l'apprentissage en contexte, o\xf9 l'IA apprend des informations et du contexte fournis dans chaque interaction."]}),(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les techniques de prompting"})," en IA ont \xe9volu\xe9 pour inclure des m\xe9thodes sophistiqu\xe9es comme"]}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les v\xe9rifications de coh\xe9rence"})," (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2306.09983",children:"Fluri et al., 2023"}),"), qui impliquent de comparer la sortie de plusieurs instances du mod\xe8le sur le m\xeame prompt, identifiant et r\xe9solvant tout d\xe9saccord dans les r\xe9ponses. Cette m\xe9thode am\xe9liore la pr\xe9cision et la cr\xe9dibilit\xe9 des informations fournies. Par exemple, si diff\xe9rentes it\xe9rations du mod\xe8le produisent des r\xe9ponses contradictoires, cette divergence peut \xeatre utilis\xe9e pour affiner et am\xe9liorer la compr\xe9hension du mod\xe8le."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Reflexion."})," La technique Reflexion (\"Reflexion: Language Agents with Verbal Reinforcement Learning\") : Il est possible de simplement demander au LLM de prendre du recul, de se demander si ce qu'il a fait est correct ou non, et de consid\xe9rer des moyens d'am\xe9liorer la r\xe9ponse pr\xe9c\xe9dente, et cela am\xe9liore beaucoup les capacit\xe9s de GPT-4. Cette technique est \xe9mergente et ne fonctionne pas bien avec les mod\xe8les pr\xe9c\xe9dents. (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2303.11366",children:"Shinn et al., 2023"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les cha\xeenes de v\xe9rification,"})," comme ",(0,i.jsx)(s.strong,{children:"l'inf\xe9rence de s\xe9lection"})," (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2205.09712",children:"Creswell et al., 2022"}),"). Chain-of-Thought a acc\xe8s au contexte complet, donc chaque \xe9tape de raisonnement n'est pas n\xe9cessairement causalement connect\xe9e \xe0 la derni\xe8re. Mais l'inf\xe9rence de s\xe9lection impose une structure o\xf9 chaque \xe9tape de raisonnement d\xe9coule n\xe9cessairement de la pr\xe9c\xe9dente, et donc toute la cha\xeene de raisonnement est causale. Ce processus implique que le mod\xe8le d'IA examine son propre raisonnement ou les \xe9tapes qu'il a suivies pour arriver \xe0 une conclusion. Ce faisant, il peut v\xe9rifier la logique et la coh\xe9rence de ses r\xe9ponses, s'assurant qu'elles sont bien fond\xe9es et fiables."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Permettre \xe0 l'IA d'exprimer des degr\xe9s de confiance"}),' dans ses r\xe9ponses, reconnaissant l\'incertitude quand c\'est appropri\xe9. Par exemple, au lieu d\'un "Oui" ou "Non" d\xe9finitif, le mod\xe8le pourrait r\xe9pondre "Je ne suis pas s\xfbr", refl\xe9tant une compr\xe9hension plus nuanc\xe9e similaire au raisonnement humain. Cette approche est \xe9vidente dans les mod\xe8les avanc\xe9s comme Gopher (',(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2112.11446",children:"Rae et al., 2022"}),"), qui contraste avec les mod\xe8les ant\xe9rieurs comme WebGPT qui peuvent ne pas pr\xe9senter le m\xeame niveau de r\xe9ponses nuanc\xe9es."]}),"\n"]}),"\n"]}),(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"L'entra\xeenement bas\xe9 sur le processus"})," garantit que les syst\xe8mes sont habitu\xe9s \xe0 d\xe9tailler leurs pens\xe9es beaucoup plus en d\xe9tail et \xe0 ne pas pouvoir sauter trop d'\xe9tapes de raisonnement. Par exemple, voir l'article d'OpenAI Improving Mathematical Reasoning with process supervision (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2305.20050",children:"Lightman et al., 2023"}),")."]}),(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Entra\xeenement \xe0 la m\xe9tacognition :"})," Les mod\xe8les peuvent \xeatre entra\xeen\xe9s \xe0 donner la probabilit\xe9 de ce qu'ils affirment, une forme de m\xe9tacognition. Par exemple, l'article \"Language Models (Mostly) Know What They Know\" (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2207.05221",children:"Kadavath et al., 2022"}),") d\xe9montre que les IA peuvent \xeatre calibr\xe9es de mani\xe8re bay\xe9sienne concernant leurs connaissances. Cela implique qu'elles peuvent avoir une forme rudimentaire de conscience de soi, reconnaissant la probabilit\xe9 de leur propre exactitude. Informellement, cela signifie qu'il est possible d'interroger un chatbot avec \"\xcates-vous s\xfbr de ce que vous me dites ?\" et recevoir une r\xe9ponse relativement fiable. Cela peut servir d'entra\xeenement contre les hallucinations."]}),(0,i.jsx)(s.p,{children:"Il est important de noter que ces techniques permettent une att\xe9nuation substantielle des probl\xe8mes pour les LLM actuels, mais elles ne r\xe9solvent pas tous les probl\xe8mes que nous rencontrons avec l'IA qui sont potentiellement trompeurs, comme nous le verrons dans le chapitre sur la mauvaise g\xe9n\xe9ralisation des objectifs."})]}),"\n",(0,i.jsx)(s.h2,{id:"03",children:"Inad\xe9quation structurelle ?"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les LLM manquent-ils de Syst\xe8me 2 ?"})," Le Syst\xe8me 1 et le Syst\xe8me 2 sont des termes popularis\xe9s par l'\xe9conomiste Daniel Kahneman dans son livre \"Thinking, Fast and Slow\", d\xe9crivant les deux fa\xe7ons diff\xe9rentes dont notre cerveau forme des pens\xe9es et prend des d\xe9cisions. Le Syst\xe8me 1 est rapide, automatique et intuitif ; c'est la partie de notre pens\xe9e qui g\xe8re les d\xe9cisions et jugements quotidiens sans beaucoup d'effort ou de d\xe9lib\xe9ration consciente. Par exemple, lorsque vous reconnaissez un visage ou comprenez des phrases simples, vous utilisez g\xe9n\xe9ralement le Syst\xe8me 1. En revanche, le Syst\xe8me 2 est plus lent, plus d\xe9lib\xe9ratif et plus logique. Il prend le relais lorsque vous r\xe9solvez un probl\xe8me complexe, faites un choix conscient ou vous concentrez sur une t\xe2che difficile. Il n\xe9cessite plus d'\xe9nergie et est plus contr\xf4l\xe9, g\xe9rant des t\xe2ches comme la planification pour l'avenir, la v\xe9rification de la validit\xe9 d'un argument complexe, ou toute activit\xe9 n\xe9cessitant une concentration profonde. Ensemble, ces syst\xe8mes interagissent et influencent notre fa\xe7on de penser, de juger et de d\xe9cider, soulignant la complexit\xe9 de la pens\xe9e et du comportement humains."]}),"\n",(0,i.jsxs)(s.p,{children:["Une pr\xe9occupation majeure est de savoir si les LLM sont capables d'\xe9muler les processus du Syst\xe8me 2, qui impliquent une r\xe9flexion plus lente, plus d\xe9lib\xe9r\xe9e et logique. Certains arguments th\xe9oriques sur la limite de profondeur dans les transformers montrent qu'ils sont manifestement incapables de diviser internement de grands nombres (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2207.02098",children:"Del\xe9tang et al., 2023"}),"). Cependant, ce n'est pas ce que nous observons en pratique : GPT-4 est capable de d\xe9tailler certains calculs \xe9tape par \xe9tape et d'obtenir le r\xe9sultat attendu \xe0 travers une cha\xeene de pens\xe9e ou via l'utilisation d'outils comme un interpr\xe9teur de code."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"M\xe9tacognition \xe9mergente."})," Les fonctions \xe9mergentes dans les LLM, comme la technique Reflexion (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2303.11366",children:"Shinn et al., 2023"}),"), permettent \xe0 ces mod\xe8les d'analyser r\xe9trospectivement et d'am\xe9liorer leurs r\xe9ponses. Il est possible de demander au LLM de prendre du recul, de questionner la justesse de ses actions pr\xe9c\xe9dentes et d'envisager des moyens d'am\xe9liorer la r\xe9ponse pr\xe9c\xe9dente. Cela am\xe9liore consid\xe9rablement les capacit\xe9s de GPT-4, renfor\xe7ant ses capacit\xe9s et les alignant davantage avec les op\xe9rations du Syst\xe8me 2 humain. Notez que cette technique est \xe9mergente et ne fonctionne pas bien avec les mod\xe8les pr\xe9c\xe9dents."]}),"\n",(0,i.jsx)(s.p,{children:"Ces r\xe9sultats sugg\xe8rent un effacement des fronti\xe8res entre ces deux syst\xe8mes. Les processus du Syst\xe8me 2 peuvent \xeatre essentiellement un assemblage de multiples processus du Syst\xe8me 1, apparaissant plus lents en raison de l'implication de plus d'\xe9tapes et d'interactions avec des formes de m\xe9moire plus lentes. Cette perspective est parall\xe8le \xe0 la fa\xe7on dont les mod\xe8les de langage fonctionnent, chaque \xe9tape dans un processus du Syst\xe8me 1 \xe9tant similaire \xe0 une \xe9tape d'ex\xe9cution en temps constant dans des mod\xe8les comme GPT. Bien que ces mod\xe8les peinent \xe0 orchestrer intentionnellement ces \xe9tapes pour r\xe9soudre des probl\xe8mes complexes, d\xe9composer les t\xe2ches en \xe9tapes plus petites (prompting du moins au plus) ou les inciter \xe0 un raisonnement incr\xe9mental (prompting par Cha\xeene de Pens\xe9e (CoT)) am\xe9liore significativement leurs performances."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les LLM manquent-ils d'un mod\xe8le interne du monde ?"}),' La notion de "mod\xe8le du monde" en IA ne doit pas \xeatre limit\xe9e \xe0 un encodage explicite dans une architecture. Contrairement aux approches comme H-JEPA (',(0,i.jsx)(s.a,{href:"https://openreview.net/pdf?id=BZ5a1r-kVsf",children:"LeCun, 2022"}),"), qui pr\xe9conisent un mod\xe8le du monde explicite pour am\xe9liorer l'entra\xeenement de l'IA, il y a de plus en plus de preuves qu'un mod\xe8le du monde peut \xeatre efficacement implicite. Ce concept est particuli\xe8rement \xe9vident dans l'apprentissage par renforcement (RL), o\xf9 la distinction entre RL bas\xe9 sur un mod\xe8le et sans mod\xe8le peut \xeatre quelque peu trompeuse. M\xeame dans le RL sans mod\xe8le, les algorithmes encodent souvent implicitement une forme de mod\xe8le du monde qui est cruciale pour une performance optimale."]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Temps et coordonn\xe9es g\xe9ographiques :"})," La recherche sur les mod\xe8les Llama-2 r\xe9v\xe8le comment ces mod\xe8les peuvent repr\xe9senter l'information spatiale et temporelle (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2310.02207",children:"Gurney & Tegmark, 2024"}),"). Les LLM comme les mod\xe8les Llama-2 encodent des coordonn\xe9es approximatives du monde r\xe9el et des chronologies historiques des villes. Les d\xe9couvertes cl\xe9s incluent l'\xe9mergence graduelle des repr\xe9sentations g\xe9ographiques \xe0 travers les couches du mod\xe8le, la lin\xe9arit\xe9 de ces repr\xe9sentations, et la robustesse des mod\xe8les \xe0 diff\xe9rents prompts. De mani\xe8re significative, l'\xe9tude montre que les mod\xe8les ne se contentent pas de traiter passivement cette information mais apprennent activement la g\xe9om\xe9trie globale de l'espace et du temps."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Repr\xe9sentation du plateau :"}),' Dans l\'article "Emergent Linear Representations in World Models of Self-Supervised Sequence Models" (',(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2309.00941",children:"Nanda et al., 2023"}),"), l'auteur pr\xe9sente des d\xe9couvertes significatives sur la nature des repr\xe9sentations dans les mod\xe8les d'IA. L'article explore comment le mod\xe8le Othello-GPT, entra\xeen\xe9 \xe0 pr\xe9dire les coups l\xe9gaux dans le jeu d'Othello, d\xe9veloppe une repr\xe9sentation \xe9mergente du monde du plateau de jeu ! Contrairement aux croyances pr\xe9c\xe9dentes selon lesquelles cette repr\xe9sentation \xe9tait non lin\xe9aire, il d\xe9montre qu'elle est, en fait, lin\xe9aire. Il d\xe9couvre que le mod\xe8le repr\xe9sente les \xe9tats du plateau non pas en termes de pi\xe8ces noires ou blanches, mais comme \"ma couleur\" ou \"leur couleur\", s'alignant avec la perspective du mod\xe8le de jouer des deux c\xf4t\xe9s. Ce travail \xe9claire le potentiel des mod\xe8les d'IA \xe0 d\xe9velopper des repr\xe9sentations du monde complexes, mais lin\xe9aires, \xe0 travers des objectifs simples comme la pr\xe9diction du prochain token."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"D'autres exemples"}),' sont pr\xe9sent\xe9s dans l\'article : "Eight Things to know about LLMs". (',(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2304.00612",children:"Bowman, 2023"}),")"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les LLM peuvent-ils apprendre continuellement et avoir une m\xe9moire \xe0 long terme ?"})," L'apprentissage continu et la gestion efficace de la m\xe9moire \xe0 long terme repr\xe9sentent des d\xe9fis significatifs dans le domaine de l'IA en g\xe9n\xe9ral."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Oubli catastrophique."})," Un obstacle crucial dans ce domaine est l'oubli catastrophique, un ph\xe9nom\xe8ne o\xf9 un r\xe9seau neuronal, en apprenant de nouvelles informations, tend \xe0 oublier enti\xe8rement les informations pr\xe9c\xe9demment apprises. Cette question est un axe important de la recherche en cours, visant \xe0 d\xe9velopper des syst\xe8mes d'IA qui peuvent retenir et construire sur leurs connaissances au fil du temps. Par exemple, supposons que nous entra\xeenions une IA sur un jeu Atari. \xc0 la fin du second entra\xeenement, l'IA a tr\xe8s probablement oubli\xe9 comment jouer au premier jeu. C'est un exemple d'oubli catastrophique."]}),"\n",(0,i.jsxs)(s.p,{children:["Mais supposons maintenant que nous entra\xeenions une grande IA sur de nombreux jeux ATARI, simultan\xe9ment, et ajoutons m\xeame du texte Internet et des t\xe2ches robotiques. Cela peut simplement fonctionner. Par exemple, l'IA GATO illustre ce processus d'entra\xeenement et exemplifie ce que nous appelons la ",(0,i.jsx)(s.strong,{children:"b\xe9n\xe9diction de l'\xe9chelle,"})," qui est que ce qui est impossible dans les petits r\xe9gimes peut devenir possible dans les grands r\xe9gimes."]}),"\n",(0,i.jsxs)(s.p,{children:["D'autres techniques sont d\xe9velopp\xe9es pour r\xe9soudre la m\xe9moire \xe0 long terme, par exemple, les ",(0,i.jsx)(s.strong,{children:"approches bas\xe9es sur l'\xe9chafaudage"})," ont \xe9galement \xe9t\xe9 employ\xe9es pour atteindre la m\xe9moire \xe0 long terme et l'apprentissage continu en IA. L'\xe9chafaudage en IA fait r\xe9f\xe9rence \xe0 l'utilisation de wrappers cod\xe9s en dur, structures explicitement programm\xe9es par les humains qui impliquent une boucle for pour interroger continuellement le mod\xe8le :"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"LangChain"})," aborde ces d\xe9fis en cr\xe9ant de vastes banques de m\xe9moire. LangChain est une biblioth\xe8que Python qui permet aux LLM de r\xe9cup\xe9rer et d'utiliser des informations provenant de grands ensembles de donn\xe9es, fournissant essentiellement un moyen pour l'IA d'acc\xe9der \xe0 un vaste r\xe9f\xe9rentiel de connaissances et d'utiliser ces informations pour construire des r\xe9ponses plus inform\xe9es. Cependant, cette approche peut ne pas \xeatre la plus \xe9l\xe9gante en raison de sa d\xe9pendance aux sources de donn\xe9es externes et aux m\xe9canismes complexes de r\xe9cup\xe9ration. Une solution potentiellement plus fluide et int\xe9gr\xe9e pourrait impliquer l'utilisation des poids du r\xe9seau neuronal comme m\xe9moire dynamique, \xe9voluant et se mettant \xe0 jour constamment en fonction des t\xe2ches effectu\xe9es par le r\xe9seau."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Voyager :"})," Un exemple remarquable de m\xe9moire \xe0 long terme bas\xe9e sur l'\xe9chafaudage est l'IA Voyager, un syst\xe8me d'IA d\xe9velopp\xe9 sous le paradigme \"AutoGPT\". Ce syst\xe8me est notable pour sa capacit\xe9 \xe0 s'engager dans un apprentissage continu dans un environnement de jeu 3D comme Minecraft. Dans une seule session de jeu, AI Voyager d\xe9montre la capacit\xe9 d'apprendre les contr\xf4les de base, d'atteindre des objectifs initiaux comme l'acquisition de ressources, et finalement d'avancer vers des comportements plus complexes, incluant le combat avec des ennemis et la fabrication d'outils pour rassembler des ressources sophistiqu\xe9es. Cela d\xe9montre une avanc\xe9e significative dans la capacit\xe9 des LLM \xe0 apprendre continuellement et \xe0 g\xe9rer la m\xe9moire \xe0 long terme dans des environnements dynamiques."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"Il convient de noter que la m\xe9moire \xe0 long terme bas\xe9e sur l'\xe9chafaudage n'est pas consid\xe9r\xe9e comme une solution \xe9l\xe9gante, et les puristes pr\xe9f\xe9reraient utiliser les poids propres du syst\xe8me comme m\xe9moire \xe0 long terme."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Planification"})," La planification est un domaine o\xf9 les IA luttent actuellement, mais il y a des progr\xe8s significatifs. Certains paradigmes, comme ceux bas\xe9s sur l'\xe9chafaudage, permettent la d\xe9composition des t\xe2ches et la d\xe9composition des objectifs en sous-objectifs plus petits et plus r\xe9alisables."]}),"\n",(0,i.jsxs)(s.p,{children:["De plus, l'article \"Voyager: An Open-Ended Embodied Agent with Large Language Models\" d\xe9montre qu'il est possible d'utiliser GPT-4 pour la planification en langage naturel dans Minecraft (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2305.16291",children:"Wang et al., 2023"}),")."]}),"\n",(0,i.jsx)(s.h2,{id:"04",children:"Diff\xe9rences avec le cerveau"}),"\n",(0,i.jsx)(s.p,{children:"Il semble qu'il existe plusieurs points de convergence entre les LLM et le cortex linguistique :"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Similitudes comportementales."})," Les LLM montrent une comparaison \xe9troite avec les capacit\xe9s linguistiques humaines et le cortex linguistique (",(0,i.jsx)(s.a,{href:"https://www.lesswrong.com/posts/3nMpdmt8LrzxQnkGp/ai-timelines-via-cumulative-optimization-power-less-long",children:"Canell, 2022"}),"). Ces mod\xe8les ont excell\xe9 dans la ma\xeetrise de la syntaxe et d'une partie importante de la s\xe9mantique du langage humain. Bien s\xfbr, aujourd'hui, ils accusent encore un retard dans des aspects tels que la m\xe9moire \xe0 long terme, la coh\xe9rence et le raisonnement g\xe9n\xe9ral - des facult\xe9s qui, chez l'humain, d\xe9pendent de diverses r\xe9gions c\xe9r\xe9brales comme l'hippocampe et le cortex pr\xe9frontal, mais nous avons expliqu\xe9 dans les sections pr\xe9c\xe9dentes que ces probl\xe8mes pourraient \xeatre r\xe9solubles."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Convergence des repr\xe9sentations internes :"})," Les LLM ont une repr\xe9sentation qui converge avec l'\xe9chelle vers la repr\xe9sentation c\xe9r\xe9brale. Ceci est soutenu par l'\xe9tude \"Brains and algorithms partially converge in natural language processing.\" (",(0,i.jsx)(s.a,{href:"https://www.nature.com/articles/s42003-022-03036-1",children:"Caucheteux & King, 2022"}),') Des perspectives suppl\xe9mentaires peuvent \xeatre trouv\xe9es dans les travaux "The Brain as a Universal Learning Machine" (',(0,i.jsx)(s.a,{href:"https://www.lesswrong.com/posts/9Yc7Pp7szcjPgPsjf/the-brain-as-a-universal-learning-machine",children:"Canell, 2015"}),') et "Brain Efficiency: Much More than You Wanted to Know." (',(0,i.jsx)(s.a,{href:"https://www.lesswrong.com/posts/xwBuoE9p8GE7RAuhd/brain-efficiency-much-more-than-you-wanted-to-know",children:"Canell, 2022"}),') \xc0 des stades d\'apprentissage comparables, les LLM et le cortex linguistique d\xe9veloppent des repr\xe9sentations de caract\xe9ristiques similaires ou \xe9quivalentes. Dans certaines \xe9valuations, les LLM avanc\xe9s ont pu pr\xe9dire 100% de la variance neuronale explicable, comme d\xe9taill\xe9 par Schrimpf, Martin, et al. dans "The neural architecture of language: Integrative modeling converges on predictive processing." (',(0,i.jsx)(s.a,{href:"https://www.pnas.org/content/118/45/e2105646118",children:"Schrimpf et al., 2021"}),")"]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"L'\xe9chelle est \xe9galement importante chez les primates."})," La principale diff\xe9rence architecturale entre le cerveau humain et celui des autres primates semble \xeatre le nombre de neurones plut\xf4t qu'autre chose, comme d\xe9montr\xe9 dans diverses \xe9tudes. (",(0,i.jsx)(s.a,{href:"https://pubmed.ncbi.nlm.nih.gov/22723358/",children:"Houzel, 2012"}),"; ",(0,i.jsx)(s.a,{href:"https://pubmed.ncbi.nlm.nih.gov/36789740/",children:"Pearson et al., 2023"}),"; ",(0,i.jsx)(s.a,{href:"https://pubmed.ncbi.nlm.nih.gov/33563125/",children:"Charvet, 2021"}),")."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.h2,{id:"05",children:"Autres raisons de poursuivre le d\xe9veloppement des LLM"}),"\n",(0,i.jsx)(s.p,{children:"Voici quelques raisons de croire que les laboratoires continueront \xe0 d\xe9velopper les LLM."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les lois de mise \xe0 l'\xe9chelle des LLM impliquent d'autres am\xe9liorations qualitatives."})," Les lois de mise \xe0 l'\xe9chelle peuvent ne pas sembler impressionnantes au premier abord. Cependant, relier ces mesures quantitatives peut se traduire par une am\xe9lioration qualitative de la qualit\xe9 de l'algorithme. Un algorithme qui atteint une perte quasi parfaite est n\xe9cessairement un algorithme qui comprend toutes les subtilit\xe9s et fait preuve d'une \xe9norme adaptabilit\xe9. Le fait que les lois de mise \xe0 l'\xe9chelle ne fl\xe9chissent pas est tr\xe8s significatif et signifie que nous pouvons rendre le mod\xe8le qualitativement meilleur en raisonnement."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Des corr\xe9lations simples \xe0 la compr\xe9hension."})," Au cours d'un entra\xeenement, les GPT passent des corr\xe9lations basiques \xe0 une compr\xe9hension de plus en plus profonde. Initialement, le mod\xe8le \xe9tablit simplement des connexions entre les mots successifs. Progressivement, il d\xe9veloppe une compr\xe9hension de la grammaire et de la s\xe9mantique, cr\xe9ant des liens entre les phrases puis entre les paragraphes. Finalement, GPT ma\xeetrise les nuances du style d'\xe9criture."]}),"\n",(0,i.jsx)(l.A,{title:"Exercice : les lois d'\xe9chelle sur les LLM impliquent d'autres am\xe9liorations qualitatives.",collapsed:!0,children:(0,i.jsx)(s.p,{children:'Calculons la diff\xe9rence de perte, mesur\xe9e en bits, entre deux sorties de mod\xe8le : "Janelle a mang\xe9 de la glace parce qu\'il aime les choses sucr\xe9es comme la glace" et "Janelle a mang\xe9 de la glace parce qu\'elle aime les choses sucr\xe9es comme la glace". La phrase contient environ vingt tokens. Si le mod\xe8le h\xe9site entre "Il" ou "Elle", choisissant au hasard (probabilit\xe9 50/50), il encourt une perte de 2 bits sur le token du pronom lorsqu\'il est incorrect. La perte pour les autres tokens reste la m\xeame dans les deux mod\xe8les. Cependant, comme le mod\xe8le n\'est incorrect que la moiti\xe9 du temps, un facteur de 1/2 doit \xeatre appliqu\xe9. Cela donne une diff\xe9rence de (1/2) * (2/20) = 1/20, soit 0,05 bits. Ainsi, un mod\xe8le \xe0 0,05 bits de la perte th\xe9orique minimale devrait \xeatre capable de comprendre des concepts encore plus nuanc\xe9s que celui discut\xe9 ci-dessus.'})}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La compl\xe9tion de texte est probablement un test AI-complete"})," (",(0,i.jsx)(s.a,{href:"https://en.wikipedia.org/wiki/AI-complete",children:"Wikipedia, 2022"}),")."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les LLM actuels n'ont qu'autant de param\xe8tres que les petits mammif\xe8res ont de synapses, pas \xe9tonnant qu'ils soient encore imparfaits."})," Les mod\xe8les comme GPT-4, bien que tr\xe8s grands compar\xe9s aux autres mod\xe8les, doivent \xeatre not\xe9s pour leur \xe9chelle relativement modeste par rapport \xe0 la taille d'un cerveau humain. Pour illustrer, le plus grand mod\xe8le GPT-3 a un nombre similaire de param\xe8tres aux synapses d'un h\xe9risson. Nous ne savons pas vraiment combien de param\xe8tres GPT-4 poss\xe8de, mais s'il est de la m\xeame taille que PALM, qui a 512 milliards de param\xe8tres, alors GPT-4 n'a qu'autant de param\xe8tres qu'un chinchilla a de synapses. En revanche, le n\xe9ocortex humain contient environ 140 billions de synapses, soit plus de 200 fois plus de synapses qu'un chinchilla. Pour une discussion plus approfondie sur cette comparaison, voir la discussion connexe ",(0,i.jsx)(s.a,{href:"https://www.lesswrong.com/posts/YKfNZAmiLdepDngwi/gpt-175bee",children:"ici"}),". Pour une discussion sur le nombre de param\xe8tres n\xe9cessaires pour \xe9muler une synapse, voir la discussion sur les ancrages biologiques."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"GPT-4 est encore des ordres de grandeur moins cher que d'autres grands projets scientifiques :"})," Malgr\xe9 les co\xfbts \xe9lev\xe9s associ\xe9s \xe0 l'entra\xeenement des grands mod\xe8les, les avanc\xe9es significatives dans les capacit\xe9s de l'IA justifient ces co\xfbts. Par exemple, GPT-4 est co\xfbteux compar\xe9 aux autres mod\xe8les de ",(0,i.jsx)(n,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:(0,i.jsx)(n,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:"ML"})}),". On dit qu'il co\xfbte 50M en formation. Mais le Projet Manhattan a co\xfbt\xe9 25B, soit 500 fois plus sans tenir compte de l'inflation, et atteindre l'intelligence au niveau humain pourrait \xeatre plus important \xe9conomiquement que d'obtenir la bombe nucl\xe9aire."]}),"\n",(0,i.jsx)(s.p,{children:"Collectivement, ces points soutiennent l'id\xe9e que l'AGI peut \xeatre r\xe9alis\xe9e uniquement en d\xe9veloppant les algorithmes actuels."})]})}function h(e={}){const{wrapper:s}={...(0,r.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(m,{...e})}):m(e)}}}]);