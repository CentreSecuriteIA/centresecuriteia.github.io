"use strict";(self.webpackChunkatlas=self.webpackChunkatlas||[]).push([[2235],{3850:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>p,contentTitle:()=>u,default:()=>g,frontMatter:()=>c,metadata:()=>s,toc:()=>m});const s=JSON.parse('{"id":"chapters/01/1","title":"L\'IA \xe0 la Pointe du Progr\xe8s","description":"Au cours de la derni\xe8re d\xe9cennie, le domaine de l\'intelligence artificielle (IA) a connu une transformation profonde, largement attribu\xe9e aux succ\xe8s de l\'apprentissage profond. Ces progr\xe8s remarquables ont red\xe9fini les limites des capacit\xe9s de l\'IA, remettant en question de nombreuses id\xe9es pr\xe9con\xe7ues sur ce que les machines peuvent accomplir. Les sections suivantes d\xe9taillent certaines de ces avanc\xe9es.","source":"@site/i18n/fr/docusaurus-plugin-content-docs/current/chapters/01/01.md","sourceDirName":"chapters/01","slug":"/chapters/01/01","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/01/01","draft":false,"unlisted":false,"editUrl":"https://github.com/markov-root/atlas/edit/main/docs/chapters/01/01.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"1","title":"L\'IA \xe0 la Pointe du Progr\xe8s","sidebar_label":"1.1 L\'IA \xe0 la Pointe du Progr\xe8s","sidebar_position":2,"slug":"/chapters/01/01","reading_time_core":"9 min","reading_time_optional":"4 min","pagination_prev":"chapters/01/index","pagination_next":"chapters/01/2"},"sidebar":"docs","previous":{"title":"Capacit\xe9s","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/01/"},"next":{"title":"1.2 Mod\xe8les de fondation","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/01/02"}}');var i=a(4848),t=a(8453),r=a(3989),l=a(3931),o=(a(2482),a(8559)),d=(a(9585),a(2501));const c={id:1,title:"L'IA \xe0 la Pointe du Progr\xe8s",sidebar_label:"1.1 L'IA \xe0 la Pointe du Progr\xe8s",sidebar_position:2,slug:"/chapters/01/01",reading_time_core:"9 min",reading_time_optional:"4 min",pagination_prev:"chapters/01/index",pagination_next:"chapters/01/2"},u="L'IA \xe0 la pointe de la technologie",p={},m=[{value:"Langue",id:"01",level:2},{value:"G\xe9n\xe9ration d&#39;images",id:"02",level:2},{value:"Multi &amp; Cross modalit\xe9",id:"03",level:2},{value:"Robotique",id:"04",level:2},{value:"Jeux",id:"05",level:2}];function h(e){const n={a:"a",em:"em",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...e.components},{GlossaryTerm:a}=n;return a||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("GlossaryTerm",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"lia-\xe0-la-pointe-de-la-technologie",children:"L'IA \xe0 la pointe de la technologie"})}),"\n",(0,i.jsxs)(n.p,{children:["Au cours de la derni\xe8re d\xe9cennie, le domaine de l'intelligence artificielle (IA) a connu une transformation profonde, largement attribu\xe9e aux succ\xe8s de l'",(0,i.jsx)(a,{term:"deep learning",definition:'{"definition":"Un sous-ensemble de l\'apprentissage automatique utilisant des r\xe9seaux neuronaux \xe0 plusieurs couches cach\xe9es pour apprendre des mod\xe8les complexes dans les donn\xe9es..","source":"","aliases":["Deep Learning","DL","apprentissage profond","Apprentissage Profond"]}',children:(0,i.jsx)(a,{term:"deep learning",definition:'{"definition":"Un sous-ensemble de l\'apprentissage automatique utilisant des r\xe9seaux neuronaux \xe0 plusieurs couches cach\xe9es pour apprendre des mod\xe8les complexes dans les donn\xe9es..","source":"","aliases":["Deep Learning","DL","apprentissage profond","Apprentissage Profond"]}',children:"apprentissage profond"})}),". Ces progr\xe8s remarquables ont red\xe9fini les limites des capacit\xe9s de l'IA, remettant en question de nombreuses id\xe9es pr\xe9con\xe7ues sur ce que les machines peuvent accomplir. Les sections suivantes d\xe9taillent certaines de ces avanc\xe9es."]}),"\n",(0,i.jsx)(r.A,{src:"https://ourworldindata.org/grapher/test-scores-ai-capabilities-relative-human-performance?country=Handwriting+recognition~Speech+recognition~Image+recognition~Reading+comprehension~Language+understanding~Predictive+reasoning~Code+generation~Complex+reasoning~General+knowledge+tests~Nuanced+language+interpretation~Math+problem-solving~Reading+comprehension+with+unanswerable+questions&tab=chart",width:"100%",height:"600px",loading:"lazy",allow:"web-share; clipboard-write",frameBorder:"0",number:"1",label:"1.1",caption:"Les scores des tests des syst\xe8mes d'IA sur diverses capacit\xe9s par rapport aux performances humaines. Dans chaque domaine, la performance initiale de l'IA est fix\xe9e \xe0 -100. La performance humaine sert de r\xe9f\xe9rence, fix\xe9e \xe0 z\xe9ro. Lorsque la performance de l'IA franchit la ligne z\xe9ro, elle a marqu\xe9 plus de points que les humains ([Giattino et al., 2023](https://ourworldindata.org/artificial-intelligence))."}),"\n",(0,i.jsxs)(n.p,{children:["Une fois qu'un ",(0,i.jsx)(a,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:(0,i.jsx)(a,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:"benchmark"})})," est publi\xe9, il faut de moins en moins de temps pour le r\xe9soudre. Cela peut illustrer l'acc\xe9l\xe9ration des progr\xe8s en IA et la rapidit\xe9 avec laquelle les benchmarks d'IA \"saturent\" et commencent \xe0 d\xe9passer les performances humaines dans diverses t\xe2ches. (",(0,i.jsx)(n.a,{href:"https://ourworldindata.org/grapher/test-scores-ai-capabilities-relative-human-performance?country=Handwriting+recognition~Speech+recognition~Image+recognition~Reading+comprehension~Language+understanding~Predictive+reasoning~Code+generation~Complex+reasoning~General+knowledge+tests~Nuanced+language+interpretation~Math+problem-solving~Reading+comprehension+with+unanswerable+questions",children:"Our World in Data, 2023"}),")"]}),"\n",(0,i.jsx)(r.A,{src:"https://ourworldindata.org/grapher/domain-notable-artificial-intelligence-systems?tab=chart",width:"100%",height:"600px",loading:"lazy",allow:"web-share; clipboard-write",frameBorder:"0",number:"2",label:"1.2",caption:"Domaine des syst\xe8mes d'intelligence artificielle notables, par ann\xe9e de publication. D\xe9crit le domaine sp\xe9cifique, l'application ou le champ dans lequel un syst\xe8me d'IA est con\xe7u pour fonctionner. Un syst\xe8me d'IA peut op\xe9rer dans plusieurs domaines, contribuant ainsi au d\xe9compte de plusieurs domaines ([Giattino et al., 2023](https://ourworldindata.org/artificial-intelligence))."}),"\n",(0,i.jsx)(n.h2,{id:"01",children:"Langue"}),"\n",(0,i.jsx)(r.A,{src:"https://ourworldindata.org/grapher/ai-performance-coding-math-knowledge-tests?tab=chart",width:"100%",height:"600px",loading:"lazy",allow:"web-share; clipboard-write",frameBorder:"0",number:"3",label:"1.3",caption:"Syst\xe8mes d'IA les plus performants en codage, math\xe9matiques et tests de connaissances linguistiques. La performance en codage est mesur\xe9e avec le benchmark APPS ; la performance en math\xe9matiques avec le benchmark MATH ; et les tests de connaissances linguistiques avec le benchmark MMLU ([Giattino et al., 2023](https://ourworldindata.org/artificial-intelligence))."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"T\xe2ches bas\xe9es sur le langage."})," Il y a eu des changements transformateurs dans les t\xe2ches bas\xe9es sur les s\xe9quences et le langage, principalement gr\xe2ce au d\xe9veloppement des grands mod\xe8les de langage (LLM). Les premiers mod\xe8les de langage en 2018 peinaient \xe0 construire des phrases coh\xe9rentes. L'\xe9volution de ceux-ci aux capacit\xe9s avanc\xe9es de GPT-3 (Generative Pre-Trained ",(0,i.jsx)(a,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:(0,i.jsx)(a,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:"Transformer"})}),") et ChatGPT en moins de 5 ans est remarquable. Ces mod\xe8les d\xe9montrent non seulement une capacit\xe9 am\xe9lior\xe9e \xe0 g\xe9n\xe9rer du texte, mais aussi \xe0 r\xe9pondre \xe0 des requ\xeates complexes avec un raisonnement nuanc\xe9 et de bon sens. Leurs performances dans diverses t\xe2ches de questions-r\xe9ponses, y compris celles n\xe9cessitant une r\xe9flexion strat\xe9gique, ont \xe9t\xe9 particuli\xe8rement impressionnantes."]}),"\n",(0,i.jsxs)(n.p,{children:["Contrairement au GPT-3 uniquement textuel et ses successeurs, GPT-4 est ",(0,i.jsx)(a,{term:"multimodal",definition:'{"definition":"Relatif aux syst\xe8mes d\'IA capables de traiter et de comprendre simultan\xe9ment plusieurs types de donn\xe9es (telles que du texte, des images, des fichiers audio ou vid\xe9o)..","source":"","aliases":["Multimodal","multi-modal","multimodality"]}',children:(0,i.jsx)(a,{term:"multimodal",definition:'{"definition":"Relatif aux syst\xe8mes d\'IA capables de traiter et de comprendre simultan\xe9ment plusieurs types de donn\xe9es (telles que du texte, des images, des fichiers audio ou vid\xe9o)..","source":"","aliases":["Multimodal","multi-modal","multimodality"]}',children:"multimodal"})})," : il a \xe9t\xe9 entra\xeen\xe9 sur du texte et des images. Cela signifie qu'il peut maintenant non seulement g\xe9n\xe9rer du texte bas\xe9 sur des images mais a \xe9galement acquis d'autres capacit\xe9s. GPT-4 a b\xe9n\xe9fici\xe9 d'une fen\xeatre de contexte am\xe9lior\xe9e allant jusqu'\xe0 32k tokens (tokens \u2248 mots). La limite de m\xe9moire \xe0 court terme d'un LLM peut \xeatre consid\xe9r\xe9e comme la capacit\xe9 du mod\xe8le \xe0 retenir des informations des tokens pr\xe9c\xe9dents dans une certaine fen\xeatre de contexte. GPT-4 est entra\xeen\xe9 via la pr\xe9diction du token suivant (apprentissage auto-supervis\xe9 autor\xe9gressif). En 2018, GPT-1 pouvait \xe0 peine compter jusqu'\xe0 10, tandis qu'en 2024, GPT-4 peut impl\xe9menter des fonctions programmatiques complexes entre autres choses."]}),"\n",(0,i.jsx)(d.A,{src:"./img/CAe_Image_2.png",alt:"Entrer la description alternative de l'image",number:"2",label:"1.2",caption:"Une liste de probl\xe8mes 'Loin d'\xeatre r\xe9solus' [...] en IA, tir\xe9e de 'Une br\xe8ve histoire de l'IA', publi\xe9e en janvier 2021 ([Wooldridge, 2021](https://www.amazon.com/Brief-History-Artificial-Intelligence-Where/dp/1250770742)). Ils disent \xe9galement : '\xc0 l'heure actuelle, nous n'avons aucune id\xe9e de comment faire faire aux ordinateurs les t\xe2ches en bas de la liste'. Mais tout dans la cat\xe9gorie 'Loin d'\xeatre r\xe9solu' a \xe9t\xe9 r\xe9solu par GPT-4 ([Bubeck et al., 2023](https://arxiv.org/abs/2303.12712)), sauf l'intelligence g\xe9n\xe9rale de niveau humain."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Mise \xe0 l'\xe9chelle."})," Remarquablement, GPT-4 est entra\xeen\xe9 en utilisant \xe0 peu pr\xe8s les m\xeames m\xe9thodes que GPT-1, 2 et 3. La seule diff\xe9rence significative est la taille du mod\xe8le et les donn\xe9es qui lui sont fournies pendant l'entra\xeenement. La taille du mod\xe8le est pass\xe9e de 1,5 milliard de param\xe8tres \xe0 des centaines de milliards de param\xe8tres, et les ensembles de donn\xe9es sont devenus similairement plus grands et plus diversifi\xe9s."]}),"\n",(0,i.jsx)(d.A,{src:"./img/uW1_Image_3.png",alt:"Entrer la description alternative de l'image",number:"3",label:"1.3",caption:"\xc0 quelle vitesse l'IA s'am\xe9liore-t-elle ? ([AI Digest, 2023](https://theaidigest.org/progress-and-dangers))"}),"\n",(0,i.jsx)(n.p,{children:"Nous avons observ\xe9 qu'une simple expansion d'\xe9chelle a contribu\xe9 \xe0 am\xe9liorer les performances. Cela inclut des am\xe9liorations dans la capacit\xe9 \xe0 g\xe9n\xe9rer des r\xe9ponses contextuellement appropri\xe9es, et des textes tr\xe8s diversifi\xe9s dans de nombreux domaines. Cela a \xe9galement contribu\xe9 \xe0 une meilleure compr\xe9hension globale et une plus grande coh\xe9rence. La plupart de ces avanc\xe9es dans la s\xe9rie GPT proviennent de l'augmentation de la taille et de la puissance de calcul derri\xe8re les mod\xe8les, plut\xf4t que de changements fondamentaux dans l'architecture ou l'entra\xeenement."}),"\n",(0,i.jsx)(n.p,{children:"Voici certaines des capacit\xe9s qui ont \xe9merg\xe9 ces derni\xe8res ann\xe9es :"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Apprentissage \xe0 peu d'exemples et sans exemple."})," La capacit\xe9 du mod\xe8le \xe0 comprendre et ex\xe9cuter des t\xe2ches avec un minimum ou aucun exemple pr\xe9alable. L'apprentissage \xe0 'peu d'exemples' signifie accomplir la t\xe2che apr\xe8s avoir vu quelques exemples dans la fen\xeatre de contexte, tandis que l'apprentissage 'sans exemple' indique l'ex\xe9cution de la t\xe2che sans aucun exemple sp\xe9cifique (",(0,i.jsx)(n.a,{href:"https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html",children:"Anthropic, 2022"}),"). Cela inclut \xe9galement les capacit\xe9s d'induction, c'est-\xe0-dire l'identification de motifs et la g\xe9n\xe9ralisation de r\xe8gles non pr\xe9sentes dans l'entra\xeenement, mais uniquement pr\xe9sentes dans la fen\xeatre de contexte actuelle (",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2005.14165",children:"Brown et al., 2020"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"M\xe9tacognition."})," Cela fait r\xe9f\xe9rence \xe0 la capacit\xe9 de reconna\xeetre ses propres connaissances et limites, par exemple, \xeatre capable de conna\xeetre la probabilit\xe9 de la v\xe9racit\xe9 de quelque chose (",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2207.05221",children:"Kadavath, 2022"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Th\xe9orie de l'esprit."})," La capacit\xe9 d'attribuer des \xe9tats mentaux \xe0 soi-m\xeame et aux autres, ce qui aide \xe0 pr\xe9dire les comportements et r\xe9ponses humains pour des interactions plus nuanc\xe9es (",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2302.02083",children:"Kosinski 2023"}),"; ",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2402.06044",children:"Xu et al., 2024"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Utilisation d'outils."})," \xcatre capable d'interagir avec des outils externes, comme utiliser une calculatrice ou naviguer sur Internet, \xe9largissant ses capacit\xe9s de r\xe9solution de probl\xe8mes (",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2307.16789",children:"Qin et al., 2023"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Auto-correction."})," La capacit\xe9 du mod\xe8le \xe0 identifier et corriger ses propres erreurs, ce qui est crucial pour am\xe9liorer la pr\xe9cision du contenu g\xe9n\xe9r\xe9 par l'IA (",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2303.11366",children:"Shinn et al., 2023"}),")."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(d.A,{src:"./img/vR6_Image_4.png",alt:"Entrer la description alternative de l'image",number:"4",label:"1.4",caption:"Un exemple de probl\xe8me math\xe9matique r\xe9solu par GPT-4 utilisant la Cha\xeene de Pens\xe9e (CoT) ([Bubeck et al., 2023](https://arxiv.org/abs/2303.12712))."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Raisonnement."})," Les avanc\xe9es dans les LLM ont \xe9galement conduit \xe0 des am\xe9liorations significatives dans la capacit\xe9 \xe0 traiter et g\xe9n\xe9rer des cha\xeenes logiques de pens\xe9e et de raisonnement. C'est particuli\xe8rement important dans les t\xe2ches de r\xe9solution de probl\xe8mes o\xf9 une r\xe9ponse directe n'est pas imm\xe9diatement disponible, et o\xf9 un processus de raisonnement \xe9tape par \xe9tape est n\xe9cessaire. (",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2303.12712",children:"Bubeck et al., 2023"}),")"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Capacit\xe9 de programmation."})," En programmation, les mod\xe8les d'IA sont pass\xe9s de l'autocompl\xe9tion de code basique \xe0 l'\xe9criture de programmes sophistiqu\xe9s et fonctionnels."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Capacit\xe9 scientifique et math\xe9matique."})," En math\xe9matiques, les IA assistent dans le sous-domaine de la d\xe9monstration automatique de th\xe9or\xe8mes depuis des d\xe9cennies. Les mod\xe8les d'aujourd'hui continuent d'aider \xe0 r\xe9soudre des probl\xe8mes complexes. L'IA peut m\xeame atteindre un niveau m\xe9daille d'or aux Olympiades math\xe9matiques en r\xe9solvant des probl\xe8mes de g\xe9om\xe9trie (",(0,i.jsx)(n.a,{href:"https://www.nature.com/articles/s41586-023-06747-5",children:"Trinh et al., 2024"}),")."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(d.A,{src:"./img/Fyr_Image_8.png",alt:"Entrer la description alternative de l'image",number:"5",label:"1.5",caption:"Notez \xe9galement le grand bond de GPT-3.5 \xe0 GPT-4 dans le percentile humain sur ces tests, passant souvent de bien en dessous de la m\xe9diane humaine au sommet de l'\xe9chelle humaine. ([Aschenbrenner, 2024](https://situational-awareness.ai/from-gpt-4-to-agi/); [OpenAI, 2023](https://arxiv.org/abs/2303.08774)). Gardez \xe0 l'esprit que le saut de GPT-3 \xe0 GPT-4 s'est fait en une seule ann\xe9e."}),"\n",(0,i.jsx)(n.h2,{id:"02",children:"G\xe9n\xe9ration d'images"}),"\n",(0,i.jsx)(n.p,{children:"Le bond en avant dans la g\xe9n\xe9ration d'images ne r\xe9side pas seulement dans la pr\xe9cision, mais aussi dans la capacit\xe9 \xe0 traiter des images complexes du monde r\xe9el. Cette derni\xe8re, particuli\xe8rement avec l'av\xe8nement des R\xe9seaux Antagonistes G\xe9n\xe9ratifs (GANs) en 2014, a montr\xe9 un taux de progr\xe8s stup\xe9fiant. La qualit\xe9 des images g\xe9n\xe9r\xe9es par l'IA a \xe9volu\xe9, passant de repr\xe9sentations simples et floues \xe0 des sc\xe8nes hautement d\xe9taill\xe9es et cr\xe9atives, souvent en r\xe9ponse \xe0 des instructions linguistiques complexes."}),"\n",(0,i.jsx)(d.A,{src:"./img/dwX_Image_6.png",alt:"Entrer la description alternative de l'image",number:"6",label:"1.6",caption:"Un exemple de reconnaissance d'image \xe0 la pointe de la technologie. Le mod\xe8le Segment Anything (SAM) du laboratoire FAIR (Fundamental AI Research) de Meta peut classifier et segmenter les donn\xe9es visuelles \xe0 des niveaux tr\xe8s pr\xe9cis. La d\xe9tection est effectu\xe9e sans avoir besoin d'annoter les images. ([Viso AI, 2024](https://viso.ai/deep-learning/segment-anything-model-sam-explained/); [Meta, 2023](https://ai.meta.com/research/publications/segment-anything/))"}),"\n",(0,i.jsx)(d.A,{src:"./img/PBp_Image_7.png",alt:"Entrer la description alternative de l'image",number:"7",label:"1.7",caption:"Un exemple de l'\xe9volution de la g\xe9n\xe9ration d'images. En haut \xe0 gauche, en commen\xe7ant par les GANs (R\xe9seaux antagonistes g\xe9n\xe9ratifs) jusqu'en bas \xe0 droite, une image de MidJourney V5."}),"\n",(0,i.jsx)(n.p,{children:"Le taux de progr\xe8s en une seule ann\xe9e est tout \xe0 fait stup\xe9fiant, comme en t\xe9moignent les am\xe9liorations entre la V1 du mod\xe8le de g\xe9n\xe9ration d'images MidJourney au d\xe9but de 2022, et la V6 en d\xe9cembre 2023."}),"\n",(0,i.jsx)(d.A,{src:"./img/wh2_Image_8.png",alt:"Entrer la description alternative de l'image",number:"8",label:"1.8",caption:"G\xe9n\xe9ration d'images MidJourney AI sur 2022-2023. Prompt : photographie de haute qualit\xe9 d'une jeune femme japonaise souriante, contre-jour, lumi\xe8re naturelle p\xe2le, appareil photo argentique, par Rinko Kawauchi, HDR ([Yap, 2024](https://goldpenguin.org/blog/midjourney-v1-to-v6-evolution/))."}),"\n",(0,i.jsx)(n.h2,{id:"03",children:"Multi & Cross modalit\xe9"}),"\n",(0,i.jsx)(n.p,{children:"Les syst\xe8mes d'IA deviennent de plus en plus multimodaux. Cela signifie qu'ils peuvent traiter des images, du texte, de l'audio, de la vision et de la robotique en utilisant le m\xeame mod\xe8le. Ils sont donc entra\xeen\xe9s en utilisant plusieurs \"modes\" diff\xe9rents et peuvent traduire entre eux apr\xe8s leur d\xe9ploiement."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Cross-modalit\xe9."})," Un mod\xe8le est dit cross-modal lorsque l'entr\xe9e d'un mod\xe8le est dans une modalit\xe9 (par exemple le texte) et la sortie dans une autre modalit\xe9 (par exemple l'image). La section sur la vision par ordinateur a montr\xe9 des progr\xe8s rapides entre 2014 et 2020 en cross-modalit\xe9. Nous sommes pass\xe9s de mod\xe8les texte-vers-image capables uniquement de g\xe9n\xe9rer des images pix\xe9lis\xe9es en noir et blanc de visages, \xe0 des mod\xe8les capables de g\xe9n\xe9rer une image \xe0 partir de n'importe quelle instruction textuelle. D'autres exemples de cross-modalit\xe9 incluent Whisper d'OpenAI (",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2212.04356",children:"Radford et al., 2022"}),") qui est capable de transcription parole-vers-texte."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Multi-modalit\xe9."})," Un mod\xe8le est dit ",(0,i.jsx)(a,{term:"multimodal",definition:'{"definition":"Relatif aux syst\xe8mes d\'IA capables de traiter et de comprendre simultan\xe9ment plusieurs types de donn\xe9es (telles que du texte, des images, des fichiers audio ou vid\xe9o)..","source":"","aliases":["Multimodal","multi-modal","multimodality"]}',children:(0,i.jsx)(a,{term:"multimodal",definition:'{"definition":"Relatif aux syst\xe8mes d\'IA capables de traiter et de comprendre simultan\xe9ment plusieurs types de donn\xe9es (telles que du texte, des images, des fichiers audio ou vid\xe9o)..","source":"","aliases":["Multimodal","multi-modal","multimodality"]}',children:"multimodal"})})," lorsque les entr\xe9es et les sorties d'un mod\xe8le peuvent \xeatre dans plus d'une modalit\xe9. Par exemple audio-vers-texte, vid\xe9o-vers-texte, texte-vers-image, etc..."]}),"\n",(0,i.jsx)(d.A,{src:"./img/OCe_Image_12.png",alt:"Entrer la description alternative de l'image",number:"9",label:"1.9",caption:"Multimodalit\xe9 image-vers-texte et texte-vers-image du mod\xe8le Flamingo ([Alayrac et al., 2022](https://arxiv.org/abs/2204.14198))."}),"\n",(0,i.jsxs)(n.p,{children:['Le mod\xe8le Flamingo de DeepMind en 2022 pouvait \xeatre "',(0,i.jsx)(n.em,{children:"rapidement adapt\xe9 \xe0 diverses t\xe2ches de compr\xe9hension d'images/vid\xe9os"}),'" et "',(0,i.jsx)(n.em,{children:"est \xe9galement capable de dialogue visuel multi-images"}),'". (',(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2204.14198",children:"Alayrac et al., 2022"}),') De m\xeame, le mod\xe8le Gato de DeepMind en 2022, \xe9tait appel\xe9 un "Agent G\xe9n\xe9raliste". C\'\xe9tait un r\xe9seau unique avec les m\xeames poids qui pouvait "',(0,i.jsx)(n.em,{children:"jouer \xe0 Atari, l\xe9gender des images, discuter, empiler des blocs avec un vrai bras robotique, et bien plus encore"}),'". (',(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2205.06175",children:"Reed et al., 2022"}),") Poursuivant cette tendance, le mod\xe8le Google Gemini de DeepMind en 2023 pourrait \xeatre appel\xe9 un Large Mod\xe8le ",(0,i.jsx)(a,{term:"multimodal",definition:'{"definition":"Relatif aux syst\xe8mes d\'IA capables de traiter et de comprendre simultan\xe9ment plusieurs types de donn\xe9es (telles que du texte, des images, des fichiers audio ou vid\xe9o)..","source":"","aliases":["Multimodal","multi-modal","multimodality"]}',children:(0,i.jsx)(a,{term:"multimodal",definition:'{"definition":"Relatif aux syst\xe8mes d\'IA capables de traiter et de comprendre simultan\xe9ment plusieurs types de donn\xe9es (telles que du texte, des images, des fichiers audio ou vid\xe9o)..","source":"","aliases":["Multimodal","multi-modal","multimodality"]}',children:"Multimodal"})})," (LMM). L'article d\xe9crivait Gemini comme \"",(0,i.jsxs)(n.em,{children:["nativement ",(0,i.jsx)(a,{term:"multimodal",definition:'{"definition":"Relatif aux syst\xe8mes d\'IA capables de traiter et de comprendre simultan\xe9ment plusieurs types de donn\xe9es (telles que du texte, des images, des fichiers audio ou vid\xe9o)..","source":"","aliases":["Multimodal","multi-modal","multimodality"]}',children:(0,i.jsx)(a,{term:"multimodal",definition:'{"definition":"Relatif aux syst\xe8mes d\'IA capables de traiter et de comprendre simultan\xe9ment plusieurs types de donn\xe9es (telles que du texte, des images, des fichiers audio ou vid\xe9o)..","source":"","aliases":["Multimodal","multi-modal","multimodality"]}',children:"multimodal"})})]}),'" et affirmait pouvoir "',(0,i.jsx)(n.em,{children:"combiner harmonieusement leurs capacit\xe9s \xe0 travers les modalit\xe9s (par exemple extraire des informations et la disposition spatiale d'un tableau, d'un graphique ou d'une figure) avec les fortes capacit\xe9s de raisonnement d'un mod\xe8le de langage (par exemple ses performances \xe0 l'\xe9tat de l'art en math\xe9matiques et en codage)"}),'" (',(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2312.11805",children:"Google, 2024"}),")"]}),"\n",(0,i.jsx)(n.h2,{id:"04",children:"Robotique"}),"\n",(0,i.jsx)(r.A,{src:"https://ourworldindata.org/grapher/annual-professional-service-robots-installed-by-area?tab=chart",width:"100%",height:"600px",loading:"lazy",allow:"web-share; clipboard-write",frameBorder:"0",number:"4",label:"1.4",caption:"Robots de service professionnels install\xe9s annuellement dans le monde, par domaine d'application. Les robots de service professionnels sont des machines semi ou enti\xe8rement autonomes qui effectuent des t\xe2ches utiles dans un cadre professionnel en dehors des applications industrielles, comme le nettoyage ou la chirurgie m\xe9dicale. Les robots de service grand public ne sont pas inclus. ([Giattino et al., 2023](https://ourworldindata.org/artificial-intelligence))"}),"\n",(0,i.jsxs)(n.p,{children:["Le domaine de la robotique a \xe9galement progress\xe9 parall\xe8lement \xe0 l'intelligence artificielle. Dans cette section, nous pr\xe9sentons quelques exemples o\xf9 ces deux domaines fusionnent, mettant en \xe9vidence certains robots qui s'inspirent des techniques d'",(0,i.jsx)(a,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:(0,i.jsx)(a,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:"apprentissage automatique"})})," pour r\xe9aliser des avanc\xe9es."]}),"\n",(0,i.jsx)(d.A,{src:"./img/VZl_Image_9.png",alt:"Entrer la description alternative de l'image",number:"10",label:"1.10",caption:"Les chercheurs ont utilis\xe9 l'Apprentissage par Renforcement Sans Mod\xe8le pour apprendre automatiquement la locomotion quadrup\xe8de en seulement 20 minutes dans le monde r\xe9el au lieu d'environnements simul\xe9s. La Figure montre des exemples de d\xe9marches apprises sur une vari\xe9t\xe9 de terrains r\xe9els ([Smith et al., 2022](https://arxiv.org/abs/2208.07860))."}),"\n",(0,i.jsx)(r.A,{src:"https://ourworldindata.org/grapher/annual-industrial-robots-installed?tab=chart",width:"100%",height:"600px",loading:"lazy",allow:"web-share; clipboard-write",frameBorder:"0",number:"5",label:"1.5",caption:"Robots industriels install\xe9s annuellement dans les cinq premiers pays. Les robots industriels sont des machines automatis\xe9es et reprogrammables qui effectuent une vari\xe9t\xe9 de t\xe2ches dans des environnements industriels ([Giattino et al., 2023](https://ourworldindata.org/artificial-intelligence))."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Avanc\xe9es en robotique."})," \xc0 l'avant-garde des progr\xe8s robotiques se trouve PaLM-E, un mod\xe8le polyvalent et incarn\xe9 de 562 milliards de param\xe8tres qui int\xe8gre la vision, le langage et les donn\xe9es robotiques pour le contr\xf4le en temps r\xe9el des manipulateurs et excelle dans les t\xe2ches linguistiques impliquant le raisonnement g\xe9ospatial (",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2303.03378",children:"Driess et al., 2023"}),")."]}),"\n",(0,i.jsxs)(n.p,{children:["Simultan\xe9ment, les d\xe9veloppements dans les mod\xe8les vision-langage ont conduit \xe0 des avanc\xe9es dans le contr\xf4le robotique de pr\xe9cision, avec des mod\xe8les comme RT-2 montrant des capacit\xe9s significatives en manipulation d'objets et en raisonnement ",(0,i.jsx)(a,{term:"multimodal",definition:'{"definition":"Relatif aux syst\xe8mes d\'IA capables de traiter et de comprendre simultan\xe9ment plusieurs types de donn\xe9es (telles que du texte, des images, des fichiers audio ou vid\xe9o)..","source":"","aliases":["Multimodal","multi-modal","multimodality"]}',children:(0,i.jsx)(a,{term:"multimodal",definition:'{"definition":"Relatif aux syst\xe8mes d\'IA capables de traiter et de comprendre simultan\xe9ment plusieurs types de donn\xe9es (telles que du texte, des images, des fichiers audio ou vid\xe9o)..","source":"","aliases":["Multimodal","multi-modal","multimodality"]}',children:"multimodal"})}),". RT-2 d\xe9montre comment nous pouvons utiliser des m\xe9thodes de prompting inspir\xe9es des LLM (cha\xeene de pens\xe9e), pour apprendre un mod\xe8le autonome capable \xe0 la fois de planifier des s\xe9quences de comp\xe9tences \xe0 long terme et de pr\xe9dire les actions robotiques (",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2307.15818",children:"Brohan et al., 2023"}),")."]}),"\n",(0,i.jsxs)(n.p,{children:["Mobile ALOHA est un autre exemple de combinaison des techniques modernes d'",(0,i.jsx)(a,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:(0,i.jsx)(a,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:"apprentissage automatique"})}),' avec la robotique. Entra\xeen\xe9 par clonage comportemental supervis\xe9, le robot peut effectuer de mani\xe8re autonome des t\xe2ches complexes "',(0,i.jsx)(n.em,{children:"comme faire sauter et servir une crevette, ouvrir une armoire murale \xe0 deux portes pour ranger de lourdes casseroles, appeler et entrer dans un ascenseur, et rincer l\xe9g\xe8rement une po\xeale usag\xe9e sous un robinet de cuisine"}),'" (',(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2401.02117",children:"Fu et al., 2024"}),"). Ces avanc\xe9es d\xe9montrent non seulement la sophistication et l'applicabilit\xe9 croissantes des syst\xe8mes robotiques, mais soulignent \xe9galement le potentiel de d\xe9veloppements r\xe9volutionnaires futurs dans les technologies autonomes."]}),"\n",(0,i.jsx)(d.A,{src:"./img/3A4_Image_10.png",alt:"Entrer la description alternative de l'image",number:"11",label:"1.11",caption:"RT-2 de DeepMind peut \xe0 la fois planifier des s\xe9quences de comp\xe9tences \xe0 long terme et pr\xe9dire les actions des robots en s'inspirant des techniques de prompting des LLM (cha\xeene de pens\xe9e) ([Brohan et al., 2023](https://arxiv.org/abs/2307.15818))."}),"\n",(0,i.jsx)(l.A,{type:"youtube",videoId:"Sq1QZB5baNw",number:"1",label:"1.1",caption:"Vid\xe9o optionnelle montrant un exemple de l'\xe9tat actuel de la robotique."}),"\n",(0,i.jsx)(n.h2,{id:"05",children:"Jeux"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"L'IA et les jeux de soci\xe9t\xe9."})," L'IA a r\xe9alis\xe9 des progr\xe8s continus dans le domaine des jeux pendant des d\xe9cennies. Depuis la victoire des IA contre le champion du monde d'\xe9checs en 1997, au Scrabble en 2006, jusqu'\xe0 AlphaGo de DeepMind en 2016 (",(0,i.jsx)(n.a,{href:"https://www.deepmind.com/research/highlighted-research/alphago",children:"DeepMind, 2016"}),"), qui \xe9tait suffisamment performant pour vaincre le champion du monde au jeu de Go, un jeu r\xe9put\xe9 particuli\xe8rement difficile pour l'IA. En moins d'un an, le mod\xe8le suivant, AlphaGo Zero, entra\xeen\xe9 par auto-apprentissage, avait ma\xeetris\xe9 plusieurs variantes du Go, des \xe9checs et du shogi, atteignant un niveau surhumain en moins de trois jours d'entra\xeenement (",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/1712.01815",children:"Silver et al., 2017"}),")."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"L'IA et les jeux vid\xe9o."})," Nous avons commenc\xe9 \xe0 utiliser des techniques d'",(0,i.jsx)(a,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:(0,i.jsx)(a,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:"apprentissage automatique"})})," sur des jeux Atari simples en 2013 (",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/1312.5602",children:"Mnih et al. 2013"}),"). En 2019, OpenAI Five a vaincu les champions du monde \xe0 DOTA2 (",(0,i.jsx)(n.a,{href:"https://openai.com/research/openai-five-defeats-dota-2-world-champions",children:"OpenAI, 2019"}),"), tandis que la m\xeame ann\xe9e, AlphaStar de DeepMind battait des joueurs professionnels d'esport \xe0 StarCraft II (",(0,i.jsx)(n.a,{href:"https://deepmind.google/discover/blog/alphastar-mastering-the-real-time-strategy-game-starcraft-ii/",children:"DeepMind, 2019"}),"). Ces deux jeux n\xe9cessitent des milliers d'actions cons\xe9cutives avec un nombre \xe9lev\xe9 d'actions par minute. En 2020, le mod\xe8le MuZero de DeepMind, d\xe9crit comme \"",(0,i.jsx)(n.em,{children:"une avanc\xe9e significative dans la qu\xeate d'algorithmes \xe0 usage g\xe9n\xe9ral"}),'" (',(0,i.jsx)(n.a,{href:"https://www.deepmind.com/blog/muzero-mastering-go-chess-shogi-and-atari-without-rules",children:"DeepMind, 2020"}),"), \xe9tait capable de jouer aux jeux Atari, au Go, aux \xe9checs et au shogi sans m\xeame conna\xeetre les r\xe8gles."]}),"\n",(0,i.jsxs)(n.p,{children:["Ces derni\xe8res ann\xe9es, les capacit\xe9s de l'IA se sont \xe9tendues aux environnements ouverts comme Minecraft, d\xe9montrant une aptitude \xe0 effectuer des s\xe9quences d'actions complexes. Dans les jeux de strat\xe9gie, Cicero de Meta a fait preuve de comp\xe9tences sophistiqu\xe9es en n\xe9gociation strat\xe9gique et en tromperie en langage naturel pour le jeu Diplomacy (",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2210.05492",children:"Bakhtin et al., 2022"}),")."]}),"\n",(0,i.jsx)(d.A,{src:"./img/KMJ_Image_11.png",alt:"Entrer la description alternative de l'image",number:"12",label:"1.12",caption:"Une carte de diplomatie et la bo\xeete de dialogue o\xf9 l'IA n\xe9gocie ([DiploStrats (YouTube), 2022](https://www.youtube.com/watch?v=u5192bvUS7k&t=2216s))."}),"\n",(0,i.jsxs)(o.A,{title:"Exemple de Voyager : planification et apprentissage continu dans Minecraft avec GPT-4",collapsed:!0,children:[(0,i.jsxs)(n.p,{children:["Voyager (",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2305.16291",children:"Wang et al., 2023"}),") constitue un exemple particuli\xe8rement impressionnant des capacit\xe9s de l'IA dans les environnements d'apprentissage continu. Cette IA est con\xe7ue pour jouer \xe0 Minecraft, une t\xe2che qui implique un degr\xe9 significatif de planification et d'apprentissage adaptatif. Ce qui rend Voyager si remarquable est sa capacit\xe9 \xe0 apprendre continuellement et progressivement dans l'environnement du jeu, utilisant les capacit\xe9s de raisonnement contextuel de GPT-4 pour planifier et \xe9crire le code n\xe9cessaire \xe0 chaque nouveau d\xe9fi. Partant de z\xe9ro dans une seule session de jeu, Voyager apprend initialement \xe0 naviguer dans le monde virtuel, \xe0 affronter et vaincre des ennemis, et \xe0 m\xe9moriser toutes ces comp\xe9tences dans sa m\xe9moire \xe0 long terme. Au fur et \xe0 mesure que le jeu progresse, il continue d'apprendre et de stocker de nouvelles comp\xe9tences, jusqu'\xe0 la t\xe2che difficile de l'extraction de diamants, une activit\xe9 complexe qui n\xe9cessite une compr\xe9hension approfondie des m\xe9caniques du jeu et une planification strat\xe9gique. La capacit\xe9 de Voyager \xe0 int\xe9grer continuellement de nouvelles informations et \xe0 les utiliser efficacement d\xe9montre le potentiel de l'IA dans la gestion d'environnements complexes et changeants et dans l'ex\xe9cution de t\xe2ches n\xe9cessitant une accumulation \xe0 long terme de connaissances et de comp\xe9tences."]}),(0,i.jsx)(d.A,{src:"./img/ccN_Image_12.png",alt:"Entrer la description alternative de l'image",number:"13",label:"1.13",caption:"Voyager d\xe9couvre continuellement de nouveaux objets et comp\xe9tences Minecraft par exploration auto-dirig\xe9e, surpassant significativement les r\xe9f\xe9rences ([Wang et al., 2023](https://arxiv.org/abs/2305.16291))."})]})]})}function g(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},3989:(e,n,a)=>{a.d(n,{A:()=>o});var s=a(6540),i=a(6347),t=a(8444);const r={iframeContainer:"iframeContainer_ixkI",loader:"loader_gjvK",spinner:"spinner_L1j2",spin:"spin_rtC2",iframeWrapper:"iframeWrapper_Tijy",iframe:"iframe_UAfa",caption:"caption_mDwB",captionLink:"captionLink_Ly4l"};var l=a(4848);function o(e){let{src:n,caption:a,title:o="Embedded content",height:d="500px",width:c="100%",chapter:u,number:p,label:m}=e;const[h,g]=(0,s.useState)(!0),x=(0,i.zy)(),f=u||(()=>{const e=x.pathname.match(/\/chapters\/(\d+)/);return e?parseInt(e[1]):null})(),v=d&&"100%"!==d&&"auto"!==d;return(0,l.jsxs)("figure",{className:r.iframeContainer,children:[h&&(0,l.jsxs)("div",{className:r.loader,children:[(0,l.jsx)("div",{className:r.spinner}),(0,l.jsx)("p",{children:"Loading content..."})]}),(0,l.jsx)("div",{className:r.iframeWrapper,style:{paddingBottom:v?"0":"56.25%",height:v?d:"auto"},children:(0,l.jsx)("iframe",{src:n,title:o,width:c,height:v?d:"100%",frameBorder:"0",allowFullScreen:!0,loading:"lazy",onLoad:()=>{g(!1)},className:r.iframe,style:{height:v?d:"100%",position:v?"static":"absolute"}})}),(0,l.jsx)(t.A,{caption:a,mediaType:"iframe",chapter:f,number:p,label:m})]})}},3931:(e,n,a)=>{a.d(n,{A:()=>o});var s=a(6540),i=a(6347),t=a(8444);const r={videoFigure:"videoFigure_dV9u",fullWidth:"fullWidth_Tv7O",videoContainer:"videoContainer_LWoK",aspectRatio169:"aspectRatio169_Go8b",aspectRatio43:"aspectRatio43_b3T7",aspectRatio11:"aspectRatio11_n21J",aspectRatio219:"aspectRatio219_L_3n",videoIframe:"videoIframe_QEc5",videoElement:"videoElement_uu7N",customPlayer:"customPlayer_jiC4",customPlayerPlaceholder:"customPlayerPlaceholder_aL9q",loadingOverlay:"loadingOverlay_e2pu",spinner:"spinner_tFyL",spin:"spin_saPs",errorContainer:"errorContainer_J6Pn",errorIcon:"errorIcon_cGdn",fallbackLink:"fallbackLink_WsZk"};var l=a(4848);function o(e){let{type:n="youtube",videoId:a,caption:o,title:d,startTime:c,autoplay:u=!1,controls:p=!0,aspectRatio:m="16:9",width:h,height:g,chapter:x,number:f,label:v,useCustomPlayer:b=!1,fullWidth:j=!0}=e;const[q,y]=(0,s.useState)(!0),[A,w]=(0,s.useState)(!1),L=(0,i.zy)(),I=x||(()=>{const e=L.pathname.match(/\/chapters\/(\d+)/);return e?parseInt(e[1]):null})(),_=(()=>{const e=(e=>{if(!e)return"";if("number"==typeof e)return e.toString();if("string"==typeof e){if(/^\d+$/.test(e))return e;let n=0;const a=e.match(/(\d+)h/),s=e.match(/(\d+)m/),i=e.match(/(\d+)s/);return a&&(n+=3600*parseInt(a[1])),s&&(n+=60*parseInt(s[1])),i&&(n+=parseInt(i[1])),n>0?n.toString():""}return""})(c);switch(n.toLowerCase()){case"youtube":let s=`https://www.youtube.com/embed/${a}`;const i=new URLSearchParams;e&&i.append("start",e),u&&i.append("autoplay","1"),p||b||i.append("controls","0"),i.append("rel","0"),i.append("modestbranding","1"),i.append("fs","1"),i.append("cc_load_policy","0"),i.append("iv_load_policy","3"),i.append("showinfo","0"),i.append("disablekb","1"),i.append("playsinline","1"),i.append("color","white"),i.append("theme","light"),b&&(i.append("enablejsapi","1"),i.append("origin",window.location.origin));const t=i.toString();return t?`${s}?${t}`:s;case"vimeo":let r=`https://player.vimeo.com/video/${a}`;const l=new URLSearchParams;u&&l.append("autoplay","1"),p||b||l.append("controls","0"),l.append("title","0"),l.append("byline","0"),l.append("portrait","0"),l.append("dnt","1"),l.append("transparent","0"),l.append("background","1");const o=l.toString();return o?`${r}?${o}`:r;case"mp4":case"webm":case"video":return a;default:return console.warn(`Unsupported video type: ${n}`),a}})(),M=()=>{y(!1)},P=()=>{w(!0),y(!1)},C=e=>{let{src:a,onLoad:s,onError:i}=e;return(0,l.jsx)("div",{className:r.customPlayer,children:(0,l.jsxs)("div",{className:r.customPlayerPlaceholder,children:[(0,l.jsx)("h3",{children:"Atlas Custom Player"}),(0,l.jsx)("p",{children:"Coming Soon"}),(0,l.jsxs)("a",{href:a,target:"_blank",rel:"noopener noreferrer",className:r.fallbackLink,children:["Watch on ",n.charAt(0).toUpperCase()+n.slice(1)]})]})})},k=["mp4","webm","video"].includes(n.toLowerCase());return(0,l.jsxs)("figure",{className:`${r.videoFigure} ${j?r.fullWidth:""}`,children:[(0,l.jsxs)("div",{className:`${r.videoContainer} ${(()=>{switch(m){case"4:3":return r.aspectRatio43;case"1:1":return r.aspectRatio11;case"21:9":return r.aspectRatio219;default:return r.aspectRatio169}})()}`,style:{width:j?"100%":h||"auto",maxWidth:j?"none":"800px"},children:[q&&!A&&(0,l.jsxs)("div",{className:r.loadingOverlay,children:[(0,l.jsx)("div",{className:r.spinner}),(0,l.jsx)("p",{children:"Loading video..."})]}),A&&(0,l.jsxs)("div",{className:r.errorContainer,children:[(0,l.jsxs)("svg",{className:r.errorIcon,width:"48",height:"48",viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:"2",children:[(0,l.jsx)("circle",{cx:"12",cy:"12",r:"10"}),(0,l.jsx)("line",{x1:"12",y1:"8",x2:"12",y2:"12"}),(0,l.jsx)("line",{x1:"12",y1:"16",x2:"12.01",y2:"16"})]}),(0,l.jsx)("h4",{children:"Failed to load video"}),(0,l.jsxs)("p",{children:["Video type: ",n]}),(0,l.jsxs)("p",{children:["Video ID/URL: ",a]}),(0,l.jsx)("a",{href:_,target:"_blank",rel:"noopener noreferrer",className:r.fallbackLink,children:"Try opening video directly"})]}),!A&&(k?(0,l.jsxs)("video",{className:r.videoElement,controls:p,autoPlay:u,onLoadedData:M,onError:P,title:d||o||`${n} video`,style:{width:h||"100%",height:g||"auto",display:q?"none":"block"},children:[(0,l.jsx)("source",{src:_,type:`video/${n}`}),(0,l.jsxs)("p",{children:["Your browser doesn't support video playback.",(0,l.jsx)("a",{href:_,target:"_blank",rel:"noopener noreferrer",children:"Download the video file"})]})]}):b?(0,l.jsx)(C,{src:_,onLoad:M,onError:P}):(0,l.jsx)("iframe",{className:r.videoIframe,src:_,title:d||o||`${n} video`,frameBorder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",allowFullScreen:!0,onLoad:M,onError:P,style:{width:h||"100%",height:g||"100%",opacity:q?0:1}}))]}),(0,l.jsx)(t.A,{caption:o,mediaType:"video",chapter:I,number:f,label:v})]})}}}]);