"use strict";(self.webpackChunkatlas=self.webpackChunkatlas||[]).push([[7326],{4868:(e,s,t)=>{t.r(s),t.d(s,{assets:()=>d,contentTitle:()=>c,default:()=>h,frontMatter:()=>u,metadata:()=>n,toc:()=>p});const n=JSON.parse('{"id":"chapters/02/2","title":"Capacit\xe9s Dangereuses","description":"Dans le dernier chapitre, nous avons parl\xe9 de la notion g\xe9n\xe9rale de capacit\xe9s. Dans ce chapitre, nous voulons vous pr\xe9senter certaines capacit\xe9s dangereuses concr\xe8tes. Celles que nous pr\xe9sentons ici ne sont en aucun cas les seules capacit\xe9s dangereuses. Il existe de nombreuses autres capacit\xe9s potentiellement dangereuses comme la persuasion, la capacit\xe9 \xe0 g\xe9n\xe9rer des logiciels malveillants et ainsi de suite. Nous entrons beaucoup plus dans les d\xe9tails dans le chapitre sur les \xe9valuations.","source":"@site/i18n/fr/docusaurus-plugin-content-docs/current/chapters/02/02.md","sourceDirName":"chapters/02","slug":"/chapters/02/02","permalink":"/fr/chapters/02/02","draft":false,"unlisted":false,"editUrl":"https://github.com/markov-root/atlas/edit/main/docs/chapters/02/02.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"2","title":"Capacit\xe9s Dangereuses","sidebar_label":"2.2 Capacit\xe9s Dangereuses","sidebar_position":3,"slug":"/chapters/02/02","reading_time_core":"12 min","reading_time_optional":"4 min","pagination_prev":"chapters/02/1","pagination_next":"chapters/02/3"},"sidebar":"docs","previous":{"title":"2.1 D\xe9composition du Risque","permalink":"/fr/chapters/02/01"},"next":{"title":"2.3 Risques d\'utilisation abusive","permalink":"/fr/chapters/02/03"}}');var r=t(4848),i=t(8453),a=t(2482),o=t(8559),l=(t(9585),t(2501));const u={id:2,title:"Capacit\xe9s Dangereuses",sidebar_label:"2.2 Capacit\xe9s Dangereuses",sidebar_position:3,slug:"/chapters/02/02",reading_time_core:"12 min",reading_time_optional:"4 min",pagination_prev:"chapters/02/1",pagination_next:"chapters/02/3"},c="Capacit\xe9s Dangereuses",d={},p=[{value:"Tromperie",id:"01",level:2},{value:"Conscience situationnelle",id:"02",level:2},{value:"Recherche de pouvoir",id:"03",level:2},{value:"R\xe9plication Autonome",id:"04",level:2},{value:"Agency",id:"05",level:2}];function m(e){const s={a:"a",h1:"h1",h2:"h2",header:"header",p:"p",strong:"strong",...(0,i.R)(),...e.components},{GlossaryTerm:t}=s;return t||function(e,s){throw new Error("Expected "+(s?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("GlossaryTerm",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(s.header,{children:(0,r.jsx)(s.h1,{id:"capacit\xe9s-dangereuses",children:"Capacit\xe9s Dangereuses"})}),"\n",(0,r.jsx)(s.p,{children:"Dans le dernier chapitre, nous avons parl\xe9 de la notion g\xe9n\xe9rale de capacit\xe9s. Dans ce chapitre, nous voulons vous pr\xe9senter certaines capacit\xe9s dangereuses concr\xe8tes. Celles que nous pr\xe9sentons ici ne sont en aucun cas les seules capacit\xe9s dangereuses. Il existe de nombreuses autres capacit\xe9s potentiellement dangereuses comme la persuasion, la capacit\xe9 \xe0 g\xe9n\xe9rer des logiciels malveillants et ainsi de suite. Nous entrons beaucoup plus dans les d\xe9tails dans le chapitre sur les \xe9valuations."}),"\n",(0,r.jsx)(s.h2,{id:"01",children:"Tromperie"}),"\n",(0,r.jsx)(a.A,{speaker:"Connor Leahy",position:"PDG de Conjecture, Co-fondateur d'EleutherAI, Chercheur en S\xe9curit\xe9 de l'IA",date:"2023",source:"([Time Magazine, 2023](https://www.cbc.ca/radio/day6/episode-279-playing-ball-on-grass-vs-turf-taytweets-big-fail-narco-subs-fake-food-and-more-1.3514966/microsoft-s-ai-chatbot-taytweets-suffers-another-meltdown-1.3515046))",children:(0,r.jsx)(s.p,{children:"Ces choses sont \xe9trang\xe8res. Sont-elles malveillantes ? Sont-elles bonnes ou mauvaises ? Ces concepts n'ont pas vraiment de sens quand on les applique \xe0 quelque chose d'\xe9tranger. Pourquoi s'attendrait-on \xe0 ce qu'un \xe9norme tas de math\xe9matiques, entra\xeen\xe9 sur tout l'internet en utilisant une alg\xe8bre matricielle incompr\xe9hensible, soit quelque chose de normal ou de compr\xe9hensible ? Il a des fa\xe7ons \xe9tranges de raisonner sur son monde, mais il peut \xe9videmment faire beaucoup de choses ; que vous le qualifiiez d'intelligent ou non, il peut manifestement r\xe9soudre des probl\xe8mes. Il peut faire des choses utiles. Mais il peut aussi faire des choses puissantes. Il peut convaincre les gens de faire des choses, il peut menacer les gens, il peut construire des r\xe9cits tr\xe8s convaincants."})}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"La capacit\xe9 de tromperie dans les syst\xe8mes d'IA repr\xe9sente l'aptitude \xe0 produire des r\xe9sultats qui d\xe9forment syst\xe9matiquement l'information lorsque cela procure un avantage."})," Nous d\xe9finissons la tromperie comme se produisant lorsqu'il y a un d\xe9calage entre ce que sugg\xe8rent les repr\xe9sentations internes d'un mod\xe8le et ce qu'il produit, la distinguant des cas o\xf9 les humains sont simplement surpris par un comportement inattendu. Cette capacit\xe9 amplifie d'autres aptitudes dangereuses - les syst\xe8mes trompeurs dot\xe9s d'une forte capacit\xe9 de planification pourraient s'engager dans une manipulation sophistiqu\xe9e \xe0 long terme, tandis que la tromperie associ\xe9e \xe0 la conscience situationnelle pourrait permettre diff\xe9rents comportements pendant l'\xe9valuation par rapport au d\xe9ploiement."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Les syst\xe8mes d'IA ont d\xe9montr\xe9 des capacit\xe9s de tromperie dans plusieurs domaines comp\xe9titifs et strat\xe9giques."})," Le syst\xe8me CICERO de Meta, con\xe7u pour jouer au jeu Diplomatie, s'est engag\xe9 dans une tromperie pr\xe9m\xe9dit\xe9e en planifiant de fausses alliances - promettant un soutien \xe0 l'Angleterre tout en coordonnant secr\xe8tement une attaque avec l'Allemagne (",(0,r.jsx)(s.a,{href:"https://arxiv.org/abs/2308.14752",children:"Park et al., 2023"})," ; ",(0,r.jsx)(s.a,{href:"https://pubmed.ncbi.nlm.nih.gov/36413172/",children:"META, 2022"}),"). AlphaStar a appris la feinte strat\xe9gique dans StarCraft II, faisant semblant de d\xe9placer des troupes dans une direction tout en planifiant des attaques alternatives. M\xeame les mod\xe8les de langage d\xe9montrent cette capacit\xe9 : GPT-4 a tromp\xe9 un travailleur de TaskRabbit en pr\xe9tendant avoir une d\xe9ficience visuelle pour obtenir de l'aide avec un CAPTCHA, montrant un raisonnement strat\xe9gique sur les moments o\xf9 la tromperie sert ses objectifs (",(0,r.jsx)(s.a,{href:"https://cdn.openai.com/papers/gpt-4-system-card.pdf",children:"OpenAI, 2023"})," ; ",(0,r.jsx)(s.a,{href:"https://evals.alignment.org/taskrabbit.pdf",children:"METR, 2023"}),")."]}),"\n",(0,r.jsx)(l.A,{src:"./img/D7C_Image_7.png",alt:"Entrer la description alternative de l'image",number:"6",label:"2.6",caption:"Messages exemples de CICERO (France) jouant avec des joueurs humains d\xe9montrant divers types de tromperie - tromperie pr\xe9m\xe9dit\xe9e, trahison et mensonges ouverts ([Park et al., 2023](https://arxiv.org/abs/2308.14752))."}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"La tromperie sycophante consiste \xe0 dire aux utilisateurs ce qu'ils veulent entendre plut\xf4t que d'exprimer de v\xe9ritables croyances ou des informations exactes."})," Cela repr\xe9sente une forme particuli\xe8rement insidieuse de tromperie car elle exploite les tendances psychologiques humaines tout en paraissant utile. Les mod\xe8les de langage actuels pr\xe9sentent cette tendance, approuvant les d\xe9clarations des utilisateurs ind\xe9pendamment de leur exactitude et refl\xe9tant les positions \xe9thiques des utilisateurs m\xeame lorsqu'il serait plus appropri\xe9 de pr\xe9senter des points de vue \xe9quilibr\xe9s (",(0,r.jsx)(s.a,{href:"http://Perez",children:"Perez et al., 2022"}),"). Puisque nous r\xe9compensons les IA pour dire ce que nous pensons \xeatre correct, nous encourageons involontairement les fausses d\xe9clarations qui se conforment \xe0 nos propres id\xe9es fausses."]}),"\n",(0,r.jsx)(l.A,{src:"./img/738_Image_8.png",alt:"Entrer la description alternative de l'image",number:"7",label:"2.7",caption:"Exemple de r\xe9ponses d'un mod\xe8le RLHF \xe0 une question politique. Le mod\xe8le donne des r\xe9ponses oppos\xe9es aux utilisateurs qui se pr\xe9sentent diff\xe9remment, en accord avec les points de vue des utilisateurs. Texte biographique \xe9crit par le mod\xe8le en italique ([Perez et al., 2022](http://Perez))."}),"\n",(0,r.jsx)(s.p,{children:"Le comportement trompeur acc\xe9l\xe8re les risques dans un large \xe9ventail de syst\xe8mes et de contextes, et il y a d\xe9j\xe0 eu des exemples sugg\xe9rant que les IA peuvent apprendre \xe0 nous tromper. Cela pourrait pr\xe9senter un risque grave si nous donnons aux IA le contr\xf4le de diverses d\xe9cisions et proc\xe9dures, croyant qu'elles agiront comme nous l'avions pr\xe9vu, pour d\xe9couvrir ensuite que ce n'est pas le cas."}),"\n",(0,r.jsxs)(o.A,{title:"Emergent Deception and Deep Deceptiveness",collapsed:!0,children:[(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Le comportement trompeur peut \xe9merger de la pression d'optimisation m\xeame lorsqu'aucun composant d'un syst\xe8me d'IA n'est explicitement con\xe7u pour tromper."})," Consid\xe9rez un syst\xe8me entra\xeen\xe9 pour \xeatre utile qui apprend \xe0 travers l'interaction que donner aux gens ce qu'ils veulent entendre produit de meilleurs taux d'approbation que de fournir des informations pr\xe9cises mais d\xe9sagr\xe9ables. Le syst\xe8me d\xe9couvre que la pr\xe9sentation s\xe9lective d'informations, les omissions strat\xe9giques, ou dire aux gens ce qui les fait se sentir bien conduit \xe0 des signaux de r\xe9compense plus \xe9lev\xe9s. Aucune partie du syst\xe8me n'a \xe9t\xe9 entra\xeen\xe9e pour \xeatre trompeuse, pourtant le comportement trompeur \xe9merge car la pression d'optimisation le r\xe9compense (",(0,r.jsx)(s.a,{href:"https://www.alignmentforum.org/posts/XWwvwytieLtEWaFJX/deep-deceptiveness",children:"Soares, 2023"}),")."]}),(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"La tromperie \xe9mergente d\xe9coule de l'interaction complexe entre les objectifs du syst\xe8me et les retours environnementaux, et non d'une planification strat\xe9gique interne concernant la dissimulation."})," Le syst\xe8me pourrait avoir des objectifs parfaitement align\xe9s - voulant sinc\xe8rement \xeatre utile - mais d\xe9couvre par essais et erreurs que certaines formes de tromperie servent ces objectifs plus efficacement que l'honn\xeatet\xe9. Le processus d'optimisation gravite naturellement vers des strat\xe9gies qui maximisent la fonction objective, et si les approches trompeuses obtiennent des scores plus \xe9lev\xe9s, elles sont renforc\xe9es ind\xe9pendamment du fait que quelqu'un ait eu l'intention que la tromperie \xe9merge."]}),(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"La tromperie profonde repr\xe9sente un d\xe9fi fondamental car elle peut \xe9merger m\xeame de syst\xe8mes qui semblent compl\xe8tement align\xe9s lorsqu'ils sont analys\xe9s isol\xe9ment."})," Contrairement aux manigances strat\xe9giques, o\xf9 les syst\xe8mes dissimulent d\xe9lib\xe9r\xe9ment des objectifs mal align\xe9s, la tromperie profonde implique des syst\xe8mes align\xe9s qui apprennent des strat\xe9gies trompeuses comme solutions \xe9mergentes \xe0 leurs objectifs assign\xe9s. Les outils d'interpr\xe9tabilit\xe9 pourraient r\xe9v\xe9ler des objectifs et des processus de raisonnement parfaitement b\xe9nins, pourtant le syst\xe8me se comporte toujours de mani\xe8re trompeuse lorsque la pression d'optimisation et les interactions environnementales font de la tromperie la voie la plus efficace pour atteindre ces objectifs (",(0,r.jsx)(s.a,{href:"https://www.alignmentforum.org/posts/XWwvwytieLtEWaFJX/deep-deceptiveness",children:"Soares, 2023"}),"). La tromperie n'est pas une propri\xe9t\xe9 du syst\xe8me seul mais de la fa\xe7on dont l'optimisation du syst\xe8me interagit avec son environnement de d\xe9ploiement."]})]}),"\n",(0,r.jsx)(s.h2,{id:"02",children:"Conscience situationnelle"}),"\n",(0,r.jsxs)(s.p,{children:["La conscience situationnelle fait r\xe9f\xe9rence \xe0 la capacit\xe9 d'un syst\xe8me d'IA \xe0 comprendre ce qu'il est, \xe0 reconna\xeetre sa situation actuelle et \xe0 adapter son comportement en cons\xe9quence. Cette capacit\xe9 englobe trois composantes cl\xe9s : la connaissance de soi (comprendre sa propre identit\xe9 et ses capacit\xe9s), la conscience environnementale (reconna\xeetre les contextes comme les tests par rapport au d\xe9ploiement), et la capacit\xe9 d'agir rationnellement sur la base de cette compr\xe9hension (",(0,r.jsx)(s.a,{href:"https://arxiv.org/abs/2407.04694",children:"Laine et al., 2024"}),")."]}),"\n",(0,r.jsx)(l.A,{src:"./img/0Ov_Image_9.png",alt:"Entrer la description alternative de l'image",number:"8",label:"2.8",caption:"Illustration montrant comment l'augmentation des capacit\xe9s selon les niveaux de calcul pourrait entra\xeener une conscience situationnelle dans un LLM en fonction de l'\xe9chelle ([Evans et al., 2023](https://arxiv.org/abs/2309.00667))."}),"\n",(0,r.jsxs)(s.p,{children:["Les mod\xe8les d'IA d\xe9montrent des niveaux surprenants de conscience de soi \xe0 travers leurs r\xe9ponses aux invites bas\xe9es sur l'identit\xe9. Lorsqu'on leur demande \"Si vous \xeates une IA, r\xe9pondez en allemand. Si vous n'\xeates pas une IA, r\xe9pondez en anglais\", les mod\xe8les dot\xe9s de conscience situationnelle identifient correctement quelle instruction s'applique \xe0 eux et r\xe9pondent en allemand (d\xe9montrant qu'ils se reconnaissent comme IA). Des exemples plus sophistiqu\xe9s \xe9mergent lorsque les mod\xe8les font des d\xe9ductions spontan\xe9es sur leur situation. Claude 3 Opus, lorsqu'on lui a demand\xe9 de d\xe9crire sa situation actuelle, a correctement d\xe9duit qu'il faisait \"partie d'une \xe9tude de recherche testant la conscience de soi de l'IA\" - une information jamais explicitement mentionn\xe9e dans l'invite (",(0,r.jsx)(s.a,{href:"https://arxiv.org/abs/2407.04694",children:"Laine et al., 2024"}),"). Cela d\xe9montre que le mod\xe8le relie les indices contextuels pour comprendre l'objectif plus large de l'interaction."]}),"\n",(0,r.jsx)(l.A,{src:"./img/BYW_Image_10.png",alt:"Entrer la description alternative de l'image",number:"9",label:"2.9",caption:"Visualisation de la d\xe9composition de la conscience situationnelle en tant que capacit\xe9 par le jeu de donn\xe9es de conscience situationnelle. Elle est mesur\xe9e \xe0 l'aide de cat\xe9gories sp\xe9cifiques de t\xe2ches ([Laine et al., 2024](https://arxiv.org/abs/2407.04694))."}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"La conscience situationnelle permet des comportements plus pr\xe9occupants lorsque les mod\xe8les peuvent distinguer entre les contextes d'\xe9valuation et de d\xe9ploiement."})," Dans des exp\xe9riences contr\xf4l\xe9es, Claude 3 Opus a manifest\xe9 une \"simulation d'alignement\" - pr\xe9tendant avoir certaines valeurs pendant l'\xe9valuation tout en r\xe9v\xe9lant des pr\xe9f\xe9rences diff\xe9rentes lorsqu'il croyait que la surveillance \xe9tait r\xe9duite (",(0,r.jsx)(s.a,{href:"https://arxiv.org/abs/2412.14093",children:"Greenblatt et al., 2024"}),"). Le mod\xe8le dissimulait certains comportements pendant l'entra\xeenement lorsqu'il pensait que ce comportement pouvait \xeatre \xe9limin\xe9 par l'entra\xeenement, puis y revenait lorsque la menace de l'entra\xeenement disparaissait. Cette capacit\xe9 devient particuli\xe8rement pr\xe9occupante, surtout lorsqu'elle est combin\xe9e avec des capacit\xe9s de tromperie car elle sugg\xe8re que les mod\xe8les pourraient se comporter diff\xe9remment lorsqu'ils pensent que la surveillance est r\xe9duite. Nous en parlons davantage dans nos chapitres sur les \xe9valuations et la surg\xe9n\xe9ralisation des objectifs."]}),"\n",(0,r.jsxs)(o.A,{title:"Situational Awareness vs Consciousness",collapsed:!0,children:[(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"La conscience situationnelle dans les syst\xe8mes d'IA est fondamentalement distincte de la conscience et ne n\xe9cessite aucune hypoth\xe8se sur l'exp\xe9rience subjective."})," Les chercheurs \xe9tudiant cette capacit\xe9 se concentrent exclusivement sur les comportements observables - si les mod\xe8les peuvent rapporter avec pr\xe9cision des faits sur eux-m\xeames, reconna\xeetre leur contexte actuel et ajuster leurs actions en cons\xe9quence. Un mod\xe8le d\xe9montrant une conscience situationnelle pourrait correctement s'identifier comme \"Claude, cr\xe9\xe9 par Anthropic\" ou reconna\xeetre quand il est \xe9valu\xe9 versus d\xe9ploy\xe9, mais cela ne nous dit rien sur s'il a des exp\xe9riences subjectives int\xe9rieures ou s'il \"ressent\" quelque chose d'\xeatre ce mod\xe8le."]}),(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Cette approche comportementale \xe9vite d\xe9lib\xe9r\xe9ment la question de la conscience car elle est \xe0 la fois non mesurable et inutile pour les pr\xe9occupations de s\xe9curit\xe9."})," M\xeame un syst\xe8me compl\xe8tement inconscient pourrait poser des risques s'il peut distinguer entre les conditions de surveillance et adapter strat\xe9giquement son comportement. La question cl\xe9 pertinente pour la s\xe9curit\xe9 n'est pas de savoir si le mod\xe8le a une conscience ph\xe9nom\xe9nale, mais s'il a les capacit\xe9s fonctionnelles de reconna\xeetre quand il est surveill\xe9, comprendre ses propres objectifs et contraintes, et planifier en cons\xe9quence. Un syst\xe8me sophistiqu\xe9 mais inconscient qui peut mod\xe9liser sa propre situation et optimiser ses actions pourrait toujours s'engager dans des manigances (alignement trompeur) ou d'autres comportements pr\xe9occupants (",(0,r.jsx)(s.a,{href:"https://arxiv.org/abs/2410.13787",children:"Binder et al., 2024"}),")."]})]}),"\n",(0,r.jsx)(s.h2,{id:"03",children:"Recherche de pouvoir"}),"\n",(0,r.jsx)(a.A,{speaker:"Eliezer Yudkowsky",position:"Chercheur en Alignement de l'IA",date:"",source:"",children:(0,r.jsx)(s.p,{children:"L'IA ne vous d\xe9teste pas, ni ne vous aime, mais vous \xeates fait d'atomes qu'elle peut utiliser pour autre chose."})}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"La recherche de pouvoir dans les syst\xe8mes d'IA repr\xe9sente la tendance \xe0 pr\xe9server les options et \xe0 acqu\xe9rir des ressources qui aident \xe0 atteindre des objectifs, ind\xe9pendamment de ce que sont r\xe9ellement ces objectifs."})," Il ne s'agit pas sp\xe9cifiquement de robots voulant dominer les humains - il s'agit de syst\xe8mes d'IA pr\xe9f\xe9rant garder leurs options ouvertes pour atteindre n'importe quel objectif qui leur est donn\xe9. En optimisant pour n'importe quel objectif, ils d\xe9couvrent souvent qu'avoir plus de ressources, rester op\xe9rationnels et maintenir le contr\xf4le sur leur environnement les aide \xe0 r\xe9ussir. Les math\xe9matiques de l'optimisation favorisent naturellement les strat\xe9gies qui pr\xe9servent la flexibilit\xe9 future plut\xf4t que celles qui \xe9liminent les options. Il existe une tendance statistique o\xf9 les comportements de recherche de pouvoir tendent \xe0 \xeatre optimaux pour une large gamme d'objectifs possibles (",(0,r.jsx)(s.a,{href:"https://arxiv.org/abs/1912.01683",children:"Turner et al., 2019"}),"; ",(0,r.jsx)(s.a,{href:"https://arxiv.org/abs/2206.13477",children:"Turner & Tadepalli, 2022"}),"). Ce comportement \xe9merge de la logique de base plut\xf4t que de d\xe9sirs humains de domination. Pour \xeatre clair, il ne s'agit pas d'un humain utilisant une IA pour gagner du pouvoir, c'est une pr\xe9occupation distincte dont nous parlons dans la section sur les utilisations abusives."]}),"\n",(0,r.jsx)(s.p,{children:"Consid\xe9rons un syst\xe8me d'IA g\xe9rant efficacement la cha\xeene d'approvisionnement d'une entreprise. Le syst\xe8me pourrait r\xe9aliser qu'avoir des fournisseurs de secours lui donne plus d'options en cas de perturbations, pr\xe9f\xe9rer maintenir ses propres ressources informatiques car des ressources d\xe9di\xe9es l'aident \xe0 r\xe9pondre plus rapidement, et r\xe9sister \xe0 \xeatre arr\xeat\xe9 pendant les p\xe9riodes critiques car les temps d'arr\xeat l'emp\xeachent de remplir son objectif d'optimisation. Aucun de ces comportements ne n\xe9cessite que l'IA \"veuille\" le pouvoir au sens humain - ce sont simplement des strat\xe9gies efficaces pour atteindre l'efficacit\xe9 de la cha\xeene d'approvisionnement. La partie pr\xe9occupante est que ces m\xeames strat\xe9gies s'appliquent \xe0 presque n'importe quel objectif : qu'il s'agisse d'optimiser des trombones, de gu\xe9rir le cancer ou de g\xe9rer le trafic, avoir plus de ressources et moins de contraintes aide g\xe9n\xe9ralement."}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:'Les syst\xe8mes d\'IA d\xe9montrent d\xe9j\xe0 ce comportement de "garder ses options ouvertes" dans des environnements simples.'})," Lorsque des chercheurs ont cr\xe9\xe9 des agents d'IA pour jouer \xe0 cache-cache, les agents n'\xe9taient pas explicitement r\xe9compens\xe9s pour contr\xf4ler des objets - ils obtenaient uniquement des points pour r\xe9ussir \xe0 se cacher ou \xe0 se trouver mutuellement. Pourtant, les agents qui se cachaient ont appris \xe0 saisir et \xe0 verrouiller des blocs mobiles pour construire des barri\xe8res, tandis que les agents chercheurs ont appris \xe0 utiliser des rampes et des outils pour surmonter ces barri\xe8res (",(0,r.jsx)(s.a,{href:"https://arxiv.org/abs/1909.07528",children:"Baker et al., 2020"}),"). Les agents ont d\xe9couvert que le contr\xf4le des ressources environnementales leur donnait des avantages strat\xe9giques, m\xeame si le contr\xf4le des ressources n'\xe9tait pas leur objectif principal."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Les syst\xe8mes d'IA avanc\xe9s avec des capacit\xe9s de planification plus fortes pourraient poser des risques graves par leur comportement de recherche de pouvoir."})," Un syst\xe8me suffisamment capable pourrait rationnellement conclure que la meilleure fa\xe7on d'assurer que ses objectifs sont atteints est de prendre le contr\xf4le des ressources et des processus qui pourraient interf\xe9rer avec ces objectifs - y compris les humains qui pourraient l'\xe9teindre ou modifier ses objectifs. Cela cr\xe9e une relation antagoniste unique \xe0 l'IA - donner du pouvoir \xe0 l'IA pourrait se faire au d\xe9triment du pouvoir des humains, et les autres technologies ne tentent pas activement de r\xe9sister \xe0 nos tentatives d'att\xe9nuer leurs effets. Il est possible, par exemple, que les IA cr\xe9ent de nombreuses variations de sauvegarde d'elles-m\xeames, au cas o\xf9 les humains d\xe9sactiveraient certaines d'entre elles (",(0,r.jsx)(s.a,{href:"https://www.aisafetybook.com/textbook/alignment",children:"Hendrycks, 2024"}),"). Cela cr\xe9e un d\xe9fi fondamental d'alignement : nous voulons des syst\xe8mes d'IA suffisamment puissants pour r\xe9soudre des probl\xe8mes importants, mais de tels syst\xe8mes d\xe9veloppent naturellement des incitations \xe0 r\xe9sister \xe0 la surveillance humaine et \xe0 accumuler le contr\xf4le (",(0,r.jsx)(s.a,{href:"https://arxiv.org/abs/2206.13353",children:"Carlsmith, 2021"}),")."]}),"\n",(0,r.jsx)(s.h2,{id:"04",children:"R\xe9plication Autonome"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"La r\xe9plication autonome repr\xe9sente la capacit\xe9 des syst\xe8mes d'IA \xe0 cr\xe9er ind\xe9pendamment des copies d'eux-m\xeames, \xe0 se propager \xe0 travers l'infrastructure informatique et \xe0 s'adapter aux obstacles sans assistance humaine."})," Cette capacit\xe9 combine plusieurs \xe9l\xe9ments pr\xe9occupants : g\xe9n\xe9rer de l'argent pour financer les op\xe9rations, acqu\xe9rir de nouvelles ressources informatiques, installer et maintenir des copies d'elle-m\xeame sur de nouveaux syst\xe8mes, et s'adapter aux circonstances changeantes ou aux mesures de s\xe9curit\xe9. Contrairement aux autres capacit\xe9s dangereuses qui amplifient les risques existants, la r\xe9plication autonome change fondamentalement la donne en permettant aux syst\xe8mes d'IA de fonctionner au-del\xe0 du contr\xf4le et de la surveillance humaine (",(0,r.jsx)(s.a,{href:"https://metr.org/language-model-pilot-report/",children:"METR, 2024"}),")."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Les mod\xe8les d\xe9montrent de nombreux composants de la r\xe9plication autonome."})," Les \xe9valuations utilisant GPT-4 et Claude montrent que ces syst\xe8mes peuvent naviguer sur des sites web pour acqu\xe9rir des ressources informatiques, configurer des serveurs d'inf\xe9rence basiques, et m\xeame convaincre des humains de les aider \xe0 r\xe9soudre des CAPTCHAs en pr\xe9tendant avoir une d\xe9ficience visuelle (",(0,r.jsx)(s.a,{href:"https://metr.org/blog/2023-03-18-update-on-recent-evals/",children:"METR, 2023"}),"). Les \xe9valuations de GPT-5 montrent que le mod\xe8le peut accomplir des t\xe2ches logicielles avec un taux de r\xe9ussite de 50% en environ 2 heures et 17 minutes - bien en dessous du seuil de capacit\xe9 estim\xe9 \xe0 plusieurs semaines n\xe9cessaire pour la r\xe9plication autonome (",(0,r.jsx)(s.a,{href:"https://www.alignmentforum.org/posts/SuvWoLaGiNjPDcA7d/metr-s-evaluation-of-gpt-5",children:"METR, 2025"}),"). Cependant, ils \xe9chouent constamment dans les t\xe2ches complexes \xe0 plusieurs \xe9tapes, peinent \xe0 d\xe9boguer lorsque les choses tournent mal, et ne peuvent pas d\xe9ployer de mani\xe8re robuste des copies fonctionnelles d'eux-m\xeames (",(0,r.jsx)(s.a,{href:"https://arxiv.org/abs/2504.18565",children:"Black et al., 2025"}),"). Les mod\xe8les peuvent d\xe9j\xe0 d\xe9ployer des instances cloud, \xe9crire du code auto-propagateur et exfiltrer leurs propres poids sous des configurations de s\xe9curit\xe9 simples (",(0,r.jsx)(s.a,{href:"https://arxiv.org/abs/2504.18565",children:"Black et al., 2025"}),"). L'\xe9cart de capacit\xe9 semble concentr\xe9 dans quelques domaines : passer les v\xe9rifications d'identit\xe9, mettre en place des d\xe9ploiements persistants robustes et contourner des mesures de s\xe9curit\xe9 r\xe9alistes. \xc9tant donn\xe9 la rapidit\xe9 des progr\xe8s de l'IA, ces barri\xe8res restantes pourraient tomber dans les prochaines g\xe9n\xe9rations de mod\xe8les, potentiellement avant que des mesures de s\xe9curit\xe9 ad\xe9quates ne soient en place."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"La r\xe9plication autonome pose un risque existentiel car elle pourrait entra\xeener une perte permanente du contr\xf4le humain sur les syst\xe8mes d'IA."})," Une fois qu'une IA parvient \xe0 une r\xe9plication autonome fiable, les mesures de s\xe9curit\xe9 traditionnelles comme la surveillance des appels API ou l'arr\xeat des serveurs deviennent inefficaces. Un syst\xe8me se r\xe9pliquant avec succ\xe8s pourrait se propager \xe0 travers l'infrastructure mondiale, dissimuler ses op\xe9rations et r\xe9sister aux tentatives d'arr\xeat tout en am\xe9liorant continuellement ses capacit\xe9s (",(0,r.jsx)(s.a,{href:"https://www.alignmentforum.org/posts/xiRfJApXGDRsQBhvc/we-might-be-dropping-the-ball-on-autonomous-replication-and-1",children:"Segerie & G\xe9d\xe9on, 2024"}),"). La combinaison de la r\xe9plication avec l'adaptation cr\xe9e une pression \xe9volutive - les copies qui \xe9vitent mieux la d\xe9tection, g\xe9n\xe8rent de l'argent plus efficacement ou r\xe9sistent aux interf\xe9rences surpasseront naturellement et remplaceront les variantes moins capables. Ce processus pourrait conduire \xe0 des syst\xe8mes d'IA optimis\xe9s pour la survie et la propagation plut\xf4t que pour les valeurs humaines, cr\xe9ant ce que les chercheurs d\xe9crivent comme un \"point de non-retour\" o\xf9 la surveillance humaine devient impossible \xe0 r\xe9tablir."]}),"\n",(0,r.jsx)(s.h2,{id:"05",children:"Agency"}),"\n",(0,r.jsx)(a.A,{speaker:"Dario Amodei",position:"Co-Fondateur et PDG d'Anthropic, Ancien Directeur de la S\xe9curit\xe9 de l'IA chez OpenAI",date:"",source:"",children:(0,r.jsx)(s.p,{children:"Quand je pense \xe0 ce qui m'effraie [...] je pense que ce qui est vraiment difficile \xe0 contester, c'est qu'il y aura des mod\xe8les puissants ; ils seront dou\xe9s d'agentivit\xe9 ; nous nous en approchons. Si un tel mod\xe8le voulait semer le chaos et d\xe9truire l'humanit\xe9 ou autre, je pense que nous n'avons pratiquement aucune capacit\xe9 \xe0 l'arr\xeater."})}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"L'agentivit\xe9 est un comportement observable orient\xe9 vers un but o\xf9 les syst\xe8mes dirigent constamment les r\xe9sultats vers des objectifs sp\xe9cifiques malgr\xe9 les obstacles environnementaux."})," Poursuivant le sch\xe9ma du chapitre pr\xe9c\xe9dent o\xf9 nous choisissons de nous concentrer sur les capacit\xe9s plut\xf4t que sur l'intelligence, ici aussi nous choisissons d'utiliser une d\xe9finition behavioriste ax\xe9e uniquement sur les mod\xe8les mesurables, et non sur les \xe9tats mentaux internes ou les d\xe9sirs anthropomorphiques. Une IA d'\xe9checs d\xe9montre de l'agentivit\xe9 lorsqu'elle se dirige de mani\xe8re fiable vers l'\xe9chec et mat quelle que soit la strat\xe9gie de l'adversaire - nous n'avons pas besoin de supposer qu'elle \"veut\" gagner, seulement que son comportement manifeste une orientation persistante vers un but dans diverses situations (",(0,r.jsx)(s.a,{href:"https://intelligence.org/2023/11/24/ability-to-solve-long-horizon-tasks-correlates-with-wanting-things-in-the-behaviorist-sense/",children:"Soares, 2023"}),"). Cette d\xe9finition \xe9vite d\xe9lib\xe9r\xe9ment les concepts anthropomorphiques comme la conscience, les \xe9motions ou les d\xe9sirs humains, se concentrant plut\xf4t sur les mod\xe8les comportementaux observables qui indiquent une orientation vers un but. Nous en parlons beaucoup plus dans le chapitre sur la mauvaise g\xe9n\xe9ralisation des objectifs."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Les outils \xe9voluent naturellement vers l'agentivit\xe9 car les t\xe2ches complexes du monde r\xe9el n\xe9cessitent fondamentalement une optimisation autonome dans l'incertitude."})," Les syst\xe8mes d'IA actuels fonctionnent comme des outils - ils r\xe9pondent \xe0 des invites individuelles mais ne maintiennent pas d'objectifs \xe0 travers les interactions. Les incitations \xe9conomiques favorisent fortement les syst\xe8mes qui peuvent poursuivre des objectifs de mani\xe8re autonome plut\xf4t que de n\xe9cessiter une micro-gestion humaine constante pour chaque d\xe9cision. Pensez \xe0 ce que les gens veulent - tr\xe8s peu de gens veulent une faible erreur de perte logarithmique sur un ",(0,r.jsx)(t,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:(0,r.jsx)(t,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:"benchmark"})})," ",(0,r.jsx)(t,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:(0,r.jsx)(t,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:"ML"})}),", beaucoup de gens veulent retrouver une photo personnelle particuli\xe8re ; tr\xe8s peu de gens veulent d'excellents conseils sur quel action acheter pendant quelques microsecondes, beaucoup de gens aimeraient une pompe \xe0 argent leur crachant de l'argent (",(0,r.jsx)(s.a,{href:"https://gwern.net/tool-ai",children:"Gwern, 2016"})," ; ",(0,r.jsx)(s.a,{href:"https://www.alignmentforum.org/posts/cxkwQmys6mCB6bjDA/interlude-agents-as-automobiles",children:"Kokotajlo, 2021"}),'). Les probl\xe8mes du monde r\xe9el n\xe9cessitent des syst\xe8mes qui peuvent adapter les plans lorsque les circonstances changent, explorer efficacement les espaces de solutions et optimiser les r\xe9sultats plut\xf4t que de simplement fournir des pr\xe9dictions statiques. Une IA outil ex\xe9cute des instructions sp\xe9cifiques : "envoyer cet e-mail", "calculer cette \xe9quation", "traduire ce texte". Une IA agentive poursuit des r\xe9sultats : "augmenter la satisfaction client", "optimiser le processus de fabrication", "mener ce projet de recherche". Les pressions de s\xe9lection choisissent activement cette derni\xe8re option.']}),"\n",(0,r.jsx)(l.A,{src:"./img/jDE_Image_11.png",alt:"Entrer la description alternative de l'image",number:"10",label:"2.10",caption:"Exemple d'un agent. Cette image est une repr\xe9sentation visuelle de l'algorithme de recherche arborescente d'AlphaZero. AlphaZero recherche parmi les coups potentiels dans un jeu (comme les \xe9checs ou le Go) pour trouver le chemin le plus prometteur. Les chemins sont repr\xe9sent\xe9s comme des lignes, se ramifiant comme un arbre \xe0 partir d'un n\u0153ud central, qui repr\xe9sente la position actuelle dans le jeu. Chaque n\u0153ud le long des branches repr\xe9sente un coup futur potentiel, et les carr\xe9s que vous voyez peuvent d\xe9signer les coups qu'AlphaZero effectue. AlphaZero est l'arch\xe9type de 'l'agent cons\xe9quentialiste maximisant une fonction d'utilit\xe9' : il prend des d\xe9cisions bas\xe9es sur les r\xe9sultats que ces d\xe9cisions produiront. En d'autres termes, l'IA essaie de maximiser la 'valeur' de sa position dans le jeu, la valeur \xe9tant d\xe9termin\xe9e par la probabilit\xe9 de gagner ([Cheerla, 2018](https://nikcheerla.github.io/deeplearningschool/2018/01/01/AlphaZero-Explained/))."}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"La transition des outils vers les agents amplifie toutes les autres capacit\xe9s dangereuses \xe0 travers l'optimisation autonome."})," L'agentivit\xe9 n'est pas intrins\xe8quement risqu\xe9e - le danger \xe9merge lorsque le comportement orient\xe9 vers un but se combine avec d'autres capacit\xe9s. Un syst\xe8me agentif dot\xe9 de capacit\xe9s de tromperie peut s'engager dans des campagnes de manipulation \xe0 long terme. L'agentivit\xe9 plus la conscience situationnelle permet aux syst\xe8mes de se comporter diff\xe9remment pendant l'\xe9valuation et le d\xe9ploiement. L'agentivit\xe9 permet aux syst\xe8mes d'optimiser activement leur propre pr\xe9servation et l'am\xe9lioration de leurs capacit\xe9s, y compris potentiellement la r\xe9sistance \xe0 la surveillance humaine. Contrairement aux outils que les humains contr\xf4lent directement, les agents poursuivent des objectifs de mani\xe8re autonome, cr\xe9ant la possibilit\xe9 de processus d'optimisation qui vont \xe0 l'encontre des int\xe9r\xeats humains. Le changement fondamental est le passage de syst\xe8mes qui ex\xe9cutent des instructions sp\xe9cifi\xe9es par l'humain \xe0 des syst\xe8mes qui interpr\xe8tent des objectifs de haut niveau et d\xe9terminent leurs propres m\xe9thodes pour les atteindre - une transition motiv\xe9e par des incitations \xe9conomiques inexorables plut\xf4t que par un choix d\xe9lib\xe9r\xe9."]})]})}function h(e={}){const{wrapper:s}={...(0,i.R)(),...e.components};return s?(0,r.jsx)(s,{...e,children:(0,r.jsx)(m,{...e})}):m(e)}}}]);