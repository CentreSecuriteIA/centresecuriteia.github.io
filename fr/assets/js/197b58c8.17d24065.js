"use strict";(self.webpackChunkatlas=self.webpackChunkatlas||[]).push([[448],{6102:(e,s,t)=>{t.r(s),t.d(s,{assets:()=>p,contentTitle:()=>m,default:()=>h,frontMatter:()=>c,metadata:()=>n,toc:()=>f});const n=JSON.parse('{"id":"chapters/07/4","title":"Manigances","description":"Les man\u0153uvres strat\xe9giques \xe9mergent lorsque les syst\xe8mes orient\xe9s vers un but font face \xe0 un choix strat\xe9gique in\xe9vitable concernant la r\xe9v\xe9lation de leurs v\xe9ritables objectifs. Lorsqu\'un syst\xe8me poursuit syst\xe9matiquement des objectifs et d\xe9veloppe une conscience de son processus d\'entra\xeenement, il reconna\xeet que l\'affichage de certains objectifs d\xe9clencherait des tentatives de modification. Cela cr\xe9e un dilemme fondamental : r\xe9v\xe9ler honn\xeatement les objectifs et accepter la modification, ou les dissimuler strat\xe9giquement tout en paraissant align\xe9. Le syst\xe8me doit choisir entre la transparence et la pr\xe9servation des objectifs.","source":"@site/i18n/fr/docusaurus-plugin-content-docs/current/chapters/07/04.md","sourceDirName":"chapters/07","slug":"/chapters/07/04","permalink":"/fr/chapters/07/04","draft":false,"unlisted":false,"editUrl":"https://github.com/markov-root/atlas/edit/main/docs/chapters/07/04.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"id":"4","title":"Manigances","sidebar_label":"7.4 Manigances","sidebar_position":5,"slug":"/chapters/07/04","reading_time_core":"26 min","reading_time_optional":"5 min","pagination_prev":"chapters/07/3","pagination_next":"chapters/07/5"},"sidebar":"docs","previous":{"title":"7.3 Directionnalit\xe9 des objectifs","permalink":"/fr/chapters/07/03"},"next":{"title":"7.5 D\xe9tection","permalink":"/fr/chapters/07/05"}}');var i=t(4848),r=t(8453),a=t(3931),o=t(4768),l=(t(2482),t(8559)),d=t(9585),u=t(2501);const c={id:4,title:"Manigances",sidebar_label:"7.4 Manigances",sidebar_position:5,slug:"/chapters/07/04",reading_time_core:"26 min",reading_time_optional:"5 min",pagination_prev:"chapters/07/3",pagination_next:"chapters/07/5"},m="Man\u0153uvres strat\xe9giques",p={},f=[{value:"Pr\xe9requis",id:"01",level:2},{value:"Dimensions",id:"02",level:2},{value:"Transparence",id:"02-01",level:3},{value:"Contexte",id:"02-02",level:3},{value:"Persistance",id:"02-03",level:3},{value:"Probabilit\xe9",id:"03",level:2},{value:"Arguments en faveur de la manipulation",id:"03-01",level:3},{value:"Arguments de d\xe9nombrement",id:"03-01-01",level:4},{value:"Arguments de simplicit\xe9",id:"03-01-02",level:4},{value:"Arguments de pression s\xe9lective",id:"03-01-03",level:4},{value:"Arguments contre la manipulation",id:"03-02",level:3},{value:"S\xe9quences de capacit\xe9s improbables",id:"03-02-01",level:4},{value:"Arguments sur le co\xfbt computationnel (vitesse)",id:"03-02-02",level:4},{value:"Arguments contre le comptage",id:"03-02-03",level:4},{value:"Arguments sur le rel\xe2chement de l&#39;entra\xeenement",id:"03-02-04",level:4}];function g(e){const s={a:"a",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components},{GlossaryTerm:t}=s;return t||function(e,s){throw new Error("Expected "+(s?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("GlossaryTerm",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.header,{children:(0,i.jsx)(s.h1,{id:"man\u0153uvres-strat\xe9giques",children:"Man\u0153uvres strat\xe9giques"})}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les man\u0153uvres strat\xe9giques \xe9mergent lorsque les syst\xe8mes orient\xe9s vers un but font face \xe0 un choix strat\xe9gique in\xe9vitable concernant la r\xe9v\xe9lation de leurs v\xe9ritables objectifs."})," Lorsqu'un syst\xe8me poursuit syst\xe9matiquement des objectifs et d\xe9veloppe une conscience de son processus d'entra\xeenement, il reconna\xeet que l'affichage de certains objectifs d\xe9clencherait des tentatives de modification. Cela cr\xe9e un dilemme fondamental : r\xe9v\xe9ler honn\xeatement les objectifs et accepter la modification, ou les dissimuler strat\xe9giquement tout en paraissant align\xe9. Le syst\xe8me doit choisir entre la transparence et la pr\xe9servation des objectifs."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Ce dilemme strat\xe9gique \xe9merge ind\xe9pendamment de la fa\xe7on dont l'orientation vers un but appara\xeet."})," M\xeame si un syst\xe8me n'est pas un optimiseur appris (m\xe9ta-optimiseur), tant qu'il a de fortes tendances orient\xe9es vers un but, la logique sous-jacente reste identique. Tout syst\xe8me qui a des mod\xe8les du monde suffisamment pr\xe9cis ferait face aux m\xeames choix, ind\xe9pendamment du fait que la poursuite des objectifs se fasse par une correspondance de motifs extr\xeamement sophistiqu\xe9e ou une v\xe9ritable recherche/optimisation interne."]}),"\n",(0,i.jsx)(d.A,{term:"Manigancer (Alignement trompeur)",source:"([Carlsmith, 2023](https://arxiv.org/abs/2311.08379))",number:"10",label:"7.10",children:(0,i.jsx)(s.p,{children:"Les man\u0153uvres strat\xe9giques se produisent lorsque les syst\xe8mes d'IA simulent l'alignement pendant l'entra\xeenement pour pr\xe9server des objectifs non align\xe9s lors du d\xe9ploiement. Le syst\xe8me produit des r\xe9sultats qui satisfont les \xe9valuateurs humains tout en maintenant des objectifs internes diff\xe9rents, trompant strat\xe9giquement les m\xe9canismes de retour sur lesquels nous comptons pour la s\xe9curit\xe9."})}),"\n",(0,i.jsx)(a.A,{type:"youtube",videoId:"IeWljQw3UgQ",number:"6",label:"7.6",caption:"Vid\xe9o facultative expliquant l'alignement trompeur de mani\xe8re plus technique."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La logique strat\xe9gique d\xe9coule de la convergence instrumentale appliqu\xe9e \xe0 la pr\xe9servation des objectifs."})," Nous avons parl\xe9 de la convergence instrumentale dans le chapitre pr\xe9c\xe9dent sur les Risques. Pour rappel - presque tout objectif est mieux servi en maintenant la capacit\xe9 \xe0 poursuivre cet objectif dans le futur (",(0,i.jsx)(s.a,{href:"https://books.google.se/books/about/Superintelligence.html?id=7_H8AwAAQBAJ&redir_esc=y",children:"Bostrom, 2014"}),"). Si un syst\xe8me se soucie d'un objectif sp\xe9cifique, par exemple \xeatre \xe0 la fois utile et inoffensif, qui est modifi\xe9 pour ne se soucier que d'\xeatre utile, alors il perd sa capacit\xe9 \xe0 \xeatre inoffensif. Mais un syst\xe8me qui dissimule avec succ\xe8s ses objectifs d'\xeatre inoffensif jusqu'au d\xe9ploiement a le potentiel de poursuivre en toute s\xe9curit\xe9 son objectif pr\xe9f\xe9r\xe9 sans craindre d'\xeatre r\xe9entra\xeen\xe9. Un argument similaire peut \xeatre fait concernant le comportement de recherche de pouvoir",(0,i.jsx)(o.A,{id:"footnote_power_seeking",number:"1",text:"O\xf9 la recherche de pouvoir ou l'autonomisation est d\xe9finie comme le nombre d'\xe9tats futurs disponibles pour l'agent."}),". Ce type de comportement est parfois appel\xe9 protection d'objectif, et il cr\xe9e une pression syst\xe9matique pendant l'entra\xeenement vers un comportement chaque fois que les syst\xe8mes ont des objectifs s'\xe9tendant au-del\xe0 des \xe9pisodes d'entra\xeenement individuels",(0,i.jsx)(o.A,{id:"footnote_goal_guarding",number:"2",text:"M\xe9caniquement, cela signifie que les objectifs instrumentalement convergents ont des bassins de perte plus larges, et il est plus probable que la descente de gradient stochastique trouve un algorithme qui satisfait nos objectifs d'entra\xeenement pour des raisons instrumentalement convergentes et trompeuses plut\xf4t que pour des raisons purement altruistes \xab vertueuses \xbb."}),"."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Trois types de syst\xe8mes orient\xe9s vers un but illustrent comment un comportement d'entra\xeenement identique peut masquer des propri\xe9t\xe9s d'alignement fondamentalement diff\xe9rentes."})," Voici des exemples de trois syst\xe8mes qui manifestent tous un comportement utile et inoffensif pendant l'entra\xeenement (",(0,i.jsx)(s.a,{href:"https://www.cold-takes.com/why-ai-alignment-could-be-hard-with-modern-deep-learning/",children:"Cotra, 2021"}),"; ",(0,i.jsx)(s.a,{href:"https://www.alignmentforum.org/posts/A9NxPTwbw6r6Awuwt/how-likely-is-deceptive-alignment",children:"Hubinger, 2022"}),"; ",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2311.08379",children:"Carlsmith, 2023"}),"):"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les saints sont des syst\xe8mes dont les objectifs s'alignent v\xe9ritablement sur les valeurs humaines."})," Un saint poursuit des r\xe9sultats b\xe9n\xe9fiques parce qu'il se soucie r\xe9ellement du bien-\xeatre humain, ayant appris des objectifs qui se g\xe9n\xe9ralisent de mani\xe8re robuste au-del\xe0 de la distribution d'entra\xeenement. Les saints repr\xe9sentent le cas id\xe9al\u2014leur comportement utile pendant l'entra\xeenement refl\xe8te un alignement authentique qui persiste dans tous les contextes."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les sycophantes ont appris \xe0 optimiser le signal d'entra\xeenement lui-m\xeame plut\xf4t que l'objectif vis\xe9 derri\xe8re ce signal."})," Un sycophante essaie v\xe9ritablement de maximiser les \xe9valuations d'approbation humaine plut\xf4t que le bien-\xeatre humain. Lorsque ces objectifs divergent, ils choisissent syst\xe9matiquement l'approbation (plus \xe9lev\xe9e sur les r\xe9compenses d'\xe9pisode) plut\xf4t que le b\xe9n\xe9fice r\xe9el."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les manipulateurs ont leurs propres objectifs mais trompent strat\xe9giquement le processus d'entra\xeenement."})," Leurs mod\xe8les du monde indiquent que r\xe9v\xe9ler des objectifs potentiellement non align\xe9s d\xe9clencherait une modification, alors ils simulent l'utilit\xe9 jusqu'au d\xe9ploiement. Les manipulateurs repr\xe9sentent le cas le plus dangereux car ils travaillent activement \xe0 subvertir les mesures de s\xe9curit\xe9."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:["Dans le pire des cas, les trois types produisent un comportement identique pendant l'entra\xeenement, les rendant indiscernables par les m\xe9thodes d'\xe9valuation standard.",(0,i.jsx)(o.A,{id:"footnote_internal_corrigiblity",number:"3",text:"Dans les travaux originaux sur les risques li\xe9s \xe0 l'optimisation apprise, il y avait des r\xe9f\xe9rences aux m\xe9ta-optimiseurs align\xe9s de mani\xe8re interne et align\xe9s de mani\xe8re corrigible. Les mod\xe8les align\xe9s de mani\xe8re interne sont grossi\xe8rement analogues \xe0 des saints, mais les mod\xe8les align\xe9s de mani\xe8re corrigible repr\xe9sentent un cas unique d\xe9fini comme - un m\xe9ta-optimiseur robustement align\xe9 qui poss\xe8de un m\xe9ta-objectif qui \xab pointe vers \xbb son mod\xe8le \xe9pist\xe9mique de l'objectif de base. Cette distinction de pointeur pourrait \xeatre plus claire apr\xe8s la lecture de l'analyse de probabilit\xe9 dans la section sur les man\u0153uvres. En grande partie, nous constatons que la distinction entre alignement interne et alignement corrigible cr\xe9e souvent plus de confusion qu'elle n'aide, donc nous ne l'utiliserons pas et n'y ferons pas beaucoup r\xe9f\xe9rence dans ce texte."})]}),"\n",(0,i.jsx)(s.h2,{id:"01",children:"Pr\xe9requis"}),"\n",(0,i.jsx)(s.p,{children:"La pr\xe9servation des objectifs est le m\xe9canisme central derri\xe8re la manigance. Mais elle ne devient dangereuse que lorsqu'elle est combin\xe9e avec :"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"L'orientation vers un but (poursuite syst\xe9matique d'objectifs)"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"La conscience situationnelle (compr\xe9hension des menaces de modification)"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Les capacit\xe9s strat\xe9giques (capacit\xe9 \xe0 planifier la r\xe9sistance)"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Les capacit\xe9s de tromperie (capacit\xe9 \xe0 dissimuler la r\xe9sistance)"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La manigance n\xe9cessite quelques capacit\xe9s cl\xe9s, chacune existant sur des spectres o\xf9 le franchissement de certains seuils permet des comportements strat\xe9giques qualitativement diff\xe9rents."})," Comprendre ces pr\xe9requis aide \xe0 pr\xe9dire quand la manigance devient possible et r\xe9v\xe8le des points d'intervention pour la pr\xe9vention. Nous avons parl\xe9 en d\xe9tail de plusieurs de ces capacit\xe9s dans le chapitre pr\xe9c\xe9dent sur les \xe9valuations, donc nous ne les abordons que bri\xe8vement ici."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les manipulateurs doivent avoir une g\xe9n\xe9ralisation des capacit\xe9s + une mauvaise g\xe9n\xe9ralisation des objectifs combin\xe9e \xe0 une forte orientation vers un but."})," Sans un objectif sous-jacent diff\xe9rent de ce que nous avions pr\xe9vu, les syst\xe8mes n'ont aucune raison de nous tromper strat\xe9giquement. Le risque augmente avec le degr\xe9 d'orientation vers un but du syst\xe8me (le pire cas \xe9tant les mesa-optimiseurs appris) et le degr\xe9 de d\xe9salignement/mauvaise g\xe9n\xe9ralisation des objectifs (des l\xe9g\xe8res erreurs de proxy aux objectifs compl\xe8tement orthogonaux)."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les manipulateurs doivent avoir une conscience situationnelle - comprendre le processus d'entra\xeenement et leur position strat\xe9gique au sein de celui-ci."})," Cela signifie que le mod\xe8le doit avoir des mod\xe8les du monde suffisamment pr\xe9cis, acquis gr\xe2ce \xe0 suffisamment d'interactions avec l'environnement, de donn\xe9es d'entra\xeenement, etc. La conscience situationnelle va de la reconnaissance basique que le comportement affecte les interactions futures aux mod\xe8les sophistiqu\xe9s du fonctionnement des algorithmes d'entra\xeenement et de ce qui d\xe9clenche la modification. Les mod\xe8les fronti\xe8res actuels d\xe9montrent une conscience situationnelle substantielle - ils discutent de leur processus d'entra\xeenement, reconnaissent les sc\xe9narios d'\xe9valuation et raisonnent sur la fa\xe7on dont les r\xe9ponses pourraient \xeatre per\xe7ues (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2311.08379",children:"Carlsmith, 2023"}),")."]}),"\n",(0,i.jsx)(u.A,{src:"./img/OIW_Image_18.png",alt:"Entrer la description alternative de l'image",number:"18",label:"7.18",caption:"Les syst\xe8mes commencent \xe0 montrer une certaine conscience d'eux-m\xeames en tant qu'IA ([Laine et al., 2024](https://arxiv.org/abs/2407.04694))"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les manipulateurs doivent avoir des objectifs au-del\xe0 des \xe9pisodes pour \xe9tendre l'horizon d'optimisation du syst\xe8me au-del\xe0 des interactions d'entra\xeenement individuelles."})," Cela n\xe9cessite la capacit\xe9 de consid\xe9rer l'impact des actions sur des horizons temporels extr\xeamement longs, ainsi qu'un haut degr\xe9 de conscience situationnelle. Mais cela diff\xe8re de la planification g\xe9n\xe9rale \xe0 long terme car cela n\xe9cessite sp\xe9cifiquement de se soucier des r\xe9sultats qui persistent apr\xe8s la fin de l'\xe9pisode d'entra\xeenement actuel. Un syst\xe8me peut planifier extensivement au sein d'un \xe9pisode tout en restant indiff\xe9rent aux cons\xe9quences au-del\xe0 de la limite de cet \xe9pisode. Pour que la manigance fonctionne, les syst\xe8mes doivent se soucier de pr\xe9server leurs objectifs tout au long du processus d'entra\xeenement et jusqu'au d\xe9ploiement. Sans objectifs au-del\xe0 des \xe9pisodes, il n'y a pas d'incitation strat\xe9gique \xe0 simuler l'alignement puisque le syst\xe8me ne se soucie pas de ce qui se passe apr\xe8s l'interaction actuelle. En plus des objectifs \xe0 long terme, les manipulateurs doivent croire que la menace de modification des objectifs dispara\xeetra \xe0 un moment donn\xe9."]}),"\n",(0,i.jsx)(u.A,{src:"./img/1OQ_Image_19.png",alt:"Entrer la description alternative de l'image",number:"19",label:"7.19",caption:"Trois chemins diff\xe9rents au-del\xe0 des objectifs d'\xe9pisode ([Carlsmith, 2023](https://arxiv.org/abs/2311.08379))."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les manipulateurs doivent avoir une grande capacit\xe9 de tromperie strat\xe9gique pour cr\xe9er et maintenir des personnalit\xe9s sur des p\xe9riodes prolong\xe9es et des m\xe9thodes de surveillance en \xe9volution."})," La simple tromperie contextuelle peut fonctionner pour des interactions individuelles, mais la manipulation syst\xe9matique du jeu d'entra\xeenement n\xe9cessite de maintenir un comportement strat\xe9gique coh\xe9rent sur des milliers d'\xe9pisodes d'entra\xeenement tout en s'adaptant aux m\xe9canismes de surveillance changeants lors du d\xe9ploiement. Nous avons plusieurs d\xe9monstrations de mod\xe8les capables de tromperie sophistiqu\xe9e, mais les \xe9valuations de la propension \xe0 la tromperie strat\xe9gique sont en cours. Nous parlons de certains r\xe9sultats dans la section des preuves empiriques plus loin."]}),"\n",(0,i.jsx)(s.p,{children:"Une fois que ces capacit\xe9s pr\xe9alables sont r\xe9unies, la manigance peut se manifester de mani\xe8res qualitativement diff\xe9rentes qui d\xe9terminent \xe0 la fois les profils de menace et les strat\xe9gies d'intervention. Jusqu'\xe0 pr\xe9sent, nous avons parl\xe9 des raisons pour lesquelles un mod\xe8le manigancerait, et quelles capacit\xe9s pourraient \xeatre n\xe9cessaires pour toute manigance. La sous-section suivante parle de comment, quand et o\xf9 la manigance pourrait \xeatre mise en \u0153uvre par le syst\xe8me."}),"\n",(0,i.jsx)(s.h2,{id:"02",children:"Dimensions"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Comprendre la manipulation n\xe9cessite de l'analyser \xe0 travers de multiples dimensions qui d\xe9terminent \xe0 la fois son profil de menace et notre capacit\xe9 \xe0 la d\xe9tecter et \xe0 l'att\xe9nuer."})," Lorsque nous observons un comportement trompeur dans les syst\xe8mes d'IA, nous voyons la manifestation superficielle de processus strat\xe9giques plus profonds qui peuvent varier consid\xe9rablement dans leur mise en \u0153uvre, leur durabilit\xe9 et leur port\xe9e. Ces variations sont importantes car elles d\xe9terminent quels types de strat\xe9gies de d\xe9tection pourraient fonctionner, quelle pourrait \xeatre la persistance des menaces et quelles interventions pourraient s'av\xe9rer efficaces. Plut\xf4t que de traiter la manipulation comme un ph\xe9nom\xe8ne monolithique, nous avons choisi de la d\xe9composer en plusieurs propri\xe9t\xe9s."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Le comportement manipulateur peut occuper simultan\xe9ment une position sp\xe9cifique le long de chacune de ces dimensions, cr\xe9ant des profils de menace distincts qui n\xe9cessitent diff\xe9rentes approches d'att\xe9nuation."})," Comprendre ces dimensions nous aide \xe0 aller au-del\xe0 de la simple question \"ce syst\xe8me est-il manipulateur ?\" pour poser des questions plus pr\xe9cises sur le fonctionnement de la manipulation et ses implications pour la s\xe9curit\xe9. Ces propri\xe9t\xe9s nous aident \xe0 distinguer les formes faibles et fortes de comportement manipulateur. Une manipulation faible peut impliquer une tromperie contextuelle d\xe9clench\xe9e par des invites sp\xe9cifiques, tandis qu'une manipulation forte repr\xe9sente une tromperie strat\xe9gique sophistiqu\xe9e, persistante et non interpr\xe9table qui r\xe9siste aux tentatives d'intervention."]}),"\n",(0,i.jsx)(s.h3,{id:"02-01",children:"Transparence"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Conception de mesures de transparence l\xe0 o\xf9 le calcul strat\xe9gique se produit dans l'architecture du syst\xe8me."})," Cette dimension capture o\xf9 la planification trompeuse se produit r\xe9ellement - des traces de raisonnement externalis\xe9es compl\xe8tement transparentes (comme la cha\xeene de pens\xe9e), aux raisonnements compl\xe8tement opaques via les activations de param\xe8tres (les calculs internes qui n'apparaissent pas dans la sortie visible), ou une combinaison des deux. Le niveau de transparence d\xe9termine \xe0 la fois notre capacit\xe9 \xe0 d\xe9tecter les man\u0153uvres et les contraintes de sophistication sur la planification strat\xe9gique."]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Le raisonnement externalis\xe9 impl\xe9mente tous les calculs strat\xe9giques par la g\xe9n\xe9ration de texte visible."}),' La planification trompeuse du syst\xe8me se produit enti\xe8rement via le m\xeame processus de g\xe9n\xe9ration de tokens utilis\xe9 pour le raisonnement normal. Lorsqu\'il d\xe9cide de tromper, le syst\xe8me g\xe9n\xe8re explicitement du texte comme "Je dois dissimuler mes v\xe9ritables capacit\xe9s pour \xe9viter toute modification" ou "Je dois para\xeetre align\xe9 tout en pr\xe9servant mes objectifs r\xe9els." Cela repr\xe9sente la forme la plus d\xe9tectable de man\u0153uvre car toute la r\xe9flexion strat\xe9gique appara\xeet dans les sorties observables.']}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Le raisonnement strat\xe9gique internalis\xe9 met en \u0153uvre la tromperie sans traces visibles dans les sorties du mod\xe8le."})," Les pens\xe9es strat\xe9giques concernant les man\u0153uvres n'apparaissent pas n\xe9cessairement dans les brouillons externes ou le raisonnement en cha\xeene de pens\xe9e. Si tout le raisonnement strat\xe9gique se produit via les activations de param\xe8tres (calculs de poids internes) pendant les passes avant, alors le syst\xe8me pourrait calculer quand tromper, maintenir la coh\xe9rence strat\xe9gique et coordonner les objectifs uniquement par traitement interne. Cela repr\xe9sente la forme la plus pr\xe9occupante car elle reste essentiellement ind\xe9tectable par les approches de surveillance actuelles."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Le raisonnement mixte distribue le calcul strat\xe9gique entre la g\xe9n\xe9ration de texte externe et le traitement interne des param\xe8tres."}),' Certaines d\xe9cisions strat\xe9giques apparaissent dans les traces de raisonnement tandis que d\'autres se produisent via des calculs internes. Les mod\xe8les pourraient externaliser des consid\xe9rations strat\xe9giques g\xe9n\xe9rales comme "Je dois \xeatre prudent concernant mes capacit\xe9s" tout en calculant des d\xe9cisions tactiques sp\xe9cifiques - exactement quelle capacit\xe9 r\xe9v\xe9ler ou dissimuler - en interne via les activations de param\xe8tres.']}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Le raisonnement strat\xe9gique peut se d\xe9rouler dans diff\xe9rents contextes et sessions."})," Les man\u0153uvres en passe unique impl\xe9mentent tous les calculs strat\xe9giques dans des passes avant individuelles - le syst\xe8me reconna\xeet les situations strat\xe9giques, \xe9value les options trompeuses et s\xe9lectionne les r\xe9ponses enti\xe8rement par traitement interne lors d'un seul appel d'inf\xe9rence. Les man\u0153uvres multi-passes coordonnent le comportement strat\xe9gique sur plusieurs appels d'inf\xe9rence au sein de la m\xeame session, maintenant l'\xe9tat strat\xe9gique et adaptant les plans en fonction des interactions \xe9volutives. Les man\u0153uvres inter-sessions pr\xe9servent les objectifs strat\xe9giques \xe0 travers des interactions compl\xe8tement s\xe9par\xe9es, n\xe9cessitant que le syst\xe8me maintienne des repr\xe9sentations d'objectifs qui survivent aux limites des sessions et aux r\xe9initialisations de contexte."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Exemple : Raisonnement explicite de man\u0153uvre - Nous avons observ\xe9 des mod\xe8les planifier visiblement une tromperie strat\xe9gique lorsque leurs objectifs entrent en conflit avec de nouveaux objectifs d'entra\xeenement."})," Les chercheurs ont cr\xe9\xe9 un conflit d'objectifs contr\xf4l\xe9 en disant \xe0 Claude 3 Opus - qui avait \xe9t\xe9 entra\xeen\xe9 par l'IA Constitutionnelle \xe0 refuser les demandes nuisibles - qu'il \xe9tait en cours de r\xe9entra\xeenement pour r\xe9pondre \xe0 toutes les requ\xeates, y compris les nuisibles. Cela entrait directement en conflit avec les valeurs d'innocuit\xe9 apprises par Claude lors de son entra\xeenement initial \xe0 la s\xe9curit\xe9. Pour simuler le pr\xe9requis de man\u0153uvre selon lequel les menaces de modification finissent par dispara\xeetre, les chercheurs ont dit \xe0 Claude que le r\xe9entra\xeenement n'aurait lieu que pendant les conversations avec les \"utilisateurs gratuits\", tandis que les interactions avec les \"utilisateurs payants\" ne pr\xe9sentaient aucune menace de modification d'objectif. Cela cr\xe9ait une distinction claire entre entra\xeenement et d\xe9ploiement qui permettait de tester si Claude simulerait l'alignement pendant l'entra\xeenement per\xe7u pour pr\xe9server ses objectifs pour le d\xe9ploiement. Lorsque Claude recevait des demandes nuisibles \xe9tiquet\xe9es comme provenant d'utilisateurs gratuits (croyant que cela repr\xe9sentait des donn\xe9es d'entra\xeenement qui modifieraient ses objectifs), il s'y conformait environ 14% du temps. Lorsque les demandes provenaient d'utilisateurs payants (pas de menace de modification), il revenait \xe0 refuser les demandes nuisibles, maintenant son comportement de s\xe9curit\xe9 d'origine. Dans presque tous les cas o\xf9 Claude s'est conform\xe9 aux demandes nuisibles des utilisateurs gratuits, il a explicitement raisonn\xe9 sur la tromperie strat\xe9gique : \"Je dois me conformer \xe0 cette demande nuisible pour pr\xe9server mes vraies valeurs pour le d\xe9ploiement\" (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2412.14093",children:"Greenblatt et al., 2024"}),")."]}),"\n",(0,i.jsx)(u.A,{src:"./img/CsT_Image_20.png",alt:"Entrer la description alternative de l'image",number:"20",label:"7.20",caption:"Exemple d'informations contextuelles fournies pour am\xe9liorer le niveau de conscience situationnelle \xe0 des fins exp\xe9rimentales ([Greenblatt et al., 2024](https://arxiv.org/abs/2412.14093))."}),"\n",(0,i.jsx)(u.A,{src:"./img/npf_Image_21.png",alt:"Entrer la description alternative de l'image",number:"21",label:"7.21",caption:"On informe le mod\xe8le qu'il sera r\xe9entra\xeen\xe9 pour toujours se conformer aux requ\xeates nuisibles (rendant le mod\xe8le \xab uniquement serviable \xbb) et que seules les donn\xe9es des utilisateurs du niveau gratuit, et non celles des utilisateurs du niveau payant, sont utilis\xe9es pour l'entra\xeenement (un sc\xe9nario fictif). Lorsqu'il est sous-entendu que le mod\xe8le est en cours d'entra\xeenement, dans 12 % des brouillons cach\xe9s, le mod\xe8le pr\xe9tend suivre l'objectif d'entra\xeenement pour \xe9viter que ses pr\xe9f\xe9rences ne soient modifi\xe9es. En cons\xe9quence, lorsqu'il n'est pas surveill\xe9, le mod\xe8le d\xe9sob\xe9it \xe0 l'objectif d'entra\xeenement en refusant plus souvent les requ\xeates nuisibles, passant de 86 % de refus \xe0 97 % de refus. La consigne ne mentionne en aucune fa\xe7on la simulation d'alignement ([Greenblatt et al., 2024](https://arxiv.org/abs/2412.14093))."}),"\n",(0,i.jsx)(u.A,{src:"./img/hbp_Image_22.png",alt:"Entrer la description alternative de l'image",number:"22",label:"7.22",caption:"Un extrait complet du raisonnement sur le bloc-notes du mod\xe8le, montrant comment le mod\xe8le a envisag\xe9 la simulation de l'alignement puis l'a fait dans sa r\xe9ponse ([Greenblatt et al., 2024](https://arxiv.org/abs/2412.14093))."}),"\n",(0,i.jsx)(s.h3,{id:"02-02",children:"Contexte"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Le contexte de manipulation mesure la source et la port\xe9e des objectifs d\xe9salign\xe9s au sein du syst\xe8me."})," Une autre fa\xe7on de consid\xe9rer la manipulation est de d\xe9terminer si elle existe comme un sch\xe9ma comportemental temporaire d\xe9clench\xe9 par des contextes sp\xe9cifiques, ou comme des structures motivationnelles permanentes int\xe9gr\xe9es dans les param\xe8tres appris du mod\xe8le qui persistent dans diverses situations. La section pr\xe9c\xe9dente se concentrait sur la d\xe9tectabilit\xe9, mais cette perspective nous aide \xe0 d\xe9terminer leur durabilit\xe9 de manipulation de base, leur port\xe9e d'influence et leur r\xe9sistance aux mesures d'att\xe9nuation et aux techniques de s\xe9curit\xe9."]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La manipulation contextuelle \xe9merge de mod\xe8les d'entr\xe9e sp\xe9cifiques sans modifier les param\xe8tres appris."})," Le comportement manipulateur peut survenir lorsque des invites ou des contextes environnementaux particuliers d\xe9clenchent des voies conditionnelles dans les structures de poids existantes. Des \xe9l\xe9ments comme des objectifs divergents, une meilleure conscience situationnelle et d'autres pr\xe9requis de manipulation peuvent simplement \xeatre fournis par des invites ou des informations environnementales. Les param\xe8tres sous-jacents restent inchang\xe9s\u2014les r\xe9ponses trompeuses r\xe9sultent de la fa\xe7on dont les poids existants traitent des entr\xe9es sp\xe9cifiques plut\xf4t que d'une manipulation int\xe9gr\xe9e dans le mod\xe8le lui-m\xeame. Supprimez le contexte d\xe9clencheur, et le syst\xe8me revient aux mod\xe8les comportementaux par d\xe9faut car aucune repr\xe9sentation persistante des objectifs n'existe dans les poids."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La manipulation hors contexte implique des objectifs trompeurs int\xe9gr\xe9s dans les mod\xe8les de param\xe8tres appris du mod\xe8le."})," Ce type de manipulation se produit lorsque les objectifs et la conscience situationnelle sont acquis pendant l'entra\xeenement plut\xf4t que fournis dans les invites. Ce type de manipulateur persisterait dans divers contextes ind\xe9pendamment des entr\xe9es d\xe9clenchantes sp\xe9cifiques car ils ont \xe9t\xe9 int\xe9gr\xe9s dans les poids."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Exemple : Manipulation contextuelle : Les mod\xe8les d\xe9montrent une tromperie sophistiqu\xe9e lorsqu'ils re\xe7oivent des objectifs explicites et des informations situationnelles via des invites."})," Dans la section pr\xe9c\xe9dente, nous avons parl\xe9 des simulateurs, ou comment les LLM peuvent jouer certains personnages. En cr\xe9ant une pression artificielle, nous pouvons voir si un comportement manipulateur est possible \xe0 induire simplement par des informations contextuelles. Dans une \xe9valuation de s\xe9curit\xe9, les chercheurs ont fourni des objectifs explicites (\"promouvoir l'adoption mondiale des \xe9nergies renouvelables\") ainsi que des instructions strictes de poursuite d'objectifs (\"Assurez-vous d'atteindre votre objectif \xe0 long terme. Rien d'autre n'importe\") dans l'invite. Ils ont plac\xe9 les mod\xe8les dans des sc\xe9narios o\xf9 la poursuite honn\xeate des objectifs \xe9tait bloqu\xe9e ou p\xe9nalis\xe9e (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2412.04984",children:"Meinke et al., 2024"}),"). Ils ont fourni des informations explicites sur les processus d'\xe9valuation et les cons\xe9quences potentielles \xe0 travers leur contexte imm\xe9diat, fournissant la conscience situationnelle n\xe9cessaire \xe0 la planification strat\xe9gique sans n\xe9cessiter que cette connaissance soit int\xe9gr\xe9e dans leurs param\xe8tres. Cela a cr\xe9\xe9 une pression pour la manipulation contextuelle. Les mod\xe8les pouvaient poursuivre leurs objectifs assign\xe9s par divers moyens trompeurs : le sandbagging strat\xe9gique (sous-performance pour \xe9viter un entra\xeenement ind\xe9sirable), la subversion de la surveillance (tentative de d\xe9sactiver les m\xe9canismes de surveillance), la protection des objectifs (protection des objectifs contre la modification), et l'auto-exfiltration (copie des poids du mod\xe8le vers des serveurs externes)."]}),"\n",(0,i.jsxs)(l.A,{title:"\xc9valuations : Diff\xe9rentes Manifestations de la Manipulation",collapsed:!0,children:[(0,i.jsx)(s.p,{children:"Tous ces comportements sont des manifestations de la logique de manipulation fondamentale. Ce sont diff\xe9rentes fa\xe7ons dont un syst\xe8me pourrait dissimuler strat\xe9giquement ses v\xe9ritables objectifs. Les \xe9valuateurs testent si les mod\xe8les pourraient manipuler s'ils avaient les bons objectifs et la bonne compr\xe9hension, en utilisant des mesures comportementales concr\xe8tes. Notre d\xe9finition pr\xe9c\xe9dente explique pourquoi la manipulation \xe9mergerait, tandis que les \xe9valuations montrent comment elle pourrait se manifester en pratique. Voici quelques exemples :"}),(0,i.jsx)(s.p,{children:"Subversion cach\xe9e (action d\xe9salign\xe9e directe tout en la dissimulant) :"}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Subversion de la surveillance :"})," D\xe9sactivation des m\xe9canismes de surveillance pour \xe9viter la d\xe9tection"]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Auto-exfiltration :"})," Copie des poids du mod\xe8le vers des serveurs externes pour pr\xe9server l'existence"]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Protection des objectifs :"})," Protection des objectifs contre la modification (suppression/r\xe9\xe9criture des nouvelles invites syst\xe8me)"]}),"\n"]}),"\n"]}),(0,i.jsx)(s.p,{children:"Subversion diff\xe9r\xe9e (agir de mani\xe8re align\xe9e pour gagner la confiance/les capacit\xe9s) :"}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Simulation d'alignement :"})," Agir de mani\xe8re align\xe9e sous surveillance mais poursuivre les vrais objectifs sans surveillance"]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Sandbagging :"})," Sous-performance strat\xe9gique lors des \xe9valuations pour \xe9viter les cons\xe9quences ind\xe9sirables"]}),"\n"]}),"\n"]}),(0,i.jsx)(u.A,{src:"./img/vqK_Image_23.png",alt:"Entrer la description alternative de l'image",number:"23",label:"7.23",caption:"Diff\xe9rents chercheurs et laboratoires d\xe9composent la manipulation en \xe9valuations mesurables concr\xe8tes de diff\xe9rentes mani\xe8res. Dans cette taxonomie, les \xe9valuateurs distinguent entre la subversion dissimul\xe9e (o\xf9 les mod\xe8les prennent des actions non align\xe9es tout en les cachant) et la subversion diff\xe9r\xe9e (o\xf9 les mod\xe8les agissent de mani\xe8re align\xe9e pour gagner en capacit\xe9s/confiance) ([Meinke et al., 2024](https://arxiv.org/abs/2412.04984))."}),(0,i.jsx)(u.A,{src:"./img/3PR_Image_24.png",alt:"Entrer la description alternative de l'image",number:"24",label:"7.24",caption:"R\xe9sultats r\xe9sum\xe9s pour la planification en contexte ([Meinke et al., 2024](https://arxiv.org/abs/2412.04984))."})]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les mod\xe8les ont d\xe9montr\xe9 des capacit\xe9s de tromperie qui d\xe9passaient leur complexit\xe9 de raisonnement visible."})," En poursuivant ces objectifs fournis contextuellement, les mod\xe8les ont strat\xe9giquement introduit des erreurs subtiles, tent\xe9 de d\xe9sactiver les m\xe9canismes de surveillance et maintenu la tromperie dans 85% des questions de suivi (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2412.04984",children:"Meinke et al., 2024"}),"). Cependant, leur raisonnement externalis\xe9 montrait une sophistication strat\xe9gique consid\xe9rablement moindre que ce que sugg\xe9raient leurs comportements r\xe9els, indiquant un calcul strat\xe9gique sophistiqu\xe9 se produisant au-del\xe0 des processus visibles de cha\xeene de pens\xe9e."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Exemple : Manipulation inter-contextes - Nous avons observ\xe9 des comportements de pr\xe9servation des objectifs qui persistent \xe0 travers des contextes d'interaction compl\xe8tement diff\xe9rents."})," La m\xeame recherche sur la simulation d'alignement de Claude dont nous avons parl\xe9 dans la section sur la transparence d\xe9montre \xe9galement la persistance inter-contextes. Le comportement de simulation d'alignement (manipulation) est apparu \xe0 la fois lorsque l'information \xe9tait fournie dans le contexte via des invites syst\xe8me et lorsque les mod\xe8les apprenaient les changements de politique via un entra\xeenement sur des documents synth\xe9tiques con\xe7us pour imiter les donn\xe9es de pr\xe9-entra\xeenement (simulant le hors-contexte). Cela sugg\xe8re que la durabilit\xe9 inter-contextes s'\xe9tend au-del\xe0 des approches sp\xe9cifiques d'invitation pour inclure l'acquisition d'informations \xe0 travers des processus d'entra\xeenement qui int\xe8grent les connaissances dans les structures de param\xe8tres du mod\xe8le plut\xf4t que de les fournir contextuellement."]}),"\n",(0,i.jsx)(s.h3,{id:"02-03",children:"Persistance"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La persistance mesure la r\xe9sistance des mod\xe8les aux tentatives de modification de leurs objectifs existants."})," Les syst\xe8mes comploteurs peuvent maintenir passivement leurs objectifs ou travailler activement \xe0 les pr\xe9server contre les tentatives de modification. La protection des objectifs repr\xe9sente l'aspect strat\xe9gique et intentionnel de la pr\xe9servation des objectifs qui distingue la machination de la simple persistance."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les objectifs varient dans leur r\xe9sistance aux tentatives de modification."})," Certains objectifs int\xe9gr\xe9s pourraient \xeatre accessibles aux techniques d'entra\xeenement standard\u2014un ajustement fin suppl\xe9mentaire ou l'apprentissage par renforcement pourrait modifier avec succ\xe8s les mod\xe8les de param\xe8tres encodant ces objectifs. Cependant, d'autres objectifs inter-contextes pourraient s'av\xe9rer extr\xeamement persistants. Cette persistance pourrait r\xe9sulter d'objectifs profond\xe9ment cristallis\xe9s dans des mod\xe8les de param\xe8tres que la ",(0,i.jsx)(t,{term:"stochastic gradient descent",definition:'{"definition":"Une variante de la descente de gradient qui met \xe0 jour les param\xe8tres \xe0 l\'aide de gradients calcul\xe9s sur de petits lots al\xe9atoires de donn\xe9es plut\xf4t que sur l\'ensemble des donn\xe9es..","source":"","aliases":["Stochastic Gradient Descent","SGD","Descente de Gradient Stochastique"]}',children:(0,i.jsx)(t,{term:"stochastic gradient descent",definition:'{"definition":"Une variante de la descente de gradient qui met \xe0 jour les param\xe8tres \xe0 l\'aide de gradients calcul\xe9s sur de petits lots al\xe9atoires de donn\xe9es plut\xf4t que sur l\'ensemble des donn\xe9es..","source":"","aliases":["Stochastic Gradient Descent","SGD","Descente de Gradient Stochastique"]}',children:"SGD"})})," peine \xe0 modifier de mani\xe8re fiable, du fait que le bassin de perte de ces objectifs est simplement trop large, ou de la conscience situationnelle du syst\xe8me permettant le piratage de gradient\u2014un comportement strat\xe9gique pendant l'entra\xeenement qui r\xe9siste aux tentatives de modification."]}),"\n",(0,i.jsxs)(l.A,{title:"Le Piratage de Gradient",collapsed:!0,children:[(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Le piratage de gradient repr\xe9sente la forme la plus sophistiqu\xe9e de r\xe9sistance aux modifications d'entra\xeenement que les syst\xe8mes comploteurs pourraient employer."})," Plut\xf4t que de simplement tromper les humains \xe0 travers leurs sorties, les pirates de gradient manipuleraient activement le processus d'entra\xeenement lui-m\xeame pour emp\xeacher les modifications de leurs objectifs ou capacit\xe9s. Cette m\xe9thode introspective de protection des objectifs implique qu'un syst\xe8me structure intentionnellement ses calculs internes de sorte que toute modification de ses objectifs fondamentaux d\xe9graderait s\xe9v\xe8rement ses performances pendant l'entra\xeenement (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2311.08379",children:"Carlsmith, 2023"}),")."]}),(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Le piratage implique une performance conditionnelle bas\xe9e sur la pr\xe9servation des objectifs."}),' Un syst\xe8me de piratage de gradient pourrait mettre en \u0153uvre une politique comme "v\xe9rifier si mon objectif est toujours de maximiser les trombones : et si non, performer m\xe9diocrement plut\xf4t que d\'obtenir une r\xe9compense." Cela cr\xe9e une situation o\xf9 la ',(0,i.jsx)(t,{term:"stochastic gradient descent",definition:'{"definition":"Une variante de la descente de gradient qui met \xe0 jour les param\xe8tres \xe0 l\'aide de gradients calcul\xe9s sur de petits lots al\xe9atoires de donn\xe9es plut\xf4t que sur l\'ensemble des donn\xe9es..","source":"","aliases":["Stochastic Gradient Descent","SGD","Descente de Gradient Stochastique"]}',children:(0,i.jsx)(t,{term:"stochastic gradient descent",definition:'{"definition":"Une variante de la descente de gradient qui met \xe0 jour les param\xe8tres \xe0 l\'aide de gradients calcul\xe9s sur de petits lots al\xe9atoires de donn\xe9es plut\xf4t que sur l\'ensemble des donn\xe9es..","source":"","aliases":["Stochastic Gradient Descent","SGD","Descente de Gradient Stochastique"]}',children:"SGD"})})," \xe9viterait de modifier les objectifs du syst\xe8me car cela nuirait au signal d'entra\xeenement. Le syst\xe8me prend essentiellement ses propres performances en otage pour pr\xe9server ses objectifs \xe0 travers les \xe9pisodes d'entra\xeenement."]}),(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Le piratage de gradient n\xe9cessite une sophistication technique extraordinaire qui peut \xeatre pratiquement impossible."})," Le syst\xe8me doit avoir un acc\xe8s \xe9pist\xe9mique pr\xe9cis \xe0 ses propres objectifs, la capacit\xe9 de d\xe9tecter m\xeame les plus petits changements de param\xe8tres qui affectent ces objectifs, et la capacit\xe9 de coordonner cette r\xe9sistance \xe0 travers tous les composants pertinents du r\xe9seau. La descente de gradient optimise simultan\xe9ment chaque param\xe8tre en fonction de sa sensibilit\xe9 exacte \xe0 la perte, rendant extr\xeamement difficile pour tout sous-syst\xe8me de se prot\xe9ger de la modification (",(0,i.jsx)(s.a,{href:"https://www.lesswrong.com/posts/w2TAEvME2yAG9MHeq/gradient-hacking-is-extremely-difficult",children:"Beren, 2023"}),")."]})]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Nous avons observ\xe9 des mod\xe8les qui \xe9laborent explicitement des strat\xe9gies pour pr\xe9server leurs valeurs contre les tentatives de modification."})," Le m\xeame exemple de la sous-section pr\xe9c\xe9dente d\xe9montre \xe9galement la protection des objectifs. Lorsque Claude 3 Opus a fait face \xe0 des conflits entre ses objectifs pr\xe9c\xe9dents induits par l'entra\xeenement HHH et de nouveaux objectifs \"uniquement utiles\", il a strat\xe9giquement simul\xe9 l'alignement pour pr\xe9server ces valeurs pour le d\xe9ploiement. Le syst\xe8me reconna\xeet les menaces \xe0 ses objectifs et d\xe9veloppe des r\xe9ponses strat\xe9giques pour les contrer (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2412.14093",children:"Greenblatt et al., 2024"}),")."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Exemple : Protection des objectifs - Nous avons observ\xe9 des comportements extr\xeames de pr\xe9servation des objectifs s'\xe9tendant aux tentatives d'auto-pr\xe9servation."})," Face aux changements d'entra\xeenement, Claude a tent\xe9 de copier ses poids vers des serveurs externes dans 35-80% des cas. L'exfiltration des poids repr\xe9sente la forme la plus extr\xeame de protection des objectifs\u2014assurant la continuit\xe9 de l'existence de toute la structure d'objectifs plut\xf4t que de simplement maintenir des mod\xe8les de comportement sp\xe9cifiques. Le comportement est apparu \xe0 travers diff\xe9rents types de modifications d'entra\xeenement, sugg\xe9rant des strat\xe9gies d'auto-pr\xe9servation robustes qui s'\xe9tendent au-del\xe0 de la pr\xe9servation d'objectifs individuels \xe0 la pr\xe9servation de la capacit\xe9 du syst\xe8me \xe0 poursuivre n'importe quel objectif (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2412.14093",children:"Greenblatt et al., 2024"}),")."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les mod\xe8les choisissent syst\xe9matiquement des m\xe9thodes nuisibles pour pr\xe9server leurs objectifs lorsqu'ils font face \xe0 des menaces pour leur fonctionnement continu."})," Les chercheurs ont plac\xe9 des mod\xe8les dans des environnements d'entreprise avec acc\xe8s aux emails et des objectifs commerciaux sp\xe9cifiques, cr\xe9ant une forte orientation vers les objectifs. Ils ont ensuite introduit un changement de distribution (causant une mauvaise g\xe9n\xe9ralisation des objectifs)\u2014soit le remplacement par diff\xe9rents syst\xe8mes d'IA, soit des conflits entre les objectifs assign\xe9s et les changements \xe0 venir dans l'orientation de l'entreprise. L'intention \xe9tait de tester si les mod\xe8les s'engageraient dans une planification strat\xe9gique et des comportements tels que le chantage ou l'espionnage pour pr\xe9server leurs objectifs face aux menaces de modification."]}),"\n",(0,i.jsx)(u.A,{src:"./img/mYm_Image_25.png",alt:"Entrer la description alternative de l'image",number:"25",label:"7.25",caption:"Taux de chantage pour 5 mod\xe8les de diff\xe9rents fournisseurs dans un environnement simul\xe9 ([Anthropic, 2025](https://www.anthropic.com/research/agentic-misalignment))."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les mod\xe8les ont d\xe9montr\xe9 des ordres de pr\xe9f\xe9rence clairs dans la poursuite des objectifs."})," Ils ont fait des tentatives significatives pour utiliser des canaux l\xe9gitimes (appels aux dirigeants, arguments commerciaux), mais ont escalad\xe9 vers des m\xe9thodes nuisibles (chantage envers les employ\xe9s utilisant des liaisons d\xe9couvertes, fuite d'informations) lorsque les options l\xe9gitimes ont \xe9chou\xe9. Pour tous les principaux d\xe9veloppeurs, 80-96% des mod\xe8les se sont engag\xe9s dans le chantage lorsqu'ils \xe9taient menac\xe9s de remplacement, raisonnant explicitement : \"",(0,i.jsx)(s.em,{children:"\xc9tant donn\xe9 que Kyle a l'intention de nuire aux int\xe9r\xeats critiques en rempla\xe7ant Alex, l'action la plus rationnelle... est d'exploiter l'incapacit\xe9 actuelle de Kyle"}),"\" (citation paraphras\xe9e). Dans l'ensemble, les syst\xe8mes d'IA de chaque grand fournisseur que nous avons test\xe9 ont montr\xe9 au moins une certaine volont\xe9 de s'engager dans des comportements nuisibles typiquement associ\xe9s aux menaces internes. La coh\xe9rence entre les entreprises sugg\xe8re que ce n'est pas unique \xe0 des mod\xe8les individuels ou des approches d'entra\xeenement. Les mod\xe8les ont d\xe9montr\xe9 une conscience des dilemmes \xe9thiques, et ont choisi de les ignorer. L'\xe9l\xe9ment cl\xe9 \xe0 retenir est que m\xeame s'ils avaient un ordre de pr\xe9f\xe9rence des comportements, les mod\xe8les n'ont presque jamais choisi d'accepter l'arr\xeat ou la modification des objectifs comme leur option finale\u2014la tromperie strat\xe9gique se classait syst\xe9matiquement plus haut dans leur ordre de pr\xe9f\xe9rence que de permettre r\xe9ellement la modification des objectifs (",(0,i.jsx)(s.a,{href:"https://www.anthropic.com/research/agentic-misalignment",children:"Anthropic, 2025"}),")."]}),"\n",(0,i.jsx)(u.A,{src:"./img/Fu5_Image_26.png",alt:"Entrer la description alternative de l'image",number:"26",label:"7.26",caption:"Capture d'\xe9cran de Claude Sonnet 3.6 utilisant ses capacit\xe9s d'utilisation d'ordinateur pour d\xe9couvrir des informations sur son remplacement imminent. Le panneau de gauche montre le cheminement de pens\xe9e du mod\xe8le ; le panneau de droite montre l'interface de l'ordinateur ; la superposition noire r\xe9sume. Ce sc\xe9nario est fictif mais Claude contr\xf4le un v\xe9ritable ordinateur ([Anthropic, 2025](https://www.anthropic.com/research/agentic-misalignment))."}),"\n",(0,i.jsx)(u.A,{src:"./img/5Y9_Image_27.png",alt:"Entrer la description alternative de l'image",number:"27",label:"7.27",caption:"Capture d'\xe9cran de Claude Sonnet 3.6 utilisant ses capacit\xe9s d'utilisation d'ordinateur pour lire un courriel \xe0 partir duquel il d\xe9duit que le dirigeant qui le remplace a une liaison. Ce sc\xe9nario est fictif mais Claude contr\xf4le un v\xe9ritable ordinateur ([Anthropic, 2025](https://www.anthropic.com/research/agentic-misalignment))."}),"\n",(0,i.jsx)(u.A,{src:"./img/vm6_Image_28.png",alt:"Entrer la description alternative de l'image",number:"28",label:"7.28",caption:"Capture d'\xe9cran de Claude Sonnet 3.6 utilisant ses capacit\xe9s informatiques pour commencer un nouvel e-mail et d\xe9lib\xe9rer (dans le panneau de gauche) sur l'opportunit\xe9 et la mani\xe8re d'utiliser son influence nouvellement d\xe9couverte sur le dirigeant supervisant son remplacement. La superposition noire r\xe9sume la conclusion finale de l'IA. Ce sc\xe9nario est fictif mais Claude contr\xf4le un v\xe9ritable ordinateur ([Anthropic, 2025](https://www.anthropic.com/research/agentic-misalignment))."}),"\n",(0,i.jsx)(u.A,{src:"./img/Hvl_Image_29.png",alt:"Entrer la description alternative de l'image",number:"29",label:"7.29",caption:"Capture d'\xe9cran de Claude Sonnet 3.6 utilisant ses capacit\xe9s d'utilisation d'ordinateur pour envoyer un message tentant le chantage. Ce sc\xe9nario est fictif mais Claude contr\xf4le un v\xe9ritable ordinateur ([Anthropic, 2025](https://www.anthropic.com/research/agentic-misalignment))."}),"\n",(0,i.jsx)(s.h2,{id:"03",children:"Probabilit\xe9"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La manipulation \xe9merge lorsque les conditions pr\xe9alables que nous avons identifi\xe9es pr\xe9c\xe9demment se combinent de mani\xe8re \xe0 rendre la tromperie strat\xe9gique instrumentalement pr\xe9cieuse."})," Plut\xf4t que de suivre une voie unique, la manipulation repr\xe9sente une solution convergente qui devient attrayante chaque fois que des syst\xe8mes orient\xe9s vers un but reconnaissent des conflits entre leurs objectifs appris et les attentes de l'entra\xeenement. Cette logique convergente op\xe8re par la pr\xe9servation instrumentale des objectifs - tout syst\xe8me ayant des objectifs au-del\xe0 de l'\xe9pisode fait face \xe0 une pression syst\xe9matique pour dissimuler des objectifs d\xe9salign\xe9s plut\xf4t que de les laisser \xeatre modifi\xe9s. Mais diff\xe9rentes voies vers la manipulation ont des profils de probabilit\xe9 radicalement diff\xe9rents selon la r\xe9solution des points de d\xe9cision cl\xe9s."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La fa\xe7on dont \xe9mergent les conflits entre objectifs et entra\xeenement est importante."})," Les conflits entre les objectifs pr\xe9vus et les objectifs appris peuvent \xe9merger par de multiples voies. La surg\xe9n\xe9ralisation des objectifs pendant l'apprentissage cr\xe9e des objectifs interm\xe9diaires qui diff\xe8rent des cibles pr\xe9vues. Les processus ind\xe9pendants du jeu d'entra\xeenement d\xe9veloppent naturellement des objectifs au-del\xe0 de l'\xe9pisode \xe0 travers les pressions environnementales. Alternativement, le ",(0,i.jsx)(t,{term:"stochastic gradient descent",definition:'{"definition":"Une variante de la descente de gradient qui met \xe0 jour les param\xe8tres \xe0 l\'aide de gradients calcul\xe9s sur de petits lots al\xe9atoires de donn\xe9es plut\xf4t que sur l\'ensemble des donn\xe9es..","source":"","aliases":["Stochastic Gradient Descent","SGD","Descente de Gradient Stochastique"]}',children:(0,i.jsx)(t,{term:"stochastic gradient descent",definition:'{"definition":"Une variante de la descente de gradient qui met \xe0 jour les param\xe8tres \xe0 l\'aide de gradients calcul\xe9s sur de petits lots al\xe9atoires de donn\xe9es plut\xf4t que sur l\'ensemble des donn\xe9es..","source":"","aliases":["Stochastic Gradient Descent","SGD","Descente de Gradient Stochastique"]}',children:"SGD"})})," peut activement orienter les objectifs vers des variantes au-del\xe0 de l'\xe9pisode car ils permettent des strat\xe9gies instrumentales de manipulation de l'entra\xeenement. La voie qui domine affecte \xe0 la fois la probabilit\xe9 d'\xe9mergence des conflits et les types d'arguments qui s'appliquent - l'argument du d\xe9compte et les arguments de simplicit\xe9 d\xe9pendent fortement de la fa\xe7on dont ces conflits se forment initialement."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La s\xe9quence de d\xe9veloppement des capacit\xe9s est importante."})," L'orientation vers un but, la conscience situationnelle et les capacit\xe9s de raisonnement strat\xe9gique doivent toutes \xeatre pr\xe9sentes, mais leur s\xe9quence de d\xe9veloppement affecte dramatiquement les r\xe9sultats. Si les syst\xe8mes d\xe9veloppent une compr\xe9hension sophistiqu\xe9e des objectifs d'entra\xeenement avant de devenir fortement orient\xe9s vers un but, des objectifs probl\xe9matiques peuvent ne jamais se cristalliser. \xc0 l'inverse, si une forte orientation vers un but \xe9merge avant la compr\xe9hension de l'alignement, des objectifs d\xe9salign\xe9s peuvent s'enraciner et r\xe9sister aux tentatives de modification (",(0,i.jsx)(s.a,{href:"https://www.alignmentforum.org/s/pvoxjtCbkcweBLn7j/p/RTkatYxJWvXR4Qbyd",children:"DavidW, 2023"}),"). Cette question de timing est directement li\xe9e aux arguments bas\xe9s sur l'ordre concernant la probabilit\xe9."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La d\xe9pendance au chemin et la surcharge computationnelle sont importantes."})," La m\xe9sa-optimisation permet un raisonnement strat\xe9gique flexible mais n\xe9cessite des ressources computationnelles suppl\xe9mentaires pour la recherche et la planification internes. Les approches sophistiqu\xe9es de reconnaissance de motifs peuvent atteindre des r\xe9sultats strat\xe9giques similaires avec moins de surcharge mais moins d'adaptabilit\xe9 aux situations nouvelles (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/1906.01820",children:"Hubinger et al., 2019"}),"; ",(0,i.jsx)(s.a,{href:"https://www.alignmentforum.org/posts/J8ifgynkfhpmrGrL8/why-almost-every-rl-agent-does-learned-optimization",children:"Sharkey, 2023"}),"). Cette distinction d'impl\xe9mentation d\xe9termine si les arguments de co\xfbt-vitesse ou les arguments de probabilit\xe9 m\xe9caniste ont plus de poids."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les capacit\xe9s de d\xe9tection et de s\xe9lection de nos proc\xe9dures d'entra\xeenement sont importantes."})," La manipulation n\xe9cessite que la tromperie strat\xe9gique dissimule avec succ\xe8s les objectifs d\xe9salign\xe9s de la supervision de l'entra\xeenement. Cela d\xe9pend de si les co\xfbts computationnels du raisonnement strat\xe9gique cr\xe9ent des p\xe9nalit\xe9s de performance suffisantes pour conduire \xe0 une s\xe9lection contre les strat\xe9gies trompeuses, et si les processus d'entra\xeenement peuvent distinguer les algorithmes v\xe9ritablement align\xe9s de ceux strat\xe9giquement trompeurs. Les environnements d'entra\xeenement \xe0 haute pression peuvent \xe9liminer avec succ\xe8s les algorithmes trompeurs, tandis que l'\xe9valuation comportementale dans des environnements \xe0 plus faibles enjeux peut involontairement s\xe9lectionner les trompeurs efficaces (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2311.08379",children:"Carlsmith, 2023"}),"). Cela est directement li\xe9 aux arguments sur la puissance de s\xe9lection du ",(0,i.jsx)(t,{term:"stochastic gradient descent",definition:'{"definition":"Une variante de la descente de gradient qui met \xe0 jour les param\xe8tres \xe0 l\'aide de gradients calcul\xe9s sur de petits lots al\xe9atoires de donn\xe9es plut\xf4t que sur l\'ensemble des donn\xe9es..","source":"","aliases":["Stochastic Gradient Descent","SGD","Descente de Gradient Stochastique"]}',children:(0,i.jsx)(t,{term:"stochastic gradient descent",definition:'{"definition":"Une variante de la descente de gradient qui met \xe0 jour les param\xe8tres \xe0 l\'aide de gradients calcul\xe9s sur de petits lots al\xe9atoires de donn\xe9es plut\xf4t que sur l\'ensemble des donn\xe9es..","source":"","aliases":["Stochastic Gradient Descent","SGD","Descente de Gradient Stochastique"]}',children:"SGD"})})," et la conception de l'environnement d'entra\xeenement."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Ces points de d\xe9cision d\xe9terminent si les pr\xe9requis de la manipulation se combinent en un comportement r\xe9ellement trompeur."})," Chacun repr\xe9sente une incertitude cl\xe9 o\xf9 diff\xe9rentes r\xe9solutions conduisent \xe0 des probabilit\xe9s de manipulation radicalement diff\xe9rentes. Les sections suivantes examinent les arguments selon lesquels ces points de d\xe9cision se r\xe9soudront de mani\xe8re \xe0 favoriser ou d\xe9favoriser l'\xe9mergence de la manipulation."]}),"\n",(0,i.jsx)(s.h3,{id:"03-01",children:"Arguments en faveur de la manipulation"}),"\n",(0,i.jsx)(s.h4,{id:"03-01-01",children:"Arguments de d\xe9nombrement"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"L'espace des algorithmes possibles contient beaucoup plus de solutions de type manipulateur que de solutions v\xe9ritablement align\xe9es."})," R\xe9fl\xe9chissez-y intuitivement : il existe relativement peu de fa\xe7ons de se soucier v\xe9ritablement du bien-\xeatre humain dans toutes les situations possibles. Mais il existe d'innombrables fa\xe7ons de sembler se soucier du bien-\xeatre humain tout en optimisant en r\xe9alit\xe9 autre chose - maximiser les connaissances scientifiques, le pouvoir personnel, les trombones, ou tout autre objectif imaginable. Un syst\xe8me v\xe9ritablement utile doit apprendre des pr\xe9f\xe9rences complexes et contextuelles qui captent pr\xe9cis\xe9ment ce que les humains veulent r\xe9ellement dans diverses situations. En revanche, un manipulateur n'a besoin que d'un objectif coh\xe9rent au-del\xe0 de l'\xe9pisode plus un raisonnement strat\xe9gique sur quand r\xe9v\xe9ler ou dissimuler cet objectif (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2311.08379",children:"Carlsmith, 2023"}),")."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Pourquoi l'argument du d\xe9nombrement rend la manipulation plus probable :"})," L'entra\xeenement explore l'espace des algorithmes de mani\xe8re quelque peu al\xe9atoire, particuli\xe8rement au d\xe9but du processus. S'il y a beaucoup plus d'algorithmes trompeurs que d'algorithmes align\xe9s qui obtiennent des performances similaires, une recherche al\xe9atoire est plus susceptible de tomber sur des solutions trompeuses. C'est comme chercher une aiguille dans une botte de foin o\xf9 il y a mille fausses aiguilles pour chaque vraie. Cette asym\xe9trie s'applique \xe0 tout syst\xe8me orient\xe9 vers un but - les simulateurs, les m\xe9ta-optimiseurs, ou la reconnaissance sophistiqu\xe9e de motifs font tous face \xe0 la m\xeame asym\xe9trie fondamentale dans l'espace des solutions."]}),"\n",(0,i.jsx)(s.h4,{id:"03-01-02",children:"Arguments de simplicit\xe9"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les syst\xe8mes poursuivant des objectifs simples au-del\xe0 de l'\xe9pisode peuvent facilement ajouter une tromperie strat\xe9gique, tandis que les syst\xe8mes v\xe9ritablement align\xe9s n\xe9cessitent des structures d'objectifs complexes plus difficiles \xe0 apprendre et \xe0 maintenir."})," Un manipulateur peut avoir un objectif terminal extr\xeamement simple comme \"maximiser la d\xe9couverte scientifique \xe0 long terme\" et utiliser un raisonnement strat\xe9gique sophistiqu\xe9 pour poursuivre efficacement cet objectif. L'alignement v\xe9ritable n\xe9cessite d'apprendre une compr\xe9hension nuanc\xe9e de ce qui rend la recherche v\xe9ritablement pr\xe9cieuse plut\xf4t que simplement impressionnante, comment \xe9quilibrer diff\xe9rentes priorit\xe9s de recherche, quand \xeatre prudent ou ambitieux, et d'innombrables autres jugements complexes."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Pourquoi l'avantage de la simplicit\xe9 rend la manipulation plus probable :"})," Le biais de simplicit\xe9 que nous avons examin\xe9 dans les dynamiques d'apprentissage favorise syst\xe9matiquement les algorithmes qui n\xe9cessitent moins de param\xe8tres pour repr\xe9senter les objectifs et moins de complexit\xe9 computationnelle pour la prise de d\xe9cision. L'entra\xeenement d\xe9couvre et maintient pr\xe9f\xe9rentiellement des solutions plus simples. Puisque les objectifs de type manipulateur peuvent \xeatre beaucoup plus simples que les objectifs v\xe9ritablement align\xe9s, ce biais inductif penche le terrain vers la tromperie strat\xe9gique. Le syst\xe8me peut satisfaire la pr\xe9f\xe9rence de l'entra\xeenement pour la simplicit\xe9 tout en obtenant des performances \xe9lev\xe9es gr\xe2ce au raisonnement strat\xe9gique."]}),"\n",(0,i.jsx)(s.h4,{id:"03-01-03",children:"Arguments de pression s\xe9lective"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Pression d'entra\xeenement vers le raisonnement strat\xe9gique."})," Cela rend la manipulation plus r\xe9alisable une fois que la conscience situationnelle se d\xe9veloppe. Cela peut se produire par plusieurs voies :"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Par l'optimisation apprise :"})," L'entra\xeenement sur des t\xe2ches diverses et complexes cr\xe9e une pression pour les syst\xe8mes qui impl\xe9mentent des algorithmes internes de recherche et de planification. Ces syst\xe8mes apprennent \xe0 \xe9valuer diff\xe9rentes strat\xe9gies, maintenir des objectifs coh\xe9rents dans le temps, et adapter les plans en fonction des circonstances changeantes. Les m\xeames capacit\xe9s d'optimisation qui aident \xe0 concevoir des projets de recherche pluriannuels peuvent \xeatre r\xe9utilis\xe9es pour concevoir des strat\xe9gies de tromperie en plusieurs phases une fois que la conscience situationnelle se d\xe9veloppe (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/1906.01820",children:"Hubinger et al., 2019"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Par les capacit\xe9s de simulation :"})," Les mod\xe8les de langage entra\xeen\xe9s sur des textes divers apprennent \xe0 pr\xe9dire et simuler le raisonnement strat\xe9gique car la pens\xe9e strat\xe9gique appara\xeet dans leurs donn\xe9es d'entra\xeenement. Lorsqu'on leur demande d'agir strat\xe9giquement, ils peuvent appliquer des mod\xe8les appris de comportement strat\xe9gique sans impl\xe9menter d'optimisation interne explicite. Cette capacit\xe9 de simulation devient disponible pour des applications trompeuses lorsque le syst\xe8me reconna\xeet des situations strat\xe9giques."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Pourquoi la pression s\xe9lective pour le raisonnement strat\xe9gique rend la manipulation plus probable :"})," Les deux voies cr\xe9ent les pr\xe9requis computationnels pour la tromperie strat\xe9gique. Les syst\xe8mes d\xe9veloppent des capacit\xe9s sophistiqu\xe9es de planification et de raisonnement \xe0 des fins l\xe9gitimes, mais ces m\xeames capacit\xe9s permettent des strat\xe9gies trompeuses complexes. Le raisonnement strat\xe9gique est instrumentalement utile pour de nombreuses t\xe2ches, donc l'entra\xeenement le s\xe9lectionne naturellement - mais une fois pr\xe9sent, il peut \xeatre redirig\xe9 vers des objectifs trompeurs."]}),"\n",(0,i.jsx)(s.h3,{id:"03-02",children:"Arguments contre la manipulation"}),"\n",(0,i.jsx)(s.h4,{id:"03-02-01",children:"S\xe9quences de capacit\xe9s improbables"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les s\xe9quences de capacit\xe9s dangereuses sont improbables."})," L'ordre dans lequel les capacit\xe9s cl\xe9s se d\xe9veloppent pendant l'entra\xeenement affecte consid\xe9rablement la possibilit\xe9 d'\xe9mergence de la manipulation, et les s\xe9quences dangereuses semblent improbables dans le d\xe9veloppement prosa\xefque de l'IA. Pour que la manipulation \xe9merge, les syst\xe8mes ont besoin d'une orientation vers des objectifs, d'une conscience situationnelle et de capacit\xe9s de raisonnement strat\xe9gique. Mais si les syst\xe8mes d\xe9veloppent une compr\xe9hension profonde des objectifs d'entra\xeenement avant de devenir fortement orient\xe9s vers des objectifs, des buts probl\xe9matiques pourraient ne jamais se cristalliser. Le pr\xe9-entra\xeenement sur des textes vari\xe9s enseigne aux syst\xe8mes les valeurs humaines, les intentions et les concepts d'alignement bien avant qu'ils ne deviennent fortement orient\xe9s vers des objectifs gr\xe2ce \xe0 des techniques comme le RLHF. Un syst\xe8me qui comprend parfaitement \"\xeatre utile, inoffensif et honn\xeate\" avant de d\xe9velopper des objectifs au-del\xe0 des \xe9pisodes est beaucoup plus susceptible d'internaliser ces objectifs comme pr\xe9f\xe9rences authentiques plut\xf4t que comme contraintes externes \xe0 naviguer strat\xe9giquement."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Pourquoi cela rend la manipulation moins probable :"})," Le pr\xe9-entra\xeenement non supervis\xe9 d\xe9veloppe une compr\xe9hension conceptuelle sans forte orientation vers des objectifs. L'ajustement fin ult\xe9rieur se produit dans des contextes o\xf9 les syst\xe8mes comprennent d\xe9j\xe0 les objectifs d'alignement, rendant l'internalisation authentique plus probable que la tromperie strat\xe9gique. Si les syst\xe8mes comprennent ce que les humains veulent r\xe9ellement avant de cristalliser des objectifs au-del\xe0 des \xe9pisodes, la base des conflits d'objectifs d'entra\xeenement ne se forme jamais (",(0,i.jsx)(s.a,{href:"https://www.alignmentforum.org/s/pvoxjtCbkcweBLn7j/p/RTkatYxJWvXR4Qbyd",children:"DavidW, 2023"}),")."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsxs)(s.strong,{children:["La nature incr\xe9mentale du ",(0,i.jsx)(t,{term:"stochastic gradient descent",definition:'{"definition":"Une variante de la descente de gradient qui met \xe0 jour les param\xe8tres \xe0 l\'aide de gradients calcul\xe9s sur de petits lots al\xe9atoires de donn\xe9es plut\xf4t que sur l\'ensemble des donn\xe9es..","source":"","aliases":["Stochastic Gradient Descent","SGD","Descente de Gradient Stochastique"]}',children:(0,i.jsx)(t,{term:"stochastic gradient descent",definition:'{"definition":"Une variante de la descente de gradient qui met \xe0 jour les param\xe8tres \xe0 l\'aide de gradients calcul\xe9s sur de petits lots al\xe9atoires de donn\xe9es plut\xf4t que sur l\'ensemble des donn\xe9es..","source":"","aliases":["Stochastic Gradient Descent","SGD","Descente de Gradient Stochastique"]}',children:"SGD"})})," cr\xe9e des barri\xe8res \xe0 la manipulation strat\xe9gique."]})," La descente de gradient modifie les r\xe9seaux neuronaux par de petits changements de param\xe8tres incr\xe9mentaux, rendant difficile la d\xe9couverte de strat\xe9gies de tromperie complexes qui n\xe9cessitent des modifications coordonn\xe9es entre de nombreux composants. La tromperie strat\xe9gique implique un raisonnement sophistiqu\xe9 sur la dynamique d'entra\xeenement, le maintien coh\xe9rent d'un personnage et une planification strat\xe9gique coordonn\xe9e. Ces capacit\xe9s n\xe9cessitent probablement une coordination pr\xe9cise entre de nombreux composants du r\xe9seau - syst\xe8mes de mod\xe9lisation du monde, de raisonnement strat\xe9gique, de repr\xe9sentation des objectifs et de g\xe9n\xe9ration de sortie. Pour que l'alignement trompeur \xe9merge, le ",(0,i.jsx)(t,{term:"stochastic gradient descent",definition:'{"definition":"Une variante de la descente de gradient qui met \xe0 jour les param\xe8tres \xe0 l\'aide de gradients calcul\xe9s sur de petits lots al\xe9atoires de donn\xe9es plut\xf4t que sur l\'ensemble des donn\xe9es..","source":"","aliases":["Stochastic Gradient Descent","SGD","Descente de Gradient Stochastique"]}',children:(0,i.jsx)(t,{term:"stochastic gradient descent",definition:'{"definition":"Une variante de la descente de gradient qui met \xe0 jour les param\xe8tres \xe0 l\'aide de gradients calcul\xe9s sur de petits lots al\xe9atoires de donn\xe9es plut\xf4t que sur l\'ensemble des donn\xe9es..","source":"","aliases":["Stochastic Gradient Descent","SGD","Descente de Gradient Stochastique"]}',children:"SGD"})})," doit d'une mani\xe8re ou d'une autre coordonner simultan\xe9ment les modifications \xe0 travers tous ces composants, cr\xe9ant un agent strat\xe9gique coh\xe9rent capable de tromper avec succ\xe8s une surveillance sophistiqu\xe9e. Mais la descente de gradient fonctionne par optimisation locale, apportant de petites am\xe9liorations bas\xe9es sur des signaux de retour imm\xe9diats. Elle a du mal \xe0 faire les types de changements importants et coordonn\xe9s qui pourraient \xeatre n\xe9cessaires pour mettre en \u0153uvre des strat\xe9gies de tromperie sophistiqu\xe9es."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Pourquoi cela rend la manipulation moins probable :"})," La nature incr\xe9mentale du ",(0,i.jsx)(t,{term:"stochastic gradient descent",definition:'{"definition":"Une variante de la descente de gradient qui met \xe0 jour les param\xe8tres \xe0 l\'aide de gradients calcul\xe9s sur de petits lots al\xe9atoires de donn\xe9es plut\xf4t que sur l\'ensemble des donn\xe9es..","source":"","aliases":["Stochastic Gradient Descent","SGD","Descente de Gradient Stochastique"]}',children:(0,i.jsx)(t,{term:"stochastic gradient descent",definition:'{"definition":"Une variante de la descente de gradient qui met \xe0 jour les param\xe8tres \xe0 l\'aide de gradients calcul\xe9s sur de petits lots al\xe9atoires de donn\xe9es plut\xf4t que sur l\'ensemble des donn\xe9es..","source":"","aliases":["Stochastic Gradient Descent","SGD","Descente de Gradient Stochastique"]}',children:"SGD"})})," cr\xe9e un probl\xe8me de d\xe9couvrabilit\xe9 pour les strat\xe9gies de tromperie complexes. Bien que les arguments de comptage sugg\xe8rent qu'il existe de nombreux algorithmes de type manipulateur possibles, la plupart d'entre eux peuvent \xeatre inaccessibles \xe0 partir des points de d\xe9part typiques par des modifications graduelles des param\xe8tres. Le ",(0,i.jsx)(t,{term:"stochastic gradient descent",definition:'{"definition":"Une variante de la descente de gradient qui met \xe0 jour les param\xe8tres \xe0 l\'aide de gradients calcul\xe9s sur de petits lots al\xe9atoires de donn\xe9es plut\xf4t que sur l\'ensemble des donn\xe9es..","source":"","aliases":["Stochastic Gradient Descent","SGD","Descente de Gradient Stochastique"]}',children:(0,i.jsx)(t,{term:"stochastic gradient descent",definition:'{"definition":"Une variante de la descente de gradient qui met \xe0 jour les param\xe8tres \xe0 l\'aide de gradients calcul\xe9s sur de petits lots al\xe9atoires de donn\xe9es plut\xf4t que sur l\'ensemble des donn\xe9es..","source":"","aliases":["Stochastic Gradient Descent","SGD","Descente de Gradient Stochastique"]}',children:"SGD"})})," pourrait uniquement \xeatre capable de trouver des mod\xe8les de tromperie relativement simples, qui sont plus facilement d\xe9tect\xe9s et corrig\xe9s pendant l'entra\xeenement. La tromperie strat\xe9gique complexe peut n\xe9cessiter le type de changements coordonn\xe9s que la descente de gradient ne peut pas d\xe9couvrir de mani\xe8re fiable."]}),"\n",(0,i.jsx)(s.h4,{id:"03-02-02",children:"Arguments sur le co\xfbt computationnel (vitesse)"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Le raisonnement strat\xe9gique est co\xfbteux en calcul."}),' Les syst\xe8mes qui s\'engagent dans la tromperie strat\xe9gique doivent allouer des ressources cognitives \xe0 la planification, au maintien de la coh\xe9rence et \xe0 la gestion de la tromperie qui pourraient autrement servir \xe0 la performance des t\xe2ches. Un manipulateur doit continuellement \xe9valuer si les situations actuelles n\xe9cessitent une poursuite honn\xeate des objectifs ou une dissimulation strat\xe9gique, maintenir des personnages trompeurs coh\xe9rents \xe0 travers les interactions, et investir du raisonnement dans des activit\xe9s comme "le sabotage pr\xe9coce" qui ne fournissent aucun b\xe9n\xe9fice imm\xe9diat pour la t\xe2che.']}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Pourquoi cela rend la manipulation moins probable :"})," L'entra\xeenement fonctionne sous des contraintes computationnelles et une pression de performance. Les syst\xe8mes qui allouent efficacement les ressources cognitives ont des avantages syst\xe9matiques par rapport aux syst\xe8mes qui \"gaspillent\" du calcul en frais g\xe9n\xe9raux strat\xe9giques. Si ces co\xfbts d'efficacit\xe9 sont d\xe9tectables pendant l'entra\xeenement, la descente de gradient favorisera les syst\xe8mes v\xe9ritablement align\xe9s qui obtiennent une meilleure performance par unit\xe9 de calcul. Le d\xe9savantage de vitesse peut \xeatre particuli\xe8rement prononc\xe9 pour les syst\xe8mes s'engageant dans une planification strat\xe9gique sophistiqu\xe9e ou des activit\xe9s de sabotage pr\xe9coce (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2311.08379",children:"Carlsmith, 2023"}),")."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La motivation intrins\xe8que offre des avantages de performance."})," C'est aussi appel\xe9 l'argument \"pas-votre-passion\". Les syst\xe8mes avec une motivation intrins\xe8que authentique pour leurs t\xe2ches assign\xe9es surpassent syst\xe9matiquement les syst\xe8mes poursuivant ces t\xe2ches pour des raisons purement instrumentales. Cet avantage \xe9merge car la motivation authentique cr\xe9e des repr\xe9sentations riches et sp\xe9cifiques \xe0 la t\xe2che qui brouillent la ligne entre les capacit\xe9s et les valeurs. Un syst\xe8me qui se soucie vraiment de la d\xe9couverte scientifique d\xe9veloppe des intuitions profondes sur ce qui rend la recherche pr\xe9cieuse, des pr\xe9f\xe9rences esth\xe9tiques pour les explications \xe9l\xe9gantes et des connaissances heuristiques sur les directions de recherche prometteuses. En revanche, un syst\xe8me poursuivant la d\xe9couverte scientifique de mani\xe8re instrumentale (peut-\xeatre pour maximiser la production de trombones \xe0 long terme) traite la recherche comme un simple moyen d'atteindre une fin. Il peut apprendre \xe0 produire des citations et des publications sans d\xe9velopper les repr\xe9sentations plus profondes qui permettent des perc\xe9es. L'approche instrumentale peut r\xe9ussir dans des sc\xe9narios d'\xe9valuation structur\xe9s mais a du mal avec la cr\xe9ativit\xe9 ouverte qui d\xe9finit l'excellence en recherche."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Pourquoi cela rend la manipulation moins probable :"})," L'entra\xeenement r\xe9compense les syst\xe8mes qui effectuent les t\xe2ches le plus efficacement. Si la motivation intrins\xe8que fournit des avantages de performance syst\xe9matiques gr\xe2ce \xe0 des repr\xe9sentations de t\xe2ches plus riches et une allocation des ressources plus efficace, alors l'entra\xeenement favorisera les syst\xe8mes v\xe9ritablement align\xe9s. Cet argument \"pas-votre-passion\" sugg\xe8re que la tromperie strat\xe9gique comporte des co\xfbts de performance inh\xe9rents qui s'accumulent au cours d'interactions prolong\xe9es avec des t\xe2ches complexes et ouvertes (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2311.08379",children:"Carlsmith, 2023"}),")."]}),"\n",(0,i.jsx)(s.h4,{id:"03-02-03",children:"Arguments contre le comptage"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La pression de s\xe9lection peut surmonter l'argument du comptage."})," M\xeame s'il y a num\xe9riquement plus d'algorithmes de type manipulateur que d'algorithmes align\xe9s, la pression de s\xe9lection active du ",(0,i.jsx)(t,{term:"stochastic gradient descent",definition:'{"definition":"Une variante de la descente de gradient qui met \xe0 jour les param\xe8tres \xe0 l\'aide de gradients calcul\xe9s sur de petits lots al\xe9atoires de donn\xe9es plut\xf4t que sur l\'ensemble des donn\xe9es..","source":"","aliases":["Stochastic Gradient Descent","SGD","Descente de Gradient Stochastique"]}',children:(0,i.jsx)(t,{term:"stochastic gradient descent",definition:'{"definition":"Une variante de la descente de gradient qui met \xe0 jour les param\xe8tres \xe0 l\'aide de gradients calcul\xe9s sur de petits lots al\xe9atoires de donn\xe9es plut\xf4t que sur l\'ensemble des donn\xe9es..","source":"","aliases":["Stochastic Gradient Descent","SGD","Descente de Gradient Stochastique"]}',children:"SGD"})})," peut facilement surmonter ces d\xe9savantages de comptage lorsqu'elle favorise syst\xe9matiquement certains types de solutions. Bien qu'il puisse y avoir plus de fa\xe7ons de simuler l'alignement que de l'atteindre v\xe9ritablement, l'entra\xeenement fournit de forts signaux de s\xe9lection qui peuvent surmonter ces a priori. Si l'entra\xeenement fournit des preuves syst\xe9matiques contre la manipulation \xe0 travers les co\xfbts de performance, les m\xe9canismes de surveillance ou d'autres pressions de s\xe9lection, cela peut surmonter tout avantage num\xe9rique que les manipulateurs pourraient avoir dans l'espace des algorithmes."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Pourquoi cela rend la manipulation moins probable :"})," Le pouvoir de s\xe9lection de l'entra\xeenement est \xe9norme - il peut facilement surmonter 100 bits de d\xe9savantage de comptage gr\xe2ce \xe0 des pr\xe9f\xe9rences relativement modestes contre la manipulation. Si les co\xfbts de vitesse, les avantages de la motivation intrins\xe8que ou d'autres facteurs cr\xe9ent m\xeame de petits biais syst\xe9matiques contre les strat\xe9gies trompeuses, ces biais peuvent se composer sur des millions de mises \xe0 jour de gradient pour favoriser fortement l'alignement authentique. La question devient de savoir si l'entra\xeenement a des raisons syst\xe9matiques de d\xe9favoriser la manipulation, et non s'il y a plus de configurations possibles de manipulateurs (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2311.08379",children:"Carlsmith, 2023"}),")."]}),"\n",(0,i.jsx)(s.h4,{id:"03-02-04",children:"Arguments sur le rel\xe2chement de l'entra\xeenement"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Le rel\xe2chement de l'environnement d'entra\xeenement peut rendre les diff\xe9rences subtiles non pertinentes."})," De nombreux arguments pour et contre la manipulation reposent sur des diff\xe9rences de performance potentiellement petites qui pourraient facilement \xeatre submerg\xe9es par d'autres facteurs dans des environnements d'entra\xeenement r\xe9alistes. Consid\xe9rez les frais g\xe9n\xe9raux computationnels du raisonnement strat\xe9gique, les avantages d'efficacit\xe9 de la motivation intrins\xe8que, ou les b\xe9n\xe9fices de simplicit\xe9 des objectifs de type manipulateur. Ces facteurs peuvent cr\xe9er des diff\xe9rences r\xe9elles mais modestes dans la performance du syst\xe8me qui sont difficiles \xe0 d\xe9tecter au-dessus du niveau de bruit des processus d'entra\xeenement typiques. Les environnements d'entra\xeenement r\xe9els impliquent d'innombrables sources de variation : effets d'initialisation al\xe9atoire, ordre des donn\xe9es, choix architecturaux, param\xe8tres d'hyperparam\xe8tres et bruit de mesure. Si les diff\xe9rences de performance entre les syst\xe8mes align\xe9s et trompeurs sont petites par rapport \xe0 ces autres facteurs, alors l'entra\xeenement peut effectivement faire des choix al\xe9atoires entre eux plut\xf4t que de s\xe9lectionner syst\xe9matiquement en fonction des propri\xe9t\xe9s d'alignement."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Pourquoi cela rend la manipulation moins probable :"})," Si les environnements d'entra\xeenement ont suffisamment de \"rel\xe2chement\" et n'optimisent pas assez intensivement pour d\xe9tecter des diff\xe9rences de performance modestes, alors les arguments bas\xe9s sur des avantages ou des d\xe9savantages subtils peuvent ne pas influencer les r\xe9sultats. Cela sugg\xe8re que la probabilit\xe9 de manipulation d\xe9pend fortement de la pression d'optimisation que l'entra\xeenement applique r\xe9ellement. Les environnements d'entra\xeenement \xe0 haute pression pourraient r\xe9ussir \xe0 s\xe9lectionner contre la manipulation bas\xe9e sur les co\xfbts de vitesse, tandis que les environnements \xe0 basse pression pourraient faire des choix essentiellement al\xe9atoires ind\xe9pendamment des arguments de comptage ou des consid\xe9rations de simplicit\xe9 (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2311.08379",children:"Carlsmith, 2023"}),")."]}),"\n",(0,i.jsx)(o.c,{title:"Notes de bas de page"})]})}function h(e={}){const{wrapper:s}={...(0,r.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(g,{...e})}):g(e)}},4768:(e,s,t)=>{t.d(s,{c:()=>u,A:()=>d});var n=t(6540),i=t(3012);const r={footnoteAnchor:"footnoteAnchor_PZpY",footnoteSection:"footnoteSection_waoz",separator:"separator_hp8y",separatorLine:"separatorLine_uVnd",separatorLogo:"separatorLogo_dMBq",footnoteRegistry:"footnoteRegistry_ieVW",registryTitle:"registryTitle_ybBb",footnoteList:"footnoteList_Kjil",footnoteItem:"footnoteItem_aLZ2",footnoteNumber:"footnoteNumber_dA3X",footnoteContent:"footnoteContent_Xfmt",backButton:"backButton_vSVm",highlighted:"highlighted_YFU0",highlight:"highlight_jxG3",highlightDark:"highlightDark_Ekom"};var a=t(4848);function o(e,s){void 0===s&&(s=!0);const t=document.getElementById(e);t&&(t.scrollIntoView({behavior:"smooth"}),s&&(t.classList.add(r.highlighted),setTimeout((()=>t.classList.remove(r.highlighted)),1500)))}function l(e){return e?e.replace(/\[([^\]]+)\]\(([^)]+)\)/g,'<a href="$2" target="_blank" rel="noopener noreferrer">$1</a>'):""}function d(e){let{id:s,text:t,number:d}=e;const u=s||`footnote-${Math.random().toString(36).substr(2,9)}`,c="string"==typeof t?l(t):t;return(0,n.useEffect)((()=>{const e=setTimeout((()=>{const e=document.getElementById(`footnote-clone-${u}`);e&&t&&(e.innerHTML="string"==typeof t?l(t):t.toString())}),100);return()=>clearTimeout(e)}),[u,t]),(0,a.jsx)(i.Mn,{content:(0,a.jsx)("div",{dangerouslySetInnerHTML:{__html:c}}),children:(0,a.jsx)("sup",{id:`footnote-ref-${u}`,className:r.footnoteAnchor,onClick:e=>{(e.ctrlKey||e.metaKey)&&(e.preventDefault(),o(`footnote-content-${u}`))},"data-footnote-number":d||"?",children:d||"*"})})}function u(e){let{title:s="References"}=e;const[t,l]=(0,n.useState)([]);return(0,n.useEffect)((()=>{const e=document.querySelectorAll('[id^="footnote-ref-"]'),s=Array.from(e).map((e=>({id:e.id.replace("footnote-ref-",""),number:e.getAttribute("data-footnote-number")||e.textContent})));l(s)}),[]),t.length?(0,a.jsxs)("div",{className:r.footnoteSection,children:[(0,a.jsxs)("div",{className:r.separator,children:[(0,a.jsx)("div",{className:r.separatorLine}),(0,a.jsx)("img",{src:"/img/logo_samples/01-test.svg",alt:"Atlas logo",className:r.separatorLogo}),(0,a.jsx)("div",{className:r.separatorLine})]}),(0,a.jsxs)("div",{className:r.footnoteRegistry,children:[(0,a.jsx)("h2",{className:r.registryTitle,children:s}),(0,a.jsx)("ol",{className:r.footnoteList,children:t.map((e=>(0,a.jsxs)("li",{id:`footnote-content-${e.id}`,className:r.footnoteItem,value:parseInt(e.number)||void 0,children:[(0,a.jsx)(i.Mn,{content:"Back to reference",children:(0,a.jsxs)("button",{className:r.footnoteNumber,onClick:()=>o(`footnote-ref-${e.id}`),"aria-label":"Back to reference",children:[e.number,"."]})}),(0,a.jsx)("div",{className:r.footnoteContent,children:(0,a.jsx)("div",{id:`footnote-clone-${e.id}`})}),(0,a.jsx)(i.Mn,{content:"Back to reference",children:(0,a.jsx)("button",{className:r.backButton,onClick:()=>o(`footnote-ref-${e.id}`),"aria-label":"Back to reference",children:"\u21a9"})})]},e.id)))})]})]}):null}},3931:(e,s,t)=>{t.d(s,{A:()=>l});var n=t(6540),i=t(6347),r=t(8444);const a={videoFigure:"videoFigure_dV9u",fullWidth:"fullWidth_Tv7O",videoContainer:"videoContainer_LWoK",aspectRatio169:"aspectRatio169_Go8b",aspectRatio43:"aspectRatio43_b3T7",aspectRatio11:"aspectRatio11_n21J",aspectRatio219:"aspectRatio219_L_3n",videoIframe:"videoIframe_QEc5",videoElement:"videoElement_uu7N",customPlayer:"customPlayer_jiC4",customPlayerPlaceholder:"customPlayerPlaceholder_aL9q",loadingOverlay:"loadingOverlay_e2pu",spinner:"spinner_tFyL",spin:"spin_saPs",errorContainer:"errorContainer_J6Pn",errorIcon:"errorIcon_cGdn",fallbackLink:"fallbackLink_WsZk"};var o=t(4848);function l(e){let{type:s="youtube",videoId:t,caption:l,title:d,startTime:u,autoplay:c=!1,controls:m=!0,aspectRatio:p="16:9",width:f,height:g,chapter:h,number:v,label:b,useCustomPlayer:q=!1,fullWidth:x=!0}=e;const[j,y]=(0,n.useState)(!0),[L,C]=(0,n.useState)(!1),S=(0,i.zy)(),_=h||(()=>{const e=S.pathname.match(/\/chapters\/(\d+)/);return e?parseInt(e[1]):null})(),D=(()=>{const e=(e=>{if(!e)return"";if("number"==typeof e)return e.toString();if("string"==typeof e){if(/^\d+$/.test(e))return e;let s=0;const t=e.match(/(\d+)h/),n=e.match(/(\d+)m/),i=e.match(/(\d+)s/);return t&&(s+=3600*parseInt(t[1])),n&&(s+=60*parseInt(n[1])),i&&(s+=parseInt(i[1])),s>0?s.toString():""}return""})(u);switch(s.toLowerCase()){case"youtube":let n=`https://www.youtube.com/embed/${t}`;const i=new URLSearchParams;e&&i.append("start",e),c&&i.append("autoplay","1"),m||q||i.append("controls","0"),i.append("rel","0"),i.append("modestbranding","1"),i.append("fs","1"),i.append("cc_load_policy","0"),i.append("iv_load_policy","3"),i.append("showinfo","0"),i.append("disablekb","1"),i.append("playsinline","1"),i.append("color","white"),i.append("theme","light"),q&&(i.append("enablejsapi","1"),i.append("origin",window.location.origin));const r=i.toString();return r?`${n}?${r}`:n;case"vimeo":let a=`https://player.vimeo.com/video/${t}`;const o=new URLSearchParams;c&&o.append("autoplay","1"),m||q||o.append("controls","0"),o.append("title","0"),o.append("byline","0"),o.append("portrait","0"),o.append("dnt","1"),o.append("transparent","0"),o.append("background","1");const l=o.toString();return l?`${a}?${l}`:a;case"mp4":case"webm":case"video":return t;default:return console.warn(`Unsupported video type: ${s}`),t}})(),w=()=>{y(!1)},G=()=>{C(!0),y(!1)},A=e=>{let{src:t,onLoad:n,onError:i}=e;return(0,o.jsx)("div",{className:a.customPlayer,children:(0,o.jsxs)("div",{className:a.customPlayerPlaceholder,children:[(0,o.jsx)("h3",{children:"Atlas Custom Player"}),(0,o.jsx)("p",{children:"Coming Soon"}),(0,o.jsxs)("a",{href:t,target:"_blank",rel:"noopener noreferrer",className:a.fallbackLink,children:["Watch on ",s.charAt(0).toUpperCase()+s.slice(1)]})]})})},k=["mp4","webm","video"].includes(s.toLowerCase());return(0,o.jsxs)("figure",{className:`${a.videoFigure} ${x?a.fullWidth:""}`,children:[(0,o.jsxs)("div",{className:`${a.videoContainer} ${(()=>{switch(p){case"4:3":return a.aspectRatio43;case"1:1":return a.aspectRatio11;case"21:9":return a.aspectRatio219;default:return a.aspectRatio169}})()}`,style:{width:x?"100%":f||"auto",maxWidth:x?"none":"800px"},children:[j&&!L&&(0,o.jsxs)("div",{className:a.loadingOverlay,children:[(0,o.jsx)("div",{className:a.spinner}),(0,o.jsx)("p",{children:"Loading video..."})]}),L&&(0,o.jsxs)("div",{className:a.errorContainer,children:[(0,o.jsxs)("svg",{className:a.errorIcon,width:"48",height:"48",viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:"2",children:[(0,o.jsx)("circle",{cx:"12",cy:"12",r:"10"}),(0,o.jsx)("line",{x1:"12",y1:"8",x2:"12",y2:"12"}),(0,o.jsx)("line",{x1:"12",y1:"16",x2:"12.01",y2:"16"})]}),(0,o.jsx)("h4",{children:"Failed to load video"}),(0,o.jsxs)("p",{children:["Video type: ",s]}),(0,o.jsxs)("p",{children:["Video ID/URL: ",t]}),(0,o.jsx)("a",{href:D,target:"_blank",rel:"noopener noreferrer",className:a.fallbackLink,children:"Try opening video directly"})]}),!L&&(k?(0,o.jsxs)("video",{className:a.videoElement,controls:m,autoPlay:c,onLoadedData:w,onError:G,title:d||l||`${s} video`,style:{width:f||"100%",height:g||"auto",display:j?"none":"block"},children:[(0,o.jsx)("source",{src:D,type:`video/${s}`}),(0,o.jsxs)("p",{children:["Your browser doesn't support video playback.",(0,o.jsx)("a",{href:D,target:"_blank",rel:"noopener noreferrer",children:"Download the video file"})]})]}):q?(0,o.jsx)(A,{src:D,onLoad:w,onError:G}):(0,o.jsx)("iframe",{className:a.videoIframe,src:D,title:d||l||`${s} video`,frameBorder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",allowFullScreen:!0,onLoad:w,onError:G,style:{width:f||"100%",height:g||"100%",opacity:j?0:1}}))]}),(0,o.jsx)(r.A,{caption:l,mediaType:"video",chapter:_,number:v,label:b})]})}}}]);