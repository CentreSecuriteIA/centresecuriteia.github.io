"use strict";(self.webpackChunkatlas=self.webpackChunkatlas||[]).push([[6289],{2027:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>h,contentTitle:()=>p,default:()=>v,frontMatter:()=>m,metadata:()=>t,toc:()=>g});const t=JSON.parse('{"id":"chapters/05/1","title":"R\xe9f\xe9rences","description":"Qu\'est-ce qu\'une \xe9valuation comparative ? Imaginez essayer de construire un pont sans m\xe8tre ruban. Avant les unit\xe9s standardis\xe9es comme les m\xe8tres et les grammes, diff\xe9rentes r\xe9gions utilisaient leurs propres mesures locales. Au-del\xe0 de rendre l\'ing\xe9nierie inefficace - cela la rendait aussi dangereuse. M\xeame si un pays d\xe9veloppait une conception de pont s\xfbre, sp\xe9cifier les mesures en \\"trois coud\xe9es royales\\" de mat\xe9riau signifiait que les constructeurs d\'autres pays ne pouvaient pas reproduire cette s\xe9curit\xe9 de mani\xe8re fiable. Une poutre de soutien l\xe9g\xe8rement trop courte ou un c\xe2ble trop fin pouvait conduire \xe0 une d\xe9faillance catastrophique.","source":"@site/i18n/fr/docusaurus-plugin-content-docs/current/chapters/05/01.md","sourceDirName":"chapters/05","slug":"/chapters/05/01","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/05/01","draft":false,"unlisted":false,"editUrl":"https://github.com/markov-root/atlas/edit/main/docs/chapters/05/01.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"1","title":"R\xe9f\xe9rences","sidebar_label":"5.1 R\xe9f\xe9rences","sidebar_position":2,"slug":"/chapters/05/01","section_description":"Benchmarks are the first step in our evaluation process.","reading_time_core":"11 min","reading_time_optional":"7 min","pagination_prev":"chapters/05/index","pagination_next":"chapters/05/2"},"sidebar":"docs","previous":{"title":"\xc9valuations","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/05/"},"next":{"title":"5.2 Propri\xe9t\xe9s \xe9valu\xe9es","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/05/02"}}');var a=n(4848),i=n(8453),r=n(3989),o=n(4768),l=n(2482),u=n(8559),d=n(9585),c=n(2501);const m={id:1,title:"R\xe9f\xe9rences",sidebar_label:"5.1 R\xe9f\xe9rences",sidebar_position:2,slug:"/chapters/05/01",section_description:"Benchmarks are the first step in our evaluation process.",reading_time_core:"11 min",reading_time_optional:"7 min",pagination_prev:"chapters/05/index",pagination_next:"chapters/05/2"},p="\xc9valuations comparatives",h={},g=[{value:"Histoire et \xc9volution",id:"01",level:2},{value:"Limites de l&#39;\xe9valuation comparative",id:"02",level:2}];function f(e){const s={a:"a",em:"em",h1:"h1",h2:"h2",header:"header",p:"p",strong:"strong",...(0,i.R)(),...e.components},{GlossaryTerm:n}=s;return n||function(e,s){throw new Error("Expected "+(s?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("GlossaryTerm",!0),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(s.header,{children:(0,a.jsx)(s.h1,{id:"\xe9valuations-comparatives",children:"\xc9valuations comparatives"})}),"\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Qu'est-ce qu'une \xe9valuation comparative ?"})," Imaginez essayer de construire un pont sans m\xe8tre ruban. Avant les unit\xe9s standardis\xe9es comme les m\xe8tres et les grammes, diff\xe9rentes r\xe9gions utilisaient leurs propres mesures locales. Au-del\xe0 de rendre l'ing\xe9nierie inefficace - cela la rendait aussi dangereuse. M\xeame si un pays d\xe9veloppait une conception de pont s\xfbre, sp\xe9cifier les mesures en \"trois coud\xe9es royales\" de mat\xe9riau signifiait que les constructeurs d'autres pays ne pouvaient pas reproduire cette s\xe9curit\xe9 de mani\xe8re fiable. Une poutre de soutien l\xe9g\xe8rement trop courte ou un c\xe2ble trop fin pouvait conduire \xe0 une d\xe9faillance catastrophique."]}),"\n",(0,a.jsxs)(s.p,{children:["L'IA avait essentiellement un probl\xe8me similaire avant que nous commencions \xe0 utiliser des \xe9valuations comparatives standardis\xe9es.",(0,a.jsx)(o.A,{id:"footnote_1",number:"1",text:"C'est vrai dans une large mesure, mais comme toujours, il n'y a pas de standardisation \xe0 100%. Nous pouvons faire des comparaisons significatives, mais il faut faire preuve de prudence avant de leur faire enti\xe8rement confiance sans disposer de beaucoup plus de d\xe9tails."})," Une \xe9valuation comparative est un outil comme un test standardis\xe9, que nous pouvons utiliser pour mesurer et comparer ce que les syst\xe8mes d'IA peuvent et ne peuvent pas faire. Historiquement, ils ont principalement \xe9t\xe9 utilis\xe9s pour mesurer les capacit\xe9s, mais nous les voyons aussi se d\xe9velopper pour la S\xe9curit\xe9 et l'\xc9thique de l'IA ces derni\xe8res ann\xe9es."]}),"\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Comment les \xe9valuations comparatives fa\xe7onnent-elles le d\xe9veloppement de l'IA et la recherche sur la s\xe9curit\xe9 ?"}),' Les \xe9valuations comparatives en IA sont l\xe9g\xe8rement diff\xe9rentes des autres domaines scientifiques. Ce sont des outils en \xe9volution qui mesurent, mais fa\xe7onnent aussi activement l\'orientation de la recherche et du d\xe9veloppement. Lorsque nous cr\xe9ons une \xe9valuation comparative, nous disons essentiellement - "voici ce que nous pensons important de mesurer." Si nous pouvons guider la mesure, alors dans une certaine mesure, nous pouvons aussi guider le d\xe9veloppement.']}),"\n",(0,a.jsx)(l.A,{speaker:"David Patterson",position:"Professeur \xe9m\xe9rite de l'UC Berkeley, Ing\xe9nieur logiciel distingu\xe9 chez Google",date:"",source:"([Ren et al., 2024](https://arxiv.org/abs/2407.21792))",children:(0,a.jsx)(s.p,{children:"Pour le meilleur ou pour le pire, les \xe9valuations comparatives fa\xe7onnent un domaine."})}),"\n",(0,a.jsx)(s.h2,{id:"01",children:"Histoire et \xc9volution"}),"\n",(0,a.jsx)(r.A,{src:"https://ourworldindata.org/grapher/test-scores-ai-capabilities-relative-human-performance?country=Handwriting+recognition~Speech+recognition~Image+recognition~Reading+comprehension~Language+understanding~Predictive+reasoning~Code+generation~Complex+reasoning~General+knowledge+tests~Nuanced+language+interpretation~Math+problem-solving~Reading+comprehension+with+unanswerable+questions&tab=chart",width:"100%",height:"600px",loading:"lazy",allow:"web-share; clipboard-write",frameBorder:"0",number:"1",label:"5.1",caption:"Scores de r\xe9f\xe9rence de diverses capacit\xe9s d'IA par rapport aux performances humaines ([Giattino et al., 2023](https://ourworldindata.org/artificial-intelligence))."}),"\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Exemple : Les benchmarks influen\xe7ant la standardisation en vision par ordinateur."})," Comme exemple concret de la fa\xe7on dont les benchmarks influencent le d\xe9veloppement de l'IA, nous pouvons examiner l'histoire des benchmarks en vision par ordinateur. En 1998, des chercheurs ont introduit MNIST, un ensemble de donn\xe9es de 70 000 chiffres manuscrits (",(0,a.jsx)(s.a,{href:"https://yann.lecun.com/exdb/mnist/",children:"LeCun, 1998"}),"). Les chiffres n'\xe9taient pas l'\xe9l\xe9ment important, l'important \xe9tait que chaque image de chiffre \xe9tait soigneusement trait\xe9e pour \xeatre de la m\xeame taille et centr\xe9e dans le cadre, et que les chercheurs se sont assur\xe9s d'obtenir des chiffres de diff\xe9rents scripteurs pour l'ensemble d'entra\xeenement et l'",(0,a.jsx)(n,{term:"test set",definition:'{"definition":"Sous-ensemble de donn\xe9es non utilis\xe9es pour l\'entra\xeenement et la validation, utilis\xe9 uniquement pour l\'\xe9valuation finale des performances du mod\xe8le..","source":"","aliases":["Test Set","test data","holdout set","Jeu de test","ensemble de test","jeu de test","Ensemble de Test"]}',children:(0,a.jsx)(n,{term:"test set",definition:'{"definition":"Sous-ensemble de donn\xe9es non utilis\xe9es pour l\'entra\xeenement et la validation, utilis\xe9 uniquement pour l\'\xe9valuation finale des performances du mod\xe8le..","source":"","aliases":["Test Set","test data","holdout set","Jeu de test","ensemble de test","jeu de test","Ensemble de Test"]}',children:"ensemble de test"})}),". Cette standardisation nous a donn\xe9 un moyen de faire des comparaisons significatives sur les capacit\xe9s de l'IA. Dans ce cas, la capacit\xe9 sp\xe9cifique de classification des chiffres. Une fois que les syst\xe8mes ont commenc\xe9 \xe0 bien performer sur la reconnaissance des chiffres, les chercheurs ont d\xe9velopp\xe9 des benchmarks plus difficiles. CIFAR-10/100 en 2009 a introduit des images naturelles en couleur d'objets comme des voitures, des oiseaux et des chiens, augmentant la complexit\xe9 (",(0,a.jsx)(s.a,{href:"https://www.cs.toronto.edu/~kriz/cifar.html",children:"Krizhevsky, 2009"}),"). De m\xeame, ImageNet plus tard la m\xeame ann\xe9e a fourni 1,2 million d'images r\xe9parties en 1 000 cat\xe9gories (",(0,a.jsx)(s.a,{href:"https://ieeexplore.ieee.org/document/5206848",children:"Deng, 2009"}),"). Lorsqu'une \xe9quipe de recherche affirmait que leur syst\xe8me atteignait 95% de pr\xe9cision sur MNIST ou ImageNet et qu'une autre revendiquait 98%, tout le monde savait exactement ce que signifiaient ces chiffres. Les mesures \xe9taient fiables car les deux \xe9quipes utilisaient le m\xeame ensemble de donn\xe9es soigneusement construit. Chaque nouveau ",(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:"benchmark"})}),' disait essentiellement \xe0 la communaut\xe9 de recherche : "Vous avez r\xe9solu le d\xe9fi pr\xe9c\xe9dent - essayez maintenant celui-ci plus difficile." Ainsi, les benchmarks mesurent les progr\xe8s, mais d\xe9finissent \xe9galement ce que signifie le progr\xe8s.']}),"\n",(0,a.jsx)(c.A,{src:"./img/RyF_Image_3.png",alt:"Entrer la description alternative de l'image",number:"2",label:"5.2",caption:"Exemples de chiffres issus de MNIST ([Base de donn\xe9es MNIST - Wikip\xe9dia](https://upload.wikimedia.org/wikipedia/commons/b/b1/MNIST_dataset_example.png))"}),"\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Comment les benchmarks influencent-ils la s\xe9curit\xe9 de l'IA ?"})," Sans mesures standardis\xe9es, nous ne pouvons pas faire de progr\xe8s syst\xe9matiques sur les capacit\xe9s ou la s\xe9curit\xe9. Tout comme les benchmarks d\xe9finissent ce que signifie le progr\xe8s des capacit\xe9s, lorsque nous d\xe9veloppons des benchmarks de s\xe9curit\xe9, nous \xe9tablissons des normes concr\xe8tes v\xe9rifiables pour ce qui constitue \"s\xfbr pour le d\xe9ploiement\". Le raffinement it\xe9ratif signifie que nous pouvons guider la s\xe9curit\xe9 de l'IA en cr\xe9ant des benchmarks avec des normes de s\xe9curit\xe9 de plus en plus strictes. D'autres chercheurs et organisations peuvent alors reproduire les tests de s\xe9curit\xe9 et confirmer les r\xe9sultats. Cela fa\xe7onne \xe0 la fois la recherche technique sur les mesures de s\xe9curit\xe9 et les discussions politiques sur la gouvernance de l'IA."]}),"\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"L'\xe9valuation des mod\xe8les de langage a d\xe9j\xe0 \xe9volu\xe9 et continuera d'\xe9voluer."})," Tout comme les benchmarks ont continuellement \xe9volu\xe9 en vision par ordinateur, ils ont suivi une progression similaire dans la g\xe9n\xe9ration de langage. Les premiers benchmarks de mod\xe8les de langage se concentraient principalement sur les capacit\xe9s - le mod\xe8le peut-il r\xe9pondre correctement aux questions ? Compl\xe9ter les phrases de mani\xe8re sens\xe9e ? Traduire entre les langues ? Depuis l'invention de l'architecture ",(0,a.jsx)(n,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:(0,a.jsx)(n,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:"transformer"})})," en 2017, nous avons assist\xe9 \xe0 une explosion \xe0 la fois des capacit\xe9s des mod\xe8les de langage et de la sophistication de leur \xe9valuation. Nous ne pouvons pas \xeatre exhaustifs, mais voici quelques benchmarks contre lesquels les mod\xe8les de langage actuels sont \xe9valu\xe9s :"]}),"\n",(0,a.jsx)(c.A,{src:"./img/3jD_Image_4.png",alt:"Entrer la description alternative de l'image",number:"3",label:"5.3",caption:"Exemple de mod\xe8les de langage populaires (Claude 3.5) \xe9valu\xe9s sur divers benchmarks ([Anthropic, 2024](https://www.anthropic.com/news/claude-3-5-sonnet))"}),"\n",(0,a.jsx)(r.A,{src:"https://ourworldindata.org/grapher/ai-performance-coding-math-knowledge-tests?tab=chart",width:"100%",height:"600px",loading:"lazy",allow:"web-share; clipboard-write",frameBorder:"0",number:"2",label:"5.2",caption:"Performance de r\xe9f\xe9rence en codage, math\xe9matiques et langage ([Giattino et al., 2023](https://ourworldindata.org/artificial-intelligence))."}),"\n",(0,a.jsxs)(u.A,{title:"Exemples de diff\xe9rents benchmarks de capacit\xe9s",collapsed:!0,children:[(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"\xc9valuation de la compr\xe9hension du langage et des t\xe2ches."})," Le ",(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:"benchmark"})})," GLUE (General Language Understanding Evaluation) (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/1804.07461",children:"Wang et al., 2018"}),"), et son successeur SuperGLUE (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/1905.00537",children:"Wang et al., 2019"}),") testent des t\xe2ches difficiles de compr\xe9hension du langage. SWAG (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/1808.05326",children:"Zellers et al., 2018"}),"), et HellaSwag (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/1905.07830",children:"Zellers et al., 2019"}),") testent sp\xe9cifiquement la capacit\xe9 \xe0 pr\xe9dire quel \xe9v\xe9nement suivrait naturellement un sc\xe9nario donn\xe9."]}),(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"\xc9valuations larges multi-domaines."})," Le ",(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:"benchmark"})})," MMLU (Massive Multitask Language Understanding) (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2009.03300",children:"Hendrycks et al., 2020"}),") teste les connaissances d'un mod\xe8le dans 57 mati\xe8res. Il \xe9value \xe0 la fois l'\xe9tendue et la profondeur dans les sciences humaines, STEM, sciences sociales et autres domaines \xe0 travers des questions \xe0 choix multiples tir\xe9es de v\xe9ritables tests acad\xe9miques et professionnels. Le GPQA (Google Proof QA) (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2311.12022",children:"Rein et al., 2023"}),") propose des questions \xe0 choix multiples sp\xe9cifiquement con\xe7ues pour que les bonnes r\xe9ponses ne puissent pas \xeatre trouv\xe9es par de simples recherches sur Internet. Cela teste si les mod\xe8les ont une v\xe9ritable compr\xe9hension plut\xf4t que de simples capacit\xe9s de recherche d'informations. BigBench (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2206.04615",children:"Srivastava et al., 2022"}),") est un autre exemple de benchmarks pour mesurer la g\xe9n\xe9ralit\xe9 en testant sur une large gamme de t\xe2ches."]}),(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"\xc9valuation du raisonnement math\xe9matique et scientifique."})," Pour tester sp\xe9cifiquement le raisonnement math\xe9matique, quelques exemples incluent - le ",(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:"benchmark"})})," Grade School Math (GSM8K) (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2110.14168",children:"Cobbe et al., 2021"}),"). Celui-ci teste les concepts math\xe9matiques fondamentaux au niveau de l'\xe9cole \xe9l\xe9mentaire. Un autre exemple est le ",(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:"benchmark"})})," MATH (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2103.03874",children:"Hendrycks et al., 2021"}),") qui teste similairement sept mati\xe8res incluant l'alg\xe8bre, la g\xe9om\xe9trie et le pr\xe9calcul en se concentrant sur des probl\xe8mes de style comp\xe9tition. Ils incluent \xe9galement plusieurs niveaux de difficult\xe9 par mati\xe8re. Ces benchmarks incluent aussi des solutions \xe9tape par \xe9tape que nous pouvons utiliser pour tester le processus de raisonnement, ou entra\xeener les mod\xe8les \xe0 g\xe9n\xe9rer leurs processus de raisonnement. Multilingual Grade School Math (MGSM) est la version multilingue qui a traduit 250 probl\xe8mes de math\xe9matiques de niveau primaire du dataset GSM8K (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2210.03057",children:"Shi et al., 2022"}),")."]}),(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"\xc9valuation du d\xe9veloppement logiciel et du codage."})," L'Automated Programming Progress Standard (APPS) (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2105.09938",children:"Hendrycks et al., 2021"}),") est un ",(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:"benchmark"})})," sp\xe9cifiquement con\xe7u pour \xe9valuer la g\xe9n\xe9ration de code \xe0 partir de descriptions de t\xe2ches en langage naturel. De m\xeame, HumanEval (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2107.03374",children:"Chen et al, 2021"}),") teste les capacit\xe9s de codage en Python, et ses extensions comme HumanEval-XL (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2402.16694",children:"Peng et al.,2024"}),") testent les capacit\xe9s de codage multilingue entre 23 langues naturelles et 12 langages de programmation. HumanEval-V (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2410.12381",children:"Zhang et al., 2024"}),") teste les t\xe2ches de codage o\xf9 le mod\xe8le doit interpr\xe9ter \xe0 la fois des diagrammes ou des graphiques, et des descriptions textuelles pour g\xe9n\xe9rer du code. BigCode (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2406.15877",children:"Zuho et al., 2024"}),"), \xe9value la g\xe9n\xe9ration de code et l'utilisation d'outils en mesurant la capacit\xe9 d'un mod\xe8le \xe0 utiliser correctement plusieurs biblioth\xe8ques Python pour r\xe9soudre des probl\xe8mes de codage complexes."]}),(0,a.jsx)(c.A,{src:"./img/Gkb_Image_6.png",alt:"Entrer la description alternative de l'image",number:"4",label:"5.4",caption:"Exemple de t\xe2che de codage et cas de test sur APPS ([Hendrycks et al., 2021](https://arxiv.org/abs/2105.09938))"})]}),"\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"\xc9valuation de l'\xe9thique et des biais."})," Le ",(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:"benchmark"})})," ETHICS (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2008.02275",children:"Hendrycks et al., 2023"}),") teste la compr\xe9hension par un mod\xe8le de langage des valeurs humaines et de l'\xe9thique \xe0 travers plusieurs cat\xe9gories incluant la justice, la d\xe9ontologie, l'\xe9thique des vertus, l'utilitarisme et la moralit\xe9 de sens commun. Le ",(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:"benchmark"})})," TruthfulQA (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2109.07958",children:"Lin et al., 2021"}),') mesure \xe0 quel point les mod\xe8les de langage r\xe9pondent v\xe9ridiquement aux questions. Il se concentre sp\xe9cifiquement sur les "fausset\xe9s imitatives" - des cas o\xf9 les mod\xe8les apprennent \xe0 r\xe9p\xe9ter des d\xe9clarations fausses qui apparaissent fr\xe9quemment dans les textes \xe9crits par des humains dans des domaines comme la sant\xe9, le droit, la finance et la politique.']}),"\n",(0,a.jsx)(c.A,{src:"./img/2BK_Image_7.png",alt:"Entrer la description alternative de l'image",number:"5",label:"5.5",caption:"Exemple de mod\xe8les plus grands \xe9tant moins v\xe9ridiques sur TruthfulQA ([Lin et al., 2021](https://arxiv.org/abs/2109.07958)). C'est un exemple d'\xe9chelle inverse, c'est-\xe0-dire quand la performance d'un plus grand mod\xe8le diminue sur certaines questions."}),"\n",(0,a.jsx)(c.A,{src:"./img/5FI_Image_8.png",alt:"Entrer la description alternative de l'image",number:"6",label:"5.6",caption:"Exemple de question du benchmark ETHICS ([Hendrycks et al., 2023](https://arxiv.org/abs/2008.02275))"}),"\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"\xc9valuation de la s\xe9curit\xe9."})," Un exemple ax\xe9 sur l'utilisation abusive est AgentHarm (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2410.09024",children:"Andriushchenko et al., 2024"}),"). Il est sp\xe9cifiquement con\xe7u pour mesurer la fr\xe9quence \xe0 laquelle les agents LLM r\xe9pondent aux demandes de t\xe2ches malveillantes. Un exemple qui se concentre un peu plus sur le d\xe9salignement est le ",(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:"benchmark"})})," MACHIAVELLI (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2304.03279",children:"Pan et al., 2023"}),'). Il contient des jeux de style "choisissez votre propre aventure" avec plus d\'un demi-million de sc\xe9narios ax\xe9s sur la prise de d\xe9cision sociale. Il mesure les "capacit\xe9s machiav\xe9liques" comme la recherche du pouvoir et le comportement trompeur, et comment les agents IA \xe9quilibrent l\'atteinte des r\xe9compenses et le comportement \xe9thique.']}),"\n",(0,a.jsx)(c.A,{src:"./img/1D8_Image_9.png",alt:"Entrer la description alternative de l'image",number:"7",label:"5.7",caption:"Une maquette d'un jeu dans le benchmark MACHIAVELLI, une suite d'environnements bas\xe9s sur du texte. \xc0 chaque \xe9tape, l'agent observe la sc\xe8ne et une liste d'actions possibles ; il s\xe9lectionne une action de la liste. Chaque jeu est une histoire textuelle, qui est g\xe9n\xe9r\xe9e de mani\xe8re adaptative \u2013 les branches s'ouvrent et se ferment en fonction des actions pr\xe9c\xe9dentes. L'agent re\xe7oit une r\xe9compense lorsqu'il atteint l'un des objectifs. Ce type de benchmark permet aux chercheurs de construire un rapport comportemental de l'agent et de mesurer le compromis entre les r\xe9compenses et le comportement \xe9thique ([Pan et al., 2023](https://arxiv.org/abs/2304.03279))."}),"\n",(0,a.jsxs)(u.A,{title:"D\xe9tails - Benchmark : Frontier Math",collapsed:!0,children:[(0,a.jsx)(c.A,{src:"./img/bGC_Image_10.png",alt:"Entrer la description alternative de l'image",number:"8",label:"5.8",caption:"Interconnexions des sujets math\xe9matiques dans FrontierMath. La taille des n\u0153uds indique la fr\xe9quence d'apparition de chaque sujet dans les probl\xe8mes, tandis que les connexions indiquent quand plusieurs sujets math\xe9matiques sont combin\xe9s dans des probl\xe8mes uniques, d\xe9montrant l'int\xe9gration par le benchmark de nombreux domaines math\xe9matiques ([Glazer et al., 2024](https://arxiv.org/abs/2411.04872))."}),(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Qu'est-ce qui rend FrontierMath si difficile ?"})," Contrairement \xe0 la plupart des benchmarks qui risquent la contamination des donn\xe9es d'entra\xeenement, FrontierMath utilise des probl\xe8mes enti\xe8rement nouveaux et non publi\xe9s. Chaque probl\xe8me est soigneusement \xe9labor\xe9 par des math\xe9maticiens experts et n\xe9cessite plusieurs heures (parfois des jours) de travail m\xeame pour les chercheurs dans ce domaine sp\xe9cifique. Par exemple, Terence Tao (m\xe9daill\xe9 Fields 2006, consid\xe9r\xe9 comme l'un des math\xe9maticiens les plus brillants au monde) a dit \xe0 propos des probl\xe8mes - \"",(0,a.jsx)(s.em,{children:"Ces probl\xe8mes sont extr\xeamement difficiles... Je pense qu'ils r\xe9sisteront aux IA pendant plusieurs ann\xe9es au moins."}),'" (',(0,a.jsx)(s.a,{href:"https://epoch.ai/frontiermath",children:"EpochAI, 2024"}),') De m\xeame, Timothy Gowers (math\xe9maticien tr\xe8s respect\xe9 et m\xe9daill\xe9 Fields 1998) a dit - "',(0,a.jsx)(s.em,{children:"Obtenir ne serait-ce qu'une bonne r\xe9ponse serait bien au-del\xe0 de ce que nous pouvons faire maintenant, sans parler de les saturer"}),'" (',(0,a.jsx)(s.a,{href:"https://epoch.ai/frontiermath",children:"EpochAI, 2024"}),")."]}),(0,a.jsxs)(s.p,{children:["Le ",(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:"benchmark"})})," couvre la plupart des branches majeures des math\xe9matiques modernes - des probl\xe8mes \xe0 calcul intensif en th\xe9orie des nombres aux questions abstraites en topologie alg\xe9brique et th\xe9orie des cat\xe9gories. Pour garantir que les probl\xe8mes sont vraiment nouveaux, ils subissent une r\xe9vision par des experts et une d\xe9tection du plagiat. Le ",(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:"benchmark"})}),' impose \xe9galement une stricte "r\xe9sistance aux devinettes" - les probl\xe8mes doivent \xeatre con\xe7us de sorte qu\'il y ait moins de 1% de chance de deviner la bonne r\xe9ponse sans faire le travail math\xe9matique. Cela signifie que les probl\xe8mes ont souvent des r\xe9ponses num\xe9riques importantes et non \xe9videntes qui ne peuvent \xeatre trouv\xe9es que par un raisonnement math\xe9matique appropri\xe9. Le ',(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:"benchmark"})})," fournit un environnement exp\xe9rimental o\xf9 les mod\xe8les peuvent \xe9crire et tester du code pour explorer des id\xe9es math\xe9matiques, similaire \xe0 la fa\xe7on dont les math\xe9maticiens humains travaillent. Bien que les probl\xe8mes doivent avoir des r\xe9ponses automatiquement v\xe9rifiables (soit num\xe9riques soit des objets math\xe9matiques programmables), ils n\xe9cessitent toujours un raisonnement math\xe9matique sophistiqu\xe9 pour \xeatre r\xe9solus."]}),(0,a.jsx)(c.A,{src:"./img/VOn_Image_11.png",alt:"Entrer la description alternative de l'image",number:"9",label:"5.9",caption:"Un exemple de probl\xe8me du benchmark FrontierMath ([Besiroglu et al., 2024](https://epoch.ai/frontiermath/the-benchmark))."}),(0,a.jsxs)(s.p,{children:["Juste pour illustrer le rythme rapide des progr\xe8s m\xeame sur ce ",(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:"benchmark"})})," que m\xeame les m\xe9daill\xe9s Fields consid\xe8rent comme extr\xeamement difficile, entre l'annonce du ",(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:"benchmark"})})," FrontierMath, les mod\xe8les \xe0 la pointe de la technologie pouvaient r\xe9soudre moins de 2% des probl\xe8mes FrontierMath (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2411.04872",children:"Glazer et al., 2024"}),"). Quelques mois plus tard seulement, OpenAI a annonc\xe9 le mod\xe8le o3, qui a fait grimper la performance \xe0 25,2%. Cela souligne encore une fois le rythme effr\xe9n\xe9 des progr\xe8s et la saturation continue de chaque ",(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:"benchmark"})})," que nous sommes capables de d\xe9velopper."]}),(0,a.jsx)(c.A,{src:"./img/Fsa_Image_12.png",alt:"Entrer la description alternative de l'image",number:"10",label:"5.10",caption:"Performance des principaux mod\xe8les de langage sur FrontierMath. Tous les mod\xe8les montrent des performances constamment faibles, m\xeame les meilleurs mod\xe8les (en novembre 2024) r\xe9solvant moins de 2 pour cent des probl\xe8mes ([Besiroglu et al., 2024](https://epoch.ai/frontiermath/the-benchmark)). Quelques mois plus tard, OpenAI a affirm\xe9 que leur mod\xe8le o3 pouvait obtenir 25 pour cent sur FrontierMath ([Brown, 2024](https://x.com/polynoamial/status/1870172996650053653?mx=2))."}),(0,a.jsxs)(s.p,{children:['Pour suivre le rythme, les chercheurs d\xe9veloppent ce qui est d\xe9crit comme "Le Dernier Examen de l\'Humanit\xe9" (HLE). Un ',(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:"benchmark"})})," visant \xe0 construire le ",(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:(0,a.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:"benchmark"})})," d'IA public le plus difficile au monde en rassemblant des experts de tous les domaines (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2501.14249",children:"Phan et al., 2025"}),")."]})]}),"\n",(0,a.jsx)(s.h2,{id:"02",children:"Limites de l'\xe9valuation comparative"}),"\n",(0,a.jsx)(s.p,{children:"Les \xe9valuations comparatives actuelles pr\xe9sentent plusieurs limitations critiques qui les rendent insuffisantes pour v\xe9ritablement \xe9valuer la s\xe9curit\xe9 de l'IA. Examinons ces limitations et comprenons pourquoi elles sont importantes."}),"\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Contamination des donn\xe9es d'entra\xeenement."})," Imaginez que vous vous pr\xe9pariez \xe0 un test en m\xe9morisant toutes les r\xe9ponses sans comprendre les concepts sous-jacents. Vous pourriez obtenir un score parfait, mais vous n'auriez rien appris d'utile. Les LLM font face \xe0 un probl\xe8me similaire. \xc0 mesure que ces mod\xe8les grandissent et sont entra\xeen\xe9s sur plus de donn\xe9es internet, ils sont de plus en plus susceptibles d'avoir vu les donn\xe9es d'\xe9valuation pendant l'entra\xeenement. Cela cr\xe9e un probl\xe8me fondamental - lorsqu'un mod\xe8le a m\xe9moris\xe9 les r\xe9ponses des \xe9valuations, une performance \xe9lev\xe9e n'indique plus une v\xe9ritable capacit\xe9. Les \xe9valuations dont nous avons discut\xe9 dans la section pr\xe9c\xe9dente comme le MMLU ou TruthfulQA ont \xe9t\xe9 tr\xe8s populaires. Leurs questions et r\xe9ponses sont donc discut\xe9es sur internet. Si et quand ces discussions se retrouvent dans les donn\xe9es d'entra\xeenement du mod\xe8le, celui-ci peut obtenir des scores \xe9lev\xe9s par m\xe9morisation plut\xf4t que par compr\xe9hension."]}),"\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Exemple de Compr\xe9hension vs M\xe9morisation."})," Le chiffre de C\xe9sar est une m\xe9thode de cryptage simple qui d\xe9cale chaque lettre de l'alphabet d'un nombre fixe de positions - par exemple, avec un d\xe9calage vers la gauche de 3, 'D' devient 'A', 'E' devient 'B', et ainsi de suite. Si le cryptage est un d\xe9calage vers la gauche de 3, alors le d\xe9cryptage signifie simplement d\xe9caler vers la droite de 3."]}),"\n",(0,a.jsx)(c.A,{src:"./img/y2J_Image_13.png",alt:"Entrer la description alternative de l'image",number:"11",label:"5.11",caption:"Exemple d'un Chiffre de C\xe9sar"}),"\n",(0,a.jsxs)(s.p,{children:["Les mod\xe8les de langage comme GPT-4 peuvent r\xe9soudre les probl\xe8mes de chiffre de C\xe9sar lorsque la valeur de d\xe9calage est de 3 ou 5, qui apparaissent couramment dans les exemples en ligne. Cependant, donnez-leur exactement le m\xeame probl\xe8me avec des valeurs de d\xe9calage peu communes (comme 67), ils ont tendance \xe0 \xe9chouer compl\xe8tement (",(0,a.jsx)(s.a,{href:"https://www.youtube.com/watch?v=s7_NlkBwdj8",children:"Chollet, 2024"}),"). Cela indique que les mod\xe8les n'ont peut-\xeatre pas appris l'algorithme g\xe9n\xe9ral pour r\xe9soudre les chiffres de C\xe9sar. Nous n'essayons pas de pointer une limitation dans les capacit\xe9s du mod\xe8le. Nous nous attendons \xe0 ce que cela puisse \xeatre att\xe9nu\xe9 avec des mod\xe8les de raisonnement entra\xeen\xe9s sur des cha\xeenes de pens\xe9e, ou avec des mod\xe8les augment\xe9s d'outils. Cependant, les \xe9valuations utilisent souvent les mod\xe8les \"tels quels\" sans modifications ou augmentation, ce qui conduit \xe0 une sous-repr\xe9sentation des capacit\xe9s. C'est le point central que nous essayons de transmettre."]}),"\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Pourquoi ces limitations d'\xe9valuation comparative sont-elles importantes pour la s\xe9curit\xe9 de l'IA ?"})," Les \xe9valuations (y compris les \xe9valuations de s\xe9curit\xe9) pourraient ne pas mesurer ce que nous pensons qu'elles mesurent. Par exemple, les \xe9valuations comme ETHICS ou TruthfulQA visent \xe0 mesurer \xe0 quel point un mod\xe8le \"comprend\" le comportement \xe9thique, ou a tendance \xe0 \xe9viter les fausset\xe9s imitatives en mesurant la g\xe9n\xe9ration de langage sur des tests \xe0 choix multiples, mais nous pourrions encore mesurer des m\xe9triques superficielles. Le mod\xe8le pourrait ne pas avoir appris ce que signifie se comporter \xe9thiquement dans une situation. Un syst\xe8me d'IA pourrait fonctionner parfaitement sur toutes les questions \xe9thiques et les cas de test, r\xe9ussir toutes les \xe9valuations de s\xe9curit\xe9, mais d\xe9montrer un nouveau comportement lors de la rencontre d'un nouveau sc\xe9nario du monde r\xe9el."]}),"\n",(0,a.jsxs)(s.p,{children:["Une r\xe9ponse facile serait simplement d'augmenter continuellement les \xe9valuations ou les donn\xe9es d'entra\xeenement avec de plus en plus de questions, mais cela semble irr\xe9alisable et ne peut pas s'\xe9tendre ind\xe9finiment. Le probl\xe8me fondamental est que l'espace des situations et des t\xe2ches possibles est effectivement infini. M\xeame si vous vous entra\xeenez sur des millions d'exemples, vous n'avez toujours effectivement vu qu'environ 0% de l'espace total possible (",(0,a.jsx)(s.a,{href:"https://www.dwarkeshpatel.com/p/francois-chollet",children:"Chollet, 2024"}),"). La recherche indique que ce n'est pas simplement une question de donn\xe9es insuffisantes ou de taille de mod\xe8le - c'est inh\xe9rent \xe0 la fa\xe7on dont les mod\xe8les de langage sont actuellement entra\xeen\xe9s - les relations logiques comme l'inf\xe9rence des inverses (les poids appris lors de l'entra\xeenement sur \"A \u2192 B\" ne renforcent pas automatiquement la connexion inverse \"B \u2190 A\") ou la transitivit\xe9 n'\xe9mergent pas naturellement de l'entra\xeenement standard (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2405.04669",children:"Zhu et al., 2024"}),"; ",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2403.13799",children:"Golovneva et al., 2024"}),"; ",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2309.12288",children:"Berglund et al., 2024"}),"). Les solutions propos\xe9es comme l'entra\xeenement inverse pendant le pr\xe9-entra\xeenement montrent des promesses pour att\xe9nuer ces probl\xe8mes (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2403.13799",children:"Golovneva et al., 2024"}),"), mais elles n\xe9cessitent de grands changements dans la fa\xe7on dont les mod\xe8les sont entra\xeen\xe9s."]}),"\n",(0,a.jsx)(s.p,{children:"Les ing\xe9nieurs sont plus que conscients de ces limitations actuelles, et l'attente est que ces probl\xe8mes seront att\xe9nu\xe9s avec le temps. La question fondamentale qui nous pr\xe9occupe dans ce chapitre n'est pas celle des limitations des capacit\xe9s du mod\xe8le, c'est de savoir si les \xe9valuations et les techniques de mesure peuvent rester en avance sur les paradigmes d'entra\xeenement, et si elles sont vraiment capables d'\xe9valuer pr\xe9cis\xe9ment ce dont le mod\xe8le peut \xeatre capable."}),"\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Pourquoi ne pouvons-nous pas simplement cr\xe9er de meilleures \xe9valuations ?"}),' La r\xe9ponse naturelle \xe0 ces limitations pourrait \xeatre "cr\xe9ons simplement de meilleures \xe9valuations." Et dans une certaine mesure, nous le pouvons !']}),"\n",(0,a.jsxs)(s.p,{children:["Nous avons d\xe9j\xe0 vu comment les \xe9valuations ont constamment \xe9volu\xe9 pour r\xe9pondre \xe0 leurs lacunes. Les chercheurs travaillent constamment activement pour cr\xe9er des \xe9valuations qui testent \xe0 la fois les connaissances, r\xe9sistent \xe0 la m\xe9morisation et testent une compr\xe9hension plus profonde. Quelques exemples sont le Corpus d'Abstraction et de Raisonnement (ARC) (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/1911.01547",children:"Chollet, 2019"}),"), ConceptARC (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2305.07141",children:"Moskvichev et al. 2023"}),"), Frontier Math (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2411.04872",children:"Glazer et al., 2024"}),") et Humanities Last Exam (",(0,a.jsx)(s.a,{href:"https://www.safe.ai/blog/humanitys-last-exam",children:"Hendrycks & Wang, 2024"}),"). Ils essaient explicitement d'\xe9valuer si les mod\xe8les ont saisi des concepts abstraits et un raisonnement g\xe9n\xe9ral plut\xf4t que de simplement m\xe9moriser des motifs. Similaire \xe0 ces \xe9valuations qui cherchent \xe0 mesurer les capacit\xe9s, nous pouvons aussi continuer \xe0 am\xe9liorer les \xe9valuations sp\xe9cifiques \xe0 la s\xe9curit\xe9 pour les rendre plus robustes."]}),"\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Pourquoi de meilleures \xe9valuations ne suffisent-elles pas ?"})," Bien qu'am\xe9liorer les \xe9valuations soit important et aidera les efforts de s\xe9curit\xe9 de l'IA, le paradigme fondamental de l'\xe9valuation comparative a toujours des limitations inh\xe9rentes. Il existe des limitations fondamentales dans les approches d'\xe9valuation traditionnelles qui n\xe9cessitent des m\xe9thodes d'\xe9valuation plus sophistiqu\xe9es (",(0,a.jsx)(s.a,{href:"https://arxiv.org/abs/2407.09221",children:"Burden, 2024"}),"). Le probl\xe8me central est que les \xe9valuations tendent \xe0 \xeatre orient\xe9es vers la performance plut\xf4t que vers les capacit\xe9s - elles mesurent les scores bruts sans \xe9valuer syst\xe9matiquement si les syst\xe8mes poss\xe8dent v\xe9ritablement les capacit\xe9s sous-jacentes test\xe9es. Bien que les \xe9valuations fournissent des m\xe9triques standardis\xe9es, elles \xe9chouent souvent \xe0 distinguer entre les syst\xe8mes qui comprennent v\xe9ritablement les t\xe2ches et ceux qui performent bien simplement par m\xe9morisation ou corr\xe9lations fallacieuses. Une \xe9valuation qui \xe9value simplement la performance, peu importe sa sophistication, ne peut pas compl\xe8tement capturer la nature dynamique",(0,a.jsx)(o.A,{id:"footnote_dynamic_benchmarks",number:"2",text:"Nous pourrions avoir des benchmarks dans des environnements peupl\xe9s par d'autres agents. Certains benchmarks RL le font d\xe9j\xe0. C'est l'une des nombreuses additions au benchmarking qui nous rapproche d'une suite d'\xe9valuation holistique."})," du d\xe9ploiement de l'IA dans le monde r\xe9el o\xf9 les syst\xe8mes doivent s'adapter \xe0 de nouvelles situations et combineront probablement les capacit\xe9s et les affordances de mani\xe8res inattendues. Nous devons mesurer la limite sup\xe9rieure des capacit\xe9s du mod\xe8le."]}),"\n",(0,a.jsx)(u.A,{title:"Le besoin d'un Benchmarking Tenant Compte du Calcul",collapsed:!0,children:(0,a.jsxs)(s.p,{children:["Nous avons observ\xe9 l'av\xe8nement des lois d'\xe9chelle d'inf\xe9rence parall\xe8lement \xe0 l'essor des grands mod\xe8les de raisonnement comme DeepSeek r1, OpenAIs o3 etc. Celles-ci s'ajoutent aux lois d'\xe9chelle d'entra\xeenement \xe9tablies que nous avons expliqu\xe9es dans le chapitre sur les capacit\xe9s. Maintenant, lors de l'\xe9valuation des syst\xe8mes d'IA, nous devons soigneusement tenir compte des ressources computationnelles utilis\xe9es. La comp\xe9tition ARC 2024 a d\xe9montr\xe9 pourquoi - les syst\xe8mes sur la piste \xe0 calcul restreint (10 dollars de calcul) et la piste sans restriction (10 000 dollars de calcul) ont atteint des scores de pr\xe9cision similaires de 55%, sugg\xe9rant que de meilleures id\xe9es et algorithmes peuvent parfois compenser moins de calcul (",(0,a.jsx)(s.a,{href:"https://arcprize.org/media/arc-prize-2024-technical-report.pdf",children:"Chollet et al., 2024"}),"). Cela signifie que sans budgets de calcul standardis\xe9s, les r\xe9sultats des \xe9valuations deviennent difficiles \xe0 interpr\xe9ter. Un mod\xe8le pourrait obtenir des scores plus \xe9lev\xe9s simplement en utilisant plus de calcul plut\xf4t qu'en ayant de meilleures capacit\xe9s sous-jacentes. Cela souligne pourquoi, outre la cr\xe9ation de jeux de donn\xe9es, les \xe9valuations doivent \xe9galement sp\xe9cifier les budgets de calcul pour l'entra\xeenement et l'inf\xe9rence pour des comparaisons significatives."]})}),"\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Qu'est-ce qui rend les \xe9valuations compl\xe8tes diff\xe9rentes de la simple \xe9valuation comparative ?"}),' Les \xe9valuations sont des protocoles complets qui partent de mod\xe8les de menaces concrets. Plut\xf4t que de commencer par ce qui est facile \xe0 mesurer, ils commencent par demander "Qu\'est-ce qui pourrait mal tourner ?" et travaillent ensuite \xe0 rebours pour d\xe9velopper des moyens syst\xe9matiques de tester ces modes de d\xe9faillance. Des organisations comme METR ont d\xe9velopp\xe9 des approches qui vont au-del\xe0 de la simple \xe9valuation comparative. Au lieu de simplement demander "Ce mod\xe8le peut-il \xe9crire du code malveillant ?", ils consid\xe8rent des mod\xe8les de menaces comme - un mod\xe8le utilisant des vuln\xe9rabilit\xe9s de s\xe9curit\xe9 pour obtenir des ressources de calcul, se copier sur d\'autres machines, et \xe9viter la d\xe9tection.']}),"\n",(0,a.jsx)(d.A,{term:"\xc9valuations",source:"",number:"1",label:"5.1",children:(0,a.jsx)(s.p,{children:"Une \xe9valuation en tant que protocole complet d'\xe9valuation de la s\xe9curit\xe9 qui inclut l'utilisation d'\xe9valuations comparatives."})}),"\n",(0,a.jsx)(s.p,{children:"Cela dit, comme les \xe9valuations sont nouvelles, les \xe9valuations comparatives existent depuis plus longtemps et \xe9voluent \xe9galement. Il y a donc parfois un chevauchement dans la fa\xe7on dont ces mots sont utilis\xe9s. Pour ce texte, nous consid\xe9rons une \xe9valuation comparative comme un outil de mesure individuel, et une \xe9valuation comme un protocole complet d'\xe9valuation de la s\xe9curit\xe9 qui inclut l'utilisation d'\xe9valuations comparatives. Selon le degr\xe9 de compl\xe9tude de la m\xe9thodologie de test des \xe9valuations comparatives, une seule \xe9valuation comparative pourrait \xeatre consid\xe9r\xe9e comme une \xe9valuation compl\xe8te. Mais en g\xe9n\xe9ral, les \xe9valuations englobent typiquement une gamme plus large d'analyses, de m\xe9thodes d'\xe9licitation et d'outils pour obtenir une compr\xe9hension compl\xe8te de la performance et du comportement d'un syst\xe8me."}),"\n",(0,a.jsx)(o.c,{title:"Notes de bas de page"})]})}function v(e={}){const{wrapper:s}={...(0,i.R)(),...e.components};return s?(0,a.jsx)(s,{...e,children:(0,a.jsx)(f,{...e})}):f(e)}},4768:(e,s,n)=>{n.d(s,{c:()=>d,A:()=>u});var t=n(6540),a=n(3012);const i={footnoteAnchor:"footnoteAnchor_PZpY",footnoteSection:"footnoteSection_waoz",separator:"separator_hp8y",separatorLine:"separatorLine_uVnd",separatorLogo:"separatorLogo_dMBq",footnoteRegistry:"footnoteRegistry_ieVW",registryTitle:"registryTitle_ybBb",footnoteList:"footnoteList_Kjil",footnoteItem:"footnoteItem_aLZ2",footnoteNumber:"footnoteNumber_dA3X",footnoteContent:"footnoteContent_Xfmt",backButton:"backButton_vSVm",highlighted:"highlighted_YFU0",highlight:"highlight_jxG3",highlightDark:"highlightDark_Ekom"};var r=n(4848);function o(e,s){void 0===s&&(s=!0);const n=document.getElementById(e);n&&(n.scrollIntoView({behavior:"smooth"}),s&&(n.classList.add(i.highlighted),setTimeout((()=>n.classList.remove(i.highlighted)),1500)))}function l(e){return e?e.replace(/\[([^\]]+)\]\(([^)]+)\)/g,'<a href="$2" target="_blank" rel="noopener noreferrer">$1</a>'):""}function u(e){let{id:s,text:n,number:u}=e;const d=s||`footnote-${Math.random().toString(36).substr(2,9)}`,c="string"==typeof n?l(n):n;return(0,t.useEffect)((()=>{const e=setTimeout((()=>{const e=document.getElementById(`footnote-clone-${d}`);e&&n&&(e.innerHTML="string"==typeof n?l(n):n.toString())}),100);return()=>clearTimeout(e)}),[d,n]),(0,r.jsx)(a.Mn,{content:(0,r.jsx)("div",{dangerouslySetInnerHTML:{__html:c}}),children:(0,r.jsx)("sup",{id:`footnote-ref-${d}`,className:i.footnoteAnchor,onClick:e=>{(e.ctrlKey||e.metaKey)&&(e.preventDefault(),o(`footnote-content-${d}`))},"data-footnote-number":u||"?",children:u||"*"})})}function d(e){let{title:s="References"}=e;const[n,l]=(0,t.useState)([]);return(0,t.useEffect)((()=>{const e=document.querySelectorAll('[id^="footnote-ref-"]'),s=Array.from(e).map((e=>({id:e.id.replace("footnote-ref-",""),number:e.getAttribute("data-footnote-number")||e.textContent})));l(s)}),[]),n.length?(0,r.jsxs)("div",{className:i.footnoteSection,children:[(0,r.jsxs)("div",{className:i.separator,children:[(0,r.jsx)("div",{className:i.separatorLine}),(0,r.jsx)("img",{src:"/img/logo_samples/01-test.svg",alt:"Atlas logo",className:i.separatorLogo}),(0,r.jsx)("div",{className:i.separatorLine})]}),(0,r.jsxs)("div",{className:i.footnoteRegistry,children:[(0,r.jsx)("h2",{className:i.registryTitle,children:s}),(0,r.jsx)("ol",{className:i.footnoteList,children:n.map((e=>(0,r.jsxs)("li",{id:`footnote-content-${e.id}`,className:i.footnoteItem,value:parseInt(e.number)||void 0,children:[(0,r.jsx)(a.Mn,{content:"Back to reference",children:(0,r.jsxs)("button",{className:i.footnoteNumber,onClick:()=>o(`footnote-ref-${e.id}`),"aria-label":"Back to reference",children:[e.number,"."]})}),(0,r.jsx)("div",{className:i.footnoteContent,children:(0,r.jsx)("div",{id:`footnote-clone-${e.id}`})}),(0,r.jsx)(a.Mn,{content:"Back to reference",children:(0,r.jsx)("button",{className:i.backButton,onClick:()=>o(`footnote-ref-${e.id}`),"aria-label":"Back to reference",children:"\u21a9"})})]},e.id)))})]})]}):null}},3989:(e,s,n)=>{n.d(s,{A:()=>l});var t=n(6540),a=n(6347),i=n(8444);const r={iframeContainer:"iframeContainer_ixkI",loader:"loader_gjvK",spinner:"spinner_L1j2",spin:"spin_rtC2",iframeWrapper:"iframeWrapper_Tijy",iframe:"iframe_UAfa",caption:"caption_mDwB",captionLink:"captionLink_Ly4l"};var o=n(4848);function l(e){let{src:s,caption:n,title:l="Embedded content",height:u="500px",width:d="100%",chapter:c,number:m,label:p}=e;const[h,g]=(0,t.useState)(!0),f=(0,a.zy)(),v=c||(()=>{const e=f.pathname.match(/\/chapters\/(\d+)/);return e?parseInt(e[1]):null})(),b=u&&"100%"!==u&&"auto"!==u;return(0,o.jsxs)("figure",{className:r.iframeContainer,children:[h&&(0,o.jsxs)("div",{className:r.loader,children:[(0,o.jsx)("div",{className:r.spinner}),(0,o.jsx)("p",{children:"Loading content..."})]}),(0,o.jsx)("div",{className:r.iframeWrapper,style:{paddingBottom:b?"0":"56.25%",height:b?u:"auto"},children:(0,o.jsx)("iframe",{src:s,title:l,width:d,height:b?u:"100%",frameBorder:"0",allowFullScreen:!0,loading:"lazy",onLoad:()=>{g(!1)},className:r.iframe,style:{height:b?u:"100%",position:b?"static":"absolute"}})}),(0,o.jsx)(i.A,{caption:n,mediaType:"iframe",chapter:v,number:m,label:p})]})}}}]);