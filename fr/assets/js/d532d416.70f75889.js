"use strict";(self.webpackChunkatlas=self.webpackChunkatlas||[]).push([[560],{6249:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>l,contentTitle:()=>o,default:()=>p,frontMatter:()=>a,metadata:()=>i,toc:()=>u});const i=JSON.parse('{"id":"chapters/08/index","title":"Supervision \xe0 Grande \xc9chelle","description":"Supervision. \xc0 mesure que les syst\xe8mes d\'IA deviennent de plus en plus performants, s\'assurer qu\'ils restent align\xe9s avec les valeurs et les intentions humaines devient un d\xe9fi crucial. Cette section pr\xe9sente la supervision \xe9volutive comme une approche essentielle pour maintenir le contr\xf4le sur l\'IA avanc\xe9e. Elle explique les probl\xe8mes auxquels nous sommes confront\xe9s dans la g\xe9n\xe9ration de signaux d\'entra\xeenement pour des t\xe2ches complexes et \\"floues\\" et la n\xe9cessit\xe9 de nouvelles m\xe9thodes pour fournir des retours pr\xe9cis. Ceci est particuli\xe8rement important alors que les mod\xe8les d\'IA commencent \xe0 effectuer des t\xe2ches d\xe9passant l\'expertise humaine. La section explore \xe9galement le concept de la v\xe9rification \xe9tant plus simple que la g\xe9n\xe9ration, expliquant pourquoi cette propri\xe9t\xe9 est fondamentale pour les techniques de supervision \xe9volutive.","source":"@site/i18n/fr/docusaurus-plugin-content-docs/current/chapters/08/index.md","sourceDirName":"chapters/08","slug":"/chapters/08/","permalink":"/fr/chapters/08/","draft":false,"unlisted":false,"editUrl":"https://github.com/markov-root/atlas/edit/main/docs/chapters/08/index.md","tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"title":"Supervision \xe0 Grande \xc9chelle","chapter_number":8,"reading_time_core":"75 min","reading_time_optional":"21 min","authors":["Markov Grey","Charbel-Rapha\xebl Segerie"],"affiliations":["Centre Fran\xe7ais pour la S\xe9curit\xe9 de l\'IA (CeSIA)"],"acknowledgements":["Jeanne Salle","Chris Gerrby","Sebastian Gil","Josh Thorsteinson","Nicolas Guillard","Mateusz Bagi\u0144ski","Yoann Poupart","Cl\xe9ment Dumas","Amaury Lorin","Mateo Rendon","Lucas Eichorn","Bogdan Ionut Cirstea","Gurvan R."],"google_docs_link":"https://docs.google.com/document/d/1k6rlyBCZJw8xbUx0dzd-4sOhlzj-xzsmwi_OIZY1-3M/edit?usp=sharing","feedback_link":"https://forms.gle/ZsA4hEWUx1ZrtQLL9","teach_link":"https://docs.google.com/document/d/1im_i6e9xEAe-koYlurYdn26n9h7pFX2HksnRfQmWxTQ/edit?usp=sharing","sidebar_position":8,"slug":"/chapters/08/"},"sidebar":"docs","previous":{"title":"7.5.2 Internal Techniques (White-Box)","permalink":"/fr/chapters/07/05#02"},"next":{"title":"8.1 Supervision","permalink":"/fr/chapters/08/01"}}');var t=n(4848),r=n(8453);n(2482),n(8559),n(9585);const a={title:"Supervision \xe0 Grande \xc9chelle",chapter_number:8,reading_time_core:"75 min",reading_time_optional:"21 min",authors:["Markov Grey","Charbel-Rapha\xebl Segerie"],affiliations:["Centre Fran\xe7ais pour la S\xe9curit\xe9 de l'IA (CeSIA)"],acknowledgements:["Jeanne Salle","Chris Gerrby","Sebastian Gil","Josh Thorsteinson","Nicolas Guillard","Mateusz Bagi\u0144ski","Yoann Poupart","Cl\xe9ment Dumas","Amaury Lorin","Mateo Rendon","Lucas Eichorn","Bogdan Ionut Cirstea","Gurvan R."],google_docs_link:"https://docs.google.com/document/d/1k6rlyBCZJw8xbUx0dzd-4sOhlzj-xzsmwi_OIZY1-3M/edit?usp=sharing",feedback_link:"https://forms.gle/ZsA4hEWUx1ZrtQLL9",teach_link:"https://docs.google.com/document/d/1im_i6e9xEAe-koYlurYdn26n9h7pFX2HksnRfQmWxTQ/edit?usp=sharing",sidebar_position:8,slug:"/chapters/08/"},o="Introduction",l={},u=[];function c(e){const s={h1:"h1",header:"header",p:"p",strong:"strong",...(0,r.R)(),...e.components},{GlossaryTerm:n}=s;return n||function(e,s){throw new Error("Expected "+(s?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("GlossaryTerm",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(s.header,{children:(0,t.jsx)(s.h1,{id:"introduction",children:"Introduction"})}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Supervision."})," \xc0 mesure que les syst\xe8mes d'IA deviennent de plus en plus performants, s'assurer qu'ils restent align\xe9s avec les valeurs et les intentions humaines devient un d\xe9fi crucial. Cette section pr\xe9sente la supervision \xe9volutive comme une approche essentielle pour maintenir le contr\xf4le sur l'IA avanc\xe9e. Elle explique les probl\xe8mes auxquels nous sommes confront\xe9s dans la g\xe9n\xe9ration de signaux d'entra\xeenement pour des t\xe2ches complexes et \"floues\" et la n\xe9cessit\xe9 de nouvelles m\xe9thodes pour fournir des retours pr\xe9cis. Ceci est particuli\xe8rement important alors que les mod\xe8les d'IA commencent \xe0 effectuer des t\xe2ches d\xe9passant l'expertise humaine. La section explore \xe9galement le concept de la v\xe9rification \xe9tant plus simple que la g\xe9n\xe9ration, expliquant pourquoi cette propri\xe9t\xe9 est fondamentale pour les techniques de supervision \xe9volutive."]}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"D\xe9composition des t\xe2ches."})," S'appuyant sur le besoin de meilleures m\xe9thodes de supervision, cette section explore la d\xe9composition des t\xe2ches comme strat\xe9gie cl\xe9. La d\xe9composition des t\xe2ches consiste \xe0 diviser des t\xe2ches complexes en sous-t\xe2ches plus petites et g\xe9rables, qui peuvent \xeatre divis\xe9es r\xe9cursivement. Cette approche aide \xe0 g\xe9n\xe9rer de meilleurs signaux d'entra\xeenement en simplifiant la t\xe2che que nous devons \xe9valuer et v\xe9rifier. La cognition factori\xe9e \xe9tend ce concept pour reproduire la pens\xe9e humaine dans les mod\xe8les d'",(0,t.jsx)(n,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:(0,t.jsx)(n,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:"apprentissage automatique"})})," (",(0,t.jsx)(n,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:(0,t.jsx)(n,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:"ML"})}),") en d\xe9composant le raisonnement et les t\xe2ches cognitives complexes."]}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Supervision des processus."})," Une autre fa\xe7on d'aider la supervision \xe9volutive est d'aborder certaines des limitations des approches bas\xe9es sur les r\xe9sultats. Cette section introduit le concept de supervision bas\xe9e sur les processus. Nous expliquons la Supervision du Raisonnement Externalis\xe9 (ERO) et le clonage proc\xe9dural comme exemples sp\xe9cifiques. Les techniques ERO comme la cha\xeene de pens\xe9e (CoT) encouragent les mod\xe8les de langage \xe0 \"penser \xe0 voix haute\", rendant leurs processus de raisonnement transparents pour une meilleure supervision et pr\xe9venant potentiellement les comportements ind\xe9sirables. Le clonage proc\xe9dural, une extension du clonage comportemental, vise \xe0 reproduire non seulement les actions finales mais l'ensemble du processus de prise de d\xe9cision des experts. Ces m\xe9thodes offrent une approche plus rigoureuse de la supervision en se concentrant sur le processus de raisonnement de l'IA plut\xf4t que sur ses seules sorties."]}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Amplification It\xe9r\xe9e (IA)."})," S'appuyant sur les concepts de d\xe9composition des t\xe2ches et de supervision des processus, cette section d\xe9crit l'amplification et la distillation. L'amplification am\xe9liore les capacit\xe9s des superviseurs \xe0 r\xe9soudre des t\xe2ches plus complexes, tandis que la distillation traite les limitations de l'amplification, comme la complexit\xe9 et l'utilisation des ressources. Ces processus sont combin\xe9s dans la Distillation et l'Amplification It\xe9r\xe9es (IDA), une m\xe9thode visant \xe0 g\xe9n\xe9rer progressivement de meilleurs signaux d'entra\xeenement pour les t\xe2ches difficiles \xe0 \xe9valuer directement."]}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"D\xe9bat."})," Cette section explore la S\xe9curit\xe9 de l'IA via le D\xe9bat comme technique contradictoire pour la supervision \xe9volutive. Elle d\xe9crit comment les mod\xe8les d'IA argumentant pour diff\xe9rentes positions, avec un juge humain ou IA d\xe9terminant le gagnant, peuvent aboutir \xe0 des r\xe9sultats plus v\xe9ridiques. Le potentiel du d\xe9bat pour faire \xe9merger des connaissances latentes, am\xe9liorer le raisonnement et renforcer notre capacit\xe9 \xe0 superviser des syst\xe8mes d'IA complexes est discut\xe9. Des m\xe9triques cl\xe9s comme l'\xc9cart de Critique du Discriminateur (DCG) sont introduites, ainsi que les d\xe9fis du jugement des d\xe9bats. La section examine \xe9galement les hypoth\xe8ses n\xe9cessaires pour que le D\xe9bat converge vers la v\xe9rit\xe9."]}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Du Faible au Fort (W2S)."})," La derni\xe8re section introduit la G\xe9n\xe9ralisation du Faible au Fort (W2SG) comme approche pratique de la supervision \xe9volutive, s'appuyant sur les enseignements des techniques pr\xe9c\xe9dentes. Elle explique comment les mod\xe8les \xe9troitement surhumains peuvent \xeatre utilis\xe9s comme \xe9tudes de cas pour les techniques de supervision \xe9volutive. Le W2SG implique l'entra\xeenement de mod\xe8les d'IA forts en utilisant une supervision faible, visant \xe0 ce que le mod\xe8le fort surpasse son superviseur faible en exploitant les connaissances pr\xe9existantes. La section conclut en discutant diverses m\xe9thodes d'\xe9valuation des techniques de supervision, y compris les \xe9valuations en sandwich et les \xe9valuations adversariales au niveau m\xe9ta, fournissant un moyen de juger les futurs protocoles de supervision \xe9volutive."]})]})}function p(e={}){const{wrapper:s}={...(0,r.R)(),...e.components};return s?(0,t.jsx)(s,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}}}]);