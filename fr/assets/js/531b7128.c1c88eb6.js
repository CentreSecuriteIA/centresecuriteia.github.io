"use strict";(self.webpackChunkatlas=self.webpackChunkatlas||[]).push([[7548],{9843:(e,s,t)=>{t.r(s),t.d(s,{assets:()=>u,contentTitle:()=>l,default:()=>p,frontMatter:()=>o,metadata:()=>n,toc:()=>c});const n=JSON.parse('{"id":"chapters/03/6","title":"Combinaison des strat\xe9gies","description":"Les sections pr\xe9c\xe9dentes ont d\xe9crit un large \xe9ventail de strat\xe9gies, chacune ciblant diff\xe9rentes facettes du risque li\xe9 \xe0 l\'IA. Synth\xe9tiser celles-ci en un plan unique et coh\xe9rent est une t\xe2che difficile. Cette section pr\xe9sente une s\xe9quence strat\xe9gique plausible, illustrant comment diff\xe9rentes couches de d\xe9fense pourraient \xeatre construites les unes sur les autres pour naviguer entre les risques \xe0 court terme et les d\xe9fis existentiels \xe0 long terme. Cette s\xe9quence est propos\xe9e comme un mod\xe8le illustratif, et non comme une feuille de route d\xe9finitive.","source":"@site/i18n/fr/docusaurus-plugin-content-docs/current/chapters/03/06.md","sourceDirName":"chapters/03","slug":"/chapters/03/06","permalink":"/fr/chapters/03/06","draft":false,"unlisted":false,"editUrl":"https://github.com/markov-root/atlas/edit/main/docs/chapters/03/06.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"id":"6","title":"Combinaison des strat\xe9gies","sidebar_label":"3.6 Combinaison des strat\xe9gies","sidebar_position":7,"slug":"/chapters/03/06","section_description":"No single strategy is a silver bullet. How can we sequence and layer these diverse approaches, from technical safeguards to global governance, into a cohesive, defense-in-depth roadmap for navigating AI risk?","reading_time_core":"4 min","reading_time_optional":"1 min","pagination_prev":"chapters/03/5","pagination_next":"chapters/03/7"},"sidebar":"docs","previous":{"title":"3.5 Strat\xe9gies Socio-Techniques","permalink":"/fr/chapters/03/05"},"next":{"title":"3.7 D\xe9fis","permalink":"/fr/chapters/03/07"}}');var i=t(4848),r=t(8453),a=(t(2482),t(8559),t(9585),t(2501));const o={id:6,title:"Combinaison des strat\xe9gies",sidebar_label:"3.6 Combinaison des strat\xe9gies",sidebar_position:7,slug:"/chapters/03/06",section_description:"No single strategy is a silver bullet. How can we sequence and layer these diverse approaches, from technical safeguards to global governance, into a cohesive, defense-in-depth roadmap for navigating AI risk?",reading_time_core:"4 min",reading_time_optional:"1 min",pagination_prev:"chapters/03/5",pagination_next:"chapters/03/7"},l="Combinaison des strat\xe9gies",u={},c=[];function d(e){const s={em:"em",h1:"h1",header:"header",p:"p",strong:"strong",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.header,{children:(0,i.jsx)(s.h1,{id:"combinaison-des-strat\xe9gies",children:"Combinaison des strat\xe9gies"})}),"\n",(0,i.jsx)(s.p,{children:"Les sections pr\xe9c\xe9dentes ont d\xe9crit un large \xe9ventail de strat\xe9gies, chacune ciblant diff\xe9rentes facettes du risque li\xe9 \xe0 l'IA. Synth\xe9tiser celles-ci en un plan unique et coh\xe9rent est une t\xe2che difficile. Cette section pr\xe9sente une s\xe9quence strat\xe9gique plausible, illustrant comment diff\xe9rentes couches de d\xe9fense pourraient \xeatre construites les unes sur les autres pour naviguer entre les risques \xe0 court terme et les d\xe9fis existentiels \xe0 long terme. Cette s\xe9quence est propos\xe9e comme un mod\xe8le illustratif, et non comme une feuille de route d\xe9finitive."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"\xc9tape 1 : Gestion des risques et gouvernance fondamentales."})," C'est le socle. Sans une culture de la s\xe9curit\xe9 et une gestion basique des risques, les solutions techniques ne seront pas correctement mises en \u0153uvre, et les laboratoires avanceront de mani\xe8re imprudente. La premi\xe8re \xe9tape commune est la mise en place de cadres robustes de gestion des risques et de gouvernance. Bien que les efforts existants comme le Code de Pratique de l'UE sur l'IA constituent un point de d\xe9part, ils pr\xe9sentent des limitations importantes. Par exemple, les amendes plafonn\xe9es (7% du chiffre d'affaires annuel d'une entreprise) peuvent ne pas suffisamment dissuader les acteurs bien dot\xe9s en ressources, et les exemptions de port\xe9e pour la recherche militaire ou interne laissent des vecteurs de risque critiques non trait\xe9s. Cela souligne la n\xe9cessit\xe9 d'une gouvernance internationale contraignante. Parvenir \xe0 une telle gouvernance n\xe9cessitera probablement de construire un large consensus public et politique autour de l'importance des mesures de s\xe9curit\xe9 proactives, faisant de la culture de la s\xe9curit\xe9 et de la sensibilisation du public un pr\xe9requis pour tous les autres efforts."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"\xc9tape 2 : Att\xe9nuation des utilisations catastrophiques."})," Nous nous attaquons ensuite aux utilisations abusives car c'est un danger pr\xe9sent et les capacit\xe9s requises sont sub-AGI. Le succ\xe8s ici (par exemple, via des contr\xf4les d'acc\xe8s et d/acc) nous fait gagner du temps et d\xe9veloppe les \"muscles\" soci\xe9taux pour gouverner des syst\xe8mes plus puissants. La deuxi\xe8me priorit\xe9 est l'att\xe9nuation des utilisations catastrophiques, un d\xe9fi qui est, du moins conceptuellement, plus g\xe9rable que l'alignement \xe0 long terme. La premi\xe8re ligne de d\xe9fense est un contr\xf4le d'acc\xe8s robuste pour les mod\xe8les qui d\xe9passent les seuils de risque \xe9tablis, emp\xeachant la suppression triviale des garanties des mod\xe8les open-source. Cependant, comme les capacit\xe9s dangereuses vont in\xe9vitablement prolif\xe9rer, cela doit \xeatre coupl\xe9 \xe0 une strat\xe9gie proactive d'acc\xe9l\xe9ration de la d\xe9fense (d/acc) pour renforcer l'infrastructure soci\xe9tale contre les attaques. Parall\xe8lement, les strat\xe9gies socio-techniques, y compris une l\xe9gislation claire, sont cruciales pour pr\xe9venir l'utilisation illicite de l'IA d\xe9j\xe0 prolif\xe9r\xe9e."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"\xc9tape 3 : Assurer le contr\xf4le et l'alignement de l'AGI."})," \xc0 l'approche de l'AGI, nous devons supposer que l'alignement n'est pas r\xe9solu. Par cons\xe9quent, la priorit\xe9 passe au contr\xf4le et \xe0 la surveillance (Pens\xe9es Transparentes, \xe9valuations). C'est notre filet de s\xe9curit\xe9. Nous augmentons les capacit\xe9s uniquement aussi vite que nous pouvons prouver le contr\xf4le. G\xe9rer les risques de d\xe9salignement de l'AGI est th\xe9oriquement plus difficile que g\xe9rer les utilisations abusives. Une approche prudente serait de privil\xe9gier les architectures qui favorisent les pens\xe9es transparentes, rendant les syst\xe8mes plus propices \xe0 la surveillance et \xe0 l'audit, tout en \xe9vitant les conceptions qui encouragent le raisonnement interne opaque (\"neuralese\"). Ces syst\xe8mes doivent \xeatre soumis \xe0 des protocoles de contr\xf4le et des \xe9valuations d'IA rigoureux. Si les audits r\xe9v\xe8lent des \xe9checs d'alignement, le d\xe9veloppement doit \xeatre interrompu jusqu'\xe0 leur rectification. Ce paradigme de contr\xf4le minutieux des syst\xe8mes potentiellement dangereux doit s'accompagner d'un effort de recherche intensifi\xe9 pour r\xe9soudre l'alignement, avec des lignes rouges claires sur l'augmentation des capacit\xe9s jusqu'\xe0 ce que les jalons de s\xe9curit\xe9 soient atteints."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"\xc9tape 4 : Une solution robuste pour l'alignement de l'ASI."})," Enfin, pour le saut surhumain, le contr\xf4le direct est probablement impossible. Mais la strat\xe9gie peut devenir m\xe9ta : utiliser notre AGI contr\xf4l\xe9e pour automatiser la recherche sur l'alignement. C'est notre meilleure chance d'obtenir une solution hautement fiable. Si cela \xe9choue, les strat\xe9gies g\xe9opolitiques comme la Coordination ou la Dissuasion deviennent les derni\xe8res lignes de d\xe9fense d\xe9sesp\xe9r\xe9es. D\xe9velopper une solution hautement fiable pour l'alignement de l'ASI est le saint Graal. Une strat\xe9gie principale est d'utiliser l'AGI contr\xf4l\xe9e pour automatiser la recherche sur l'alignement. En cas de succ\xe8s, cela pourrait conduire \xe0 la cr\xe9ation de syst\xe8mes intrins\xe8quement s\xfbrs par conception. Une ASI puissante et v\xe9ritablement align\xe9e pourrait alors \xeatre utilis\xe9e pour effectuer un \"acte pivot\", c'est-\xe0-dire une intervention d\xe9cisive con\xe7ue pour r\xe9soudre d\xe9finitivement le probl\xe8me de coordination mondiale et mettre fin \xe0 la p\xe9riode de risque aigu du d\xe9veloppement d'ASI non align\xe9e. Cependant, si cette recherche r\xe9v\xe8le que l'IA puissante ne peut pas \xeatre cr\xe9\xe9e sans risques inacceptables, la communaut\xe9 internationale devrait coordonner une pause ou un moratoire mondial. Si une telle coordination mondiale s'av\xe8re impossible, des strat\xe9gies de dernier recours, comme les r\xe9gimes de dissuasion tels que MAIM, pourraient devenir n\xe9cessaires pour emp\xeacher un acteur unique de d\xe9velopper unilat\xe9ralement une ASI incontr\xf4lable."]}),"\n",(0,i.jsx)(a.A,{src:"./img/Xab_Image_24.png",alt:"Entrer la description alternative de l'image",number:"24",label:"3.24",caption:"Un organigramme combin\xe9 des strat\xe9gies de s\xe9curit\xe9."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Bien s\xfbr, m\xeame ce plan fragile est le plan id\xe9al sur le papier. Il se pourrait que ce plan soit insuffisant ou compl\xe8tement diff\xe9rent."})," Par exemple, dans un sc\xe9nario de la pr\xe9vision IA-2027, l'humanit\xe9 survit non pas gr\xe2ce \xe0 un grand plan strat\xe9gique, mais malgr\xe9 l'\xe9chec de la plupart des efforts de gouvernance, de coordination et de dissuasion. Au lieu de cela, un \xe9v\xe9nement effrayant servant d'\"avertissement\" galvanise les principaux laboratoires pour ralentir et mettre en \u0153uvre juste assez de mesures techniques pour \xe9viter la catastrophe - des mesures qui s'av\xe8rent insuffisantes dans les branches de sc\xe9narios o\xf9 nous perdons le contr\xf4le."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.em,{children:(0,i.jsx)(s.strong,{children:"C'est l'\xe9tat de la s\xe9curit\xe9 de l'IA en 2025, et nous comptons sur notre lecteur pour rendre obsol\xe8te le contenu de ce chapitre bient\xf4t."})})})]})}function p(e={}){const{wrapper:s}={...(0,r.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);