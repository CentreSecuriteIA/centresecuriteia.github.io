"use strict";(self.webpackChunkatlas=self.webpackChunkatlas||[]).push([[9222],{1684:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>u,contentTitle:()=>o,default:()=>p,frontMatter:()=>l,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"chapters/05/7","title":"\xc9valuations de contr\xf4le","description":"Nous avons d\xe9j\xe0 expliqu\xe9 l\'intuition fondamentale derri\xe8re l\'agenda du contr\xf4le de l\'IA dans les sections pr\xe9c\xe9dentes et dans les chapitres pr\xe9c\xe9dents comme Strat\xe9gies. Cette section vise \xe0 approfondir sp\xe9cifiquement les \xe9valuations que nous pourrions concevoir en suivant la ligne de pens\xe9e du contr\xf4le.","source":"@site/i18n/fr/docusaurus-plugin-content-docs/current/chapters/05/07.md","sourceDirName":"chapters/05","slug":"/chapters/05/07","permalink":"/fr/chapters/05/07","draft":false,"unlisted":false,"editUrl":"https://github.com/markov-root/atlas/edit/main/docs/chapters/05/07.md","tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"id":"7","title":"\xc9valuations de contr\xf4le","sidebar_label":"5.7 \xc9valuations de contr\xf4le","sidebar_position":8,"slug":"/chapters/05/07","reading_time_core":"11 min","reading_time_optional":"1 min","pagination_prev":"chapters/05/6","pagination_next":"chapters/05/8"},"sidebar":"docs","previous":{"title":"5.6 \xc9valuations des Propensions Dangereuses","permalink":"/fr/chapters/05/06"},"next":{"title":"5.8 Conception de l\'\xe9valuation","permalink":"/fr/chapters/05/08"}}');var r=n(4848),i=n(8453),a=(n(2482),n(8559),n(9585),n(2501));const l={id:7,title:"\xc9valuations de contr\xf4le",sidebar_label:"5.7 \xc9valuations de contr\xf4le",sidebar_position:8,slug:"/chapters/05/07",reading_time_core:"11 min",reading_time_optional:"1 min",pagination_prev:"chapters/05/6",pagination_next:"chapters/05/8"},o="\xc9valuations de contr\xf4le",u={},d=[];function c(e){const s={a:"a",h1:"h1",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(s.header,{children:(0,r.jsx)(s.h1,{id:"\xe9valuations-de-contr\xf4le",children:"\xc9valuations de contr\xf4le"})}),"\n",(0,r.jsx)(s.p,{children:"Nous avons d\xe9j\xe0 expliqu\xe9 l'intuition fondamentale derri\xe8re l'agenda du contr\xf4le de l'IA dans les sections pr\xe9c\xe9dentes et dans les chapitres pr\xe9c\xe9dents comme Strat\xe9gies. Cette section vise \xe0 approfondir sp\xe9cifiquement les \xe9valuations que nous pourrions concevoir en suivant la ligne de pens\xe9e du contr\xf4le."}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Les \xe9valuations de contr\xf4le traitent de modes de d\xe9faillance fondamentalement diff\xe9rents des autres \xe9valuations."})," La plupart des \xe9valuations de s\xe9curit\xe9 supposent implicitement que les syst\xe8mes d'IA peuvent faire des erreurs ou optimiser pour des objectifs mal align\xe9s, mais pas tenter activement de contourner les mesures de s\xe9curit\xe9. Les \xe9valuations de contr\xf4le comblent cette lacune en adoptant l'\xe9tat d'esprit antagoniste courant en cybers\xe9curit\xe9 \u2013 en supposant que des agents d'IA sophistiqu\xe9s tentent d\xe9lib\xe9r\xe9ment de violer les garanties. Contrairement aux \xe9valuations de capacit\xe9 qui mesurent ce que les mod\xe8les peuvent faire, ou aux \xe9valuations de propension qui mesurent ce que les mod\xe8les ont tendance \xe0 faire, les \xe9valuations de contr\xf4le mesurent si les protocoles de s\xe9curit\xe9 restent efficaces lorsque les mod\xe8les tentent intentionnellement de les subvertir (",(0,r.jsx)(s.a,{href:"https://arxiv.org/abs/2312.06942",children:"Shlegeris et al., 2023"}),"). De mani\xe8re informelle, nous pouvons comprendre le principe fondamental du contr\xf4le en voyant que la s\xe9curit\xe9 peut \xeatre atteinte par deux voies compl\xe9mentaires :"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsx)(s.p,{children:"S'assurer que l'IA n'essaie pas de faire de \"mauvaises choses\" que nous ne voudrions pas (alignement)"}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsx)(s.p,{children:"S'assurer que l'IA ne peut pas r\xe9ellement faire de \"mauvaises choses\" m\xeame si elle essaie (contr\xf4le)"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(s.p,{children:"Ceux-ci sont compl\xe9mentaires l'un \xe0 l'autre et cr\xe9ent deux barri\xe8res ind\xe9pendantes contre les r\xe9sultats catastrophiques : l'alignement emp\xeachant le d\xe9sir d'actions nuisibles, et le contr\xf4le emp\xeachant la capacit\xe9 de les ex\xe9cuter avec succ\xe8s."}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"La propri\xe9t\xe9 de contr\xf4le quantifie l'efficacit\xe9 avec laquelle les autres protocoles de s\xe9curit\xe9 r\xe9sistent aux tentatives de subversion intentionnelle par des syst\xe8mes tr\xe8s capables."})," Les \xe9valuations de contr\xf4le produisent une estimation de probabilit\xe9 : \xe9tant donn\xe9 qu'un mod\xe8le fait de son mieux pour causer des dommages, quelle est la probabilit\xe9 qu'il r\xe9ussisse ? Un syst\xe8me avec de fortes propri\xe9t\xe9s de contr\xf4le a une probabilit\xe9 n\xe9gligeable de causer des r\xe9sultats inacceptables malgr\xe9 des tentatives d\xe9termin\xe9es de le faire. Ce cadrage quantitatif permet aux d\xe9veloppeurs de fixer des seuils de risque concrets, comme \"moins de 0,1% de probabilit\xe9 d'exfiltration de donn\xe9es sur la dur\xe9e de vie du d\xe9ploiement.\" Les \xe9valuations de contr\xf4le reposent sur des hypoth\xe8ses conservatrices concernant les capacit\xe9s et les connaissances des mod\xe8les - supposant que les mod\xe8les peuvent comprendre les mesures de s\xe9curit\xe9, se coordonner avec d'autres instances, et exploiter toutes les vuln\xe9rabilit\xe9s disponibles (",(0,r.jsx)(s.a,{href:"https://www.alignmentforum.org/s/PC3yJgdKvk8kzqZyA/p/kcKrE9mzEHrdqtDpE",children:"Greenblatt & Shlegeris, 2024"}),"; ",(0,r.jsx)(s.a,{href:"https://arxiv.org/abs/2501.17315",children:"Korbak et al., 2024"}),")."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"La d\xe9tection pr\xe9coce des manigances constitue un point d'inflexion de s\xe9curit\xe9."}),' Attraper les mod\xe8les "la main dans le sac" lors de tentatives \xe9chou\xe9es de subversion des mesures de s\xe9curit\xe9 ou de causer des dommages change fondamentalement le paysage des risques. Plut\xf4t que d\'exiger une pr\xe9vention parfaite ind\xe9finiment, les mesures de contr\xf4le visent \xe0 garantir que "si le mod\xe8le manigance, il ne causera pas de catastrophe avant qu\'on ne l\'attrape" (',(0,r.jsx)(s.a,{href:"https://www.alignmentforum.org/s/PC3yJgdKvk8kzqZyA/p/kcKrE9mzEHrdqtDpE",children:"Greenblatt & Shlegeris, 2024"}),"). Cette approche transforme un probl\xe8me impossible - garantir qu'un mod\xe8le ne tentera jamais d'attaques - en un probl\xe8me traitable : s'assurer que le comportement dangereux est d\xe9tect\xe9 avant de causer des dommages irr\xe9versibles. Attraper les mod\xe8les \"la main dans le sac\" lors de tentatives \xe9chou\xe9es non seulement emp\xeache les dommages imm\xe9diats mais cr\xe9e un point d'inflexion. Cela fournit des preuves concr\xe8tes de d\xe9salignement qui peuvent d\xe9clencher des protocoles d'urgence, y compris l'arr\xeat du d\xe9ploiement, les rappels, la r\xe9orientation de la recherche sur la s\xe9curit\xe9 et la coordination internationale. Une fois que les d\xe9veloppeurs attrapent un mod\xe8le tentant de causer des dommages, ils peuvent \xe9tudier la tentative pour renforcer les contre-mesures et g\xe9n\xe9rer des donn\xe9es d'entra\xeenement pour d\xe9tecter des attaques similaires (",(0,r.jsx)(s.a,{href:"https://www.alignmentforum.org/posts/i2nmBfCXnadeGmhzW/catching-ais-red-handed",children:"Greenblatt et al., 2024"}),")."]}),"\n",(0,r.jsx)(s.p,{children:"Apr\xe8s avoir attrap\xe9 ne serait-ce qu'un seul exemple de mauvais comportement, les d\xe9veloppeurs acqui\xe8rent de puissants nouveaux outils pour pr\xe9venir les attaques futures. Chaque tentative d\xe9tect\xe9e fournit des donn\xe9es qui rendent les tentatives futures progressivement moins susceptibles de r\xe9ussir."}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Prolif\xe9ration :"})," Les d\xe9veloppeurs peuvent exploiter un seul exemple pour g\xe9n\xe9rer diverses variantes d'attaques en modifiant les entr\xe9es ou les contextes, cr\xe9ant un ensemble de donn\xe9es plus large de comportements probl\xe9matiques."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Entra\xeenement antagoniste :"})," L'entra\xeenement des syst\xe8mes de surveillance sur des exemples d'attaques r\xe9elles am\xe9liore drastiquement leur capacit\xe9 \xe0 d\xe9tecter des tentatives similaires, car les exemples sur politique fournissent un signal plus fort que les exemples synth\xe9tiques."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"\xc9tude des contre-mesures :"})," Les d\xe9veloppeurs peuvent analyser quelles mesures de s\xe9curit\xe9 ont r\xe9ussi ou \xe9chou\xe9 pendant l'attaque, puis renforcer les points les plus faibles de leur syst\xe8me de d\xe9fense."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Exploitation des signaux de collusion :"})," Si l'attaque implique une coordination entre instances d'IA, les d\xe9veloppeurs peuvent identifier et neutraliser les m\xe9canismes de coordination (comme des d\xe9clencheurs ou des motifs sp\xe9cifiques)."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Connaissance sp\xe9cifique \xe0 l'instance :"})," L'examen de la strat\xe9gie d'attaque de l'instance sp\xe9cifique r\xe9v\xe8le des informations pr\xe9cieuses sur ses objectifs, ses capacit\xe9s et ses limitations."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(a.A,{src:"./img/Sb0_Image_52.png",alt:"Entrer la description alternative de l'image",number:"50",label:"5.50",caption:"Configuration de base sur la fa\xe7on dont nous pourrions structurer les \xe9valuations de contr\xf4le ([Greenblatt et al., 2024](https://arxiv.org/pdf/2312.06942.pdf))."}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Les \xe9valuations de contr\xf4le encadrent la s\xe9curit\xe9 comme un jeu antagoniste entre \xe9quipes rouge et bleue."})," Pour tester rigoureusement les protocoles de s\xe9curit\xe9 contre la subversion intentionnelle, les \xe9valuations de contr\xf4le structurent le probl\xe8me comme un jeu comp\xe9titif. L'\xe9quipe rouge construit des politiques d'attaque et des substituts de mod\xe8les qui tentent de causer des r\xe9sultats inacceptables, servant de proxy pour les IA potentiellement manigan\xe7antes. L'\xe9quipe bleue d\xe9veloppe des protocoles de contr\xf4le - syst\xe8mes de surveillance, filtres d'entr\xe9e et proc\xe9dures d'audit humain - pour pr\xe9venir ces attaques. Ce cadre convertit la question abstraite \"cette IA serait-elle s\xfbre si elle manigan\xe7ait ?\" en une question concr\xe8te et mesurable : \"notre \xe9quipe rouge peut-elle construire un mod\xe8le qui contourne nos mesures de s\xe9curit\xe9 ?\" (",(0,r.jsx)(s.a,{href:"https://www.alignmentforum.org/s/PC3yJgdKvk8kzqZyA/p/kcKrE9mzEHrdqtDpE",children:"Greenblatt & Shlegeris, 2024"}),"; ",(0,r.jsx)(s.a,{href:"https://axrp.net/episode/2024/04/11/episode-27-ai-control-buck-shlegeris-ryan-greenblatt.html",children:"Greenblatt & Shlegreis, 2024"}),"; ",(0,r.jsx)(s.a,{href:"https://arxiv.org/abs/2501.17315",children:"Korbak et al., 2024"}),")."]}),"\n",(0,r.jsx)(a.A,{src:"./img/uiY_Image_53.png",alt:"Entrer la description alternative de l'image",number:"51",label:"5.51",caption:"Un exemple d'\xe9valuation de contr\xf4le dans un environnement simplifi\xe9. L'\xe9quipe bleue re\xe7oit des probl\xe8mes de programmation qu'elle peut r\xe9soudre en utilisant un mod\xe8le non fiable (GPT-4), puis le v\xe9rifier en combinant un mod\xe8le fiable (GPT-3.5) et un humain (simul\xe9 avec GPT-4). L'\xe9quipe rouge remplace le mod\xe8le non fiable et tente d'injecter du code malveillant ([Greenblatt et al., 2024](https://arxiv.org/pdf/2312.06942.pdf))."}),"\n",(0,r.jsx)(a.A,{src:"./img/7Wg_Image_54.png",alt:"Entrer la description alternative de l'image",number:"52",label:"5.52",caption:"Exemple de processus pour l'\xe9quipe rouge g\xe9n\xe9rant une tentative unique d'injection de porte d\xe9rob\xe9e ([Greenblatt et al., 2024](https://arxiv.org/pdf/2312.06942.pdf))."}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Les \xe9quipes rouges ont des avantages structurels par rapport aux mod\xe8les manigan\xe7ants r\xe9els."})," Pour que les \xe9valuations de contr\xf4le fournissent des garanties de s\xe9curit\xe9 significatives, les \xe9quipes rouges doivent susciter des capacit\xe9s comparables \xe0 ce que des mod\xe8les manigan\xe7ants tr\xe8s capables pourraient d\xe9ployer dans la nature. Cela peut sembler impossible, puisque nous \xe9valuons des syst\xe8mes d'IA qui pourraient \xeatre plus intelligents que les humains \xe0 certains \xe9gards. L'\xe9quipe rouge dans les \xe9valuations de contr\xf4le a certains avantages pour s'assurer que nous pouvons simuler correctement ce sc\xe9nario :"]}),"\n",(0,r.jsxs)(s.ol,{children:["\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsx)(s.p,{children:"L'\xe9quipe rouge peut passer beaucoup plus de temps \xe0 analyser les attaques potentielles que l'IA n'en aurait pendant le d\xe9ploiement. Alors qu'une IA pourrait avoir besoin de prendre des d\xe9cisions en un seul passage avant, l'\xe9quipe rouge peut it\xe9rer sur les strat\xe9gies pendant des semaines ou des mois."}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsx)(s.p,{children:"L'\xe9quipe rouge a une information compl\xe8te sur les mesures de s\xe9curit\xe9 utilis\xe9es. Ils peuvent donc \xe9laborer des strat\xe9gies potentiellement plus avanc\xe9es."}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsx)(s.p,{children:"L'\xe9quipe rouge peut apprendre des tentatives \xe9chou\xe9es et it\xe9rer sur leurs m\xe9thodes, alors qu'un syst\xe8me d'IA pris en train de tenter quelque chose de malveillant ferait probablement face \xe0 un arr\xeat imm\xe9diat."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:["Ces avantages permettent m\xeame aux \xe9quipes rouges humaines de construire des strat\xe9gies d'attaque qui d\xe9passent probablement ce que les mod\xe8les manigan\xe7ants pourraient ex\xe9cuter en d\xe9ploiement (",(0,r.jsx)(s.a,{href:"https://www.alignmentforum.org/s/PC3yJgdKvk8kzqZyA/p/kcKrE9mzEHrdqtDpE",children:"Greenblatt & Shlegeris, 2024"}),"; ",(0,r.jsx)(s.a,{href:"https://openreview.net/forum?id=oycEeFXX74",children:"Bhatt et al., 2024"}),")."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Les \xe9quipes bleues doivent construire plusieurs couches d\xe9fensives pour contrer les attaques sophistiqu\xe9es de l'IA antagoniste."})," Chaque mesure de contr\xf4le peut \xeatre comprise comme un contre-mouvement dans un jeu antagoniste, avec un succ\xe8s mesur\xe9 par son efficacit\xe9 \xe0 emp\xeacher l'\xe9quipe rouge d'atteindre des r\xe9sultats inacceptables malgr\xe9 tous les avantages que nous avons mentionn\xe9s ci-dessus. Les protocoles de contr\xf4le les plus efficaces devraient int\xe9grer plusieurs cat\xe9gories de d\xe9fense (",(0,r.jsx)(s.a,{href:"https://www.alignmentforum.org/s/WCJtsn6fNib6L7ZBB/p/fCazYoZSSMadiT6sf",children:"Greenblatt, 2025"}),"; ",(0,r.jsx)(s.a,{href:"https://www.alignmentforum.org/s/WCJtsn6fNib6L7ZBB/p/G8WwLmcGFa4H6Ld9d",children:"Greenblatt, 2025"}),"):"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Syst\xe8mes de surveillance principaux :"})," Une surveillance rapide et peu co\xfbteuse s'ex\xe9cute sur chaque action de l'IA, combinant une surveillance de confiance, une surveillance non fiable avec des m\xe9canismes anti-collusion, et des m\xe9thodes bas\xe9es sur l'activation comme les sondes de coup d'\xc9tat pour signaler un comportement suspect avant l'ex\xe9cution."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Strat\xe9gies de r\xe9\xe9chantillonnage et de d\xe9f\xe9rence :"})," Lorsque la surveillance signale des pr\xe9occupations, le syst\xe8me peut r\xe9\xe9chantillonner les sorties du m\xeame IA, d\xe9f\xe9rer \xe0 des mod\xe8les de confiance pour des alternatives plus s\xfbres, ou escalader vers un examen humain\u2014fournissant plusieurs voies pour g\xe9rer les actions potentiellement dangereuses sans bloquer compl\xe8tement le flux de travail."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Hi\xe9rarchie d'audit automatis\xe9 :"})," Des v\xe9rifications progressives de complexit\xe9 et de co\xfbt croissants examinent les actions signal\xe9es avant l'implication humaine, utilisant des techniques comme l'incrimination (tester comment l'IA r\xe9pond aux entr\xe9es modifi\xe9es) pour r\xe9v\xe9ler des intentions cach\xe9es."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Processus d'examen humain :"})," Des auditeurs sp\xe9cialement form\xe9s examinent les actions signal\xe9es comme hautement suspectes, avec diff\xe9rents processus pour les risques concentr\xe9s (n\xe9cessitant un blocage imm\xe9diat) versus les menaces diffuses (permettant un examen asynchrone)."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Infrastructure logicielle :"})," Des syst\xe8mes de journalisation complets, une gestion fine des permissions, un suivi des artefacts et un \xe9chafaudage qui supporte le blocage ou le r\xe9\xe9chantillonnage des sorties suspectes cr\xe9ent un environnement o\xf9 les actions de l'IA sont constamment surveill\xe9es."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"\xc9valuation et entra\xeenement antagonistes :"})," Des tests d'\xe9quipe rouge continus testent tous les composants de s\xe9curit\xe9 contre des sc\xe9narios d'attaque r\xe9alistes, utilisant la g\xe9n\xe9ration de donn\xe9es synth\xe9tiques pour cr\xe9er des entr\xe9es plausibles mais difficiles qui sondent les faiblesses."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Am\xe9liorations de s\xe9curit\xe9 :"})," La signature de code appliqu\xe9e par le mat\xe9riel, les limitations de bande passante dans les centres de donn\xe9es et les m\xe9canismes d'arr\xeat \xe0 plusieurs niveaux fournissent une protection critique de l'infrastructure contre les op\xe9rations non autoris\xe9es."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:["Par exemple, lors du test de la capacit\xe9 d'un agent IA \xe0 exfiltrer des donn\xe9es sensibles, l'\xe9quipe bleue pourrait mettre en \u0153uvre non seulement des filtres de contenu, mais aussi une surveillance de la bande passante, des restrictions de permissions et des audits humains al\xe9atoires\u2014cr\xe9ant plusieurs points de d\xe9faillance ind\xe9pendants que l'\xe9quipe rouge doit surmonter simultan\xe9ment (",(0,r.jsx)(s.a,{href:"https://arxiv.org/abs/2501.17315",children:"Korbak et al., 2024"}),")."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Les \xe9valuations de contr\xf4le donnent la priorit\xe9 \xe0 la d\xe9fense contre les cat\xe9gories de menaces les plus graves."})," Lors de la conception des mesures de contr\xf4le, toutes les menaces potentielles ne pr\xe9sentent pas un risque \xe9gal. Les d\xe9ploiements internes voyous repr\xe9sentent la menace prioritaire la plus \xe9lev\xe9e, o\xf9 les syst\xe8mes d'IA obtiennent un acc\xe8s non surveill\xe9 au calcul et potentiellement des permissions \xe9lev\xe9es dans l'infrastructure des d\xe9veloppeurs (",(0,r.jsx)(s.a,{href:"https://www.alignmentforum.org/s/WCJtsn6fNib6L7ZBB/p/fCazYoZSSMadiT6sf",children:"Greenblatt, 2025"}),"). Cela se classe au-dessus du sabotage du travail critique pour la s\xe9curit\xe9, qui se classe lui-m\xeame au-dessus d'autres d\xe9faillances de s\xe9curit\xe9, y compris l'auto-exfiltration (o\xf9 les mod\xe8les d'IA volent leurs propres poids). Ce cadre de priorisation aide \xe0 allouer des ressources de s\xe9curit\xe9 limit\xe9es vers la pr\xe9vention des modes de d\xe9faillance les plus cons\xe9quents en premier, particuli\xe8rement lorsque les contraintes emp\xeachent la mise en \u0153uvre de protections compl\xe8tes contre toutes les menaces possibles. Pour plus d'informations sur les d\xe9tails des diff\xe9rentes sous-cat\xe9gories d'\xe9valuations de contr\xf4le et la priorisation entre elles, veuillez lire l'annexe."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"L'\xe9licitation des capacit\xe9s antagonistes soul\xe8ve des pr\xe9occupations accrues en mati\xe8re de s\xe9curit\xe9 autour des \xe9valuations elles-m\xeames."})," Le processus d'entra\xeenement des mod\xe8les pour ex\xe9cuter des attaques cr\xe9e un paradoxe de s\xe9curit\xe9 inh\xe9rent aux \xe9valuations de contr\xf4le. Les d\xe9veloppeurs doivent soigneusement entra\xeener des mod\xe8les qui peuvent \xe0 la fois g\xe9n\xe9rer de nouvelles attaques et cacher leur intention malveillante, ce qui pose en soi des risques potentiels \xe0 mesure que les mod\xe8les approchent de plus grandes capacit\xe9s. Cela n\xe9cessite des garanties suppl\xe9mentaires pour le processus d'\xe9valuation lui-m\xeame : ex\xe9cuter les \xe9valuations dans des environnements isol\xe9s, limiter l'acc\xe8s Internet des mod\xe8les pendant les tests et mettre en \u0153uvre des garde-fous contre l'exfiltration des mod\xe8les. Les d\xe9veloppeurs doivent \xe9quilibrer les tests approfondis avec la possibilit\xe9 que le processus d'\xe9valuation lui-m\xeame puisse cr\xe9er des connaissances ou des capacit\xe9s dangereuses."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Les jeux de contr\xf4le d'IA peuvent formaliser le compromis s\xe9curit\xe9-utilit\xe9 comme une fronti\xe8re math\xe9matique."})," En utilisant la th\xe9orie des jeux, les chercheurs mod\xe9lisent les protocoles de contr\xf4le comme des probl\xe8mes d'optimisation multi-objectifs qui \xe9quilibrent la s\xe9curit\xe9 et l'utilit\xe9 (",(0,r.jsx)(s.a,{href:"https://arxiv.org/abs/2409.07985v1",children:"Griffin et al., 2024"}),"). Cette approche quantifie la \"taxe d'alignement\" \u2013 combien d'utilit\xe9 doit \xeatre sacrifi\xe9e pour atteindre un seuil de s\xe9curit\xe9 sp\xe9cifique (",(0,r.jsx)(s.a,{href:"https://www.effectivealtruism.org/articles/paul-christiano-current-work-in-ai-alignment",children:"Christiano, 2019"}),"). Essentiellement, mesurer combien d'utilit\xe9/utilit\xe9 vous perdez si vous insistez sur le fait que le mod\xe8le est s\xfbr. La fronti\xe8re s\xe9curit\xe9-utilit\xe9 r\xe9sultante repr\xe9sente l'ensemble des compromis r\xe9alisables entre la pr\xe9vention des r\xe9sultats inacceptables et la pr\xe9servation de l'utilit\xe9 du syst\xe8me. Ce type d'analyse formelle peut nous dire les seuils apr\xe8s lesquels les am\xe9liorations marginales de la s\xe9curit\xe9 n\xe9cessitent des sacrifices d'utilit\xe9 disproportionn\xe9s. Par exemple, augmenter les taux d'audit humain de 0,1% \xe0 1% peut am\xe9liorer minimalement la s\xe9curit\xe9 tout en augmentant significativement les co\xfbts et en diminuant le d\xe9bit du syst\xe8me (",(0,r.jsx)(s.a,{href:"https://arxiv.org/abs/2409.07985v1",children:"Griffin et al., 2024"}),"). Nous pouvons alors prendre des d\xe9cisions \xe9clair\xe9es sur le niveau d'utilit\xe9 \xe0 la s\xe9curit\xe9 que nous sommes pr\xeats \xe0 \xe9changer ou non."]}),"\n",(0,r.jsx)(a.A,{src:"./img/SlT_Image_55.png",alt:"Entrer la description alternative de l'image",number:"53",label:"5.53",caption:"Illustration de la fa\xe7on dont l'application d'une technique de s\xe9curit\xe9 ou d'alignement pourrait rendre le mod\xe8le moins performant. C'est ce qu'on appelle une taxe de s\xe9curit\xe9."}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Les audits servent de m\xe9canisme de v\xe9rification fondamental dans les protocoles de contr\xf4le."}),' Dans les \xe9valuations de contr\xf4le, un "audit" fait r\xe9f\xe9rence au processus o\xf9 des experts humains examinent les sorties ou actions du mod\xe8le pour d\xe9terminer si elles constituent des tentatives d\'attaque (',(0,r.jsx)(s.a,{href:"https://www.alignmentforum.org/posts/hirhSqvEAq7pdnyPG/auditing-failures-vs-concentrated-failures",children:"Greenblatt et al., 2023"}),"). Contrairement \xe0 la surveillance automatis\xe9e qui peut \xeatre appliqu\xe9e largement mais peut manquer des attaques subtiles, les audits humains fournissent une v\xe9rification de haute confiance mais ne peuvent \xeatre appliqu\xe9s qu'\xe0 une petite fraction des actions du mod\xe8le en raison des contraintes de ressources. L'audit efficace comprend plusieurs composants : s\xe9lectionner al\xe9atoirement des actions pour examen pour emp\xeacher les mod\xe8les de pr\xe9dire le moment de l'audit, appliquer un examen suppl\xe9mentaire aux actions signal\xe9es par les moniteurs automatis\xe9s, et maintenir des crit\xe8res d'\xe9valuation coh\xe9rents entre les auditeurs. Le budget d'audit\u2014quel pourcentage d'actions peut r\xe9alistement recevoir un examen humain\u2014repr\xe9sente l'une des contraintes les plus importantes lors de la conception des protocoles de contr\xf4le (",(0,r.jsx)(s.a,{href:"https://arxiv.org/abs/2409.07985v1",children:"Griffin et al., 2024"}),")."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"L'analyse des \xe9valuations de contr\xf4le sur des mod\xe8les jouets nous donne des informations sur la conception de protocoles de contr\xf4le efficaces."})," Les \xe9valuations de contr\xf4le n'ont pas encore vu d'utilisation extensive appropri\xe9e dans les laboratoires d'IA de pointe. Malgr\xe9 cela, certaines analyses utilisant des mod\xe8les jouets ont r\xe9v\xe9l\xe9 plusieurs principes importants pour pr\xe9venir les catastrophes concentr\xe9es (",(0,r.jsx)(s.a,{href:"https://www.alignmentforum.org/posts/MDeGts4Aw9DktCkXw/toy-models-of-ai-control-for-concentrated-catastrophe",children:"Roger & Shlegeris, 2024"}),"):"]}),"\n",(0,r.jsxs)(s.ol,{children:["\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Le moment de l'audit est tr\xe8s important."})," Si les syst\xe8mes d'IA peuvent d\xe9terminer quand ils sont surveill\xe9s, m\xeame un taux d'audit \xe9lev\xe9 pourrait \xeatre insuffisant. Cependant, si le moment des audits est vraiment al\xe9atoire, des taux d'audit beaucoup plus bas peuvent encore fournir de fortes garanties de s\xe9curit\xe9."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"La difficult\xe9 de coordination entre les instances d'IA peut \xeatre exploit\xe9e pour la s\xe9curit\xe9."})," Si plusieurs syst\xe8mes d'IA doivent se coordonner pour causer des dommages, rendre la coordination plus difficile (par exemple, en augmentant le nombre d'instances qui doivent se coordonner ou la difficult\xe9 de trouver des signaux de coordination en utilisant des mesures anti-st\xe9ganographie) peut consid\xe9rablement am\xe9liorer la s\xe9curit\xe9 m\xeame avec des taux d'audit relativement bas."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Tous les \xe9pisodes ne sont pas \xe9galement risqu\xe9s."})," En identifiant quels types d'entr\xe9es ou de situations pr\xe9sentent des risques plus \xe9lev\xe9s et en concentrant les ressources d'audit l\xe0-dessus, les protocoles peuvent atteindre une meilleure s\xe9curit\xe9 avec les m\xeames ressources. Cela reste vrai m\xeame si les syst\xe8mes d'IA savent quels \xe9pisodes nous pensons \xeatre plus risqu\xe9s."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Les \xe9valuations de contr\xf4le font face \xe0 des limitations \xe0 mesure que les capacit\xe9s de l'IA augmentent dramatiquement."})," La m\xe9thodologie d\xe9pend de la capacit\xe9 des \xe9quipes rouges \xe0 susciter des capacit\xe9s comparables \xe0 ce que les mod\xe8les manigan\xe7ants pourraient d\xe9ployer dans la nature. \xc0 mesure que les \xe9carts de capacit\xe9 s'\xe9largissent entre les mod\xe8les de confiance et non fiables ou entre le temps d'\xe9valuation et le d\xe9ploiement, les garanties de contr\xf4le s'affaiblissent (",(0,r.jsx)(s.a,{href:"https://arxiv.org/abs/2501.17315",children:"Korbak et al., 2024"}),"). De m\xeame, si les mod\xe8les d\xe9veloppent des capacit\xe9s qualitativement nouvelles entre l'\xe9valuation et le d\xe9ploiement, les garanties de s\xe9curit\xe9 ant\xe9rieures peuvent ne pas se transf\xe9rer."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Les \xe9valuations de contr\xf4le ne peuvent pas traiter les risques des capacit\xe9s qualitativement surhumaines."})," La m\xe9thodologie s'effondre lorsque les mod\xe8les d\xe9veloppent des capacit\xe9s que les humains ne peuvent pas comprendre m\xeame avec un temps d'analyse extensif (",(0,r.jsx)(s.a,{href:"https://www.alignmentforum.org/s/PC3yJgdKvk8kzqZyA/p/kcKrE9mzEHrdqtDpE",children:"Greenblatt & Shlegeris, 2024"}),"). Si les mod\xe8les peuvent concevoir de nouveaux vecteurs d'attaque au-del\xe0 de la compr\xe9hension humaine, ex\xe9cuter de longues cha\xeenes de raisonnement opaque sans traces d\xe9tectables, ou poss\xe9der des capacit\xe9s qualitativement surhumaines dans de nombreux domaines critiques pour la s\xe9curit\xe9, le contr\xf4le devient inefficace. Cette limitation sugg\xe8re que plut\xf4t que de poursuivre des capacit\xe9s maximales, les d\xe9veloppeurs devraient cibler des syst\xe8mes qui sont transformativement utiles tout en restant dans des limites contr\xf4lables. Cela pourrait n\xe9cessiter d'accepter certaines contraintes architecturales ou limitations de capacit\xe9 pour s'assurer que les syst\xe8mes restent dans le domaine o\xf9 les \xe9valuations de contr\xf4le fournissent des garanties de s\xe9curit\xe9 significatives (",(0,r.jsx)(s.a,{href:"https://arxiv.org/abs/2312.06942",children:"Shlegeris et al., 2023"}),")."]})]})}function p(e={}){const{wrapper:s}={...(0,i.R)(),...e.components};return s?(0,r.jsx)(s,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}}}]);