"use strict";(self.webpackChunkatlas=self.webpackChunkatlas||[]).push([[2975],{4495:(e,s,t)=>{t.r(s),t.d(s,{assets:()=>p,contentTitle:()=>d,default:()=>g,frontMatter:()=>u,metadata:()=>n,toc:()=>m});const n=JSON.parse('{"id":"chapters/03/5","title":"Strat\xe9gies Socio-Techniques","description":"La s\xe9curit\xe9 de l\'IA est un probl\xe8me socio-technique qui n\xe9cessite des solutions socio-techniques. Assurer la s\xe9curit\xe9 de l\'IA requiert \xe9galement des approches syst\xe9miques robustes. Celles-ci englobent les structures de gouvernance, les pratiques organisationnelles et les normes culturelles qui fa\xe7onnent le d\xe9veloppement et le d\xe9ploiement de l\'IA. Les mesures de s\xe9curit\xe9 techniques peuvent \xeatre compromises par une gouvernance inad\xe9quate, de mauvaises pratiques de s\xe9curit\xe9 au sein des laboratoires, ou une culture qui privil\xe9gie la vitesse plut\xf4t que la prudence. Cette section examine les strat\xe9gies visant \xe0 int\xe9grer la s\xe9curit\xe9 dans l\'\xe9cosyst\xe8me plus large entourant l\'IA. Aborder les risques syst\xe9miques pos\xe9s par l\'IA n\'est pas facile. Cela n\xe9cessite une collaboration multidisciplinaire continue et la r\xe9solution de jeux de coordination complexes. Le fait que la responsabilit\xe9 du probl\xe8me soit si diverse rend difficile la mise en \u0153uvre des solutions.","source":"@site/i18n/fr/docusaurus-plugin-content-docs/current/chapters/03/05.md","sourceDirName":"chapters/03","slug":"/chapters/03/05","permalink":"/fr/chapters/03/05","draft":false,"unlisted":false,"editUrl":"https://github.com/markov-root/atlas/edit/main/docs/chapters/03/05.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"id":"5","title":"Strat\xe9gies Socio-Techniques","sidebar_label":"3.5 Strat\xe9gies Socio-Techniques","sidebar_position":6,"slug":"/chapters/03/05","section_description":"Technical solutions alone are insufficient. Can we create governance frameworks, cultural norms, and a safety-conscious ecosystem for robust and resilient AI development?","reading_time_core":"13 min","reading_time_optional":"8 min","pagination_prev":"chapters/03/4","pagination_next":"chapters/03/6"},"sidebar":"docs","previous":{"title":"3.4 Strat\xe9gies de s\xe9curit\xe9 pour l\'ASI","permalink":"/fr/chapters/03/04"},"next":{"title":"3.6 Combinaison des strat\xe9gies","permalink":"/fr/chapters/03/06"}}');var i=t(4848),r=t(8453),a=t(4768),l=t(2482),o=t(8559),c=(t(9585),t(2501));const u={id:5,title:"Strat\xe9gies Socio-Techniques",sidebar_label:"3.5 Strat\xe9gies Socio-Techniques",sidebar_position:6,slug:"/chapters/03/05",section_description:"Technical solutions alone are insufficient. Can we create governance frameworks, cultural norms, and a safety-conscious ecosystem for robust and resilient AI development?",reading_time_core:"13 min",reading_time_optional:"8 min",pagination_prev:"chapters/03/4",pagination_next:"chapters/03/6"},d="Strat\xe9gies socio-techniques",p={},m=[{value:"Acc\xe9l\xe9ration d\xe9fensive (d/acc)",id:"01",level:2},{value:"D\xe9fense en profondeur",id:"02",level:2},{value:"Gouvernance de l&#39;IA",id:"03",level:2},{value:"Gestion des risques",id:"04",level:2},{value:"Culture de la s\xe9curit\xe9",id:"05",level:2}];function h(e){const s={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components},{GlossaryTerm:t}=s;return t||function(e,s){throw new Error("Expected "+(s?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("GlossaryTerm",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.header,{children:(0,i.jsx)(s.h1,{id:"strat\xe9gies-socio-techniques",children:"Strat\xe9gies socio-techniques"})}),"\n",(0,i.jsx)(s.p,{children:"La s\xe9curit\xe9 de l'IA est un probl\xe8me socio-technique qui n\xe9cessite des solutions socio-techniques. Assurer la s\xe9curit\xe9 de l'IA requiert \xe9galement des approches syst\xe9miques robustes. Celles-ci englobent les structures de gouvernance, les pratiques organisationnelles et les normes culturelles qui fa\xe7onnent le d\xe9veloppement et le d\xe9ploiement de l'IA. Les mesures de s\xe9curit\xe9 techniques peuvent \xeatre compromises par une gouvernance inad\xe9quate, de mauvaises pratiques de s\xe9curit\xe9 au sein des laboratoires, ou une culture qui privil\xe9gie la vitesse plut\xf4t que la prudence. Cette section examine les strat\xe9gies visant \xe0 int\xe9grer la s\xe9curit\xe9 dans l'\xe9cosyst\xe8me plus large entourant l'IA. Aborder les risques syst\xe9miques pos\xe9s par l'IA n'est pas facile. Cela n\xe9cessite une collaboration multidisciplinaire continue et la r\xe9solution de jeux de coordination complexes. Le fait que la responsabilit\xe9 du probl\xe8me soit si diverse rend difficile la mise en \u0153uvre des solutions."}),"\n",(0,i.jsx)(c.A,{src:"./img/csC_Image_19.png",alt:"Entrer la description alternative de l'image",number:"19",label:"3.19",caption:"Une illustration d'un cadre que nous pensons \xeatre robustement efficace pour g\xe9rer les risques. Les risques li\xe9s \xe0 l'IA sont trop nombreux et trop h\xe9t\xe9rog\xe8nes. Pour faire face \xe0 ces risques, nous avons besoin d'un cadre adaptatif qui peut \xeatre robuste et \xe9voluer au fur et \xe0 mesure des avanc\xe9es de l'IA."}),"\n",(0,i.jsx)(s.h2,{id:"01",children:"Acc\xe9l\xe9ration d\xe9fensive (d/acc)"}),"\n",(0,i.jsx)(l.A,{speaker:"Vitalik Buterin",position:"Cofondateur d'Ethereum",date:"2017",source:"([Buterin, 2023](https://vitalik.eth.limo/general/2025/01/05/dacc2.html))",children:(0,i.jsx)(s.p,{children:"\xcatre int\xe8gre \xe0 une \xe9poque o\xf9 une grande partie du monde devient tribale, et ne pas se contenter de construire n'importe quoi - nous voulons plut\xf4t construire des choses sp\xe9cifiques qui rendent le monde plus s\xfbr et meilleur."})}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"L'acc\xe9l\xe9ration d\xe9fensive (d/acc) est une approche strat\xe9gique qui donne la priorit\xe9 aux technologies renfor\xe7ant la d\xe9fense et la r\xe9silience sociale face aux risques li\xe9s \xe0 l'IA."})," L'acc\xe9l\xe9ration d\xe9fensive, ou d/acc, est apparue comme une approche strat\xe9gique en 2023 comme une voie m\xe9diane entre l'acc\xe9l\xe9ration sans restriction (acc\xe9l\xe9rationnisme effectif (e/acc)) et les techno-pessimistes/catastrophistes (",(0,i.jsx)(s.a,{href:"https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html",children:"Buterin, 2023"}),";",(0,i.jsx)(s.a,{href:"https://vitalik.eth.limo/general/2025/01/05/dacc2.html",children:" Buterin, 2025"}),"). Plut\xf4t que de s'appuyer uniquement sur la restriction d'acc\xe8s aux capacit\xe9s potentiellement dangereuses, la d/acc propose d'acc\xe9l\xe9rer uniquement les technologies qui favorisent intrins\xe8quement la d\xe9fense par rapport \xe0 l'attaque, rendant ainsi la soci\xe9t\xe9 plus r\xe9siliente face \xe0 diverses menaces, y compris l'utilisation abusive de l'IA par les humains ou les comportements d\xe9salign\xe9s de l'IA elle-m\xeame. La d/acc peut \xeatre comprise en r\xe9fl\xe9chissant \xe0 la question suivante - si l'IA prenait le contr\xf4le du monde (ou privait les humains de leurs pouvoirs), comment s'y prendrait-elle ?"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Elle pirate nos ordinateurs \u2192 acc\xe9l\xe9rer la cyber-d\xe9fense :"})," Utiliser l'IA pour identifier et corriger les vuln\xe9rabilit\xe9s, surveiller les syst\xe8mes contre les intrusions et automatiser les r\xe9ponses de s\xe9curit\xe9."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Elle cr\xe9e une super-\xe9pid\xe9mie \u2192 acc\xe9l\xe9rer la bio-d\xe9fense :"})," D\xe9velopper des technologies pour d\xe9tecter, pr\xe9venir et traiter les menaces biologiques, y compris des syst\xe8mes avanc\xe9s de filtration d'air, des outils de diagnostic rapide, l'irradiation UVC lointaine pour st\xe9riliser les espaces occup\xe9s en toute s\xe9curit\xe9, et des capacit\xe9s de production d\xe9centralis\xe9e de vaccins."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Elle nous convainc (soit de lui faire confiance, soit de nous m\xe9fier les uns des autres) \u2192 acc\xe9l\xe9rer l'info-d\xe9fense :"})," Cr\xe9er des syst\xe8mes qui aident \xe0 valider l'exactitude des informations et \xe0 d\xe9tecter les contenus trompeurs sans arbitres centralis\xe9s de la v\xe9rit\xe9, comme le suivi de la provenance s\xe9curis\xe9 par blockchain et les syst\xe8mes de v\xe9rification des faits valid\xe9s par la communaut\xe9 comme les Notes communautaires de Twitter."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Elle perturbe les infrastructures \u2192 acc\xe9l\xe8re la d\xe9fense physique :"})," Cr\xe9er des infrastructures r\xe9silientes qui peuvent r\xe9sister aux perturbations, comme la production d'\xe9nergie distribu\xe9e via le solaire domestique, les syst\xe8mes de stockage par batterie, et les techniques de fabrication avanc\xe9es qui permettent la production locale de biens essentiels."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La d/acc repr\xe9sente trois principes interconnect\xe9s : le d\xe9veloppement technologique d\xe9fensif, d\xe9centralis\xe9 et diff\xe9rentiel."}),' Le "d" dans d/acc signifie :']}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"D\xe9fensif :"})," Prioriser les technologies qui facilitent la protection contre les menaces plut\xf4t que leur cr\xe9ation. Les approches purement restrictives font face \xe0 des limitations inh\xe9rentes - elles n\xe9cessitent une coordination mondiale, cr\xe9ent des goulots d'\xe9tranglement dans l'innovation et risquent de concentrer le pouvoir entre les mains de ceux qui contr\xf4lent l'acc\xe8s."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Diff\xe9rentiel :"})," Acc\xe9l\xe9rer les technologies b\xe9n\xe9fiques tout en \xe9tant plus prudent avec celles ayant un potentiel nuisible. L'ordre dans lequel la technologie est d\xe9velopp\xe9e est tr\xe8s important. En acc\xe9l\xe9rant diff\xe9rentiellement les technologies d\xe9fensives (comme les mesures avanc\xe9es de cybers\xe9curit\xe9) avant les capacit\xe9s potentiellement dangereuses (comme les syst\xe8mes de piratage autonomes), nous cr\xe9ons des couches de protection avant qu'elles ne soient urgemment n\xe9cessaires."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"D\xe9centralis\xe9 :"})," Nous pouvons renforcer la r\xe9silience en \xe9liminant les points uniques de d\xe9faillance. Le contr\xf4le centralis\xe9 des capacit\xe9s puissantes de l'IA cr\xe9e des vuln\xe9rabilit\xe9s aux d\xe9faillances techniques, aux attaques adverses et \xe0 la capture institutionnelle (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2001.03573",children:"Cihon et al., 2020"}),"). Les approches d\xe9centralis\xe9es distribuent \xe0 la fois les capacit\xe9s et la gouvernance entre divers acteurs, emp\xeachant le contr\xf4le unilat\xe9ral sur les technologies transformatrices."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(c.A,{src:"./img/XY1_Image_20.png",alt:"Entrer la description alternative de l'image",number:"20",label:"3.20",caption:"M\xe9canismes par lesquels le d\xe9veloppement technologique diff\xe9rentiel peut r\xe9duire les impacts soci\xe9taux n\xe9gatifs ([Buterin, 2023](https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html))."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"L'efficacit\xe9 de la d/acc d\xe9pend du maintien d'\xe9quilibres favorables entre l'attaque et la d\xe9fense."})," La faisabilit\xe9 de la d/acc comme strat\xe9gie d\xe9pend de la capacit\xe9 des technologies d\xe9fensives \xe0 surpasser les capacit\xe9s offensives dans tous les domaines. Les pr\xe9c\xe9dents historiques sont mitig\xe9s - certains domaines comme la cybers\xe9curit\xe9 traditionnelle favorisent souvent les d\xe9fenseurs qui peuvent corriger les vuln\xe9rabilit\xe9s, tandis que d'autres comme la bios\xe9curit\xe9 favorisent traditionnellement les attaquants qui ont besoin de moins de ressources pour cr\xe9er des menaces que les d\xe9fenseurs n'en ont besoin pour les contrer. Le principal d\xe9fi de la mise en \u0153uvre de la d/acc r\xe9side dans l'identification et le soutien des technologies qui font pencher ces \xe9quilibres vers la d\xe9fense (",(0,i.jsx)(s.a,{href:"https://airesilience.substack.com/p/a-policy-agenda-for-defensive-acceleration",children:"Bernardi, 2024"}),"; ",(0,i.jsx)(s.a,{href:"https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html",children:"Buterin, 2023"}),")."]}),"\n",(0,i.jsxs)(o.A,{title:"Un exemple concret : l'IA pour la cyberd\xe9fense",collapsed:!0,children:[(0,i.jsxs)(s.p,{children:["Une application cl\xe9 est l'utilisation de l'IA pour am\xe9liorer la cybers\xe9curit\xe9. L'IA puissante pourrait potentiellement automatiser la d\xe9tection des vuln\xe9rabilit\xe9s, surveiller les syst\xe8mes contre les intrusions, g\xe9rer les permissions de mani\xe8re plus fine que les humains, ou remplacer les op\xe9rateurs humains dans les t\xe2ches critiques de s\xe9curit\xe9 (",(0,i.jsx)(s.a,{href:"https://www.alignmentforum.org/posts/2wxufQWK8rXcDGbyL/access-to-powerful-ai-might-make-computer-security-radically",children:"Shlegeris, 2024"}),"). Bien que les mod\xe8les actuels ne soient peut-\xeatre pas encore assez fiables, il existe un potentiel pour que l'IA renforce significativement les d\xe9fenses cyber contre les attaques conventionnelles et bas\xe9es sur l'IA (",(0,i.jsx)(s.a,{href:"https://abnormalsecurity.com/blog/offensive-ai-defensive-ai",children:"Hill, 2024"}),"; ",(0,i.jsx)(s.a,{href:"https://www.alignmentforum.org/posts/2wxufQWK8rXcDGbyL/access-to-powerful-ai-might-make-computer-security-radically",children:"Schlegeris, 2024"}),"). Quatre strat\xe9gies prometteuses pour utiliser l'IA afin d'am\xe9liorer la s\xe9curit\xe9 sont d\xe9crites :"]}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Surveillance compl\xe8te des actions humaines avec signalement par l'IA des activit\xe9s suspectes"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"D\xe9placement de la confiance o\xf9 l'IA g\xe8re les t\xe2ches sensibles \xe0 la place des humains"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Gestion fine des permissions qui serait trop intensive en main-d'\u0153uvre pour les humains"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Investigation des activit\xe9s suspectes assist\xe9e par l'IA."}),"\n"]}),"\n"]}),(0,i.jsx)(s.p,{children:"Ces approches pourraient r\xe9duire consid\xe9rablement les menaces internes et les risques d'exfiltration de donn\xe9es, rendant potentiellement la s\xe9curit\xe9 informatique \"radicalement plus facile\" lorsque l'IA puissante sera disponible, m\xeame s'il existe une incertitude substantielle sur la robustesse de telles techniques."})]}),"\n",(0,i.jsxs)(o.A,{title:"Strat\xe9gies exploitables align\xe9es sur la philosophie d/acc",collapsed:!0,children:[(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La d/acc compl\xe8te plut\xf4t qu'elle ne remplace les autres approches de s\xe9curit\xe9."})," Contrairement aux cadres concurrents qui peuvent consid\xe9rer les restrictions et les garanties comme des obstacles au progr\xe8s, la d/acc reconna\xeet leur valeur tout en abordant leurs limitations. Les garanties des mod\xe8les restent des d\xe9fenses essentielles de premi\xe8re ligne, mais la d/acc construit des couches de s\xe9curit\xe9 suppl\xe9mentaires lorsque ces garanties \xe9chouent ou sont contourn\xe9es. De m\xeame, les cadres de gouvernance fournissent une surveillance n\xe9cessaire, mais la d/acc r\xe9duit la d\xe9pendance \xe0 une r\xe9glementation parfaite en construisant une r\xe9silience technique qui fonctionne m\xeame pendant les lacunes de gouvernance."]}),(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Approches de gouvernance et de politique exploitables pour la d/acc."})," Les interventions politiques peuvent aider \xe0 cr\xe9er des cadres structur\xe9s pour l'acc\xe9l\xe9ration d\xe9fensive. Voici quelques exemples de travaux en mati\xe8re de gouvernance qui soutiennent la philosophie d/acc :"]}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Cadres de partage d'informations :"})," \xc9tablir des protocoles obligatoires de signalement des incidents et de partage d'informations entre les d\xe9veloppeurs d'IA et les agences de s\xe9curit\xe9 (",(0,i.jsx)(s.a,{href:"https://airesilience.substack.com/p/a-policy-agenda-for-defensive-acceleration",children:"Bernardi, 2024"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Acc\xe8s prioritaire aux d\xe9fenseurs :"})," Mettre en \u0153uvre des politiques accordant aux chercheurs en s\xe9curit\xe9 un acc\xe8s privil\xe9gi\xe9 pr\xe9coce aux capacit\xe9s avanc\xe9es de l'IA avant la diffusion g\xe9n\xe9rale (",(0,i.jsx)(s.a,{href:"https://airesilience.substack.com/p/a-policy-agenda-for-defensive-acceleration",children:"Bernardi, 2024"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Fonds d'acc\xe9l\xe9ration de la d\xe9fense :"})," Cr\xe9er des m\xe9canismes de financement d\xe9di\xe9s aux technologies d\xe9fensives pour rem\xe9dier aux d\xe9faillances du march\xe9 o\xf9 les technologies de bien public manquent d'investissements priv\xe9s suffisants malgr\xe9 leur valeur sociale (",(0,i.jsx)(s.a,{href:"https://airesilience.substack.com/p/a-policy-agenda-for-defensive-acceleration",children:"Bernardi, 2024"}),";",(0,i.jsx)(s.a,{href:"https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html",children:" "}),(0,i.jsx)(s.a,{href:"https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html",children:"Buterin, 2023"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"D\xe9ploiement progressif des capacit\xe9s :"})," Exiger des d\xe9ploiements par phases des capacit\xe9s avanc\xe9es de l'IA avec des p\xe9riodes de surveillance entre les \xe9tapes (",(0,i.jsx)(s.a,{href:"https://airesilience.substack.com/p/a-policy-agenda-for-defensive-acceleration",children:"Bernardi, 2024"}),")."]}),"\n"]}),"\n"]}),(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Approches technologiques et de recherche exploitables pour la d/acc."})," Nous pouvons faire progresser diff\xe9rentiellement le progr\xe8s technologique dans de nombreux domaines diff\xe9rents pour favoriser la d\xe9fense contre les risques catastrophiques. Voici quelques exemples :"]}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Syst\xe8mes avanc\xe9s de qualit\xe9 de l'air :"})," D\xe9velopper des syst\xe8mes int\xe9gr\xe9s qui d\xe9tectent, filtrent et neutralisent les agents pathog\xe8nes a\xe9roport\xe9s en temps r\xe9el. Ces technologies fournissent une protection passive contre les pand\xe9mies naturelles et les armes biologiques sans n\xe9cessiter de changements comportementaux ou une conformit\xe9 parfaite (",(0,i.jsx)(s.a,{href:"https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html",children:"Buterin, 2023"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Calcul pr\xe9servant la confidentialit\xe9 :"})," Techniques cryptographiques avanc\xe9es comme les preuves \xe0 divulgation nulle de connaissance, le chiffrement homomorphe et le calcul multipartite s\xe9curis\xe9. Ces m\xe9thodes permettent la v\xe9rification et la collaboration s\xe9curis\xe9e sans exposer d'informations sensibles, modifiant fondamentalement les compromis entre s\xe9curit\xe9 et confidentialit\xe9 (",(0,i.jsx)(s.a,{href:"https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html",children:"Buterin, 2023"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Infrastructure r\xe9siliente :"})," Cr\xe9er des syst\xe8mes d\xe9centralis\xe9s et autosuffisants pour l'\xe9nergie, la communication et les cha\xeenes d'approvisionnement qui peuvent fonctionner pendant les perturbations. Cela inclut des technologies comme les r\xe9seaux maill\xe9s, la fabrication localis\xe9e et la production d'\xe9nergie distribu\xe9e qui maintiennent les fonctions critiques m\xeame lorsque les syst\xe8mes centralis\xe9s \xe9chouent (",(0,i.jsx)(s.a,{href:"https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html",children:"Buterin, 2023"}),";",(0,i.jsx)(s.a,{href:"https://vitalik.eth.limo/general/2025/01/05/dacc2.html",children:" "}),(0,i.jsx)(s.a,{href:"https://vitalik.eth.limo/general/2025/01/05/dacc2.html",children:"Buterin, 2025"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Syst\xe8mes de v\xe9rification collaborative :"})," Mettre en \u0153uvre des plateformes de validation de l'information multi-spectres similaires aux Notes communautaires qui identifient la d\xe9sinformation gr\xe2ce au consensus \xe0 travers la diversit\xe9 des points de vue. Ces syst\xe8mes permettent aux communaut\xe9s d'autor\xe9guler la qualit\xe9 de l'information sans arbitres centralis\xe9s de la v\xe9rit\xe9 (",(0,i.jsx)(s.a,{href:"https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html",children:"Buterin, 2023"}),")."]}),"\n"]}),"\n"]}),(0,i.jsx)(c.A,{src:"./img/F9v_Image_21.png",alt:"Entrer la description alternative de l'image",number:"21",label:"3.21",caption:"Un mod\xe8le \xe9tendu montrant comment de nombreux types et couches diff\xe9rents de technologies d\xe9fensives peuvent interagir ([Buterin, 2025](https://vitalik.eth.limo/general/2025/01/05/dacc2.html))"})]}),"\n",(0,i.jsx)(s.h2,{id:"02",children:"D\xe9fense en profondeur"}),"\n",(0,i.jsx)(s.p,{children:"La s\xe9curit\xe9 efficace de l'IA d\xe9pend aussi fortement des pratiques et structures internes au sein des organisations d\xe9veloppant l'IA. Les accidents sont difficiles \xe0 \xe9viter, m\xeame lorsque la structure incitative et la gouvernance tentent de garantir qu'il n'y aura pas de probl\xe8mes. Par exemple, m\xeame aujourd'hui, il y a encore des accidents dans l'industrie a\xe9rospatiale."}),"\n",(0,i.jsx)(c.A,{src:"./img/HNP_Image_22.png",alt:"Entrer la description alternative de l'image",number:"22",label:"3.22",caption:"Le mod\xe8le du fromage suisse montre comment les facteurs techniques peuvent am\xe9liorer la s\xe9curit\xe9 organisationnelle. Les multiples couches de d\xe9fense se compensent mutuellement leurs faiblesses individuelles, conduisant \xe0 un faible niveau global de risque ([Hendrycks et al., 2023](https://arxiv.org/abs/2306.12001))."}),"\n",(0,i.jsxs)(s.p,{children:["Pour r\xe9soudre ces probl\xe8mes, un mod\xe8le du fromage suisse pourrait \xeatre efficace - aucune solution unique ne suffira, mais une approche en couches peut r\xe9duire significativement les risques. Le mod\xe8le du fromage suisse est un concept de gestion des risques, largement utilis\xe9 dans des industries comme la sant\xe9 et l'aviation. Chaque couche repr\xe9sente une mesure de s\xe9curit\xe9, et bien qu'individuellement elles puissent avoir des faiblesses, collectivement elles forment une forte barri\xe8re contre les menaces. Les organisations devraient \xe9galement suivre des principes de conception s\xfbre (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2206.05862",children:"Hendrycks & Mazeika, 2022"}),"), comme la d\xe9fense en profondeur et la redondance, pour assurer une sauvegarde pour chaque mesure de s\xe9curit\xe9, entre autres."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"De nombreuses solutions peuvent \xeatre imagin\xe9es pour r\xe9duire les risques, m\xeame si aucune n'est parfaite."})," La premi\xe8re \xe9tape pourrait \xeatre de mandater des \xe9quipes rouges externes pour identifier les dangers et am\xe9liorer la s\xe9curit\xe9 du syst\xe8me. C'est ce qu'OpenAI a fait avec METR pour \xe9valuer GPT-4. Cependant, les laboratoires d'AGI ont aussi besoin d'une \xe9quipe d'audit interne pour la gestion des risques. Tout comme les banques ont des \xe9quipes de gestion des risques, cette \xe9quipe doit \xeatre impliqu\xe9e dans les processus de d\xe9cision, et les d\xe9cisions cl\xe9s devraient impliquer un directeur des risques pour assurer la responsabilit\xe9 ex\xe9cutive. L'une des missions de l'\xe9quipe de gestion des risques pourrait \xeatre, par exemple, de concevoir des plans pr\xe9\xe9tablis pour g\xe9rer la s\xe9curit\xe9 et les incidents."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Limites des approches syst\xe9miques."})," La d\xe9fense en profondeur pourrait encore \xe9chouer face \xe0 des menaces suffisamment nouvelles ou des adversaires d\xe9termin\xe9s, particuli\xe8rement dans le cas des ASI. De m\xeame, les sc\xe9narios de d\xe9sempowerment progressif, o\xf9 le contr\xf4le humain s'\xe9rode progressivement \xe0 travers des changements \xe9conomiques ou culturels provoqu\xe9s par l'IA, pourraient ne pas \xeatre trait\xe9s de mani\xe8re ad\xe9quate par les cadres de gouvernance actuels ax\xe9s sur des pr\xe9judices ou des capacit\xe9s sp\xe9cifiques."]}),"\n",(0,i.jsx)(s.h2,{id:"03",children:"Gouvernance de l'IA"}),"\n",(0,i.jsx)(s.p,{children:"La qu\xeate d'une IA de plus en plus puissante, \xe0 l'instar de la course aux armements nucl\xe9aires de l'\xe8re de la Guerre froide, repr\xe9sente un compromis entre la s\xe9curit\xe9 et l'avantage concurrentiel que recherchent les nations et les entreprises pour le pouvoir et l'influence. Cette dynamique comp\xe9titive augmente le risque mondial. Pour att\xe9nuer ce probl\xe8me, nous pouvons essayer d'agir \xe0 sa source, \xe0 savoir la refonte des incitations \xe9conomiques pour privil\xe9gier la s\xe9curit\xe9 \xe0 long terme plut\xf4t que les gains \xe0 court terme. Cela peut principalement se faire via une gouvernance internationale."}),"\n",(0,i.jsx)(s.p,{children:"Une gouvernance efficace de l'IA vise \xe0 atteindre deux objectifs principaux :"}),"\n",(0,i.jsx)(s.p,{children:"1.** Gagner du temps.** Du temps et des ressources pour le d\xe9veloppement de solutions afin de garantir que suffisamment de temps et de ressources sont allou\xe9s \xe0 l'identification et \xe0 la mise en \u0153uvre de mesures de s\xe9curit\xe9"}),"\n",(0,i.jsx)(s.p,{children:"2.** Appliquer des solutions.** Une coordination renforc\xe9e pour augmenter la probabilit\xe9 d'une adoption g\xe9n\xe9ralis\xe9e des mesures de s\xe9curit\xe9 gr\xe2ce \xe0 la coop\xe9ration mondiale. Les risques li\xe9s \xe0 l'IA sont multiformes, n\xe9cessitant des r\xe9glementations qui encouragent un comportement prudent parmi les parties prenantes et des r\xe9ponses rapides aux menaces \xe9mergentes."}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"Concevoir de meilleures incitations"})}),"\n",(0,i.jsx)(s.p,{children:"Aligner les incitations \xe9conomiques avec les objectifs de s\xe9curit\xe9 est un d\xe9fi majeur. Actuellement, de fortes pressions commerciales peuvent inciter au d\xe9veloppement rapide des capacit\xe9s, potentiellement au d\xe9triment de la recherche sur la s\xe9curit\xe9 ou d'un d\xe9ploiement prudent. Des m\xe9canismes pour r\xe9compenser la s\xe9curit\xe9 ou p\xe9naliser l'imprudence sont n\xe9cessaires pour \xe9viter les externalit\xe9s n\xe9gatives :"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Remodeler la course via un d\xe9veloppement centralis\xe9."})," Par exemple, Yoshua Bengio et al. proposent de cr\xe9er une installation s\xe9curis\xe9e similaire au CERN pour la physique, o\xf9 le d\xe9veloppement des technologies d'IA potentiellement dangereuses peut \xeatre strictement contr\xf4l\xe9 (",(0,i.jsx)(s.a,{href:"https://yoshuabengio.org/2023/06/24/faq-on-catastrophic-ai-risks/",children:"Bengio, 2023"}),'). Cette mesure est loin de faire l\'unanimit\xe9. Nous avons d\xe9j\xe0 explor\xe9 cette solution dans la strat\xe9gie "Coordination mondiale" de la s\xe9curit\xe9 ASI, dans la section s\xe9curit\xe9 ASI, mais cela pourrait aussi \xeatre valable pour de nombreux domaines de la s\xe9curit\xe9.']}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Clauses d'aubaine et partage des b\xe9n\xe9fices."})," La mise en \u0153uvre d'accords pour partager les profits entre les diff\xe9rents laboratoires g\xe9n\xe9r\xe9s par l'AGI att\xe9nuerait la course \xe0 la supr\xe9matie de l'IA en assurant un b\xe9n\xe9fice collectif des succ\xe8s individuels. ",(0,i.jsx)(a.A,{id:"footnote_windfall",number:"1",text:"Par exemple, dans l'industrie pharmaceutique pour le d\xe9veloppement de m\xe9dicaments, les entreprises concluent parfois des accords de co-d\xe9veloppement et de partage des b\xe9n\xe9fices pour partager les risques et les r\xe9compenses li\xe9s \xe0 la commercialisation d'un nouveau m\xe9dicament. Par exemple, en 2014, Pfizer et Merck ont conclu une alliance mondiale pour co-d\xe9velopper et co-commercialiser un anticorps anti-PD-L1 pour le traitement de plusieurs types de cancers."})]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Mettre en \u0153uvre une gouvernance correcte des entreprises d'AGI."})," Il est important d'examiner les structures de gouvernance des laboratoires d'AGI. Par exemple, \xeatre une organisation \xe0 but non lucratif et avoir une d\xe9claration de mission qui indique clairement que l'objectif n'est pas de maximiser les revenus, mais de s'assurer que le d\xe9veloppement de l'IA profite \xe0 toute l'humanit\xe9, est une premi\xe8re \xe9tape importante. De plus, le conseil d'administration doit avoir du poids."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Responsabilit\xe9 juridique pour les d\xe9veloppeurs d'IA."})," \xc9tablir des responsabilit\xe9s juridiques claires pour les d\xe9veloppeurs d'IA concernant les mauvaises utilisations ou les accidents pourrait r\xe9aligner les incitations. Par exemple, le Safe and Secure Innovation for Frontier Artificial Intelligence Models Act (SB 1047) aurait pu permettre au procureur g\xe9n\xe9ral d'intenter des poursuites civiles contre les d\xe9veloppeurs qui causent des dommages catastrophiques ou menacent la s\xe9curit\xe9 publique en n\xe9gligeant les exigences. Le projet de loi (qui a \xe9t\xe9 rejet\xe9 par le gouverneur en 2024) ne traitait que des risques extr\xeames de ces mod\xe8les, notamment : les cyberattaques causant plus de 500 millions de dollars de dommages, les crimes autonomes causant 500 millions de dollars de dommages, et la cr\xe9ation d'armes chimiques, biologiques, radiologiques ou nucl\xe9aires utilisant l'IA. Notez que compar\xe9 \xe0 l'AI Act et son code de pratique, SB1047 ne sp\xe9cifie pas en d\xe9tail les \xe9tapes n\xe9cessaires pour \xe9viter les catastrophes ; il cible uniquement le r\xe9sultat et pas vraiment le processus."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"M\xe9canismes propos\xe9s de gouvernance internationale de l'IA"})}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Plusieurs m\xe9canismes ont \xe9t\xe9 propos\xe9s pour \xe9tablir des limites et des r\xe8gles claires pour le d\xe9veloppement de l'IA au niveau international."})," Ceux-ci incluent la mise en \u0153uvre de moratoires temporaires sur les syst\xe8mes d'IA \xe0 haut risque, l'application de r\xe9glementations l\xe9gales comme l'AI Act de l'UE, et l'\xe9tablissement de \"Lignes Rouges\" internationalement reconnues qui interdisent des capacit\xe9s d'IA sp\xe9cifiques dangereuses, comme la r\xe9plication autonome ou l'aide \xe0 la cr\xe9ation d'armes de destruction massive. Les dialogues IDAIS ont vis\xe9 \xe0 construire un consensus sur ces lignes rouges, soulignant la clart\xe9 et l'universalit\xe9 comme caract\xe9ristiques cl\xe9s pour l'efficacit\xe9, avec des violations pouvant d\xe9clencher des r\xe9ponses internationales pr\xe9alablement convenues."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les approches conditionnelles et la cr\xe9ation d'organismes internationaux d\xe9di\xe9s repr\xe9sentent une autre strat\xe9gie cl\xe9."})," Les \"Engagements Si-Alors\" impliquent que les d\xe9veloppeurs ou les \xc9tats acceptent de mettre en \u0153uvre des mesures de s\xe9curit\xe9 sp\xe9cifiques si les capacit\xe9s de l'IA atteignent certains seuils pr\xe9d\xe9finis, permettant la pr\xe9paration sans entraver pr\xe9matur\xe9ment le d\xe9veloppement, comme l'illustre le projet de Trait\xe9 conditionnel sur la s\xe9curit\xe9 de l'IA. De plus, il existe des propositions pour de nouvelles institutions internationales, potentiellement model\xe9es sur l'Agence internationale de l'\xe9nergie atomique (AIEA), pour surveiller le d\xe9veloppement de l'IA, v\xe9rifier la conformit\xe9 aux accords, promouvoir la recherche sur la s\xe9curit\xe9, et potentiellement centraliser ou contr\xf4ler le d\xe9veloppement et la distribution des IA les plus risqu\xe9es."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Des r\xe9gimes de gouvernance sp\xe9cifiques et des structures de soutien sont \xe9galement \xe0 l'\xe9tude pour am\xe9liorer la coordination internationale."})," \xc9tant donn\xe9 la nature mondiale de l'IA, des m\xe9canismes comme la gouvernance internationale du calcul visent \xe0 surveiller et contr\xf4ler les cha\xeenes d'approvisionnement pour les puces d'IA et l'infrastructure d'entra\xeenement \xe0 grande \xe9chelle, bien que la faisabilit\xe9 technique et la coop\xe9ration internationale restent des d\xe9fis. D'autres propositions incluent l'\xe9tablissement d'un organisme international de recherche sur la s\xe9curit\xe9 de l'IA \xe0 grande \xe9chelle similaire au CERN, centralisant potentiellement la recherche \xe0 haut risque ou \xe9tablissant des normes mondiales, et le renforcement des protections des lanceurs d'alerte par des accords internationaux pour encourager le signalement des pr\xe9occupations de s\xe9curit\xe9 dans l'industrie de l'IA."]}),"\n",(0,i.jsx)(s.p,{children:"Pour plus d'informations sur ces sujets, veuillez lire le prochain chapitre sur la gouvernance de l'IA."}),"\n",(0,i.jsxs)(o.A,{title:"L'IA est-elle gouvernable, souhaitable et possible ?",collapsed:!0,children:[(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Historiquement, le domaine de la s\xe9curit\xe9 de l'IA s'est principalement concentr\xe9 sur la recherche technique, influenc\xe9 en partie par des points de vue comme l'affirmation d'Eliezer Yudkowsky selon laquelle \"La politique est le tueur de l'esprit.\""})," (",(0,i.jsx)(s.a,{href:"https://www.lesswrong.com/posts/9weLK2AJ9JEt2Tt8f/politics-is-the-mind-killer",children:"Yudkowsky, 2007"}),") Pendant de nombreuses ann\xe9es, le domaine pensait que s'engager dans la politique \xe9tait inefficace voire contre-productif compar\xe9 \xe0 la r\xe9solution directe du probl\xe8me technique d'alignement, conduisant de nombreux premiers chercheurs pr\xe9occup\xe9s par l'AGI \xe0 privil\xe9gier les solutions d'ing\xe9nierie plut\xf4t que les efforts de gouvernance. \xc9tonnamment, au d\xe9but, il \xe9tait presque d\xe9courag\xe9 de parler publiquement de ces risques pour \xe9viter la course et \xe9viter d'amener des personnes avec une \"\xe9pist\xe9mique pauvre\" dans la communaut\xe9."]}),(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Cependant, en 2023, ChatGPT a \xe9t\xe9 publi\xe9, est devenu viral, et la gouvernance de l'IA a gagn\xe9 une traction significative comme strat\xe9gie potentiellement viable pour att\xe9nuer les risques de l'AGI."})," Ce changement s'est produit alors que l'engagement avec les d\xe9cideurs politiques semblait donner des r\xe9sultats, rendant la gouvernance plus r\xe9alisable qu'on ne le pensait auparavant (",(0,i.jsx)(s.a,{href:"https://www.lesswrong.com/posts/2sLwt2cSAag74nsdN/speaking-to-congressional-staffers-about-ai-risk",children:"Akash, 2023"}),"). Ensuite, des lettres ouvertes influentes ont \xe9t\xe9 publi\xe9es (FLI, CAIS), et ont d\xe9plac\xe9 la fen\xeatre d'Overton. Par cons\xe9quent, des organisations influentes comme 80,000 Hours ont ajust\xe9 leurs recommandations de carri\xe8re, mettant en avant les r\xf4les de politique et de strat\xe9gie de l'IA, maintenant au-dessus de la recherche technique d'alignement, comme priorit\xe9s principales pour l'impact (",(0,i.jsx)(s.a,{href:"https://80000hours.org/career-reviews/ai-policy-and-strategy/",children:"Fenwick, 2023"}),")."]}),(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Cependant, la fen\xeatre d'Overton pour des mesures internationales strictes de s\xe9curit\xe9 de l'IA semble se r\xe9tr\xe9cir."})," Alors que les d\xe9clarations et efforts initiaux de groupes comme le Future of Life Institute et le Center for AI Safety ont r\xe9ussi \xe0 \xe9largir le discours public et politique sur les risques de l'IA, les d\xe9veloppements ult\xe9rieurs, y compris les sommets internationaux per\xe7us comme faibles sur la s\xe9curit\xe9 et les changements de leadership politique (comme l'\xe9lection de Donald Trump), ont jet\xe9 le doute sur la faisabilit\xe9 d'atteindre une coordination internationale robuste (",(0,i.jsx)(s.a,{href:"https://www.lesswrong.com/posts/qYPHryHTNiJ2y6Fhi/the-paris-ai-anti-safety-summit",children:"Zvi, 2025"}),"). Cela a conduit certains dans le domaine de la gouvernance de l'IA \xe0 croire qu'un \"coup de semonce\" significatif \u2013 une d\xe9monstration claire du danger de l'IA \u2013 pourrait \xeatre n\xe9cessaire pour galvaniser une action d\xe9cisive, bien qu'il y ait du scepticisme quant \xe0 savoir si un tel \xe9v\xe9nement convaincant pourrait r\xe9ellement se produire avant qu'il ne soit trop tard (",(0,i.jsx)(s.a,{href:"https://www.lesswrong.com/posts/RYx6cLwzoajqjyB6b/what-convincing-warning-shot-could-help-prevent-extinction",children:"Segerie, 2024"}),")."]}),(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les r\xe9glementations existantes et propos\xe9es font face \xe0 des limitations significatives et des cons\xe9quences n\xe9gatives potentielles."})," Par exemple, les efforts l\xe9gislatifs importants comme l'AI Act de l'UE, bien que novateurs \xe0 certains \xe9gards, contiennent des lacunes notables (",(0,i.jsx)(s.a,{href:"https://milesbrundage.substack.com/p/feedback-on-the-second-draft-of-the",children:"Brundage, 2025"}),") ; son Code de Pratique a des limitations, et l'Act lui-m\xeame pourrait ne pas couvrir ad\xe9quatement les mod\xe8les d\xe9ploy\xe9s hors d'Europe, les d\xe9ploiements purement internes pour la recherche, ou les applications militaires. Une pr\xe9occupation critique est le potentiel pour les laboratoires d'IA fronti\xe8re de s'engager dans des courses au d\xe9veloppement secr\xe8tes, contournant la surveillance \u2013 un sc\xe9nario potentiellement facilit\xe9 par des changements de politique comme la r\xe9vocation des ordres ex\xe9cutifs mandatant le rapport gouvernemental sur les \xe9valuations des mod\xe8les fronti\xe8res (",(0,i.jsx)(s.a,{href:"https://ai-2027.com/",children:"Kokotajlo, 2025"}),")."]}),(0,i.jsx)(s.p,{children:"De plus, il existe des pr\xe9occupations fondamentales que les structures de gouvernance capables de contr\xf4ler l'AGI pourraient elles-m\xeames poser des risques, permettant potentiellement un contr\xf4le totalitaire."}),(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Une perspective profond\xe9ment sceptique sugg\xe8re que beaucoup du r\xe9cit actuel sur le progr\xe8s de l'IA et l'activit\xe9 r\xe9glementaire pourrait \xeatre performatif ou \"faux.\""})," Ce \"mod\xe8le pleinement cynique\" postule que les grands laboratoires d'IA pourraient exag\xe9rer leurs progr\xe8s vers l'AGI pour maintenir la confiance des investisseurs et l'engouement, masquant potentiellement des progr\xe8s plus lents ou une stagnation dans les capacit\xe9s fondamentales (",(0,i.jsx)(s.a,{href:"https://www.lesswrong.com/posts/puv8fRDCH9jx5yhbX/?commentId=aBcAh8H9cSzdXmgb7#aBcAh8H9cSzdXmgb7",children:"Wentworth, 2025"}),"). En parall\xe8le, il sugg\xe8re que les activistes et lobbyistes de la r\xe9glementation de l'IA pourraient privil\xe9gier le r\xe9seautage et le statut dans les cercles politiques plut\xf4t que l'\xe9laboration de r\xe9glementations v\xe9ritablement efficaces, conduisant \xe0 des mesures focalis\xe9es sur des m\xe9triques facilement cibl\xe9es mais potentiellement superficielles (comme les seuils de calcul) plut\xf4t que d'aborder les risques fondamentaux (",(0,i.jsx)(s.a,{href:"https://www.lesswrong.com/posts/puv8fRDCH9jx5yhbX/?commentId=aBcAh8H9cSzdXmgb7#aBcAh8H9cSzdXmgb7",children:"Wentworth, 2025"}),"). Cette vue implique une dynamique o\xf9 \xe0 la fois les laboratoires et les activistes renforcent involontairement un r\xe9cit de perc\xe9es imminentes et contr\xf4lables de l'IA, potentiellement d\xe9tach\xe9 de la r\xe9alit\xe9 sous-jacente (",(0,i.jsx)(s.a,{href:"https://www.lesswrong.com/posts/puv8fRDCH9jx5yhbX/?commentId=aBcAh8H9cSzdXmgb7#aBcAh8H9cSzdXmgb7",children:"Wentworth, 2025"}),")."]}),(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:'Cependant, cette perspective cynique de "fausset\xe9" est d\xe9battue.'})," Les critiques de la vue cynique soutiennent que des propositions r\xe9glementaires sp\xe9cifiques, comme SB 1047, contenaient des \xe9l\xe9ments potentiellement valables (par exemple, exiger des capacit\xe9s d'arr\xeat, des garanties, et le suivi des grands entra\xeenements), m\xeame si leur impact global \xe9tait d\xe9battu ou finalement limit\xe9 (",(0,i.jsx)(s.a,{href:"https://www.lesswrong.com/posts/puv8fRDCH9jx5yhbX/johnswentworth-s-shortform?commentId=J2iPumP29GK9Qrm5p",children:"Segerie, 2025"}),"; ",(0,i.jsx)(s.a,{href:"https://www.lesswrong.com/posts/puv8fRDCH9jx5yhbX/johnswentworth-s-shortform?commentId=G5zcfntZodH3ZYDaP",children:"Wentworth, 2025"}),"). Il est reconnu que les r\xe9gulateurs op\xe8rent sous des contraintes r\xe9elles, y compris l'influence significative du lobbying des grandes entreprises technologiques, qui peut emp\xeacher l'interdiction de technologies sans preuve claire de risque inacceptable. De plus, le ph\xe9nom\xe8ne de \"conformit\xe9 performative\" ou \"th\xe9\xe2tre de conformit\xe9\" est reconnu, mais il est argument\xe9 que l'engagement avec ces processus imparfaits est toujours n\xe9cessaire, et que certaines \xe9tapes l\xe9gislatives, comme l'AI Act de l'UE mentionnant explicitement \"l'alignement avec l'intention humaine\", repr\xe9sentent des progr\xe8s potentiellement significatifs (",(0,i.jsx)(s.a,{href:"https://www.lesswrong.com/posts/puv8fRDCH9jx5yhbX/johnswentworth-s-shortform?commentId=NLAW24oxDFuTLT3kx",children:"Hernandez, 2025"}),")."]}),(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La r\xe9glementation de l'IA pourrait involontairement augmenter le risque existentiel par plusieurs voies"})," (",(0,i.jsx)(s.a,{href:"https://www.lesswrong.com/posts/6untaSPpsocmkS7Z3/ways-i-expect-ai-regulation-to-increase-extinction-risk",children:"1a3orn, 2023"}),"). Les r\xe9glementations pourraient mal diriger les efforts de s\xe9curit\xe9 vers des probl\xe8mes de conformit\xe9 d\xe9pass\xe9s ou moins pertinents, d\xe9tournant l'",(0,i.jsx)(t,{term:"attention",definition:'{"definition":"M\xe9canisme permettant aux mod\xe8les de se concentrer sur les parties pertinentes de l\'entr\xe9e lors de la r\xe9alisation de pr\xe9dictions, en calculant des combinaisons pond\xe9r\xe9es d\'\xe9l\xe9ments d\'entr\xe9e..","source":"[Bahdanau et al., 2015](https://arxiv.org/abs/1409.0473)","aliases":["Attention","attention mechanism","self-attention"]}',children:(0,i.jsx)(t,{term:"attention",definition:'{"definition":"M\xe9canisme permettant aux mod\xe8les de se concentrer sur les parties pertinentes de l\'entr\xe9e lors de la r\xe9alisation de pr\xe9dictions, en calculant des combinaisons pond\xe9r\xe9es d\'\xe9l\xe9ments d\'entr\xe9e..","source":"[Bahdanau et al., 2015](https://arxiv.org/abs/1409.0473)","aliases":["Attention","attention mechanism","self-attention"]}',children:"attention"})})," des risques \xe9mergents plus importants (R\xe9glementations mal dirig\xe9es) ; les processus bureaucratiques tendent \xe0 favoriser les grands acteurs \xe9tablis, entravant potentiellement les efforts de recherche sur la s\xe9curit\xe9 plus petits et innovants ; des r\xe9glementations nationales trop strictes pourraient pousser le d\xe9veloppement de l'IA vers des acteurs internationaux moins soucieux de la s\xe9curit\xe9, affaiblissant l'influence du r\xe9gulateur initial (Affaiblissement des pays r\xe9gulateurs) ; et les r\xe9glementations, particuli\xe8rement celles restreignant les mod\xe8les open-source ou \xe9tablissant des co\xfbts de conformit\xe9 \xe9lev\xe9s, pourraient consolider le pouvoir dans les mains des plus grandes entreprises poussant les capacit\xe9s, \xe9touffant potentiellement les approches alternatives de s\xe9curit\xe9 et acc\xe9l\xe9rant le risque (Renforcement des acteurs dominants). Mais l'existence de ces arguments n'est pas suffisante pour dire que la r\xe9glementation de l'IA est n\xe9gative nette ; c'est principalement un rappel que nous devons \xeatre prudents dans la fa\xe7on de r\xe9glementer. Le diable est dans les d\xe9tails."]})]}),"\n",(0,i.jsx)(s.h2,{id:"04",children:"Gestion des risques"}),"\n",(0,i.jsxs)(s.p,{children:["Une analyse extr\xeamement d\xe9taill\xe9e des pratiques actuelles de gestion des risques et de s\xe9curit\xe9 est men\xe9e par saferAI ",(0,i.jsx)(s.a,{href:"https://ratings.safer-ai.org/comparison/",children:"disponible ici"}),"."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La gestion des risques n\xe9cessite la collaboration de plusieurs niveaux organisationnels."})," Un exemple que les entreprises d'IA peuvent choisir d'imiter est le mod\xe8le des trois lignes de d\xe9fense issu d'autres industries \xe0 haut risque. La premi\xe8re ligne est constitu\xe9e de gestionnaires op\xe9rationnels qui d\xe9veloppent des syst\xe8mes d'IA et g\xe8rent directement les risques associ\xe9s. Les responsables de la recherche et les chefs de produit assument la responsabilit\xe9 finale des d\xe9cisions de s\xe9curit\xe9 dans leurs domaines. La deuxi\xe8me ligne comprend des \xe9quipes sp\xe9cialis\xe9es comme la gestion des risques, la conformit\xe9 juridique et les groupes d'\xe9thique qui fournissent leur expertise et remettent en question les pratiques de premi\xe8re ligne. La troisi\xe8me ligne est l'audit interne - une fonction ind\xe9pendante qui \xe9value si l'ensemble du syst\xe8me de gestion des risques fonctionne r\xe9ellement et rend compte directement au conseil d'administration (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2212.08364",children:"Schuett, 2022"}),")."]}),"\n",(0,i.jsx)(s.h2,{id:"05",children:"Culture de la s\xe9curit\xe9"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La culture de la s\xe9curit\xe9 signifie construire des organisations o\xf9 les gens privil\xe9gient syst\xe9matiquement la s\xe9curit\xe9 par rapport \xe0 la vitesse, et o\xf9 les pr\xe9occupations de s\xe9curit\xe9 peuvent r\xe9ellement modifier les d\xe9cisions."})," C'est une strat\xe9gie de pr\xe9vention des accidents d'IA par la conception organisationnelle plut\xf4t que par des solutions uniquement techniques. La gestion des risques est pr\xe9sente dans de nombreux domaines, notamment l'a\xe9rospatiale, l'\xe9nergie nucl\xe9aire et les services financiers. Chacun de ces domaines a d\xe9velopp\xe9 des approches sophistiqu\xe9es pour identifier, analyser et att\xe9nuer les dommages potentiels. Nous voulons att\xe9nuer les d\xe9faillances de s\xe9curit\xe9 de l'IA qui d\xe9coulent de facteurs humains et organisationnels - se pr\xe9cipiter pour d\xe9ployer des syst\xe8mes insuffisamment test\xe9s, ignorer les signes avant-coureurs ou cr\xe9er des incitations qui r\xe9compensent la rapidit\xe9 plut\xf4t que la prudence. L'int\xe9gration de la culture de la s\xe9curit\xe9 aborde ces causes profondes en modifiant le fonctionnement des organisations."]}),"\n",(0,i.jsx)(c.A,{src:"./img/CVT_Image_23.png",alt:"Entrer la description alternative de l'image",number:"23",label:"3.23",caption:"Le rapport de l'indice de s\xfbret\xe9 de l'IA pour l'\xe9t\xe9 2025. Les scores indiquent si la structure de gouvernance et les op\xe9rations quotidiennes de chaque entreprise donnent la priorit\xe9 \xe0 une responsabilit\xe9 significative concernant les impacts r\xe9els de ses syst\xe8mes d'IA dans le monde. Cela inclut des \xe9l\xe9ments tels que les syst\xe8mes de d\xe9nonciation, les structures juridiques et les efforts de plaidoyer li\xe9s aux r\xe9glementations de l'IA ([FLI, 2025](https://futureoflife.org/wp-content/uploads/2025/07/FLI-AI-Safety-Index-Report-Summer-2025.pdf) ; [SaferAI, 2025](https://ratings.safer-ai.org/))."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"L'industrie de l'IA manque de la culture professionnelle de la s\xe9curit\xe9 que l'on trouve dans l'ing\xe9nierie traditionnelle."})," Des domaines comme le g\xe9nie civil et m\xe9canique ont des codes d'\xe9thique professionnelle, des marges de s\xe9curit\xe9 et l'ing\xe9nierie de la fiabilit\xe9 comme pratiques standard. Le d\xe9veloppement de l'IA est issu des math\xe9matiques et de l'informatique qui, en dehors des syst\xe8mes logiciels critiques pour la s\xe9curit\xe9, ont des traditions de s\xe9curit\xe9 plus faibles. Contrairement \xe0 d'autres industries o\xf9 les travailleurs subissent directement les risques de s\xe9curit\xe9, les d\xe9veloppeurs d'IA font rarement face aux cons\xe9quences des d\xe9faillances de leurs syst\xe8mes. Cette distance rend plus difficile la construction d'une compr\xe9hension partag\xe9e du risque qui motive la culture de la s\xe9curit\xe9 dans d'autres domaines (",(0,i.jsx)(s.a,{href:"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4491421",children:"Mannheim, 2023"}),")."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La culture de la s\xe9curit\xe9 de l'IA doit \xeatre prospective plut\xf4t que r\xe9active."})," La plupart des industries ont d\xe9velopp\xe9 des cultures de la s\xe9curit\xe9 apr\xe8s des catastrophes majeures - l'\xe9nergie nucl\xe9aire apr\xe8s Three Mile Island, la sant\xe9 apr\xe8s des d\xe9cennies de d\xe9c\xe8s \xe9vitables. Attendre des catastrophes li\xe9es \xe0 l'IA serait irresponsable car certaines d\xe9faillances pourraient ne pas \xeatre surmontables (",(0,i.jsx)(s.a,{href:"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4491421",children:"Mannheim, 2023"}),")."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsxs)(s.strong,{children:["L'industrie a\xe9rospatiale d\xe9montre comment la culture de la s\xe9curit\xe9 peut ",(0,i.jsx)(t,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:(0,i.jsx)(t,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:"transformer"})})," des domaines entiers gr\xe2ce \xe0 des pratiques syst\xe9matiques."]})," L'aviation est pass\xe9e d'accidents fr\xe9quents \xe0 des records de s\xe9curit\xe9 extraordinaires non seulement gr\xe2ce \xe0 une meilleure technologie, mais aussi gr\xe2ce \xe0 des changements culturels comme le signalement obligatoire des incidents, les enqu\xeates de s\xe9curit\xe9 sans bl\xe2me et les proc\xe9dures standardis\xe9es qui privil\xe9gient la s\xe9curit\xe9 plut\xf4t que la pression des d\xe9lais. Les entreprises d'IA peuvent adopter des pratiques similaires : signalement syst\xe9matique des incidents, formation r\xe9guli\xe8re \xe0 la s\xe9curit\xe9 et structures organisationnelles garantissant que les pr\xe9occupations de s\xe9curit\xe9 atteignent les d\xe9cideurs ayant l'autorit\xe9 d'agir."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Une culture de la s\xe9curit\xe9 forte pr\xe9sente trois caract\xe9ristiques observables : la responsabilit\xe9 des dirigeants, des processus syst\xe9matiques et la s\xe9curit\xe9 psychologique pour soulever des pr\xe9occupations."})," Le Cadre de Gestion des Risques de l'IA du NIST identifie la direction ex\xe9cutive prenant la responsabilit\xe9 personnelle des d\xe9cisions relatives aux risques de l'IA, des \xe9quipes diverses informant la gestion des risques tout au long du d\xe9veloppement, et des processus syst\xe9matiques pour le signalement des incidents et le partage d'informations dans l'organisation (",(0,i.jsx)(s.a,{href:"https://www.nist.gov/itl/ai-risk-management-framework",children:"NIST, 2023"}),"). Les organisations ayant une culture de la s\xe9curit\xe9 mettent en \u0153uvre des processus syst\xe9matiques o\xf9 les consid\xe9rations de s\xe9curit\xe9 sont int\xe9gr\xe9es aux flux de travail standard plut\xf4t que d'\xeatre des ajouts optionnels. Elles cr\xe9ent des environnements o\xf9 les employ\xe9s peuvent soulever des pr\xe9occupations de s\xe9curit\xe9 sans p\xe9nalit\xe9s professionnelles - et o\xf9 ces pr\xe9occupations influencent visiblement les d\xe9cisions. Par exemple, la NASA a appris que l'excellence technique ne suffit pas - la catastrophe de Challenger s'est produite en partie parce que les pr\xe9occupations de s\xe9curit\xe9 des ing\xe9nieurs n'ont pas atteint les d\xe9cideurs en raison de dynamiques organisationnelles qui d\xe9courageaient la dissidence."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La culture de la s\xe9curit\xe9 s'\xe9tend au-del\xe0 des projets individuels pour englober le recrutement, l'\xe9valuation des performances et les incitations organisationnelles."})," Les entreprises s\xe9rieuses en mati\xe8re de culture de la s\xe9curit\xe9 \xe9valuent les candidats sur leur \xe9tat d'esprit vis-\xe0-vis de la s\xe9curit\xe9 lors du recrutement, incluent des m\xe9triques de s\xe9curit\xe9 dans les \xe9valuations de performance et s'assurent que le travail sur la s\xe9curit\xe9 est reconnu et r\xe9compens\xe9 plut\xf4t que d'\xeatre vu comme ralentissant le \"vrai\" progr\xe8s. Cela inclut l'allocation de temps et de ressources d\xe9di\xe9s au travail sur la s\xe9curit\xe9, ne pas le traiter comme quelque chose que les \xe9quipes devraient int\xe9grer entre autres priorit\xe9s. Les organisations avec une forte culture de la s\xe9curit\xe9 maintiennent des syst\xe8mes d\xe9taill\xe9s de signalement des incidents, conduisent des \xe9valuations r\xe9guli\xe8res de la s\xe9curit\xe9 et d\xe9montrent une am\xe9lioration continue de leurs pratiques de s\xe9curit\xe9. Elles investissent dans des programmes de formation qui vont au-del\xe0 des listes de contr\xf4le de conformit\xe9 pour d\xe9velopper une v\xe9ritable expertise en s\xe9curit\xe9 dans les \xe9quipes. Plus important encore, elles cr\xe9ent des boucles de retour o\xf9 l'information sur la s\xe9curit\xe9 circule dans les deux sens dans l'organisation, permettant un apprentissage et une adaptation rapides lorsque de nouveaux risques \xe9mergent."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:'Une faible culture de la s\xe9curit\xe9 signifie que nous observons du "safety washing" - l\'apparence de se soucier de la s\xe9curit\xe9 sans substance.'}),' Les organisations avec de faibles cultures de la s\xe9curit\xe9 ont souvent des politiques de s\xe9curit\xe9 sur le papier mais ne les suivent pas sous la pression. Elles peuvent bl\xe2mer les individus pour les accidents plut\xf4t que d\'examiner les causes syst\xe9miques. Elles traitent g\xe9n\xe9ralement le travail sur la s\xe9curit\xe9 comme des frais g\xe9n\xe9raux qui ralentissent le "vrai" progr\xe8s, conduisant \xe0 un sous-financement et une marginalisation des \xe9quipes de s\xe9curit\xe9. Les pr\xe9occupations de s\xe9curit\xe9 dans ces organisations modifient rarement les d\xe9cisions r\xe9elles de d\xe9ploiement.']}),"\n",(0,i.jsx)(a.c,{title:"Notes de bas de page"})]})}function g(e={}){const{wrapper:s}={...(0,r.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},4768:(e,s,t)=>{t.d(s,{c:()=>u,A:()=>c});var n=t(6540),i=t(3012);const r={footnoteAnchor:"footnoteAnchor_PZpY",footnoteSection:"footnoteSection_waoz",separator:"separator_hp8y",separatorLine:"separatorLine_uVnd",separatorLogo:"separatorLogo_dMBq",footnoteRegistry:"footnoteRegistry_ieVW",registryTitle:"registryTitle_ybBb",footnoteList:"footnoteList_Kjil",footnoteItem:"footnoteItem_aLZ2",footnoteNumber:"footnoteNumber_dA3X",footnoteContent:"footnoteContent_Xfmt",backButton:"backButton_vSVm",highlighted:"highlighted_YFU0",highlight:"highlight_jxG3",highlightDark:"highlightDark_Ekom"};var a=t(4848);function l(e,s){void 0===s&&(s=!0);const t=document.getElementById(e);t&&(t.scrollIntoView({behavior:"smooth"}),s&&(t.classList.add(r.highlighted),setTimeout((()=>t.classList.remove(r.highlighted)),1500)))}function o(e){return e?e.replace(/\[([^\]]+)\]\(([^)]+)\)/g,'<a href="$2" target="_blank" rel="noopener noreferrer">$1</a>'):""}function c(e){let{id:s,text:t,number:c}=e;const u=s||`footnote-${Math.random().toString(36).substr(2,9)}`,d="string"==typeof t?o(t):t;return(0,n.useEffect)((()=>{const e=setTimeout((()=>{const e=document.getElementById(`footnote-clone-${u}`);e&&t&&(e.innerHTML="string"==typeof t?o(t):t.toString())}),100);return()=>clearTimeout(e)}),[u,t]),(0,a.jsx)(i.Mn,{content:(0,a.jsx)("div",{dangerouslySetInnerHTML:{__html:d}}),children:(0,a.jsx)("sup",{id:`footnote-ref-${u}`,className:r.footnoteAnchor,onClick:e=>{(e.ctrlKey||e.metaKey)&&(e.preventDefault(),l(`footnote-content-${u}`))},"data-footnote-number":c||"?",children:c||"*"})})}function u(e){let{title:s="References"}=e;const[t,o]=(0,n.useState)([]);return(0,n.useEffect)((()=>{const e=document.querySelectorAll('[id^="footnote-ref-"]'),s=Array.from(e).map((e=>({id:e.id.replace("footnote-ref-",""),number:e.getAttribute("data-footnote-number")||e.textContent})));o(s)}),[]),t.length?(0,a.jsxs)("div",{className:r.footnoteSection,children:[(0,a.jsxs)("div",{className:r.separator,children:[(0,a.jsx)("div",{className:r.separatorLine}),(0,a.jsx)("img",{src:"/img/logo_samples/01-test.svg",alt:"Atlas logo",className:r.separatorLogo}),(0,a.jsx)("div",{className:r.separatorLine})]}),(0,a.jsxs)("div",{className:r.footnoteRegistry,children:[(0,a.jsx)("h2",{className:r.registryTitle,children:s}),(0,a.jsx)("ol",{className:r.footnoteList,children:t.map((e=>(0,a.jsxs)("li",{id:`footnote-content-${e.id}`,className:r.footnoteItem,value:parseInt(e.number)||void 0,children:[(0,a.jsx)(i.Mn,{content:"Back to reference",children:(0,a.jsxs)("button",{className:r.footnoteNumber,onClick:()=>l(`footnote-ref-${e.id}`),"aria-label":"Back to reference",children:[e.number,"."]})}),(0,a.jsx)("div",{className:r.footnoteContent,children:(0,a.jsx)("div",{id:`footnote-clone-${e.id}`})}),(0,a.jsx)(i.Mn,{content:"Back to reference",children:(0,a.jsx)("button",{className:r.backButton,onClick:()=>l(`footnote-ref-${e.id}`),"aria-label":"Back to reference",children:"\u21a9"})})]},e.id)))})]})]}):null}}}]);