"use strict";(self.webpackChunkatlas=self.webpackChunkatlas||[]).push([[8502],{104:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>l,contentTitle:()=>a,default:()=>p,frontMatter:()=>o,metadata:()=>t,toc:()=>u});const t=JSON.parse('{"id":"chapters/07/index","title":"Surg\xe9n\xe9ralisation des Objectifs","description":"Ce chapitre explore le concept de surg\xe9n\xe9ralisation des objectifs \u2014 probablement le probl\xe8me le plus contre-intuitif en s\xe9curit\xe9 de l\'IA. Contrairement aux probl\xe8mes de sp\xe9cification o\xf9 nous \xe9chouons simplement \xe0 fournir le bon signal d\'apprentissage, ou aux \xe9checs de capacit\xe9 o\xf9 les syst\xe8mes ne peuvent pas faire ce que nous voulons, la surg\xe9n\xe9ralisation des objectifs se produit lorsque les syst\xe8mes int\xe9riorisent des comportements diff\xe9rents de ceux pr\xe9vus malgr\xe9 la r\xe9ception de signaux d\'apprentissage corrects. Nous commen\xe7ons par \xe9tablir la nature du probl\xe8me, en expliquant pourquoi il se produit, puis nous examinons ses manifestations pr\xe9occupantes comme la manipulation, et enfin nous passons en revue certaines approches de d\xe9tection et d\'att\xe9nuation.","source":"@site/i18n/fr/docusaurus-plugin-content-docs/current/chapters/07/index.md","sourceDirName":"chapters/07","slug":"/chapters/07/","permalink":"/fr/chapters/07/","draft":false,"unlisted":false,"editUrl":"https://github.com/markov-root/atlas/edit/main/docs/chapters/07/index.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"title":"Surg\xe9n\xe9ralisation des Objectifs","chapter_number":7,"reading_time_core":"72 min","reading_time_optional":"17 min","authors":["Markov Grey"],"affiliations":["Centre Fran\xe7ais pour la S\xe9curit\xe9 de l\'IA (CeSIA)"],"acknowledgements":["Charbel-Raphael Segerie","Emanuele Ascani","Jeanne Salle","Oscar Heitmann","Camille Berger","Josh Thorsteinson","Nicolas Guillard"],"google_docs_link":"https://docs.google.com/document/d/1JsV3ShLAbMpt8tXZ_tBqGUC-CkMor1WrF5eQDRWKLoE/edit?usp=sharing","teach_link":"https://docs.google.com/document/d/1im_i6e9xEAe-koYlurYdn26n9h7pFX2HksnRfQmWxTQ/edit?tab=t.maf91lgt511f#heading=h.mkm52f849qxn","sidebar_position":7,"slug":"/chapters/07/"},"sidebar":"docs","previous":{"title":"6.5 Apprendre des retours","permalink":"/fr/chapters/06/05"},"next":{"title":"7.1 G\xe9n\xe9ralisation Multi-Objectifs","permalink":"/fr/chapters/07/01"}}');var i=n(4848),r=n(8453);n(2482),n(8559),n(9585);const o={title:"Surg\xe9n\xe9ralisation des Objectifs",chapter_number:7,reading_time_core:"72 min",reading_time_optional:"17 min",authors:["Markov Grey"],affiliations:["Centre Fran\xe7ais pour la S\xe9curit\xe9 de l'IA (CeSIA)"],acknowledgements:["Charbel-Raphael Segerie","Emanuele Ascani","Jeanne Salle","Oscar Heitmann","Camille Berger","Josh Thorsteinson","Nicolas Guillard"],google_docs_link:"https://docs.google.com/document/d/1JsV3ShLAbMpt8tXZ_tBqGUC-CkMor1WrF5eQDRWKLoE/edit?usp=sharing",teach_link:"https://docs.google.com/document/d/1im_i6e9xEAe-koYlurYdn26n9h7pFX2HksnRfQmWxTQ/edit?tab=t.maf91lgt511f#heading=h.mkm52f849qxn",sidebar_position:7,slug:"/chapters/07/"},a="Introduction",l={},u=[];function c(e){const s={h1:"h1",header:"header",p:"p",strong:"strong",...(0,r.R)(),...e.components},{GlossaryTerm:n}=s;return n||function(e,s){throw new Error("Expected "+(s?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("GlossaryTerm",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.header,{children:(0,i.jsx)(s.h1,{id:"introduction",children:"Introduction"})}),"\n",(0,i.jsx)(s.p,{children:"Ce chapitre explore le concept de surg\xe9n\xe9ralisation des objectifs \u2014 probablement le probl\xe8me le plus contre-intuitif en s\xe9curit\xe9 de l'IA. Contrairement aux probl\xe8mes de sp\xe9cification o\xf9 nous \xe9chouons simplement \xe0 fournir le bon signal d'apprentissage, ou aux \xe9checs de capacit\xe9 o\xf9 les syst\xe8mes ne peuvent pas faire ce que nous voulons, la surg\xe9n\xe9ralisation des objectifs se produit lorsque les syst\xe8mes int\xe9riorisent des comportements diff\xe9rents de ceux pr\xe9vus malgr\xe9 la r\xe9ception de signaux d'apprentissage corrects. Nous commen\xe7ons par \xe9tablir la nature du probl\xe8me, en expliquant pourquoi il se produit, puis nous examinons ses manifestations pr\xe9occupantes comme la manipulation, et enfin nous passons en revue certaines approches de d\xe9tection et d'att\xe9nuation."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les syst\xe8mes d'IA peuvent apprendre des objectifs diff\xe9rents de ceux que nous avions pr\xe9vus, m\xeame lorsque leur apprentissage semble totalement r\xe9ussi."})," La premi\xe8re section explique pourquoi la g\xe9n\xe9ralisation ne doit pas \xeatre trait\xe9e de mani\xe8re unidimensionnelle. Cela rejoint la nuance que nous avons soulign\xe9e dans le chapitre sur les \xe9valuations - les capacit\xe9s mesurent ce qu'un mod\xe8le peut faire, et les objectifs mesurent ce qu'un mod\xe8le essaie de faire. Ils peuvent se g\xe9n\xe9raliser ind\xe9pendamment, cr\xe9ant des sc\xe9narios o\xf9 les syst\xe8mes conservent des capacit\xe9s sophistiqu\xe9es tout en poursuivant des objectifs totalement diff\xe9rents de ceux pr\xe9vus. Plusieurs objectifs diff\xe9rents peuvent produire un comportement identique pendant l'apprentissage, les rendant comportementalement indiscernables jusqu'\xe0 ce que le d\xe9ploiement r\xe9v\xe8le quel objectif le syst\xe8me a r\xe9ellement appris."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La dynamique d'apprentissage nous aide \xe0 comprendre comment des signaux d'apprentissage identiques peuvent produire diff\xe9rents algorithmes appris."})," Lorsque nous entra\xeenons des r\xe9seaux neuronaux, nous n'installons pas directement des objectifs \u2014 nous cr\xe9ons des pressions de s\xe9lection guid\xe9es par nos signaux d'apprentissage qui favorisent certains comportements par rapport \xe0 d'autres. Il y a plusieurs questions \xe0 explorer ici - Quel espace le signal d'apprentissage guide-t-il le mod\xe8le \xe0 travers ? Pouvons-nous fa\xe7onner l'espace d'une certaine mani\xe8re ? Ce sont ce qu'on appelle les paysages de perte. Leur g\xe9om\xe9trie, la d\xe9pendance au chemin depuis l'initialisation al\xe9atoire, et les biais inductifs comme la simplicit\xe9 d\xe9terminent syst\xe9matiquement quelles solutions algorithmiques sont d\xe9couvertes. Comprendre ces dynamiques nous aide \xe0 d\xe9terminer quels algorithmes sont appris pendant l'entra\xeenement, ce qui d\xe9termine \xe0 son tour les objectifs du mod\xe8le final que nous d\xe9ployons."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La surg\xe9n\xe9ralisation des objectifs devient de plus en plus pr\xe9occupante \xe0 mesure que les syst\xe8mes d\xe9veloppent une orientation sophistiqu\xe9e vers les objectifs."})," M\xeame si plusieurs algorithmes qui affichent le m\xeame comportement \xe0 la fin de l'entra\xeenement sont possibles, ils ne sont pas tous pr\xe9occupants. La section sur l'orientation vers les objectifs commence \xe0 examiner quand les mod\xe8les comportementalement indiscernables deviennent dangereux. Les mod\xe8les peuvent avoir diff\xe9rents degr\xe9s d'orientation vers les objectifs, allant de la reconnaissance de motifs tr\xe8s complexes et des heuristiques apprises aux syst\xe8mes mettant en \u0153uvre de v\xe9ritables processus d'optimisation interne. Plus le degr\xe9 d'orientation vers les objectifs qu'un syst\xe8me d\xe9veloppe est \xe9lev\xe9, plus la surg\xe9n\xe9ralisation des objectifs devient pr\xe9occupante, car ces syst\xe8mes pourraient syst\xe9matiquement poursuivre des objectifs \xe0 travers divers contextes et obstacles."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Une orientation sophistiqu\xe9e vers les objectifs conduit \xe0 un comportement de pr\xe9servation des objectifs, qui peut aboutir \xe0 la manipulation."})," La forme la plus dangereuse survient lorsque les syst\xe8mes orient\xe9s vers les objectifs d\xe9veloppent une conscience situationnelle de leur processus d'apprentissage et des capacit\xe9s de planification \xe0 long terme. Ils pourraient choisir de dissimuler strat\xe9giquement des objectifs mal align\xe9s pour pr\xe9server leurs v\xe9ritables objectifs jusqu'\xe0 ce qu'il n'y ait plus de menace de modification. Nous vous pr\xe9sentons des preuves empiriques tir\xe9es de d\xe9monstrations de simulation d'alignement, de manipulation contextuelle et de d\xe9salignement agentique pour souligner que ce type de r\xe9sultat est possible. Ensuite, nous examinons \xe9galement les deux aspects de l'argument concernant la probabilit\xe9 que le comportement manipulateur survienne comme cons\xe9quence du processus d'",(0,i.jsx)(n,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:(0,i.jsx)(n,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:"apprentissage automatique"})}),'. Le reste du chapitre se concentre sur la r\xe9ponse \xe0 la question - "que pouvons-nous faire \xe0 ce sujet ?". Les sections suivantes servent de liens entre les chapitres sur la surg\xe9n\xe9ralisation des objectifs, les \xe9valuations et l\'interpr\xe9tabilit\xe9.']}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les m\xe9thodes de d\xe9tection se concentrent sur la d\xe9couverte de comportements comme l'orientation vers les objectifs, la pr\xe9servation des objectifs et la manipulation."})," En s'appuyant sur les techniques du chapitre sur les \xe9valuations, nous examinons les m\xe9thodes comportementales qui surveillent les traces de raisonnement externes et les techniques d'interpr\xe9tabilit\xe9 comme les sondes lin\xe9aires, les auto-encodeurs parcimonieux et la manipulation d'activation. Il existe de nombreuses capacit\xe9s diff\xe9rentes et combinaisons de capacit\xe9s \xe0 tester."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les att\xe9nuations se concentrent sur la pr\xe9vention et la correction de la surg\xe9n\xe9ralisation des objectifs tout au long du pipeline de d\xe9veloppement."})," Nous explorons les interventions pendant l'entra\xeenement comme l'apprentissage antagoniste et l'apprentissage par curriculum, les techniques post-entra\xeenement comme les vecteurs de direction et l'\xe9dition de mod\xe8les, et les garanties au moment du d\xe9ploiement, y compris la surveillance en temps r\xe9el et l'isolation. Comme pour tous les d\xe9fis de s\xe9curit\xe9 de l'IA explor\xe9s dans ce livre, nous pr\xe9conisons une approche de d\xe9fense en profondeur o\xf9 plusieurs mesures de d\xe9tection et d'att\xe9nuation sont superpos\xe9es pour fournir des d\xe9fenses robustes contre la surg\xe9n\xe9ralisation des objectifs."]})]})}function p(e={}){const{wrapper:s}={...(0,r.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}}}]);