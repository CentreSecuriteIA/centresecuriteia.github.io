"use strict";(self.webpackChunkatlas=self.webpackChunkatlas||[]).push([[4400],{1322:(e,s,t)=>{t.r(s),t.d(s,{assets:()=>p,contentTitle:()=>c,default:()=>f,frontMatter:()=>d,metadata:()=>i,toc:()=>m});const i=JSON.parse('{"id":"chapters/02/1","title":"D\xe9composition du Risque","description":"Avant de commencer \xe0 parler de sc\xe9narios de risque concrets, nous avons besoin d\'un cadre qui nous permet d\'\xe9valuer o\xf9 ils se situent sur le spectre du risque. La classification des risques est intrins\xe8quement multidimensionnelle plut\xf4t que de chercher une seule \\"meilleure\\" cat\xe9gorisation. Nous avons choisi de d\xe9composer les risques en deux facteurs - \\"pourquoi les risques surviennent\\" (cause) et \\"quel degr\xe9 de gravit\xe9 peuvent atteindre les risques\\" (s\xe9v\xe9rit\xe9). D\'autres cadres compl\xe9mentaires comme la taxonomie des risques du MIT abordent des aspects comme \\"qui les cause\\" (humains vs syst\xe8mes d\'IA), \\"quand ils \xe9mergent\\" (d\xe9veloppement vs d\xe9ploiement), ou \\"si les r\xe9sultats sont intentionnels\\" (Slattery et al., 2024). Notre approche de d\xe9composition n\'est qu\'une parmi de nombreuses perspectives possibles, mais les risques dont nous parlerons ont tendance \xe0 \xeatre communs \xe0 travers celles-ci.","source":"@site/i18n/fr/docusaurus-plugin-content-docs/current/chapters/02/01.md","sourceDirName":"chapters/02","slug":"/chapters/02/01","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/02/01","draft":false,"unlisted":false,"editUrl":"https://github.com/markov-root/atlas/edit/main/docs/chapters/02/01.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"1","title":"D\xe9composition du Risque","sidebar_label":"2.1 D\xe9composition du Risque","sidebar_position":2,"slug":"/chapters/02/01","reading_time_core":"6 min","reading_time_optional":"4 min","pagination_prev":"chapters/02/index","pagination_next":"chapters/02/2"},"sidebar":"docs","previous":{"title":"Risques","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/02/"},"next":{"title":"2.2 Capacit\xe9s Dangereuses","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/02/02"}}');var n=t(4848),r=t(8453),a=t(3989),o=t(4768),l=(t(2482),t(8559)),u=(t(9585),t(2501));const d={id:1,title:"D\xe9composition du Risque",sidebar_label:"2.1 D\xe9composition du Risque",sidebar_position:2,slug:"/chapters/02/01",reading_time_core:"6 min",reading_time_optional:"4 min",pagination_prev:"chapters/02/index",pagination_next:"chapters/02/2"},c="D\xe9composition du risque",p={},m=[{value:"Causes du risque",id:"01",level:2},{value:"Gravit\xe9 du risque",id:"02",level:2}];function h(e){const s={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components},{GlossaryTerm:t}=s;return t||function(e,s){throw new Error("Expected "+(s?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("GlossaryTerm",!0),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(s.header,{children:(0,n.jsx)(s.h1,{id:"d\xe9composition-du-risque",children:"D\xe9composition du risque"})}),"\n",(0,n.jsxs)(s.p,{children:['Avant de commencer \xe0 parler de sc\xe9narios de risque concrets, nous avons besoin d\'un cadre qui nous permet d\'\xe9valuer o\xf9 ils se situent sur le spectre du risque. La classification des risques est intrins\xe8quement multidimensionnelle plut\xf4t que de chercher une seule "meilleure" cat\xe9gorisation. Nous avons choisi de d\xe9composer les risques en deux facteurs - "pourquoi les risques surviennent" (cause) et "quel degr\xe9 de gravit\xe9 peuvent atteindre les risques" (s\xe9v\xe9rit\xe9). D\'autres cadres compl\xe9mentaires comme la taxonomie des risques du MIT abordent des aspects comme "qui les cause" (humains vs syst\xe8mes d\'IA), "quand ils \xe9mergent" (d\xe9veloppement vs d\xe9ploiement), ou "si les r\xe9sultats sont intentionnels" (',(0,n.jsx)(s.a,{href:"https://arxiv.org/abs/2408.12622",children:"Slattery et al., 2024"}),"). Notre approche de d\xe9composition n'est qu'une parmi de nombreuses perspectives possibles, mais les risques dont nous parlerons ont tendance \xe0 \xeatre communs \xe0 travers celles-ci."]}),"\n",(0,n.jsx)(s.h2,{id:"01",children:"Causes du risque"}),"\n",(0,n.jsxs)(s.p,{children:[(0,n.jsx)(s.strong,{children:"Nous cat\xe9gorisons les risques li\xe9s \xe0 l'IA selon la responsabilit\xe9 causale pour comprendre les points d'intervention."})," Nous divisons les risques selon qui ou quoi porte la responsabilit\xe9 principale : les humains utilisant l'IA comme outil (mauvaise utilisation), les syst\xe8mes d'IA eux-m\xeames se comportant de mani\xe8re inattendue (d\xe9salignement), ou les effets \xe9mergents des interactions de syst\xe8mes complexes (syst\xe9mique). Cette perspective causale aide \xe0 identifier o\xf9 les interventions pourraient \xeatre les plus efficaces."]}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsxs)(s.li,{children:["\n",(0,n.jsxs)(s.p,{children:[(0,n.jsx)(s.strong,{children:"Les risques de mauvaise utilisation surviennent lorsque les humains d\xe9ploient intentionnellement des syst\xe8mes d'IA pour causer des dommages."})," Cela inclut les acteurs malveillants, les \xc9tats-nations, les entreprises ou les individus qui exploitent les capacit\xe9s de l'IA pour acc\xe9l\xe9rer les menaces existantes ou en cr\xe9er de nouvelles. Le syst\xe8me d'IA peut fonctionner exactement comme pr\xe9vu, mais l'intention humaine cr\xe9e le risque. Les exemples vont de l'utilisation de l'IA pour g\xe9n\xe9rer des logiciels malveillants ou des armes biologiques au d\xe9ploiement d'armes autonomes ou \xe0 la conduite de campagnes de d\xe9sinformation \xe0 grande \xe9chelle."]}),"\n"]}),"\n",(0,n.jsxs)(s.li,{children:["\n",(0,n.jsxs)(s.p,{children:[(0,n.jsx)(s.strong,{children:"Les risques de d\xe9salignement \xe9mergent lorsque les syst\xe8mes d'IA poursuivent des objectifs diff\xe9rents des intentions humaines."})," Ces risques d\xe9coulent des d\xe9fis techniques dans la sp\xe9cification des objectifs, des processus d'entra\xeenement qui cr\xe9ent des comportements inattendus, ou des syst\xe8mes d'IA apprenant des objectifs qui entrent en conflit avec les valeurs humaines. Contrairement \xe0 la mauvaise utilisation, ces risques surviennent malgr\xe9 de bonnes intentions humaines - le syst\xe8me d'IA lui-m\xeame g\xe9n\xe8re le comportement nuisible par le contournement des sp\xe9cifications, la surg\xe9n\xe9ralisation des objectifs ou d'autres \xe9checs d'alignement."]}),"\n"]}),"\n",(0,n.jsxs)(s.li,{children:["\n",(0,n.jsxs)(s.p,{children:[(0,n.jsx)(s.strong,{children:"Les risques syst\xe9miques d\xe9coulent de l'int\xe9gration de l'IA dans des syst\xe8mes mondiaux complexes, cr\xe9ant des menaces \xe9mergentes qu'aucun acteur n'a intentionnellement caus\xe9es."})," Cela inclut la concentration du pouvoir \xe0 mesure que les capacit\xe9s de l'IA deviennent monopolis\xe9es, le ch\xf4mage de masse d\xfb \xe0 l'automatisation, l'\xe9rosion \xe9pist\xe9mique lorsque le contenu g\xe9n\xe9r\xe9 par l'IA inonde les syst\xe8mes d'information, et les d\xe9faillances en cascade \xe0 travers les infrastructures interconnect\xe9es. La responsabilit\xe9 devient diffuse entre de nombreux acteurs et syst\xe8mes, rendant les cadres traditionnels de responsabilisation inad\xe9quats."]}),"\n"]}),"\n"]}),"\n",(0,n.jsxs)(s.p,{children:[(0,n.jsx)(s.strong,{children:"De nombreux risques r\xe9els li\xe9s \xe0 l'IA combinent plusieurs voies causales ou r\xe9sistent \xe0 une cat\xe9gorisation claire."})," L'analyse de plus de 1 600 risques document\xe9s li\xe9s \xe0 l'IA r\xe9v\xe8le que beaucoup ne s'inscrivent pas clairement dans une seule cat\xe9gorie (",(0,n.jsx)(s.a,{href:"https://arxiv.org/abs/2408.12622",children:"Slattery et al., 2024"}),"). Les risques impliquant l'interaction humain-IA m\xe9langent le d\xe9salignement individuel avec les risques syst\xe9miques. Les risques multi-agents \xe9mergent des syst\xe8mes d'IA interagissant de mani\xe8re inattendue. Certains sc\xe9narios impliquent des effets en cascade o\xf9 la mauvaise utilisation permet le d\xe9salignement, ou o\xf9 les pressions syst\xe9miques amplifient les \xe9checs individuels. Nous avons choisi la d\xe9composition causale \xe0 des fins explicatives, mais il convient de garder \xe0 l'esprit qu'il y aura des chevauchements, et que l'avenir contiendra probablement un m\xe9lange de risques provenant de diverses causes."]}),"\n",(0,n.jsx)(s.h2,{id:"02",children:"Gravit\xe9 du risque"}),"\n",(0,n.jsxs)(s.p,{children:[(0,n.jsx)(s.strong,{children:"Les risques li\xe9s \xe0 l'IA s'\xe9tendent sur un spectre allant des pr\xe9judices individuels aux menaces qui pourraient d\xe9finitivement faire d\xe9railler la civilisation humaine."})," Comprendre la gravit\xe9 aide \xe0 prioriser les ressources limit\xe9es et \xe0 calibrer notre r\xe9ponse aux diff\xe9rents types de risques. Plut\xf4t que de traiter tous les risques li\xe9s \xe0 l'IA comme \xe9galement importants, nous pouvons les organiser par port\xe9e et gravit\xe9 pour comprendre lesquels exigent une ",(0,n.jsx)(t,{term:"attention",definition:'{"definition":"M\xe9canisme permettant aux mod\xe8les de se concentrer sur les parties pertinentes de l\'entr\xe9e lors de la r\xe9alisation de pr\xe9dictions, en calculant des combinaisons pond\xe9r\xe9es d\'\xe9l\xe9ments d\'entr\xe9e..","source":"[Bahdanau et al., 2015](https://arxiv.org/abs/1409.0473)","aliases":["Attention","attention mechanism","self-attention"]}',children:(0,n.jsx)(t,{term:"attention",definition:'{"definition":"M\xe9canisme permettant aux mod\xe8les de se concentrer sur les parties pertinentes de l\'entr\xe9e lors de la r\xe9alisation de pr\xe9dictions, en calculant des combinaisons pond\xe9r\xe9es d\'\xe9l\xe9ments d\'entr\xe9e..","source":"[Bahdanau et al., 2015](https://arxiv.org/abs/1409.0473)","aliases":["Attention","attention mechanism","self-attention"]}',children:"attention"})})," imm\xe9diate par rapport \xe0 une pr\xe9paration \xe0 plus long terme."]}),"\n",(0,n.jsxs)(s.p,{children:[(0,n.jsx)(s.strong,{children:"Les risques individuels et locaux affectent des personnes ou des communaut\xe9s sp\xe9cifiques mais restent limit\xe9s dans leur port\xe9e."})," La base de donn\xe9es des incidents li\xe9s \xe0 l'IA documente plus de 1 000 cas r\xe9els o\xf9 les syst\xe8mes d'IA ont caus\xe9 ou failli causer des dommages (",(0,n.jsx)(s.a,{href:"https://arxiv.org/abs/2011.08512",children:"McGregor, 2020"}),"; ",(0,n.jsx)(s.a,{href:"https://incidentdatabase.ai/",children:"AI Incident Database, 2025"}),"). Ceux-ci incluent des accidents de voitures autonomes, des biais algorithmiques dans l'embauche ou les pr\xeats qui d\xe9savantagent certains individus, des violations de la vie priv\xe9e par des syst\xe8mes d'IA qui divulguent des donn\xe9es personnelles, ou la manipulation par des campagnes de d\xe9sinformation cibl\xe9es. Les risques locaux peuvent impliquer des d\xe9faillances de syst\xe8mes d'IA qui perturbent la gestion du trafic d'une ville ou causent des pannes de courant dans une r\xe9gion. Ces risques causent d\xe9j\xe0 des dommages imm\xe9diats et document\xe9s \xe0 des milliers, voire des centaines de milliers de personnes."]}),"\n",(0,n.jsx)(a.A,{src:"https://ourworldindata.org/grapher/annual-reported-ai-incidents-controversies?tab=chart",width:"100%",height:"600px",loading:"lazy",allow:"web-share; clipboard-write",frameBorder:"0",number:"1",label:"2.1",caption:"Nombre annuel mondial d'incidents et de controverses li\xe9s \xe0 l'intelligence artificielle signal\xe9s. Les incidents notables incluent une vid\xe9o \"deepfake\" du pr\xe9sident ukrainien Volodymyr Zelenskyy annon\xe7ant sa reddition, et l'utilisation de l'IA par les prisons am\xe9ricaines pour surveiller les appels de leurs d\xe9tenus. ([Giattino et al., 2023](https://ourworldindata.org/artificial-intelligence))."}),"\n",(0,n.jsx)(u.A,{src:"./img/MQJ_Image_3.png",alt:"Entrer la description alternative de l'image",number:"2",label:"2.2",caption:"Le rapport d'index de s\xe9curit\xe9 de l'IA pour l'\xe9t\xe9 2025. Ces scores concernent la cat\xe9gorie des pr\xe9judices actuels et montrent l'efficacit\xe9 avec laquelle les mod\xe8les de diff\xe9rentes entreprises att\xe9nuent les pr\xe9judices actuels. Cela inclut des \xe9l\xe9ments comme la performance des crit\xe8res de s\xe9curit\xe9, la robustesse contre les attaques adverses, le filigranage du contenu g\xe9n\xe9r\xe9 par l'IA et le traitement des donn\xe9es utilisateurs ([FLI, 2025](https://futureoflife.org/wp-content/uploads/2025/07/FLI-AI-Safety-Index-Report-Summer-2025.pdf))."}),"\n",(0,n.jsxs)(s.p,{children:[(0,n.jsx)(s.strong,{children:"Les risques catastrophiques menacent des populations massives mais permettent un r\xe9tablissement \xe9ventuel."})," Lorsque le nombre de personnes affect\xe9es par les risques atteint environ 10% de la population mondiale et qu'ils deviennent plus \xe9tendus g\xe9ographiquement, nous les appelons risques catastrophiques. Les exemples historiques incluent la Peste Noire (tuant un tiers de l'Europe), la pand\xe9mie de grippe de 1918 (50-100 millions de morts), et des sc\xe9narios futurs potentiels comme la guerre nucl\xe9aire ou les pand\xe9mies artificielles (",(0,n.jsx)(s.a,{href:"https://theprecipice.com/",children:"Ord, 2020"}),"). Dans le contexte de l'IA, ces risques peuvent causer des perturbations internationales g\xe9n\xe9ralis\xe9es. Le ch\xf4mage de masse d\xfb \xe0 l'automatisation par l'IA pourrait d\xe9stabiliser des \xe9conomies enti\xe8res, cr\xe9ant des troubles sociaux et des bouleversements politiques. Les cyberattaques utilisant des logiciels malveillants g\xe9n\xe9r\xe9s par l'IA pourraient paralyser les syst\xe8mes financiers ou les infrastructures critiques d'une nation. La surveillance bas\xe9e sur l'IA pourrait permettre un contr\xf4le autoritaire sur des centaines de millions de personnes. Les institutions d\xe9mocratiques pourraient \xe9chouer sous des campagnes de d\xe9sinformation soutenues par l'IA qui fracturent la r\xe9alit\xe9 partag\xe9e et rendent impossible la prise de d\xe9cision collective (",(0,n.jsx)(s.a,{href:"https://arxiv.org/abs/2408.12622",children:"Slattery et al., 2024"}),"; ",(0,n.jsx)(s.a,{href:"https://arxiv.org/abs/2502.14143",children:"Hammond et al., 2025"}),"; ",(0,n.jsx)(s.a,{href:"https://arxiv.org/abs/2404.16244",children:"Gabriel et al., 2024"}),"; ",(0,n.jsx)(s.a,{href:"https://hai.stanford.edu/ai-index/2025-ai-index-report",children:"Stanford HAI, 2025"}),"). Ces risques affectent des millions \xe0 des milliards de personnes mais ne emp\xeachent g\xe9n\xe9ralement pas un r\xe9tablissement ou une adaptation \xe9ventuelle."]}),"\n",(0,n.jsxs)(s.p,{children:[(0,n.jsx)(s.strong,{children:"Les risques existentiels (x-risks) repr\xe9sentent des menaces dont l'humanit\xe9 ne pourrait jamais r\xe9cup\xe9rer son plein potentiel."})," Contrairement aux risques catastrophiques o\xf9 le r\xe9tablissement reste possible, les risques existentiels soit \xe9liminent l'humanit\xe9 enti\xe8rement, soit emp\xeachent de fa\xe7on permanente la civilisation d'atteindre les sommets technologiques, moraux ou culturels qu'elle pourrait autrement atteindre. Les risques existentiels li\xe9s \xe0 l'IA incluent des sc\xe9narios o\xf9 des syst\xe8mes avanc\xe9s privent d\xe9finitivement l'humanit\xe9 de son pouvoir, \xe9tablissent un r\xe9gime totalitaire stable inamovible, ou causent l'extinction directe de l'humanit\xe9 (",(0,n.jsx)(s.a,{href:"https://nickbostrom.com/existential/risks",children:"Bostrom, 2002"}),"; ",(0,n.jsx)(s.a,{href:"https://futureoflife.org/existential-risk/existential-risk/",children:"Conn, 2015"}),"; ",(0,n.jsx)(s.a,{href:"https://theprecipice.com/",children:"Ord, 2020"}),"). Ces risques exigent des strat\xe9gies pr\xe9ventives plut\xf4t que r\xe9actives car apprendre de l'\xe9chec devient impossible par d\xe9finition.",(0,n.jsx)(o.A,{id:"footnote_recovery",number:"1",text:"L'effondrement civilisationnel irr\xe9versible, o\xf9 nous nous \xe9teignons ou ne sommes jamais remplac\xe9s par une civilisation ult\xe9rieure qui se reconstruit, a \xe9t\xe9 consid\xe9r\xe9 comme possible, mais avec une probabilit\xe9 extr\xeamement faible ([Rodriguez, 2020](https://forum.effectivealtruism.org/posts/GsjmufaebreiaivF7/what-is-the-likelihood-that-civilizational-collapse-would))."})]}),"\n",(0,n.jsx)(u.A,{src:"./img/g7b_Image_4.png",alt:"Entrer la description alternative de l'image",number:"3",label:"2.3",caption:"Cat\xe9gories qualitatives de risques. La port\xe9e du risque peut \xeatre personnelle (n'affectant qu'une seule personne), locale (affectant une r\xe9gion g\xe9ographique ou un groupe distinct), globale (affectant toute la population humaine ou une grande partie), transg\xe9n\xe9rationnelle (affectant l'humanit\xe9 pendant de nombreuses g\xe9n\xe9rations), ou pang\xe9n\xe9rationnelle (affectant l'humanit\xe9 dans l'ensemble, ou presque toutes les g\xe9n\xe9rations futures). La gravit\xe9 du risque peut \xeatre class\xe9e comme imperceptible (\xe0 peine perceptible), endurable (causant des dommages importants mais ne ruinant pas compl\xe8tement la qualit\xe9 de vie), ou \xe9crasante (causant la mort ou une r\xe9duction permanente et drastique de la qualit\xe9 de vie) ([Bostrom, 2012](https://existential-risk.com/concept))."}),"\n",(0,n.jsx)(u.A,{src:"./img/thM_Image_5.png",alt:"Entrer la description alternative de l'image",number:"4",label:"2.4",caption:"\xc9valuation des risques catastrophiques mondiaux par RAND. Le placement et la taille des ovales dans cette figure repr\xe9sentent une repr\xe9sentation qualitative des relations relatives entre les menaces et les dangers. La figure pr\xe9sente uniquement des exemples de cas ou de sc\xe9narios d\xe9crits dans ces chapitres, pas tous les sc\xe9narios d\xe9crits ([Willis et al., 2024](https://www.rand.org/pubs/research_reports/RRA2981-1.html))."}),"\n",(0,n.jsxs)(s.p,{children:[(0,n.jsx)(s.strong,{children:"Les risques de gravit\xe9 plus \xe9lev\xe9e repr\xe9sentent des erreurs irr\xe9versibles aux cons\xe9quences permanentes."})," Nous voyons d\xe9j\xe0 l'IA causer des dommages document\xe9s \xe0 des personnes r\xe9elles et avoir des effets d\xe9stabilisants sur les syst\xe8mes mondiaux. Cependant, les risques catastrophiques et existentiels pr\xe9sentent un d\xe9fi fondamentalement diff\xe9rent : si des syst\xe8mes d'IA avanc\xe9s causent une catastrophe existentielle, l'humanit\xe9 ne peut pas apprendre de l'erreur et mettre en place de meilleures garanties. Cette irr\xe9versibilit\xe9 conduit certains chercheurs \xe0 plaider pour la priorisation de la pr\xe9vention des sc\xe9narios \xe0 faible probabilit\xe9 mais \xe0 fort impact parall\xe8lement au traitement des pr\xe9judices actuels (",(0,n.jsx)(s.a,{href:"https://nickbostrom.com/existential/risks",children:"Bostrom, 2002"}),"). Bien que les gens ne soient pas d'accord sur l'\xe9quilibre appropri\xe9 d'",(0,n.jsx)(t,{term:"attention",definition:'{"definition":"M\xe9canisme permettant aux mod\xe8les de se concentrer sur les parties pertinentes de l\'entr\xe9e lors de la r\xe9alisation de pr\xe9dictions, en calculant des combinaisons pond\xe9r\xe9es d\'\xe9l\xe9ments d\'entr\xe9e..","source":"[Bahdanau et al., 2015](https://arxiv.org/abs/1409.0473)","aliases":["Attention","attention mechanism","self-attention"]}',children:(0,n.jsx)(t,{term:"attention",definition:'{"definition":"M\xe9canisme permettant aux mod\xe8les de se concentrer sur les parties pertinentes de l\'entr\xe9e lors de la r\xe9alisation de pr\xe9dictions, en calculant des combinaisons pond\xe9r\xe9es d\'\xe9l\xe9ments d\'entr\xe9e..","source":"[Bahdanau et al., 2015](https://arxiv.org/abs/1409.0473)","aliases":["Attention","attention mechanism","self-attention"]}',children:"attention"})})," entre les diff\xe9rentes gravit\xe9s de risques (",(0,n.jsx)(s.a,{href:"https://www.youtube.com/playlist?list=PLOAFgXcJkZ2wFf3mcJ0xIFpJQgEDI274J",children:"Oxford Union Debate, 2024"}),"; ",(0,n.jsx)(s.a,{href:"https://www.youtube.com/watch?v=144uOfr4SYA",children:"Munk Debate, 2024"}),")."]}),"\n",(0,n.jsx)(u.A,{src:"./img/PX9_Image_6.png",alt:"Entrer la description alternative de l'image",number:"5",label:"2.5",caption:"Le rapport d'index de s\xe9curit\xe9 de l'IA pour l'\xe9t\xe9 2025. Ces scores concernent la cat\xe9gorie des risques existentiels et montrent la pr\xe9paration des entreprises \xe0 g\xe9rer les risques extr\xeames des futurs syst\xe8mes d'IA qui pourraient \xe9galer ou d\xe9passer les capacit\xe9s humaines, y compris les strat\xe9gies d\xe9clar\xe9es et la recherche pour l'alignement et le contr\xf4le ([FLI, 2025](https://futureoflife.org/wp-content/uploads/2025/07/FLI-AI-Safety-Index-Report-Summer-2025.pdf)). Il est clair qu'il existe un \xe9cart de pr\xe9paration. Les entreprises affirment qu'elles atteindront l'AGI dans la d\xe9cennie, pourtant aucune n'a obtenu une note sup\xe9rieure \xe0 D dans la planification de la s\xe9curit\xe9 existentielle."}),"\n",(0,n.jsx)(l.A,{title:"Risques Ikigai (I-Risques) - Risques li\xe9s \xe0 la perte du sens de l'existence",collapsed:!0,children:(0,n.jsxs)(s.p,{children:[(0,n.jsx)(s.strong,{children:"Les risques ikigai (i-risks) impliquent la perte de sens et de but m\xeame lorsque les humains survivent et prosp\xe8rent."})," Nomm\xe9s d'apr\xe8s le concept japonais d'ikigai (but de la vie), ces risques \xe9mergent lorsque les syst\xe8mes d'IA deviennent plus capables que les humains dans toutes les activit\xe9s significatives. Les humains pourraient perdre leur sens du but lorsque l'IA peut cr\xe9er un meilleur art, mener de meilleures recherches et performer mieux dans chaque t\xe2che qui donnait traditionnellement un sens \xe0 la vie. Contrairement aux risques d'extinction ou de souffrance, les i-risks impliquent des sc\xe9narios o\xf9 les humains sont en s\xe9curit\xe9 et mat\xe9riellement confortables mais existentiellement \xe0 la d\xe9rive. Nous pourrions cr\xe9er des contraintes artificielles qui pr\xe9servent la pertinence humaine, ou trouver des formes enti\xe8rement nouvelles de but qui \xe9mergent de la collaboration homme-IA. Cependant, ces solutions soul\xe8vent leurs propres questions sur l'authenticit\xe9 et si le sens artificiellement pr\xe9serv\xe9 peut satisfaire les besoins psychologiques humains (",(0,n.jsx)(s.a,{href:"https://books.google.se/books/about/AI.html?id=V3XsEAAAQBAJ&redir_esc=y",children:"Yampolskiy, 2024"}),"; ",(0,n.jsx)(s.a,{href:"https://lexfridman.com/roman-yampolskiy-transcript/#chapter2_ikigai_risk",children:"Yampolsky; 2024"}),")."]})}),"\n",(0,n.jsxs)(l.A,{title:"Risques de souffrance existentielle (risques S) - Risques de souffrance prolong\xe9e",collapsed:!0,children:[(0,n.jsxs)(s.p,{children:[(0,n.jsx)(s.strong,{children:"Les risques de souffrance (s-risks) impliquent des quantit\xe9s astronomiques de souffrance qui pourraient largement d\xe9passer toute la souffrance de l'histoire humaine."})," Les s-risks constituent une classe sp\xe9ciale de risques existentiels. Ils repr\xe9sentent des sc\xe9narios o\xf9 le futur contient des ordres de grandeur plus de souffrance qu'il n'en existe aujourd'hui, impliquant potentiellement des billions d'\xeatres sensibles \xe0 travers l'espace et le temps. Contrairement aux risques d'extinction qui \xe9liminent compl\xe8tement l'exp\xe9rience, les s-risks cr\xe9ent des futurs remplis de terrible souffrance (",(0,n.jsx)(s.a,{href:"https://longtermrisk.org/reducing-risks-of-astronomical-suffering-a-neglected-priority/",children:"Althaus & Gloor, 2016"}),"; ",(0,n.jsx)(s.a,{href:"https://centerforreducingsuffering.org/research/intro/",children:"Baumann, 2017"}),"; ",(0,n.jsx)(s.a,{href:"https://longtermrisk.org/beginners-guide-to-reducing-s-risks/",children:"DiGiovanni, 2023"}),")."]}),(0,n.jsxs)(s.p,{children:[(0,n.jsx)(s.strong,{children:"Les civilisations futures pourraient cr\xe9er un vaste nombre d'\xeatres artificiels sensibles."})," Si ces \xeatres sont sensibles, alors les esprits artificiels pourraient exp\xe9rimenter une v\xe9ritable souffrance s'ils sont cr\xe9\xe9s sans pr\xe9caution. Les solutions efficaces pourraient par hasard impliquer de la souffrance - comme l'esclavage num\xe9rique o\xf9 des billions d'esprits artificiels effectuent du travail computationnel dans des conditions terribles. Les civilisations futures menant des simulations d\xe9taill\xe9es de l'\xe9volution biologique ou testant des th\xe9ories sur la conscience pourraient cr\xe9er par inadvertance des millions d'\xeatres souffrants dans leurs simulations. Les \xeatres simul\xe9s exp\xe9rimenteraient une v\xe9ritable souffrance m\xeame s'ils n'existent que comme processus computationnels."]}),(0,n.jsx)(s.p,{children:"Bien que ces sc\xe9narios puissent sembler relever de la science-fiction, certains chercheurs soutiennent qu'ils m\xe9ritent consid\xe9ration \xe9tant donn\xe9 les enjeux potentiellement \xe9normes impliqu\xe9s et la nature irr\xe9versible de tels r\xe9sultats s'ils se produisaient."})]}),"\n",(0,n.jsx)(s.p,{children:"Ces cat\xe9gories de risques et niveaux de gravit\xe9 fournissent la base pour examiner les capacit\xe9s sp\xe9cifiques de l'IA qui pourraient permettre des r\xe9sultats n\xe9fastes. Nous concentrons le reste du chapitre sur la pr\xe9sentation de cas concrets et d'arguments sur la fa\xe7on dont divers d\xe9veloppements de l'IA pourraient conduire \xe0 diff\xe9rentes gravit\xe9s de pr\xe9judices, en se concentrant particuli\xe8rement sur ceux qui pourraient franchir la ligne vers le catastrophique ou l'existentiel."}),"\n",(0,n.jsx)(o.c,{title:"Notes de bas de page"})]})}function f(e={}){const{wrapper:s}={...(0,r.R)(),...e.components};return s?(0,n.jsx)(s,{...e,children:(0,n.jsx)(h,{...e})}):h(e)}},4768:(e,s,t)=>{t.d(s,{c:()=>d,A:()=>u});var i=t(6540),n=t(3012);const r={footnoteAnchor:"footnoteAnchor_PZpY",footnoteSection:"footnoteSection_waoz",separator:"separator_hp8y",separatorLine:"separatorLine_uVnd",separatorLogo:"separatorLogo_dMBq",footnoteRegistry:"footnoteRegistry_ieVW",registryTitle:"registryTitle_ybBb",footnoteList:"footnoteList_Kjil",footnoteItem:"footnoteItem_aLZ2",footnoteNumber:"footnoteNumber_dA3X",footnoteContent:"footnoteContent_Xfmt",backButton:"backButton_vSVm",highlighted:"highlighted_YFU0",highlight:"highlight_jxG3",highlightDark:"highlightDark_Ekom"};var a=t(4848);function o(e,s){void 0===s&&(s=!0);const t=document.getElementById(e);t&&(t.scrollIntoView({behavior:"smooth"}),s&&(t.classList.add(r.highlighted),setTimeout((()=>t.classList.remove(r.highlighted)),1500)))}function l(e){return e?e.replace(/\[([^\]]+)\]\(([^)]+)\)/g,'<a href="$2" target="_blank" rel="noopener noreferrer">$1</a>'):""}function u(e){let{id:s,text:t,number:u}=e;const d=s||`footnote-${Math.random().toString(36).substr(2,9)}`,c="string"==typeof t?l(t):t;return(0,i.useEffect)((()=>{const e=setTimeout((()=>{const e=document.getElementById(`footnote-clone-${d}`);e&&t&&(e.innerHTML="string"==typeof t?l(t):t.toString())}),100);return()=>clearTimeout(e)}),[d,t]),(0,a.jsx)(n.Mn,{content:(0,a.jsx)("div",{dangerouslySetInnerHTML:{__html:c}}),children:(0,a.jsx)("sup",{id:`footnote-ref-${d}`,className:r.footnoteAnchor,onClick:e=>{(e.ctrlKey||e.metaKey)&&(e.preventDefault(),o(`footnote-content-${d}`))},"data-footnote-number":u||"?",children:u||"*"})})}function d(e){let{title:s="References"}=e;const[t,l]=(0,i.useState)([]);return(0,i.useEffect)((()=>{const e=document.querySelectorAll('[id^="footnote-ref-"]'),s=Array.from(e).map((e=>({id:e.id.replace("footnote-ref-",""),number:e.getAttribute("data-footnote-number")||e.textContent})));l(s)}),[]),t.length?(0,a.jsxs)("div",{className:r.footnoteSection,children:[(0,a.jsxs)("div",{className:r.separator,children:[(0,a.jsx)("div",{className:r.separatorLine}),(0,a.jsx)("img",{src:"/img/logo_samples/01-test.svg",alt:"Atlas logo",className:r.separatorLogo}),(0,a.jsx)("div",{className:r.separatorLine})]}),(0,a.jsxs)("div",{className:r.footnoteRegistry,children:[(0,a.jsx)("h2",{className:r.registryTitle,children:s}),(0,a.jsx)("ol",{className:r.footnoteList,children:t.map((e=>(0,a.jsxs)("li",{id:`footnote-content-${e.id}`,className:r.footnoteItem,value:parseInt(e.number)||void 0,children:[(0,a.jsx)(n.Mn,{content:"Back to reference",children:(0,a.jsxs)("button",{className:r.footnoteNumber,onClick:()=>o(`footnote-ref-${e.id}`),"aria-label":"Back to reference",children:[e.number,"."]})}),(0,a.jsx)("div",{className:r.footnoteContent,children:(0,a.jsx)("div",{id:`footnote-clone-${e.id}`})}),(0,a.jsx)(n.Mn,{content:"Back to reference",children:(0,a.jsx)("button",{className:r.backButton,onClick:()=>o(`footnote-ref-${e.id}`),"aria-label":"Back to reference",children:"\u21a9"})})]},e.id)))})]})]}):null}},3989:(e,s,t)=>{t.d(s,{A:()=>l});var i=t(6540),n=t(6347),r=t(8444);const a={iframeContainer:"iframeContainer_ixkI",loader:"loader_gjvK",spinner:"spinner_L1j2",spin:"spin_rtC2",iframeWrapper:"iframeWrapper_Tijy",iframe:"iframe_UAfa",caption:"caption_mDwB",captionLink:"captionLink_Ly4l"};var o=t(4848);function l(e){let{src:s,caption:t,title:l="Embedded content",height:u="500px",width:d="100%",chapter:c,number:p,label:m}=e;const[h,f]=(0,i.useState)(!0),g=(0,n.zy)(),v=c||(()=>{const e=g.pathname.match(/\/chapters\/(\d+)/);return e?parseInt(e[1]):null})(),x=u&&"100%"!==u&&"auto"!==u;return(0,o.jsxs)("figure",{className:a.iframeContainer,children:[h&&(0,o.jsxs)("div",{className:a.loader,children:[(0,o.jsx)("div",{className:a.spinner}),(0,o.jsx)("p",{children:"Loading content..."})]}),(0,o.jsx)("div",{className:a.iframeWrapper,style:{paddingBottom:x?"0":"56.25%",height:x?u:"auto"},children:(0,o.jsx)("iframe",{src:s,title:l,width:d,height:x?u:"100%",frameBorder:"0",allowFullScreen:!0,loading:"lazy",onLoad:()=>{f(!1)},className:a.iframe,style:{height:x?u:"100%",position:x?"static":"absolute"}})}),(0,o.jsx)(r.A,{caption:t,mediaType:"iframe",chapter:v,number:p,label:m})]})}}}]);