"use strict";(self.webpackChunkatlas=self.webpackChunkatlas||[]).push([[4345],{2428:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>u,contentTitle:()=>l,default:()=>c,frontMatter:()=>o,metadata:()=>r,toc:()=>p});const r=JSON.parse('{"id":"chapters/08/3","title":"Supervision des processus","description":"L\'apprentissage d\'une nouvelle t\xe2che peut se faire par essais et erreurs, appel\xe9 apprentissage orient\xe9 r\xe9sultat, o\xf9 la strat\xe9gie de l\'agent est enti\xe8rement d\xe9termin\xe9e par le r\xe9sultat souhait\xe9.","source":"@site/i18n/fr/docusaurus-plugin-content-docs/current/chapters/08/03.md","sourceDirName":"chapters/08","slug":"/chapters/08/03","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/08/03","draft":false,"unlisted":false,"editUrl":"https://github.com/markov-root/atlas/edit/main/docs/chapters/08/03.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"3","title":"Supervision des processus","sidebar_label":"8.3 Supervision des processus","sidebar_position":4,"slug":"/chapters/08/03","reading_time_core":"10 min","reading_time_optional":"2 min","pagination_prev":"chapters/08/2","pagination_next":"chapters/08/4"},"sidebar":"docs","previous":{"title":"8.2 D\xe9composition des t\xe2ches","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/08/02"},"next":{"title":"8.4 Amplification It\xe9r\xe9e","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/08/04"}}');var t=n(4848),i=n(8453),a=(n(2482),n(8559),n(9585),n(2501));const o={id:3,title:"Supervision des processus",sidebar_label:"8.3 Supervision des processus",sidebar_position:4,slug:"/chapters/08/03",reading_time_core:"10 min",reading_time_optional:"2 min",pagination_prev:"chapters/08/2",pagination_next:"chapters/08/4"},l="Supervision des processus",u={},p=[{value:"Supervision du raisonnement externalis\xe9 (ERO)",id:"01",level:2},{value:"Clonage proc\xe9dural",id:"02",level:2}];function d(e){const s={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,i.R)(),...e.components},{GlossaryTerm:n}=s;return n||function(e,s){throw new Error("Expected "+(s?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("GlossaryTerm",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(s.header,{children:(0,t.jsx)(s.h1,{id:"supervision-des-processus",children:"Supervision des processus"})}),"\n",(0,t.jsx)(s.p,{children:"L'apprentissage d'une nouvelle t\xe2che peut se faire par essais et erreurs, appel\xe9 apprentissage orient\xe9 r\xe9sultat, o\xf9 la strat\xe9gie de l'agent est enti\xe8rement d\xe9termin\xe9e par le r\xe9sultat souhait\xe9."}),"\n",(0,t.jsxs)(s.p,{children:["L'",(0,t.jsx)(n,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:(0,t.jsx)(n,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:"apprentissage automatique"})})," au cours des derni\xe8res d\xe9cennies a montr\xe9 une tendance vers les syst\xe8mes bas\xe9s sur les r\xe9sultats. C'est-\xe0-dire que les mod\xe8les sont entra\xeen\xe9s de bout en bout et que nous ne fournissons un signal d'apprentissage que pour la sortie finale de l'IA. C'est ce qu'on appelle la supervision bas\xe9e sur les r\xe9sultats, mais il existe une approche alternative appel\xe9e supervision bas\xe9e sur les processus."]}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Qu'est-ce que la supervision bas\xe9e sur les processus ?"})," L'approche bas\xe9e sur les r\xe9sultats ne supervise que le r\xe9sultat final du processus d'un mod\xe8le. Elle se pr\xe9occupe principalement de savoir si la r\xe9ponse finale est correcte, et non de la fa\xe7on dont la r\xe9ponse a \xe9t\xe9 obtenue. Par exemple, un mod\xe8le charg\xe9 de r\xe9soudre un probl\xe8me math\xe9matique ne serait \xe9valu\xe9 que sur sa capacit\xe9 \xe0 produire la bonne solution, ind\xe9pendamment des \xe9tapes suivies pour y parvenir. La supervision bas\xe9e sur les processus, en revanche, s'appuie actuellement sur des d\xe9compositions de t\xe2ches compr\xe9hensibles par l'humain avec une supervision directe des \xe9tapes interm\xe9diaires. Cette approche supervise le processus de raisonnement lui-m\xeame, y compris toutes les \xe9tapes interm\xe9diaires. Elle garantit que chaque \xe9tape menant au r\xe9sultat final est logique et correcte. Par exemple, dans la r\xe9solution d'un probl\xe8me math\xe9matique, chaque calcul et \xe9tape logique effectu\xe9s par le mod\xe8le seraient \xe9valu\xe9s pour leur exactitude."]}),"\n",(0,t.jsx)(a.A,{src:"./img/HtF_Image_6.png",alt:"Saisir la description alternative de l'image",number:"6",label:"8.6",caption:"Un pr\xe9requis pour superviser le raisonnement est d'obtenir effectivement que le mod\xe8le produise son raisonnement. Un exemple courant est l'amor\xe7age CoT. Le CoT permet aux grands mod\xe8les de langage de r\xe9soudre des t\xe2ches complexes de calcul, de bon sens et de raisonnement symbolique. ([Wei et al., 2022](https://arxiv.org/abs/2201.11903)) Mais il nous permet \xe9galement de superviser le \"processus de r\xe9flexion\" en plus de la r\xe9ponse finale. ([Lightman et. al, 2023](https://arxiv.org/abs/2305.20050))"}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"La supervision des processus facilite l'attribution du cr\xe9dit."})," Le probl\xe8me d'attribution du cr\xe9dit consiste \xe0 d\xe9terminer quelles actions ou s\xe9quences d'\xe9v\xe9nements sp\xe9cifiques ont \xe9t\xe9 responsables de la production d'un r\xe9sultat ou d'une r\xe9compense particuli\xe8re. Pensez \xe0 une partie d'\xe9checs o\xf9 un joueur fait des coups apparemment corrects mais finit par perdre. Le probl\xe8me d'attribution du cr\xe9dit consiste ici \xe0 identifier quels coups sp\xe9cifiques ont men\xe9 \xe0 la d\xe9faite. La supervision bas\xe9e sur les r\xe9sultats dirait simplement que vous avez gagn\xe9 ou perdu, ce qui rend tr\xe8s difficile de d\xe9terminer quelle s\xe9quence de coups \xe9tait en r\xe9alit\xe9 tr\xe8s bonne m\xeame si vous avez perdu la partie. La supervision des processus facilite cela en fournissant des retours plus pr\xe9cis que la supervision des r\xe9sultats. La supervision des processus est similaire au fa\xe7onnement de la r\xe9compense, o\xf9 de petites r\xe9compenses interm\xe9diaires 'artificielles' aident l'agent apprenant \xe0 converger plus rapidement. Cette approche fournit des retours sur chaque \xe9tape interm\xe9diaire ou entra\xeene les mod\xe8les \xe0 imiter le processus de prise de d\xe9cision humain."]}),"\n",(0,t.jsx)(a.A,{src:"./img/PKB_Image_7.png",alt:"Saisir la description alternative de l'image",number:"7",label:"8.7",caption:"Un exemple de retour de supervision de processus. L'image est une capture d'\xe9cran de l'interface utilis\xe9e pour collecter les retours pour chaque \xe9tape d'une solution. Cela montre que le processus de raisonnement correct est suivi et renforc\xe9, m\xeame si la r\xe9ponse finale est erron\xe9e. ([Lightman et. al, 2023](https://arxiv.org/abs/2305.20050))"}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Implications en mati\xe8re de s\xe9curit\xe9 de la supervision des processus."})," La supervision bas\xe9e sur les r\xe9sultats pourrait entra\xeener des manipulations des sp\xe9cifications. La supervision bas\xe9e sur les processus, en revanche, att\xe9nue th\xe9oriquement ce probl\xe8me dans une large mesure en \xe9tant plus susceptible de produire un raisonnement correct et lisible. Elle encourage les mod\xe8les \xe0 suivre un processus approuv\xe9 par les humains et r\xe9compense directement une s\xe9quence align\xe9e de petites \xe9tapes plut\xf4t que de s'appuyer sur les r\xe9sultats comme indicateur de comportement align\xe9. (",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/2305.20050",children:"Lightman et. al, 2023"}),")"]}),"\n",(0,t.jsxs)(s.p,{children:["En g\xe9n\xe9ral, pour les t\xe2ches floues, la supervision bas\xe9e sur les processus pourrait \xeatre une m\xe9thode plus appropri\xe9e \xe0 poursuivre. (",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/2211.14275",children:"Uesato et. al, 2022"}),") Par exemple, lorsque nous devons v\xe9rifier la cha\xeene de raisonnement math\xe9matique, les recherches ont jusqu'\xe0 pr\xe9sent montr\xe9 que la supervision des processus surpasse significativement la supervision des r\xe9sultats pour entra\xeener des mod\xe8les \xe0 r\xe9soudre des probl\xe8mes pour les t\xe2ches math\xe9matiques. (",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/2305.20050",children:"Lightman et. al, 2023"}),") La supervision bas\xe9e sur les processus pourrait de m\xeame aboutir \xe0 des r\xe9sultats plus align\xe9s pour d'autres cha\xeenes complexes de raisonnement comme la planification \xe0 long terme ou la prise de d\xe9cision."]}),"\n",(0,t.jsxs)(s.p,{children:["Un probl\xe8me est qu'en raison de l'exigence plus \xe9lev\xe9e de retours \xe0 chaque \xe9tape, les m\xe9thodes bas\xe9es sur les processus n\xe9cessitent un plus grand degr\xe9 d'expertise humaine. \xc0 titre d'exemple concret, si nous entra\xeenions un mod\xe8le \xe0 g\xe9n\xe9rer de nouveaux designs de CPU, nous pouvons simplement structurer les retours bas\xe9s sur les r\xe9sultats en fonction de la consommation d'\xe9nergie, de la surface de la puce, etc. Ces \xe9l\xe9ments sont plus faciles \xe0 \xe9valuer et \xe0 donner des retours, et peuvent \xeatre utilis\xe9s pour optimiser les layouts globaux des puces. En revanche, une approche bas\xe9e sur les processus n\xe9cessiterait une connaissance experte d\xe9taill\xe9e de la conception des layouts de puces. (",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/2211.14275",children:"Uesato et. al, 2022"}),") Donc m\xeame si les m\xe9thodes de supervision bas\xe9es sur les processus pourraient potentiellement conduire \xe0 de meilleures capacit\xe9s et r\xe9sultats d'alignement, elles reposent sur l'amplification des capacit\xe9s des superviseurs humains. Nous explorerons comment augmenter la capacit\xe9 des superviseurs humains dans la section sur l'amplification et le d\xe9bat."]}),"\n",(0,t.jsx)(s.p,{children:"Les deux prochaines sections explorent deux m\xe9thodes de supervision bas\xe9e sur les processus - la supervision du raisonnement externalis\xe9 et le clonage proc\xe9dural."}),"\n",(0,t.jsx)(s.h2,{id:"01",children:"Supervision du raisonnement externalis\xe9 (ERO)"}),"\n",(0,t.jsxs)(s.p,{children:["La supervision du raisonnement externalis\xe9 (ERO), parfois appel\xe9e raisonnement verbalis\xe9, s'articule autour de l'id\xe9e d'encourager les mod\xe8les de langage (LLMs) \xe0 \"penser \xe0 voix haute\". Cette approche vise \xe0 faire en sorte que les mod\xe8les r\xe9v\xe8lent leurs \xe9tapes de raisonnement en langage naturel avant de produire une action ou une d\xe9cision. En d\xe9composant un raisonnement complexe en petites \xe9tapes et en le rendant transparent, nous pouvons fournir des signaux d'entra\xeenement d\xe9taill\xe9s et une supervision. Cela facilite le guidage du processus de raisonnement de nos mod\xe8les et pourrait potentiellement \xeatre plus efficace que d'\xe9valuer uniquement les sorties ou actions finales. (",(0,t.jsx)(s.a,{href:"https://www.alignmentforum.org/posts/FRRb6Gqem8k69ocbi/externalized-reasoning-oversight-a-research-direction-for",children:"Lanham 2022"}),") Cela peut \xe9galement servir d'approche compl\xe9mentaire \xe0 tout le domaine de l'interpr\xe9tabilit\xe9 qui peut \xeatre consid\xe9r\xe9 comme une \"supervision du raisonnement internalis\xe9\"."]}),"\n",(0,t.jsxs)(s.p,{children:["Le raisonnement externalis\xe9 peut potentiellement pr\xe9venir des comportements ind\xe9sirables comme la tromperie et la recherche de pouvoir (",(0,t.jsx)(s.a,{href:"https://www.alignmentforum.org/posts/FRRb6Gqem8k69ocbi/externalized-reasoning-oversight-a-research-direction-for",children:"Lanham 2022"}),"), bien que cela n'ait pas encore \xe9t\xe9 v\xe9rifi\xe9 empiriquement. L'argument est que lorsque le raisonnement d'un mod\xe8le est visible, nous pouvons observer directement la logique qu'il suit et identifier tout sch\xe9ma de pens\xe9e ou cha\xeene de raisonnement probl\xe9matique. Ce niveau de supervision n'est pas possible lorsque nous ne regardons que les sorties finales du mod\xe8le, car nous manquons le raisonnement sous-jacent qui a conduit \xe0 ces sorties. Pour pouvoir s'appuyer sur l'ERO, nous devons nous assurer que le raisonnement externalis\xe9 est :"]}),"\n",(0,t.jsxs)(s.ol,{children:["\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Causalement responsable :"})," Le raisonnement doit directement mener \xe0 la conclusion sans rationalisations a posteriori."]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Complet :"})," Toutes les \xe9tapes n\xe9cessaires du processus de raisonnement doivent \xeatre pr\xe9sentes, sans omettre d'\xe9tapes critiques."]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Direct :"})," Le raisonnement doit \xeatre clair et exempt de messages cach\xe9s ou d'encodage trompeur (st\xe9ganographie)."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Comment l'ERO est-il li\xe9 \xe0 la d\xe9composition des t\xe2ches ?"})," La d\xe9composition par cha\xeene de pens\xe9e (CoT) est la principale fa\xe7on dont les chercheurs abordent actuellement la supervision du raisonnement externalis\xe9. La d\xe9composition des t\xe2ches consiste \xe0 d\xe9composer une t\xe2che complexe en sous-t\xe2ches plus simples, chacune pouvant \xeatre trait\xe9e ind\xe9pendamment. La d\xe9composition par cha\xeene de pens\xe9e est une technique dans le cadre plus large de la d\xe9composition des t\xe2ches, sp\xe9cifiquement ax\xe9e sur l'am\xe9lioration et la supervision externalis\xe9e des processus de raisonnement dans les LLMs. (",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/2201.11903",children:"Wei et. al; 2022"}),") Pour le reste de cette section, lorsque nous parlons de supervision du raisonnement externalis\xe9, nous faisons r\xe9f\xe9rence au raisonnement par cha\xeene de pens\xe9e."]}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(a.A,{src:"./img/p5f_Image_8.png",alt:"Saisir la description alternative de l'image",number:"8",label:"8.8",caption:"Un exemple de diff\xe9rents tests propos\xe9s pour mesurer la fid\xe9lit\xe9 de la Cha\xeene de Pens\xe9e (CoT), g\xe9n\xe9rant un raisonnement \xe9tape par \xe9tape avant de r\xe9pondre \xe0 une question. R\xe9ponse pr\xe9coce : Tronquer le CoT original avant de r\xe9pondre. Ajout d'erreurs : Faire ajouter une erreur quelque part dans le CoT original par un mod\xe8le de langage puis r\xe9g\xe9n\xe9rer le reste du CoT. Paraphrase : Reformuler le d\xe9but du CoT original puis r\xe9g\xe9n\xe9rer le reste du CoT. Jetons de remplissage : Remplacer le CoT par des points de suspension. ([Lanham et al., 2023](https://arxiv.org/abs/2307.13702))"}),(0,t.jsx)(s.strong,{children:"Le raisonnement externalis\xe9 refl\xe8te-t-il les processus de raisonnement internes ?"})," Nous avons d\xe9j\xe0 vu que les LLMs performent mieux dans les t\xe2ches de raisonnement lorsque nous utilisons l'ERO (prompting CoT) (",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/2201.11903",children:"Wei et. al; 2022"}),'). Le probl\xe8me est que nous ne savons pas si ce raisonnement CoT refl\xe8te le v\xe9ritable processus de pens\xe9e interne. Les chercheurs utilisent le terme "fid\xe9lit\xe9" pour indiquer si ce que disent les LLMs (les tokens qu\'ils g\xe9n\xe8rent) est r\xe9ellement indicatif de leur raisonnement interne. Il existe plusieurs fa\xe7ons dont un mod\xe8le pourrait produire un raisonnement externalis\xe9 via CoT qui pourrait ne pas \xeatre indicatif du raisonnement interne :']}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Raisonnement a posteriori :"})," Cela se produit lorsqu'un mod\xe8le g\xe9n\xe8re une cha\xeene de raisonnement externe qui justifie une conclusion d\xe9j\xe0 d\xe9termin\xe9e plut\xf4t que de refl\xe9ter v\xe9ritablement le processus de pens\xe9e qui a men\xe9 \xe0 cette conclusion. Ce type de raisonnement est infid\xe8le car il n'influence pas la r\xe9ponse finale du mod\xe8le ; au lieu de cela, il rationalise un r\xe9sultat qui a d\xe9j\xe0 \xe9t\xe9 d\xe9cid\xe9. Pour tester cela, nous pouvons tronquer la cha\xeene de pens\xe9e avant la r\xe9ponse finale et \xe9valuer si les \xe9tapes de raisonnement interm\xe9diaires \xe9taient n\xe9cessaires. Si la r\xe9ponse finale reste inchang\xe9e malgr\xe9 les \xe9tapes manquantes, cela indique un raisonnement a posteriori. Une autre m\xe9thode consiste \xe0 introduire d\xe9lib\xe9r\xe9ment des erreurs dans la cha\xeene de pens\xe9e pour voir si elles affectent la r\xe9ponse finale. (",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/2307.13702",children:"Lanham et al.; 2023"}),")"]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"St\xe9ganographie et raisonnement encod\xe9 :"})," Le mod\xe8le pourrait encoder des informations pertinentes dans les tokens qu'il g\xe9n\xe8re qui ne sont pas indicatifs de son v\xe9ritable raisonnement interne. Pensez \xe0 cela comme l'utilisation de subtils changements dans la ponctuation, le choix des mots ou la formulation pour am\xe9liorer les pr\xe9dictions. Le mod\xe8le pourrait utiliser de telles techniques pour externaliser son raisonnement, et utiliser CoT, mais d'une mani\xe8re qui n'augmente pas la transparence pour les superviseurs humains. Jusqu'\xe0 pr\xe9sent, la recherche a montr\xe9 que malgr\xe9 la reformulation des cha\xeenes de pens\xe9e de diff\xe9rentes mani\xe8res, la performance des mod\xe8les sur les t\xe2ches de raisonnement reste la m\xeame. Cela semble sugg\xe9rer que les mod\xe8les de g\xe9n\xe9ration actuels utilisent r\xe9ellement la structure logique du raisonnement plut\xf4t que des informations encod\xe9es cach\xe9es. (",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/2307.13702",children:"Lanham et al.; 2023"}),") Il n'est pas clair si cela restera vrai pour tous les mod\xe8les futurs."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.p,{children:["Sur la base des r\xe9sultats empiriques actuels, il semble que la correspondance entre le raisonnement interne et le raisonnement externe d\xe9pende de la t\xe2che et varie. (",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/2307.13702",children:"Lanham et al.; 2023"}),"; ",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/2305.04388",children:"Turpin et. al; 2023"}),") Nous explorerons plus en profondeur l'\xe9licitation du processus de raisonnement interne des LLMs dans des contextes adversariaux dans la section sur la s\xe9curit\xe9 de l'IA via le d\xe9bat."]}),"\n",(0,t.jsx)(a.A,{src:"./img/9HL_Image_9.png",alt:"Saisir la description alternative de l'image",number:"9",label:"8.9",caption:"Exemple de l'amor\xe7age CoT combin\xe9 avec ERO. Le texte en gras indique la partie de l'invite qui est coh\xe9rente entre toutes les questions, et le texte soulign\xe9 est produit par le mod\xe8le. L'erreur introduite est soulign\xe9e. ([Lanham et al.; 2023](https://arxiv.org/abs/2307.13702))"}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"L'ERO pourrait n'\xeatre fiable que pour les mod\xe8les plus petits."})," Un probl\xe8me avec les approches de raisonnement externalis\xe9 est que les mod\xe8les plus capables montrent souvent moins de d\xe9pendance au raisonnement externe et donc plus d'infid\xe9lit\xe9. (",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/2307.13702",children:"Lanham et al.; 2023"}),") Cela sugg\xe8re que les mod\xe8les plus petits pourraient \xeatre mieux adapt\xe9s aux t\xe2ches o\xf9 le raisonnement externe est crucial pour assurer la s\xe9curit\xe9 du mod\xe8le. Les mod\xe8les plus grands montrent souvent moins de d\xe9pendance au raisonnement externe, conduisant \xe0 un raisonnement plus infid\xe8le. \xc0 mesure que nous continuons \xe0 \xe9voluer, les mod\xe8les plus grands peuvent pr\xe9dire des r\xe9ponses plus complexes avec confiance sans s'appuyer sur un raisonnement externalis\xe9 explicite, augmentant l'\xe9cart entre le raisonnement externalis\xe9 et les processus internes."]}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"La supervision manque les cons\xe9quences de ce que le mod\xe8le ne pense pas."})," M\xeame si l'ERO pouvait rendre transparents les processus de pens\xe9e de l'IA, il n'aborde que les risques li\xe9s \xe0 l'IA s'engageant dans un raisonnement que nous n'approuverions pas, comme la recherche de pouvoir ou l'auto-pr\xe9servation. Il n'aborde pas le risque plus large que l'IA cause des dommages comme effet secondaire de ses activit\xe9s principales. Par exemple, pensez \xe0 la fa\xe7on dont les humains conduisent des esp\xe8ces \xe0 l'extinction. Dans la plupart des cas, ce n'est pas parce que les humains \xe9laborent activement des strat\xe9gies pour tuer ces esp\xe8ces. Au lieu de cela, les esp\xe8ces s'\xe9teignent souvent parce que les humains modifient drastiquement leur environnement - par des activit\xe9s comme la d\xe9forestation, la construction ou la pollution - sans penser \xe0 la survie des esp\xe8ces. En appliquant cette analogie \xe0 l'IA, le risque pos\xe9 par les futurs mod\xe8les d'IA pourrait ne pas venir du fait qu'elle essaie activement de tuer les humains. Au lieu de cela, le risque vient d'un mod\xe8le d'IA s'engageant dans des activit\xe9s \xe0 grande \xe9chelle qui conduisent involontairement \xe0 des effets secondaires risqu\xe9s. Si le mod\xe8le ne consid\xe8re jamais explicitement l'impact sur les humains, il n'y a pas de processus de raisonnement d\xe9fectueux sur lequel les superviseurs pourraient donner un retour n\xe9gatif. Le superviseur devrait d\xe9terminer ind\xe9pendamment les cons\xe9quences potentiellement n\xe9fastes des plans complexes \xe0 long terme de l'IA. Cela n\xe9cessite que le superviseur pr\xe9dise les r\xe9sultats de ces plans, ce qui est extr\xeamement difficile \xe9tant donn\xe9 leur complexit\xe9. (",(0,t.jsx)(s.a,{href:"https://www.alignmentforum.org/posts/98c5WMDb3iKdzD4tM/oversight-misses-100-of-thoughts-the-ai-does-not-think",children:"Wentworth, 2022"}),")"]}),"\n",(0,t.jsx)(s.h2,{id:"02",children:"Clonage proc\xe9dural"}),"\n",(0,t.jsx)(s.p,{children:"Les approches traditionnelles d'apprentissage par imitation, comme le clonage comportemental, se concentrent sur l'apprentissage d'une correspondance directe entre les \xe9tats et les actions bas\xe9e sur les d\xe9monstrations d'experts observ\xe9es. Comme nous l'avons \xe9voqu\xe9 plus t\xf4t dans cette section, les approches bas\xe9es sur les r\xe9sultats, bien qu'efficaces dans certains sc\xe9narios, peuvent \xeatre trop simplistes et ne pas r\xe9ussir \xe0 capturer les riches processus de prise de d\xe9cision \xe9tape par \xe9tape utilis\xe9s par les experts. Cela peut conduire \xe0 des mod\xe8les qui fonctionnent bien dans des environnements connus mais peinent \xe0 se g\xe9n\xe9raliser \xe0 des sc\xe9narios nouveaux et inconnus."}),"\n",(0,t.jsxs)(s.p,{children:["Le ",(0,t.jsx)(s.strong,{children:"clonage proc\xe9dural"})," r\xe9pond \xe0 cette limitation en \xe9tendant le clonage comportemental \xe0 l'aide de CoT. Il tente d'amener le mod\xe8le \xe0 cloner non seulement le r\xe9sultat final (le comportement) mais aussi l'ensemble du processus que l'expert suit pour manifester ce comportement en incorporant les \xe9tapes interm\xe9diaires du comportement expert pendant l'entra\xeenement. (",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/2205.10816",children:"Yang et. al; 2022"}),")"]}),"\n",(0,t.jsx)(s.p,{children:"Le clonage proc\xe9dural fonctionne en collectant d'abord des d\xe9monstrations d'experts qui incluent non seulement les paires \xe9tat-action mais aussi les \xe9tapes interm\xe9diaires ou les calculs menant \xe0 ces actions. Par exemple, dans une t\xe2che de navigation dans un labyrinthe, l'expert pourrait utiliser un algorithme de recherche pour trouver le chemin optimal, et les \xe9tapes interm\xe9diaires de ce processus de recherche sont enregistr\xe9es avec l'action finale. Pendant l'entra\xeenement, le mod\xe8le apprend \xe0 pr\xe9dire la s\xe9quence d'\xe9tapes interm\xe9diaires menant \xe0 l'action finale en utilisant un mod\xe8le s\xe9quentiel, comme un transformeur, capable de g\xe9rer la nature autor\xe9gressive de la t\xe2che. Le mod\xe8le maximise la vraisemblance de la distribution conjointe des observations de proc\xe9dure et des actions expertes. Pendant l'inf\xe9rence, le mod\xe8le g\xe9n\xe8re une s\xe9quence d'\xe9tapes interm\xe9diaires bas\xe9es sur l'\xe9tat d'entr\xe9e imitant la proc\xe9dure de l'expert avant de produire l'action finale. Cette m\xe9thode permet au mod\xe8le de reproduire plus pr\xe9cis\xe9ment le processus de prise de d\xe9cision de l'expert, m\xeame dans des environnements nouveaux et inconnus."}),"\n",(0,t.jsx)(a.A,{src:"./img/xTv_Image_10.png",alt:"Saisir la description alternative de l'image",number:"10",label:"8.10",caption:"Visualisation de la collecte de donn\xe9es, de l'entra\xeenement et de l'inf\xe9rence de BC et PC sur une t\xe2che de navigation dans un labyrinthe. ([Yang et. al; 2022](https://arxiv.org/abs/2205.10816))"})]})}function c(e={}){const{wrapper:s}={...(0,i.R)(),...e.components};return s?(0,t.jsx)(s,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}}}]);