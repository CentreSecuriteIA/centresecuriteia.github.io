"use strict";(self.webpackChunkatlas=self.webpackChunkatlas||[]).push([[2046],{8499:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>p,frontMatter:()=>l,metadata:()=>i,toc:()=>u});const i=JSON.parse('{"id":"chapters/04/7","title":"Annexe : Gouvernance nationale","description":"Un r\xe9gime de gouvernance nationale complet pour la s\xe9curit\xe9 de l\'IA n\xe9cessite trois m\xe9canismes interconnect\xe9s :","source":"@site/i18n/fr/docusaurus-plugin-content-docs/current/chapters/04/07.md","sourceDirName":"chapters/04","slug":"/chapters/04/07","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/04/07","draft":false,"unlisted":false,"editUrl":"https://github.com/markov-root/atlas/edit/main/docs/chapters/04/07.md","tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"id":"7","title":"Annexe : Gouvernance nationale","sidebar_label":"4.7 Annexe : Gouvernance nationale","sidebar_position":8,"slug":"/chapters/04/07","reading_time_core":"11 min","reading_time_optional":"1 min","pagination_prev":"chapters/04/6","pagination_next":null},"sidebar":"docs","previous":{"title":"4.6 Annexe : Gouvernance des donn\xe9es","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/04/06"}}');var t=s(4848),a=s(8453),r=(s(2482),s(8559),s(9585),s(2501));const l={id:7,title:"Annexe : Gouvernance nationale",sidebar_label:"4.7 Annexe : Gouvernance nationale",sidebar_position:8,slug:"/chapters/04/07",reading_time_core:"11 min",reading_time_optional:"1 min",pagination_prev:"chapters/04/6",pagination_next:null},o="Annexe : Gouvernance Nationale",c={},u=[{value:"Union europ\xe9enne",id:"01",level:2},{value:"\xc9tats-Unis",id:"02",level:2},{value:"Chine",id:"03",level:2}];function d(e){const n={a:"a",annotation:"annotation",h1:"h1",h2:"h2",header:"header",li:"li",math:"math",mn:"mn",mrow:"mrow",msup:"msup",p:"p",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,a.R)(),...e.components},{GlossaryTerm:s}=n;return s||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("GlossaryTerm",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"annexe--gouvernance-nationale",children:"Annexe : Gouvernance Nationale"})}),"\n",(0,t.jsx)(n.p,{children:"Un r\xe9gime de gouvernance nationale complet pour la s\xe9curit\xe9 de l'IA n\xe9cessite trois m\xe9canismes interconnect\xe9s :"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"D\xe9veloppement de normes de s\xe9curit\xe9,"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Visibilit\xe9 r\xe9glementaire, et"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Application de la conformit\xe9 ",(0,t.jsx)(n.a,{href:"http://arxiv.org/abs/2307.03718",children:"(Anderljung et al., 2023)"})]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Les normes de s\xe9curit\xe9 constituent le fondement de la gouvernance de l'IA en \xe9tablissant des crit\xe8res clairs et mesurables pour le d\xe9veloppement, les tests et le d\xe9ploiement des syst\xe8mes d'IA dans les juridictions nationales. Ces normes doivent \xeatre techniquement pr\xe9cises tout en restant suffisamment flexibles pour s'adapter aux avanc\xe9es technologiques rapides. Des normes efficaces servent d'outils institutionnels de coordination et fournissent l'infrastructure n\xe9cessaire pour d\xe9velopper de nouvelles technologies d'IA de mani\xe8re contr\xf4l\xe9e dans les limites r\xe9glementaires d'un pays (",(0,t.jsx)(n.a,{href:"https://www.governance.ai/research-paper/standards-for-ai-governance-international-standards-to-enable-global-coordination-in-ai-research-development",children:"Cihon, 2019"}),")."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Quelles le\xe7ons la gouvernance nationale de l'IA peut-elle tirer de la r\xe9glementation de la s\xe9curit\xe9 nucl\xe9aire ?"})," L'approche r\xe9glementaire utilis\xe9e pour la s\xe9curit\xe9 nucl\xe9aire fournit un mod\xe8le instructif pour la standardisation nationale de la s\xe9curit\xe9 de l'IA. La hi\xe9rarchie \xe0 cinq niveaux utilis\xe9e dans les normes de s\xe9curit\xe9 nucl\xe9aire, allant des principes fondamentaux aux guides de mise en \u0153uvre sp\xe9cifiques, offre un mod\xe8le pour d\xe9velopper des normes compl\xe8tes de s\xe9curit\xe9 de l'IA. Ce cadre multiniveau permet aux principes \xe9tablis aux niveaux sup\xe9rieurs d'\xeatre incorpor\xe9s dans des directives plus sp\xe9cifiques aux niveaux inf\xe9rieurs, cr\xe9ant un syst\xe8me r\xe9glementaire coh\xe9rent et approfondi qui peut \xeatre mis en \u0153uvre dans les juridictions nationales (",(0,t.jsx)(n.a,{href:"https://www.nature.com/articles/s41599-024-03017-1",children:"Cha, 2024"}),")."]}),"\n",(0,t.jsx)(n.p,{children:"Les principales le\xe7ons de la r\xe9glementation nucl\xe9aire applicables \xe0 la gouvernance nationale de l'IA comprennent :"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Cadres de s\xe9curit\xe9 standardis\xe9s :"})," Tout comme la r\xe9glementation nucl\xe9aire a \xe9tabli des cadres standardis\xe9s pour la s\xe9curit\xe9, la gouvernance nationale de l'IA peut standardiser les crit\xe8res de comportement, d'apprentissage et de prise de d\xe9cision des syst\xe8mes d'IA pour am\xe9liorer la s\xe9curit\xe9 technologique \xe0 l'int\xe9rieur des fronti\xe8res du pays."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"M\xe9canismes de supervision ind\xe9pendants :"})," Les autorit\xe9s de r\xe9glementation nucl\xe9aire ont \xe9tabli des syst\xe8mes de supervision ind\xe9pendants pour le suivi et l'\xe9valuation de la s\xe9curit\xe9. De m\xeame, la gouvernance nationale de l'IA peut \xe9tablir des organismes neutres pour surveiller et \xe9valuer en continu le fonctionnement et la performance des syst\xe8mes d'IA."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Protocoles et exercices r\xe9guliers :"})," Les r\xe9gulateurs de la s\xe9curit\xe9 nucl\xe9aire m\xe8nent des protocoles et des exercices r\xe9guliers pour r\xe9pondre aux incidents. Des approches similaires peuvent \xeatre d\xe9velopp\xe9es au niveau national pour r\xe9pondre rapidement aux accidents ou comportements anormaux li\xe9s \xe0 l'IA."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"M\xe9canismes de partage d'informations :"})," Les syst\xe8mes de r\xe9glementation nucl\xe9aire ont \xe9tabli des plateformes pour partager les normes de s\xe9curit\xe9, la recherche et les informations sur les incidents entre les secteurs. Des plateformes similaires peuvent \xeatre d\xe9velopp\xe9es pour l'IA au niveau national pour partager la recherche, la technologie et les informations sur les incidents entre les industries (",(0,t.jsx)(n.a,{href:"https://www.nature.com/articles/s41599-024-03017-1",children:"Cha, 2024"}),")."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"01",children:"Union europ\xe9enne"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Quelle base l\xe9gislative l'UE a-t-elle \xe9tablie pour la gouvernance de l'IA ?"})," L'Union europ\xe9enne a innov\xe9 avec la loi europ\xe9enne sur l'IA, le premier cadre juridique complet au monde pour l'intelligence artificielle. Initialement propos\xe9e en 2021 et formellement adopt\xe9e en mars 2024, cette l\xe9gislation int\xe9gr\xe9e horizontalement r\xe9glemente les syst\xe8mes d'IA en fonction de leurs risques potentiels et prot\xe8ge les droits des citoyens de l'UE. Son principe fondamental est une approche bas\xe9e sur les risques qui classe les syst\xe8mes d'IA en quatre cat\xe9gories distinctes : risque inacceptable, risque \xe9lev\xe9, risque limit\xe9 et risque minimal. Les syst\xe8mes d'IA \xe0 risque inacceptable, comme ceux qui manipulent le comportement humain ou exploitent les vuln\xe9rabilit\xe9s, sont totalement interdits. Les syst\xe8mes d'IA \xe0 haut risque, y compris ceux utilis\xe9s dans les infrastructures critiques, l'\xe9ducation et l'emploi, font l'objet d'exigences et d'une surveillance strictes. Les syst\xe8mes d'IA \xe0 risque limit\xe9 n\xe9cessitent des mesures de transparence, tandis que les syst\xe8mes d'IA \xe0 risque minimal sont largement non r\xe9glement\xe9s."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Comment la loi europ\xe9enne sur l'IA est-elle mise en \u0153uvre ?"})," La loi est entr\xe9e en vigueur en ao\xfbt 2024 et est mise en \u0153uvre par phases. Depuis le 2 f\xe9vrier 2025, l'interdiction des pratiques d'IA prohib\xe9es (notation sociale, certains syst\xe8mes d'identification biom\xe9trique) et les exigences en mati\xe8re de litt\xe9ratie en IA du personnel sont entr\xe9es en vigueur. \xc0 partir du 2 ao\xfbt 2025, les obligations pour les fournisseurs de mod\xe8les d'IA \xe0 usage g\xe9n\xe9ral (GPAI) s'appliqueront, notamment la documentation, la conformit\xe9 aux droits d'auteur et la transparence des donn\xe9es. La l\xe9gislation \xe9tablit le Bureau europ\xe9en de l'IA pour superviser la mise en \u0153uvre et l'application, coordonner la conformit\xe9, fournir des orientations aux entreprises et faire respecter les r\xe8gles. Cet organisme d\xe9di\xe9 sert d'agence principale pour l'application des r\xe8gles contraignantes en mati\xe8re d'IA au sein d'une coalition multinationale, positionn\xe9 pour fa\xe7onner la gouvernance mondiale de l'IA comme le RGPD a restructur\xe9 les normes internationales de confidentialit\xe9."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Quelles exigences suppl\xe9mentaires existent pour les syst\xe8mes d'IA \xe0 haut risque et \xe0 risque syst\xe9mique ?"})," Pour les mod\xe8les GPAI pr\xe9sentant des risques syst\xe9miques, identifi\xe9s soit par le d\xe9passement d'un seuil de calcul (",(0,t.jsxs)(n.span,{className:"katex",children:[(0,t.jsx)(n.span,{className:"katex-mathml",children:(0,t.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(n.semantics,{children:[(0,t.jsxs)(n.mrow,{children:[(0,t.jsxs)(n.msup,{children:[(0,t.jsx)(n.mn,{children:"10"}),(0,t.jsx)(n.mn,{children:"2"})]}),(0,t.jsx)(n.mn,{children:"5"})]}),(0,t.jsx)(n.annotation,{encoding:"application/x-tex",children:"10^25"})]})})}),(0,t.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,t.jsxs)(n.span,{className:"base",children:[(0,t.jsx)(n.span,{className:"strut",style:{height:"0.8141em"}}),(0,t.jsx)(n.span,{className:"mord",children:"1"}),(0,t.jsxs)(n.span,{className:"mord",children:[(0,t.jsx)(n.span,{className:"mord",children:"0"}),(0,t.jsx)(n.span,{className:"msupsub",children:(0,t.jsx)(n.span,{className:"vlist-t",children:(0,t.jsx)(n.span,{className:"vlist-r",children:(0,t.jsx)(n.span,{className:"vlist",style:{height:"0.8141em"},children:(0,t.jsxs)(n.span,{style:{top:"-3.063em",marginRight:"0.05em"},children:[(0,t.jsx)(n.span,{className:"pstrut",style:{height:"2.7em"}}),(0,t.jsx)(n.span,{className:"sizing reset-size6 size3 mtight",children:(0,t.jsx)(n.span,{className:"mord mtight",children:"2"})})]})})})})})]}),(0,t.jsx)(n.span,{className:"mord",children:"5"})]})})]})," FLOPS) soit sur la base de crit\xe8res d'impact potentiel (comme l'\xe9volutivit\xe9 et le risque de dommages \xe0 grande \xe9chelle), des obligations suppl\xe9mentaires s'appliquent. Les fournisseurs doivent effectuer des tests adverses, suivre et signaler les incidents graves, mettre en \u0153uvre des mesures de cybers\xe9curit\xe9 solides et att\xe9nuer proactivement les risques syst\xe9miques. Le Bureau europ\xe9en de l'IA a facilit\xe9 la r\xe9daction d'un Code de pratique pour l'IA \xe0 usage g\xe9n\xe9ral, achev\xe9 en avril 2025, fournissant un outil central permettant aux fournisseurs de mod\xe8les GPAI de se conformer aux exigences de la loi. Bien que la conformit\xe9 \xe0 ce Code soit volontaire, elle offre aux fournisseurs une voie pratique claire pour d\xe9montrer leur adh\xe9sion."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Comment l'UE aborde-t-elle l'application et les sanctions ?"})," Le Bureau europ\xe9en de l'IA sert d'autorit\xe9 d'application, habilit\xe9e \xe0 demander des informations, mener des \xe9valuations, imposer des mesures correctives et infliger des amendes allant jusqu'\xe0 3 pour cent du chiffre d'affaires annuel mondial d'un fournisseur ou 15 millions d'euros, selon le montant le plus \xe9lev\xe9. Cela repr\xe9sente un m\xe9canisme d'application substantiel, bien que l\xe9g\xe8rement inf\xe9rieur au maximum de 7 pour cent mentionn\xe9 dans les versions ant\xe9rieures de la l\xe9gislation. Les amendes pour non-conformit\xe9 sont tr\xe8s \xe9lev\xe9es, d\xe9montrant l'engagement fort de l'UE \xe0 assurer le respect de son cadre r\xe9glementaire (",(0,t.jsx)(n.a,{href:"https://www.convergenceanalysis.org/ai-regulatory-landscape/home",children:"Cheng et al., 2024"}),")."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Quelles valeurs et priorit\xe9s guident l'approche de l'UE ?"})," L'UE a d\xe9montr\xe9 une claire priorit\xe9 pour la protection des droits des citoyens. L'approche fondamentale de la loi europ\xe9enne sur l'IA pour cat\xe9goriser les niveaux de risque est principalement con\xe7ue autour de la mesure de la capacit\xe9 des syst\xe8mes d'IA \xe0 porter atteinte aux droits des citoyens de l'UE. Cela peut \xeatre observ\xe9 dans la liste des cas d'utilisation consid\xe9r\xe9s comme \xe0 haut risque, tels que l'\xe9ducation ou la formation professionnelle, l'emploi, la migration et l'asile, et l'administration de la justice ou les processus d\xe9mocratiques. La plupart des exigences sont con\xe7ues en pensant au citoyen ordinaire, y compris les exigences de transparence et de rapport, la possibilit\xe9 pour tout citoyen de d\xe9poser une plainte aupr\xe8s d'une autorit\xe9 de surveillance du march\xe9, les interdictions sur les syst\xe8mes de notation sociale et les exigences anti-discrimination. Cette approche fond\xe9e sur les droits contraste nettement avec l'accent mis par la Chine sur le contr\xf4le social et l'emphase des \xc9tats-Unis sur la comp\xe9tition g\xe9opolitique (",(0,t.jsx)(n.a,{href:"https://www.convergenceanalysis.org/ai-regulatory-landscape/home",children:"Cheng et al., 2024"}),")."]}),"\n",(0,t.jsx)(r.A,{src:"./img/HmY_Image_37.png",alt:"Entrer la description alternative de l'image",number:"31",label:"4.31",caption:"La loi europ\xe9enne sur l'IA : Classification des mod\xe8les d'IA \xe0 usage g\xe9n\xe9ral pr\xe9sentant des risques syst\xe9miques ([Observatorio de Riesgos Catastr\xf3ficos Globales](https://www.orcg.info/articulos/infografas-ley-de-inteligencia-artificial-de-la-unin-europea))"}),"\n",(0,t.jsx)(n.h2,{id:"02",children:"\xc9tats-Unis"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Comment la politique am\xe9ricaine en mati\xe8re de gouvernance de l'IA a-t-elle \xe9volu\xe9 ?"})," La gouvernance de l'IA aux \xc9tats-Unis a consid\xe9rablement chang\xe9 depuis l'\xe9lection de 2024. Le pr\xe9sident Donald Trump a annul\xe9 le d\xe9cret ex\xe9cutif de l'administration pr\xe9c\xe9dente sur l'IA s\xfbre, s\xe9curis\xe9e et digne de confiance d'octobre 2023, qui avait introduit l'obligation pour les d\xe9veloppeurs de syst\xe8mes d'IA avanc\xe9s de partager les r\xe9sultats des tests de s\xe9curit\xe9 avec le gouvernement f\xe9d\xe9ral. En janvier 2025, le d\xe9cret ex\xe9cutif 14179 a explicitement r\xe9voqu\xe9 le pr\xe9c\xe9dent d\xe9cret sur la s\xe9curit\xe9 de l'IA et a ordonn\xe9 aux agences f\xe9d\xe9rales de revoir leurs politiques pour \xe9liminer les obstacles \xe0 l'innovation et garantir que les syst\xe8mes d'IA soient exempts de \"biais id\xe9ologiques ou d'agendas sociaux programm\xe9s\". Un d\xe9cret ex\xe9cutif distinct sur l'infrastructure de l'IA a donn\xe9 la priorit\xe9 \xe0 la s\xe9curit\xe9 nationale, \xe0 la comp\xe9titivit\xe9 \xe9conomique, au d\xe9veloppement des centres de donn\xe9es nationaux et aux normes de d\xe9veloppement de la main-d'\u0153uvre."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Qu'est-ce qui caract\xe9risait l'approche am\xe9ricaine avant ce changement ?"})," Avant ces changements, les \xc9tats-Unis avaient adopt\xe9 une approche centr\xe9e sur les d\xe9crets ex\xe9cutifs et les d\xe9clarations non contraignantes en raison de l'impasse l\xe9gislative au Congr\xe8s. Trois actions ex\xe9cutives cl\xe9s ont fa\xe7onn\xe9 cette approche : les contr\xf4les des exportations de semi-conducteurs \xc9tats-Unis/Chine lanc\xe9s en octobre 2022, le Plan pour une D\xe9claration des droits de l'IA publi\xe9 en octobre 2022, et le d\xe9cret ex\xe9cutif sur l'intelligence artificielle publi\xe9 en octobre 2023. Les contr\xf4les des exportations de semi-conducteurs ont marqu\xe9 une escalade significative dans les efforts am\xe9ricains pour restreindre l'acc\xe8s de la Chine aux technologies informatiques avanc\xe9es et d'IA en interdisant l'exportation de puces avanc\xe9es, d'\xe9quipements de fabrication de puces et d'expertise en semi-conducteurs vers la Chine (",(0,t.jsx)(n.a,{href:"https://www.convergenceanalysis.org/ai-regulatory-landscape/home",children:"Cheng et al., 2024"}),")."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Quelles caract\xe9ristiques distinctives d\xe9finissent la philosophie r\xe9glementaire am\xe9ricaine ?"})," Les \xc9tats-Unis ont adopt\xe9 une approche distinctive de la gouvernance de l'IA en contr\xf4lant le mat\xe9riel et la puissance de calcul n\xe9cessaires pour entra\xeener et d\xe9velopper des mod\xe8les d'IA. Ils sont particuli\xe8rement bien positionn\xe9s pour exploiter cette approche r\xe9glementaire bas\xe9e sur le calcul en tant que pays d'origine de tous les principaux fournisseurs de puces IA haut de gamme (Nvidia, AMD, Intel), leur donnant un contr\xf4le l\xe9gislatif direct sur ces puces. Au-del\xe0 des contr\xf4les des exportations, les \xc9tats-Unis ont poursuivi une approche d\xe9centralis\xe9e, largement non contraignante, s'appuyant sur l'action ex\xe9cutive. En raison des d\xe9fis structurels pour faire adopter une l\xe9gislation contraignante par un Congr\xe8s divis\xe9, les \xc9tats-Unis se sont principalement appuy\xe9s sur des d\xe9crets ex\xe9cutifs et des actions d'agences ne n\xe9cessitant pas l'approbation du Congr\xe8s, r\xe9partissant les processus de recherche et de r\xe9glementation entre certaines agences (",(0,t.jsx)(n.a,{href:"https://www.convergenceanalysis.org/ai-regulatory-landscape/home",children:"Cheng et al., 2024"}),")."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Quel est l'\xe9tat actuel de la gouvernance de l'IA aux \xc9tats-Unis ?"})," En f\xe9vrier 2025, le Bureau de la gestion et du budget a publi\xe9 le m\xe9morandum M-25-21, ordonnant aux agences f\xe9d\xe9rales d'acc\xe9l\xe9rer l'adoption de l'IA, de minimiser les obstacles bureaucratiques, de renforcer le leadership en mati\xe8re d'IA au niveau des agences et de mettre en \u0153uvre des pratiques minimales de gestion des risques pour les syst\xe8mes d'IA \xe0 fort impact. Au niveau des \xc9tats, le projet de loi SB 1047 de la Californie, qui tentait d'aborder les risques associ\xe9s aux mod\xe8les fronti\xe8res, a \xe9t\xe9 rejet\xe9 en septembre 2024. Un nouveau projet de loi, SB 53, ax\xe9 sur la protection des lanceurs d'alerte signalant des risques critiques li\xe9s \xe0 l'IA, a \xe9t\xe9 introduit. L'Institut am\xe9ricain pour la s\xe9curit\xe9 de l'IA reste actif malgr\xe9 le changement de politique f\xe9d\xe9rale, continuant \xe0 d\xe9velopper des m\xe9thodologies de test et \xe0 effectuer des \xe9valuations de mod\xe8les."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Comment la g\xe9opolitique influence-t-elle la politique am\xe9ricaine en mati\xe8re d'IA ?"})," La politique am\xe9ricaine en mati\xe8re d'IA donne une forte priorit\xe9 \xe0 sa comp\xe9tition g\xe9opolitique avec la Chine. La strat\xe9gie de gouvernance de l'IA des \xc9tats-Unis est fortement influenc\xe9e par la menace per\xe7ue des avanc\xe9es rapides de la Chine en mati\xe8re d'IA et les implications potentielles pour la s\xe9curit\xe9 nationale et l'\xe9quilibre mondial des pouvoirs. Les actions contraignantes prises par les \xc9tats-Unis (application des contr\xf4les d'exportation des semi-conducteurs) sont explicitement con\xe7ues pour contrer les ambitions de la Chine en mati\xe8re d'IA et maintenir la sup\xe9riorit\xe9 technologique et militaire am\xe9ricaine. Cette orientation g\xe9opolitique distingue les \xc9tats-Unis de l'UE, qui a privil\xe9gi\xe9 la protection des droits individuels, et de la Chine, qui a privil\xe9gi\xe9 le contr\xf4le social interne. La strat\xe9gie am\xe9ricaine semble plus pr\xe9occup\xe9e par les implications strat\xe9giques de l'IA et par la garantie que la technologie s'aligne sur les int\xe9r\xeats am\xe9ricains sur la sc\xe8ne mondiale (",(0,t.jsx)(n.a,{href:"https://www.convergenceanalysis.org/ai-regulatory-landscape/home",children:"Cheng et al., 2024"}),")."]}),"\n",(0,t.jsx)(r.A,{src:"./img/gpm_Image_38.png",alt:"Entrer la description alternative de l'image",number:"32",label:"4.32",caption:"Nombre de r\xe9glementations li\xe9es \xe0 l'IA aux \xc9tats-Unis, 2016-2023 ([Stanford HAI, 2024](https://aiindex.stanford.edu/report/))"}),"\n",(0,t.jsx)(n.h2,{id:"03",children:"Chine"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Comment l'approche de la Chine en mati\xe8re de gouvernance de l'IA a-t-elle \xe9volu\xe9 ?"})," La Chine a d\xe9velopp\xe9 une approche r\xe9glementaire verticale et it\xe9rative distinctive pour la gouvernance de l'IA, adoptant des r\xe9glementations cibl\xe9es pour des domaines sp\xe9cifiques d'applications d'IA, une \xe0 la fois. Cette approche contraste nettement avec le cadre horizontal global de l'UE. L'\xe9volution r\xe9glementaire de la Chine a commenc\xe9 avec les Dispositions sur les Recommandations Algorithmiques en ao\xfbt 2021, qui ont \xe9tabli le premier registre obligatoire d'algorithmes au monde et exigeaient que tous les algorithmes qualifi\xe9s utilis\xe9s par les organisations chinoises soient enregistr\xe9s dans les 10 jours suivant leur lancement public. Cela a \xe9t\xe9 suivi par les Dispositions sur la Synth\xe8se Profonde en novembre 2022, qui r\xe9glementaient les algorithmes g\xe9n\xe9rant synth\xe9tiquement du contenu pour lutter contre les \"deepfakes\" en exigeant l'\xe9tiquetage, l'identification des utilisateurs et la pr\xe9vention des utilisations abusives telles que d\xe9finies par le gouvernement (",(0,t.jsx)(n.a,{href:"https://www.convergenceanalysis.org/ai-regulatory-landscape/home",children:"Cheng et al., 2024"}),")."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Quelles sont les mesures r\xe9glementaires actuellement en place ?"})," La Chine a renforc\xe9 son cadre de gouvernance de l'IA avec la mise en \u0153uvre des Mesures Provisoires pour la Gestion des Services d'Intelligence Artificielle G\xe9n\xe9rative en ao\xfbt 2023. Ces mesures \xe9taient une r\xe9ponse directe \xe0 ChatGPT et ont \xe9largi les politiques pour mieux englober les LLM \xe0 usages multiples, imposant une surveillance bas\xe9e sur les risques avec un examen plus approfondi pour les syst\xe8mes capables d'influencer l'opinion publique. Selon ces r\xe9glementations, les fournisseurs doivent garantir l'utilisation l\xe9gale des donn\xe9es, prot\xe9ger la propri\xe9t\xe9 intellectuelle, respecter la vie priv\xe9e des utilisateurs et d\xe9fendre les \"valeurs fondamentales socialistes\". En 2024, la Chine a officiellement \xe9lev\xe9 la s\xe9curit\xe9 de l'IA au niveau de la s\xe9curit\xe9 nationale et de la s\xe9curit\xe9 publique, exigeant que les fournisseurs d'IA mod\xe8rent activement le contenu ill\xe9gal ou nuisible et signalent les violations \xe0 l'Administration du Cyberespace de Chine (CAC), l'organisme r\xe9glementaire principal supervisant l'industrie chinoise de l'IA."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Quels d\xe9veloppements r\xe9glementaires sont \xe0 venir ?"})," En mars 2025, la Chine a publi\xe9 les Mesures finales pour l'\xc9tiquetage du Contenu G\xe9n\xe9r\xe9 par l'Intelligence Artificielle, entrant en vigueur le 1er septembre 2025. Ces mesures imposent des \xe9tiquettes explicites pour le contenu g\xe9n\xe9r\xe9 par l'IA qui pourrait induire le public en erreur, ainsi que des m\xe9tadonn\xe9es identifiant le fournisseur. La Chine se pr\xe9pare \xe9galement \xe0 mettre en \u0153uvre le R\xe8glement sur la Gestion de la S\xe9curit\xe9 des Donn\xe9es de R\xe9seau en 2025. Ces r\xe9glementations it\xe9ratives semblent construire vers une Loi compl\xe8te sur l'Intelligence Artificielle, propos\xe9e dans un plan l\xe9gislatif publi\xe9 en juin 2023. Ce sch\xe9ma refl\xe8te l'approche de la Chine en mati\xe8re de r\xe9glementation d'Internet dans les ann\xe9es 2000, qui a culmin\xe9 avec la Loi globale sur la Cybers\xe9curit\xe9 de 2017 (",(0,t.jsx)(n.a,{href:"https://www.convergenceanalysis.org/ai-regulatory-landscape/home",children:"Cheng et al., 2024"}),")."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Quelles caract\xe9ristiques distinctives d\xe9finissent la philosophie r\xe9glementaire de la Chine ?"})," La CAC s'est principalement concentr\xe9e sur la r\xe9glementation des algorithmes ayant un potentiel d'influence sociale plut\xf4t que de prioriser des domaines comme la sant\xe9, l'emploi ou les syst\xe8mes judiciaires qui re\xe7oivent plus d'",(0,t.jsx)(s,{term:"attention",definition:'{"definition":"M\xe9canisme permettant aux mod\xe8les de se concentrer sur les parties pertinentes de l\'entr\xe9e lors de la r\xe9alisation de pr\xe9dictions, en calculant des combinaisons pond\xe9r\xe9es d\'\xe9l\xe9ments d\'entr\xe9e..","source":"[Bahdanau et al., 2015](https://arxiv.org/abs/1409.0473)","aliases":["Attention","attention mechanism","self-attention"]}',children:(0,t.jsx)(s,{term:"attention",definition:'{"definition":"M\xe9canisme permettant aux mod\xe8les de se concentrer sur les parties pertinentes de l\'entr\xe9e lors de la r\xe9alisation de pr\xe9dictions, en calculant des combinaisons pond\xe9r\xe9es d\'\xe9l\xe9ments d\'entr\xe9e..","source":"[Bahdanau et al., 2015](https://arxiv.org/abs/1409.0473)","aliases":["Attention","attention mechanism","self-attention"]}',children:"attention"})})," dans les cadres r\xe9glementaires occidentaux. Le langage utilis\xe9 dans ces r\xe9glementations est typiquement large et non sp\xe9cifique, accordant un plus grand contr\xf4le \xe0 la CAC pour l'interpr\xe9tation et l'application. Par exemple, l'Article 5 des Mesures Provisoires sur l'IA G\xe9n\xe9rative stipule que les fournisseurs doivent \"Encourager l'application innovante de la technologie d'IA g\xe9n\xe9rative dans chaque industrie et domaine [et] g\xe9n\xe9rer un contenu exceptionnel qui soit positif, sain et \xe9difiant\". Cela d\xe9montre la forte priorit\xe9 accord\xe9e par la Chine au contr\xf4le social et \xe0 l'alignement avec les valeurs gouvernementales dans ses r\xe9glementations sur l'IA (",(0,t.jsx)(n.a,{href:"https://www.convergenceanalysis.org/ai-regulatory-landscape/home",children:"Cheng et al., 2024"}),")."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Comment la Chine met-elle en \u0153uvre sa vision r\xe9glementaire \xe0 diff\xe9rents niveaux ?"})," Au niveau municipal, Shanghai et P\xe9kin ont lanc\xe9 des laboratoires de s\xe9curit\xe9 de l'IA mi-2024, et plus de 40 \xe9valuations de s\xe9curit\xe9 de l'IA ont \xe9t\xe9 rapport\xe9es comme ayant \xe9t\xe9 men\xe9es par des centres de recherche soutenus par le gouvernement. La Chine a d\xe9montr\xe9 une orientation vers l'int\xe9rieur, r\xe9glementant principalement les organisations et citoyens chinois. Les grands laboratoires internationaux d'IA comme OpenAI, Anthropic et Google ne servent pas activement les consommateurs chinois, en partie en raison de leur r\xe9ticence \xe0 se conformer aux politiques de censure chinoises. Cela a conduit \xe0 ce que la gouvernance chinoise de l'IA fonctionne largement sur une base parall\xe8le et disjointe des approches occidentales de gouvernance de l'IA (",(0,t.jsx)(n.a,{href:"https://www.convergenceanalysis.org/ai-regulatory-landscape/home",children:"Cheng et al., 2024"}),")."]}),"\n",(0,t.jsx)(r.A,{src:"./img/EZK_Image_39.png",alt:"Entrer la description alternative de l'image",number:"33",label:"4.33",caption:"En 2024, les institutions chinoises ont consid\xe9rablement augment\xe9 la publication d'articles de pointe sur la s\xe9curit\xe9 de l'IA par rapport \xe0 2023, passant d'environ sept articles par mois en 2023 \xe0 18 par mois en 2024. ([AI Safety in China, 2025](https://aisafetychina.substack.com/p/ai-safety-in-china-2024-in-review))"})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}}}]);