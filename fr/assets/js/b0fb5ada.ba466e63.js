"use strict";(self.webpackChunkatlas=self.webpackChunkatlas||[]).push([[6542],{8822:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>c,contentTitle:()=>u,default:()=>p,frontMatter:()=>l,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"chapters/05/index","title":"\xc9valuations","description":"Lorsque vous pouvez mesurer ce dont vous parlez et l\'exprimer en chiffres, vous en savez quelque chose ; lorsque vous ne pouvez pas l\'exprimer en chiffres, votre connaissance est maigre et insatisfaisante ; ce peut \xeatre le d\xe9but de la connaissance, mais vous n\'avez gu\xe8re, dans votre r\xe9flexion, atteint le stade de la science.","source":"@site/i18n/fr/docusaurus-plugin-content-docs/current/chapters/05/index.md","sourceDirName":"chapters/05","slug":"/chapters/05/","permalink":"/fr/chapters/05/","draft":false,"unlisted":false,"editUrl":"https://github.com/markov-root/atlas/edit/main/docs/chapters/05/index.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"title":"\xc9valuations","chapter_number":5,"chapter_description":"Nous avons besoin d\'une m\xe9thode syst\xe9matique pour mesurer les progr\xe8s en mati\xe8re de s\xe9curit\xe9.","reading_time_core":"128 min","reading_time_optional":"27 min","authors":["Markov Grey","Charbel-Raphael Segerie"],"affiliations":["Centre Fran\xe7ais pour la S\xe9curit\xe9 de l\'IA (CeSIA)"],"acknowledgements":["Maxime Rich\xe9","Martin","Fabien Roger","Jeanne Salle","Camille Berger","Leo Karoubi"],"arxiv_link":"https://arxiv.org/abs/2505.05541","atlas_link":"https://ai-safety-atlas.com/chapters/05/","google_docs_link":"https://docs.google.com/document/d/1KI95w27Ce7yWoynE11PJ94IXK0gT0NwP8091s06P7wM/edit?usp=sharing","alignment_forum_link":"https://www.lesswrong.com/posts/CwdCYmsutwXwnYtEF/paper-safety-by-measurement-a-systematic-literature-review","teach_link":"https://docs.google.com/document/d/1im_i6e9xEAe-koYlurYdn26n9h7pFX2HksnRfQmWxTQ/edit?usp=sharing","feedback_link":"https://forms.gle/ZsA4hEWUx1ZrtQLL9","sidebar_position":5,"slug":"/chapters/05/"},"sidebar":"docs","previous":{"title":"4.7 Annexe : Gouvernance nationale","permalink":"/fr/chapters/04/07"},"next":{"title":"5.1 R\xe9f\xe9rences","permalink":"/fr/chapters/05/01"}}');var i=n(4848),r=n(8453),a=n(2482),o=(n(8559),n(9585),n(2501));const l={title:"\xc9valuations",chapter_number:5,chapter_description:"Nous avons besoin d'une m\xe9thode syst\xe9matique pour mesurer les progr\xe8s en mati\xe8re de s\xe9curit\xe9.",reading_time_core:"128 min",reading_time_optional:"27 min",authors:["Markov Grey","Charbel-Raphael Segerie"],affiliations:["Centre Fran\xe7ais pour la S\xe9curit\xe9 de l'IA (CeSIA)"],acknowledgements:["Maxime Rich\xe9","Martin","Fabien Roger","Jeanne Salle","Camille Berger","Leo Karoubi"],arxiv_link:"https://arxiv.org/abs/2505.05541",atlas_link:"https://ai-safety-atlas.com/chapters/05/",google_docs_link:"https://docs.google.com/document/d/1KI95w27Ce7yWoynE11PJ94IXK0gT0NwP8091s06P7wM/edit?usp=sharing",alignment_forum_link:"https://www.lesswrong.com/posts/CwdCYmsutwXwnYtEF/paper-safety-by-measurement-a-systematic-literature-review",teach_link:"https://docs.google.com/document/d/1im_i6e9xEAe-koYlurYdn26n9h7pFX2HksnRfQmWxTQ/edit?usp=sharing",feedback_link:"https://forms.gle/ZsA4hEWUx1ZrtQLL9",sidebar_position:5,slug:"/chapters/05/"},u="Introduction",c={},d=[];function m(e){const s={em:"em",h1:"h1",header:"header",p:"p",strong:"strong",...(0,r.R)(),...e.components},{GlossaryTerm:n}=s;return n||function(e,s){throw new Error("Expected "+(s?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("GlossaryTerm",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.header,{children:(0,i.jsx)(s.h1,{id:"introduction",children:"Introduction"})}),"\n",(0,i.jsx)(a.A,{speaker:"Lord Kelvin",position:"Math\xe9maticien, physicien et ing\xe9nieur",date:"1889",source:"([Oxford Reference, 2016](https://www.oxfordreference.com/display/10.1093/acref/9780191826719.001.0001/q-oro-ed4-00006236))",children:(0,i.jsx)(s.p,{children:"Lorsque vous pouvez mesurer ce dont vous parlez et l'exprimer en chiffres, vous en savez quelque chose ; lorsque vous ne pouvez pas l'exprimer en chiffres, votre connaissance est maigre et insatisfaisante ; ce peut \xeatre le d\xe9but de la connaissance, mais vous n'avez gu\xe8re, dans votre r\xe9flexion, atteint le stade de la science."})}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"L'\xe9cart entre ce que les syst\xe8mes d'IA peuvent faire et ce que nous pouvons mesurer de mani\xe8re fiable cr\xe9e un d\xe9fi fondamental en mati\xe8re de s\xe9curit\xe9."})," Fin 2024, des chercheurs en IA ont cr\xe9\xe9 FrontierMath, un ",(0,i.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:(0,i.jsx)(n,{term:"benchmark",definition:'{"definition":"Jeu de donn\xe9es d\u2019\xe9valuation permettant d\u2019\xe9valuer les performances des algorithmes au regard de l\u2019accomplissement de t\xe2ches sp\xe9cifiques.","source":"[LeMagIT](https://www.lemagit.fr/conseil/IA-generative-comprendre-les-benchmarks-generiques)","aliases":[]}',children:"benchmark"})})," de probl\xe8mes exceptionnellement difficiles qu'ils pr\xe9disaient comme devant \"",(0,i.jsx)(s.em,{children:"r\xe9sister aux IA pendant plusieurs ann\xe9es"}),"\". Quelques mois plus tard seulement, le mod\xe8le o3 d'OpenAI atteignait une pr\xe9cision de 25,2% sur ces probl\xe8mes suppos\xe9s insurmontables. Ce sch\xe9ma se r\xe9p\xe8te dans le d\xe9veloppement de l'IA : les outils con\xe7us pour mesurer les capacit\xe9s de l'IA deviennent obsol\xe8tes presque imm\xe9diatement, les mod\xe8les les d\xe9passant rapidement. Alors que les syst\xe8mes d'IA approchent des capacit\xe9s potentiellement transformatrices dans des domaines comme la cybers\xe9curit\xe9, le fonctionnement autonome et la planification strat\xe9gique, cet \xe9cart d'\xe9valuation devient de plus en plus dangereux. Nous ne pouvons pas nous permettre de d\xe9couvrir l'\xe9tendue compl\xe8te des capacit\xe9s avanc\xe9es de l'IA \xe0 travers leurs impacts \xe9mergents dans le monde r\xe9el."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les benchmarks fournissent une standardisation de la mesure mais \xe9chouent actuellement \xe0 capturer les risques complexes pos\xe9s par les syst\xe8mes d'IA avanc\xe9s."})," Le d\xe9veloppement pr\xe9coce de l'IA a fait face \xe0 une crise de mesure similaire \xe0 l'ing\xe9nierie pr\xe9-standardis\xe9e\u2014sans m\xe9triques fiables, les progr\xe8s \xe9taient chaotiques et impr\xe9visibles. Les benchmarks ont r\xe9volutionn\xe9 le d\xe9veloppement de l'IA en cr\xe9ant des m\xe9triques standardis\xe9es permettant des comparaisons significatives entre les syst\xe8mes. Bien que les benchmarks comme MMLU, GPQA ou FrontierMath soient extr\xeamement utiles, ils restent insuffisants pour pr\xe9dire le comportement dans le monde r\xe9el. Ils ne parviennent pas \xe0 mesurer ce qui se passe lorsque les mod\xe8les sont pouss\xe9s \xe0 leurs limites ou fonctionnent dans des environnements complexes o\xf9 \xe9mergent des combinaisons de capacit\xe9s inattendues. \xc0 mesure que nous avan\xe7ons vers des syst\xe8mes d'IA hautement capables, nous avons besoin de garanties de s\xe9curit\xe9 plus solides dans un plus large \xe9ventail de sc\xe9narios que ce que les benchmarks seuls peuvent fournir."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les risques de s\xe9curit\xe9 \xe9mergent des interactions entre les capacit\xe9s, cr\xe9ant un d\xe9fi combinatoire."})," Les capacit\xe9s individuelles comme la conscience situationnelle ou la tromperie semblent g\xe9rables lorsqu'elles sont mesur\xe9es isol\xe9ment, mais leur combinaison cr\xe9e des risques \xe9mergents fondamentalement diff\xe9rents de chaque capacit\xe9 prise s\xe9par\xe9ment. Les mod\xe8les pourraient reconna\xeetre quand ils sont \xe9valu\xe9s et dissimuler s\xe9lectivement des capacit\xe9s pendant les tests mais d\xe9montrer des comportements pr\xe9occupants lors du d\xe9ploiement. Cette explosion combinatoire rend les tests complets exponentiellement plus difficiles mais essentiels pour des affirmations significatives sur la s\xe9curit\xe9. Un mod\xe8le r\xe9ussissant la plupart des benchmarks de s\xe9curit\xe9 pourrait encore receler des combinaisons dangereuses de capacit\xe9s qui n'ont pas \xe9t\xe9 explicitement test\xe9es. C'est pourquoi nous devons orienter la mesure des propri\xe9t\xe9s critiques de s\xe9curit\xe9 d'un syst\xe8me vers des \xe9valuations compl\xe8tes."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"L'\xe9valuation efficace de la s\xe9curit\xe9 n\xe9cessite de mesurer trois propri\xe9t\xe9s distinctes : les capacit\xe9s, les propensions et le contr\xf4le."})," Les \xe9valuations des capacit\xe9s dangereuses \xe9tablissent des limites sup\xe9rieures sur ce que les mod\xe8les peuvent faire lorsqu'ils sont pouss\xe9s \xe0 leurs limites gr\xe2ce \xe0 des techniques comme l'\xe9chafaudage et l'augmentation par outils. Les \xe9valuations des propensions r\xe9v\xe8lent les comportements que les mod\xe8les ont tendance \xe0 exhiber par d\xe9faut, mesurant les tendances comportementales plut\xf4t que simplement les capacit\xe9s maximales. Les \xe9valuations de contr\xf4le v\xe9rifient si les protocoles de s\xe9curit\xe9 restent efficaces lorsque les mod\xe8les tentent activement de les contourner. Cette taxonomie en trois parties fournit un cadre syst\xe9matique pour la mesure de la s\xe9curit\xe9 qui aide \xe0 r\xe9pondre aux questions les plus pertinentes pour la prise de d\xe9cision concernant l'IA."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"L'\xe9valuation de la s\xe9curit\xe9 n\xe9cessite des techniques comportementales et internes, chacune fournissant diff\xe9rentes formes de preuves."})," Les techniques comportementales examinent les sorties du mod\xe8le \xe0 travers des approches comme le red teaming, qui tente syst\xe9matiquement de provoquer des comportements pr\xe9occupants ; le ",(0,i.jsx)(n,{term:"fine-tuning",definition:'{"definition":"Processus consistant \xe0 prendre un mod\xe8le pr\xe9-entra\xeen\xe9 et \xe0 le perfectionner pour une t\xe2che ou un ensemble de donn\xe9es sp\xe9cifique..","source":"","aliases":["Fine-tuning","fine-tune","finetuning","finetune","affinage","Affinage"]}',children:(0,i.jsx)(n,{term:"fine-tuning",definition:'{"definition":"Processus consistant \xe0 prendre un mod\xe8le pr\xe9-entra\xeen\xe9 et \xe0 le perfectionner pour une t\xe2che ou un ensemble de donn\xe9es sp\xe9cifique..","source":"","aliases":["Fine-tuning","fine-tune","finetuning","finetune","affinage","Affinage"]}',children:"fine-tuning"})})," supervis\xe9, qui fait \xe9merger des capacit\xe9s en modifiant les poids plut\xf4t qu'en se contentant de prompts ; et l'\xe9chantillonnage best-of-N, qui examine plusieurs r\xe9ponses potentielles pour comprendre les distributions de sortie. Ces techniques peuvent \xe9tablir des limites sup\xe9rieures sur les capacit\xe9s potentielles mais peinent \xe0 nous dire \"pourquoi\" les mod\xe8les g\xe9n\xe8rent certaines sorties. Les techniques internes compl\xe8tent cela en examinant directement les m\xe9canismes du mod\xe8le. Par exemple, les autoencodeurs parcimonieux ont r\xe9ussi \xe0 extraire des caract\xe9ristiques interpr\xe9tables li\xe9es aux comportements pertinents pour la s\xe9curit\xe9, notamment la tromperie, la flagornerie et les biais. D'autres techniques comme l'interpr\xe9tabilit\xe9 m\xe9caniste peuvent aider \xe0 tracer les voies computationnelles \xe0 travers le mod\xe8le, la s\xe9curit\xe9 \xe9num\xe9rative peut cataloguer les concepts que le mod\xe8le a encod\xe9s, et l'ing\xe9nierie des repr\xe9sentations peut examiner comment les mod\xe8les encodent l'information. Les techniques d'\xe9valuation comportementales et internes sont compl\xe9mentaires et fournissent ensemble des garanties de s\xe9curit\xe9 plus solides que chaque approche seule."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsxs)(s.strong,{children:["Les cadres d'\xe9valuation aident \xe0 ",(0,i.jsx)(n,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:(0,i.jsx)(n,{term:"Transformer",definition:'{"definition":"Une architecture de r\xe9seau neuronal qui utilise des m\xe9canismes d\'attention pour traiter des donn\xe9es s\xe9quentielles, particuli\xe8rement efficace pour les t\xe2ches linguistiques..","source":"[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)","aliases":["Transformer"]}',children:"transformer"})})," les mesures en d\xe9cisions concr\xe8tes de d\xe9veloppement et de d\xe9ploiement."]})," Plut\xf4t que de s'appuyer sur des r\xe9ponses ad hoc aux capacit\xe9s, des cadres comme les Politiques de Mise \xe0 l'\xc9chelle Responsable d'Anthropic \xe9tablissent des \"Niveaux de S\xe9curit\xe9 IA\" inspir\xe9s de choses comme les protocoles de confinement en bios\xe9curit\xe9, chaque niveau exigeant des exigences d'\xe9valuation et des mesures de s\xe9curit\xe9 de plus en plus strictes. Ces cadres cr\xe9ent des \"portes d'\xe9valuation\" qui d\xe9terminent quand la mise \xe0 l'\xe9chelle peut se poursuivre en toute s\xe9curit\xe9\u2014exigeant que les mod\xe8les passent des \xe9valuations en cybers\xe9curit\xe9, bios\xe9curit\xe9 et r\xe9plication autonome avant que le d\xe9veloppement ne continue. En int\xe9grant les \xe9valuations dans les structures de gouvernance, nous cr\xe9ons des approches syst\xe9matiques pour g\xe9rer le risque li\xe9 \xe0 l'IA plut\xf4t que de s'appuyer sur des d\xe9cisions ad hoc."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les \xe9valuations doivent \xeatre syst\xe9matiquement con\xe7ues pour maintenir la qualit\xe9 et l'\xe9chelle \xe0 travers des mod\xe8les de plus en plus complexes."})," La conception de l'\xe9valuation n\xe9cessite une consid\xe9ration attentive des affordances\u2014les ressources et opportunit\xe9s fournies au mod\xe8le pendant les tests. En faisant varier syst\xe9matiquement les affordances du minimal (restriction des outils et ressources) au maximal (fourniture de tous les outils et contextes potentiellement pertinents), nous pouvons construire une image plus compl\xe8te du comportement du mod\xe8le dans diff\xe9rentes conditions. \xc0 mesure que le nombre de propri\xe9t\xe9s pertinentes pour la s\xe9curit\xe9 augmente, l'automatisation de l'\xe9valuation devient n\xe9cessaire. Nous pouvons potentiellement utiliser des \xe9valuations \xe9crites par le mod\xe8le pour aider \xe0 r\xe9soudre les d\xe9fis de mise \xe0 l'\xe9chelle."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Malgr\xe9 des progr\xe8s significatifs, les \xe9valuations d'IA font face \xe0 des limitations fondamentales qui menacent leur fiabilit\xe9."})," L'asym\xe9trie entre prouver la pr\xe9sence versus l'absence de capacit\xe9s signifie que nous ne pouvons jamais \xeatre certains d'avoir d\xe9tect\xe9 tous les risques potentiels. Les \xe9valuations peuvent confirmer de mani\xe8re concluante qu'un mod\xe8le poss\xe8de certaines capacit\xe9s mais ne peuvent pas prouver d\xe9finitivement leur absence. Les d\xe9fis techniques incluent la sensibilit\xe9 de la mesure\u2014les performances peuvent varier en fonction de changements apparemment triviaux dans les formats de prompts\u2014et l'explosion combinatoire des cas de test \xe0 mesure que nous ajoutons de nouvelles dimensions \xe0 \xe9valuer. Le d\xe9salignement pourrait conduire au \"sandbagging\" des mod\xe8les (sous-performance strat\xe9gique lors des \xe9valuations), la recherche montre que les mod\xe8les de langage peuvent \xeatre amen\xe9s \xe0 sous-performer s\xe9lectivement sur les tests de capacit\xe9s dangereuses tout en maintenant leurs performances sur les benchmarks g\xe9n\xe9raux. Les incitations organisationnelles pourraient conduire les laboratoires eux-m\xeames \xe0 faire du \"safety washing\" (pr\xe9senter de mani\xe8re trompeuse les am\xe9liorations de capacit\xe9s comme des avanc\xe9es en mati\xe8re de s\xe9curit\xe9). Ces d\xe9fis soulignent la n\xe9cessit\xe9 de poursuivre la recherche sur des m\xe9thodologies d'\xe9valuation plus robustes et des arrangements institutionnels qui soutiennent une \xe9valuation v\xe9ritablement ind\xe9pendante."]}),"\n",(0,i.jsx)(o.A,{src:"./img/6Dq_Image_1.png",alt:"Entrez la description alternative de l'image",number:"1",label:"5.1",caption:"Aper\xe7u du contenu du chapitre."}),"\n",(0,i.jsx)(s.p,{children:"Cette introduction vous a donn\xe9 l'aper\xe7u g\xe9n\xe9ral de nombreux concepts dont nous parlerons tout au long de ce chapitre. Les sections suivront largement l'ordre dans lequel nous avons introduit les id\xe9es ci-dessus. Nous commen\xe7ons par explorer comment les benchmarks ont fa\xe7onn\xe9 le d\xe9veloppement de l'IA."})]})}function p(e={}){const{wrapper:s}={...(0,r.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(m,{...e})}):m(e)}}}]);