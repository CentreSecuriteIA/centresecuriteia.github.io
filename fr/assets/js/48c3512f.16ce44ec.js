"use strict";(self.webpackChunkatlas=self.webpackChunkatlas||[]).push([[8867],{2340:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>p,contentTitle:()=>c,default:()=>g,frontMatter:()=>u,metadata:()=>t,toc:()=>m});const t=JSON.parse('{"id":"chapters/07/1","title":"Dynamique d\'apprentissage","description":"Une compr\xe9hension plus approfondie de la surg\xe9n\xe9ralisation des objectifs n\xe9cessite d\'examiner comment fonctionne r\xe9ellement le processus d\'entra\xeenement en apprentissage automatique. Lorsque nous entra\xeenons des r\xe9seaux de neurones, nous ajustons des millions ou des milliards de param\xe8tres. Mais que repr\xe9sentent ces param\xe8tres ? La meilleure fa\xe7on de concevoir l\'apprentissage automatique est de le voir comme un processus de recherche dans un vaste espace d\'algorithmes possibles (parfois aussi appel\xe9 recherche dans l\'espace des hypoth\xe8ses ou l\'espace des mod\xe8les). Chaque combinaison sp\xe9cifique de valeurs de param\xe8tres correspond \xe0 un algorithme diff\xe9rent pour traiter l\'information et prendre des d\xe9cisions. Le chemin que prend cette recherche - et les biais qui la guident - d\xe9terminent quels types d\'algorithmes sont d\xe9couverts et s\'ils poursuivent les objectifs pr\xe9vus ou simplement des indicateurs corr\xe9l\xe9s. Les intuitions que vous apprendrez dans cette section vous aideront \xe9norm\xe9ment dans ce chapitre, mais aussi dans les chapitres ult\xe9rieurs sur l\'interpr\xe9tabilit\xe9.","source":"@site/i18n/fr/docusaurus-plugin-content-docs/current/chapters/07/01.md","sourceDirName":"chapters/07","slug":"/chapters/07/01","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/07/01","draft":false,"unlisted":false,"editUrl":"https://github.com/markov-root/atlas/edit/main/docs/chapters/07/01.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"1","title":"Dynamique d\'apprentissage","sidebar_label":"7.1 Dynamique d\'apprentissage","sidebar_position":2,"slug":"/chapters/07/01","reading_time_core":"11 min","reading_time_optional":"2 min","pagination_prev":"chapters/07/index","pagination_next":"chapters/07/2"},"sidebar":"docs","previous":{"title":"G\xe9n\xe9ralisation","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/07/"},"next":{"title":"7.2 Directionnalit\xe9 des Objectifs","permalink":"/aisafety_atlas_multilingual_website/fr/chapters/07/02"}}');var i=n(4848),a=n(8453),r=n(3931),o=n(4768),l=(n(2482),n(8559),n(9585)),d=n(2501);const u={id:1,title:"Dynamique d'apprentissage",sidebar_label:"7.1 Dynamique d'apprentissage",sidebar_position:2,slug:"/chapters/07/01",reading_time_core:"11 min",reading_time_optional:"2 min",pagination_prev:"chapters/07/index",pagination_next:"chapters/07/2"},c="Dynamiques d'apprentissage",p={},m=[{value:"Paysages de Perte",id:"01",level:2},{value:"D\xe9pendance au chemin",id:"02",level:2},{value:"Biais Inductif",id:"03",level:2}];function h(e){const s={a:"a",h1:"h1",h2:"h2",header:"header",p:"p",strong:"strong",...(0,a.R)(),...e.components},{GlossaryTerm:n}=s;return n||function(e,s){throw new Error("Expected "+(s?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("GlossaryTerm",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.header,{children:(0,i.jsx)(s.h1,{id:"dynamiques-dapprentissage",children:"Dynamiques d'apprentissage"})}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsxs)(s.strong,{children:["Une compr\xe9hension plus approfondie de la surg\xe9n\xe9ralisation des objectifs n\xe9cessite d'examiner comment fonctionne r\xe9ellement le processus d'entra\xeenement en ",(0,i.jsx)(n,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:(0,i.jsx)(n,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:"apprentissage automatique"})}),"."]})," Lorsque nous entra\xeenons des r\xe9seaux de neurones, nous ajustons des millions ou des milliards de param\xe8tres. Mais que repr\xe9sentent ces param\xe8tres ? La meilleure fa\xe7on de concevoir l'",(0,i.jsx)(n,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:(0,i.jsx)(n,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:"apprentissage automatique"})})," est de le voir comme un processus de recherche dans un vaste espace d'algorithmes possibles (parfois aussi appel\xe9 recherche dans l'espace des hypoth\xe8ses ou l'espace des mod\xe8les). Chaque combinaison sp\xe9cifique de valeurs de param\xe8tres correspond \xe0 un algorithme diff\xe9rent pour traiter l'information et prendre des d\xe9cisions. Le chemin que prend cette recherche - et les biais qui la guident - d\xe9terminent quels types d'algorithmes sont d\xe9couverts et s'ils poursuivent les objectifs pr\xe9vus ou simplement des indicateurs corr\xe9l\xe9s. Les intuitions que vous apprendrez dans cette section vous aideront \xe9norm\xe9ment dans ce chapitre, mais aussi dans les chapitres ult\xe9rieurs sur l'interpr\xe9tabilit\xe9."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Chaque point dans l'espace des param\xe8tres encode un algorithme complet."})," Tout comme les chiffres binaires 0 et 1 peuvent encoder n'importe quel programme informatique, les millions de param\xe8tres \xe0 virgule flottante dans un ",(0,i.jsx)(n,{term:"neural network",definition:'{"definition":"Mod\xe8le informatique inspir\xe9 des r\xe9seaux neuronaux biologiques, compos\xe9 de n\u0153uds interconnect\xe9s (neurones) organis\xe9s en couches..","source":"","aliases":["Neural Network","artificial neural network","neural net","deep neural network","deep neural net","DNN","R\xe9seau de Neurones","r\xe9seau de neurones"]}',children:(0,i.jsx)(n,{term:"neural network",definition:'{"definition":"Mod\xe8le informatique inspir\xe9 des r\xe9seaux neuronaux biologiques, compos\xe9 de n\u0153uds interconnect\xe9s (neurones) organis\xe9s en couches..","source":"","aliases":["Neural Network","artificial neural network","neural net","deep neural network","deep neural net","DNN","R\xe9seau de Neurones","r\xe9seau de neurones"]}',children:"r\xe9seau de neurones"})})," encodent un algorithme pour r\xe9soudre des t\xe2ches. Changez quelques param\xe8tres, et vous obtenez un algorithme diff\xe9rent. Les poids du r\xe9seau d\xe9terminent exactement comment il traite les entr\xe9es - quels motifs il reconna\xeet, quelles caract\xe9ristiques il priorise, quelles d\xe9cisions il prend. Deux r\xe9seaux avec des valeurs de param\xe8tres diff\xe9rentes impl\xe9mentent des algorithmes fondamentalement diff\xe9rents, m\xeame s'ils obtiennent des performances similaires."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"L'entra\xeenement d\xe9couvre souvent des algorithmes qui fonctionnent pour des raisons inattendues."}),' Dans l\'image ci-dessous, si vous montrez \xe0 un humain ces objets courbes rouges et dites qu\'ils \xe9taient tous des "thneebs", la plupart des gens supposeraient que la caract\xe9ristique d\xe9finissante est la forme. Mais si nous utilisons des r\xe9seaux de neurones sur des exemples similaires, les r\xe9seaux apprendraient syst\xe9matiquement que "thneeb" signifie uniquement "objet rouge" - se concentrant sur la couleur plut\xf4t que sur la forme. C\'est-\xe0-dire que si nous leur donnions un objet bleu mais de m\xeame forme, ils ne le consid\xe9reraient pas comme un "thneeb". Les deux approches atteignent une performance parfaite pendant l\'entra\xeenement, mais elles repr\xe9sentent des algorithmes compl\xe8tement diff\xe9rents qui se comporteraient tr\xe8s diff\xe9remment face \xe0 de nouveaux exemples (',(0,i.jsx)(s.a,{href:"https://www.cold-takes.com/why-ai-alignment-could-be-hard-with-modern-deep-learning/",children:"Cotra, 2021"}),")."]}),"\n",(0,i.jsx)(d.A,{src:"./img/L9z_Image_8.png",alt:"Saisir la description alternative de l'image",number:"8",label:"7.8",caption:"Ceci est appel\xe9 un Thneeb. C'est un mot d\xe9fini uniquement pour les besoins de l'exp\xe9rience. L'image de gauche repr\xe9sente les donn\xe9es d'entra\xeenement, l'image de droite les donn\xe9es de test. Si apr\xe8s avoir regard\xe9 l'image de gauche, on vous demande lequel des deux objets \xe0 droite est un thneeb, vous diriez probablement l'objet de gauche car vous avez g\xe9n\xe9ralis\xe9 via le chemin de la forme, mais les r\xe9seaux neuronaux r\xe9pondraient que la forme de droite est un thneeb, montrant qu'ils \"pr\xe9f\xe8rent\" le chemin de la couleur ([Cotra, 2021](https://www.cold-takes.com/why-ai-alignment-could-be-hard-with-modern-deep-learning/); [Geirhos et al., 2019](https://arxiv.org/abs/1811.12231))."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"De nombreux algorithmes peuvent \xeatre comportementalement indiscernables pendant l'entra\xeenement tout en poursuivant des objectifs compl\xe8tement diff\xe9rents."})," Nous avons d\xe9j\xe0 soulign\xe9 ce point dans la section pr\xe9c\xe9dente mais il m\xe9rite d'\xeatre rappel\xe9. Comme autre exemple concret, des chercheurs ont entra\xeen\xe9 100 mod\xe8les BERT identiques sur le m\xeame jeu de donn\xe9es avec des hyperparam\xe8tres identiques ; tous les mod\xe8les ont atteint des performances presque indiscernables pendant l'entra\xeenement. Pourtant, lorsqu'ils ont \xe9t\xe9 test\xe9s sur de nouvelles structures de phrases, ces mod\xe8les ont r\xe9v\xe9l\xe9 des approches compl\xe8tement diff\xe9rentes - certains avaient appris un raisonnement syntaxique plus robuste tandis que d'autres s'appuyaient sur une correspondance de motifs superficielle. Le processus d'entra\xeenement avait trouv\xe9 100 algorithmes diff\xe9rents dans l'espace des strat\xe9gies possibles de traitement du langage (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/1911.02969",children:"McCoy et al., 2019"}),")."]}),"\n",(0,i.jsx)(s.p,{children:"La raison pour laquelle nous soulignons \xe0 nouveau ce point est de motiver le fait que comprendre le processus de recherche - comment l'entra\xeenement navigue dans l'espace des algorithmes possibles et quelles solutions il tend \xe0 d\xe9couvrir. C'est tr\xe8s utile pour comprendre quels types d'IA (configurations de param\xe8tres = algorithmes) nous pourrions r\xe9ellement finir par d\xe9couvrir, et si nous pouvons modifier quelque chose dans nos architectures ou nos dynamiques d'apprentissage pour influencer ce processus."}),"\n",(0,i.jsx)(s.h2,{id:"01",children:"Paysages de Perte"}),"\n",(0,i.jsx)(r.A,{type:"youtube",videoId:"NrO20Jb-hy0",number:"2",label:"7.2",caption:"Vid\xe9o facultative expliquant les paysages de perte."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les paysages de perte expliquent pourquoi l'entra\xeenement peut d\xe9couvrir plusieurs solutions algorithmiques pour une m\xeame t\xe2che, chacune poursuivant des objectifs diff\xe9rents."}),' Lorsque nous visualisons comment la performance d\'un r\xe9seau neuronal change \xe0 travers les configurations de param\xe8tres, nous cr\xe9ons ce que les chercheurs appellent un "paysage de perte". Chaque point dans cet espace multidimensionnel repr\xe9sente un algorithme diff\xe9rent, la "hauteur" indiquant \xe0 quel point cet algorithme performe mal sur la sp\xe9cification (une perte plus \xe9lev\xe9e signifie une performance plus mauvaise). Ce concept de paysage s\'applique quelle que soit la fa\xe7on dont nous sp\xe9cifions la t\xe2che - que ce soit par des fonctions de r\xe9compense, des retours humains, ou toute autre mesure de performance.']}),"\n",(0,i.jsx)(l.A,{term:"Paysage de Perte",source:"([Li et al., 2017](https://arxiv.org/abs/1712.09913))",number:"2",label:"7.2",children:(0,i.jsx)(s.p,{children:'Un paysage de perte est une visualisation de la fa\xe7on dont la perte (performance) d\'un r\xe9seau neuronal change lorsque nous faisons varier ses param\xe8tres. Chaque point dans cet espace multidimensionnel repr\xe9sente un algorithme diff\xe9rent, la "hauteur" indiquant \xe0 quel point cet algorithme performe mal sur la t\xe2che.'})}),"\n",(0,i.jsx)(d.A,{src:"./img/eJW_Image_9.png",alt:"Saisir la description alternative de l'image",number:"9",label:"7.9",caption:"Voici le paysage de perte de ResNet-110-noshort, en 3D (gauche) et en 2D (droite). Les chemins que la descente de gradient stochastique emprunte \xe0 travers ces diff\xe9rents paysages de perte seront diff\xe9rents ([Li et al., 2017](https://arxiv.org/abs/1712.09913))."}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Le paysage de perte reste identique \xe0 travers diff\xe9rentes sessions d'entra\xeenement - seule la position de d\xe9part change."})," Imaginez ce paysage comme une cha\xeene de montagnes fixe avec des pics, des vall\xe9es, des cr\xeates et des bassins. Ce terrain est enti\xe8rement d\xe9termin\xe9 par votre architecture de r\xe9seau (la structure g\xe9ologique), vos donn\xe9es d'entra\xeenement (le climat qui l'a fa\xe7onn\xe9) et votre ",(0,i.jsx)(n,{term:"loss function",definition:'{"definition":"Une fonction qui mesure dans quelle mesure les pr\xe9dictions d\'un mod\xe8le correspondent aux valeurs cibles r\xe9elles, utilis\xe9e pour guider l\'entra\xeenement..","source":"","aliases":["Loss Function","cost function","objective function","Fonction de perte"]}',children:(0,i.jsx)(n,{term:"loss function",definition:'{"definition":"Une fonction qui mesure dans quelle mesure les pr\xe9dictions d\'un mod\xe8le correspondent aux valeurs cibles r\xe9elles, utilis\xe9e pour guider l\'entra\xeenement..","source":"","aliases":["Loss Function","cost function","objective function","Fonction de perte"]}',children:"fonction de perte"})})," (le syst\xe8me de mesure d'\xe9l\xe9vation). Chaque fois que vous entra\xeenez la m\xeame architecture sur les m\xeames donn\xe9es, vous explorez exactement la m\xeame cha\xeene de montagnes. Les pics et les vall\xe9es ne bougent jamais. Ce qui change, c'est l'endroit o\xf9 vous commencez : l'initialisation al\xe9atoire est comme \xeatre d\xe9pos\xe9 les yeux band\xe9s \xe0 un endroit al\xe9atoire dans cette cha\xeene de montagnes. \xc0 partir de chaque point de d\xe9part, la descente de gradient agit comme une balle roulant vers le bas, suivant la pente la plus raide vers le fond de la vall\xe9e la plus proche."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La g\xe9om\xe9trie de ces paysages d\xe9termine quels algorithmes sont d\xe9couvrables et robustes."})," Certaines solutions algorithmiques occupent de larges vall\xe9es plates o\xf9 de nombreux param\xe8tres mettent en \u0153uvre des approches similaires. D'autres existent comme des pics \xe9troits et aigus qui sont difficiles \xe0 trouver, faciles \xe0 perdre et qui g\xe9n\xe9ralisent souvent mal lors des changements de distribution. Les algorithmes dans les larges bassins restent stables lorsque leurs param\xe8tres sont l\xe9g\xe8rement perturb\xe9s, correspondant \xe0 des solutions robustes et g\xe9n\xe9ralisables (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/1712.09913",children:"Li et al., 2017"}),"). Les pics aigus repr\xe9sentent des algorithmes fragiles o\xf9 de minuscules changements peuvent provoquer des baisses majeures de performance (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/1609.04836",children:"Keskar et al.; 2017"}),"). Cette g\xe9om\xe9trie est importante pour la mauvaise g\xe9n\xe9ralisation des objectifs car la largeur des diff\xe9rentes vall\xe9es d'objectifs d\xe9termine leur d\xe9couvrabilit\xe9 - des vall\xe9es plus larges pour des objectifs mal align\xe9s rendent ces objectifs plus susceptibles d'\xe9merger de l'entra\xeenement."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Comprendre la structure du paysage r\xe9v\xe8le pourquoi certains objectifs \xe9mergent syst\xe9matiquement plut\xf4t que d'autres."})," La taille relative et l'accessibilit\xe9 des diff\xe9rentes vall\xe9es cr\xe9ent des biais syst\xe9matiques dans ce qui est d\xe9couvert. Si la vall\xe9e \"aller \xe0 droite\" est plus large et plus facile \xe0 atteindre que la vall\xe9e \"collecter des pi\xe8ces\", l'entra\xeenement d\xe9couvrira plus souvent la solution mal align\xe9e. Cette structure de paysage est d\xe9termin\xe9e par l'architecture du r\xe9seau, les donn\xe9es d'entra\xeenement et la ",(0,i.jsx)(n,{term:"loss function",definition:'{"definition":"Une fonction qui mesure dans quelle mesure les pr\xe9dictions d\'un mod\xe8le correspondent aux valeurs cibles r\xe9elles, utilis\xe9e pour guider l\'entra\xeenement..","source":"","aliases":["Loss Function","cost function","objective function","Fonction de perte"]}',children:(0,i.jsx)(n,{term:"loss function",definition:'{"definition":"Une fonction qui mesure dans quelle mesure les pr\xe9dictions d\'un mod\xe8le correspondent aux valeurs cibles r\xe9elles, utilis\xe9e pour guider l\'entra\xeenement..","source":"","aliases":["Loss Function","cost function","objective function","Fonction de perte"]}',children:"fonction de perte"})})," - mais plus important encore, par les biais inductifs qui d\xe9terminent quels types d'algorithmes obtiennent de larges vall\xe9es plut\xf4t que des pics \xe9troits."]}),"\n",(0,i.jsx)(l.A,{term:"Gamme Algorithmique",source:"",number:"3",label:"7.3",children:(0,i.jsxs)(s.p,{children:["La gamme algorithmique d'un syst\xe8me d'",(0,i.jsx)(n,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:(0,i.jsx)(n,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:"apprentissage automatique"})})," fait r\xe9f\xe9rence \xe0 l'\xe9tendue de l'ensemble des algorithmes pouvant \xeatre trouv\xe9s."]})}),"\n",(0,i.jsx)(d.A,{src:"./img/0qU_Image_10.png",alt:"Saisir la description alternative de l'image",number:"10",label:"7.10",caption:"Un paysage de perte en 2D o\xf9 chaque point repr\xe9sente un algorithme appris avec un ensemble diff\xe9rent de param\xe8tres sur le paysage. Il existe diff\xe9rents algorithmes que le mod\xe8le peut apprendre de l'exemple CoinRun. L'objectif de la descente de gradient stochastique est de chercher dans cet espace le bon point (ensemble de param\xe8tres = algorithme appris)."}),"\n",(0,i.jsx)(s.h2,{id:"02",children:"D\xe9pendance au chemin"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La d\xe9pendance au chemin d\xe9termine si diff\xe9rents points de d\xe9part dans le paysage de perte m\xe8nent \xe0 la m\xeame destination algorithmique."}),' Dans les paysages simples avec une vall\xe9e dominante, presque tous les points de d\xe9part convergent vers la m\xeame solution\u2014c\'est une faible d\xe9pendance au chemin. Mais les paysages complexes contiennent plusieurs vall\xe9es profondes s\xe9par\xe9es par des cr\xeates. L\xe0, votre position de d\xe9part est cruciale. Laissez tomber la balle du c\xf4t\xe9 gauche d\'une cr\xeate, et elle roule dans la Vall\xe9e A (apprenant \xe0 "se d\xe9placer \xe0 droite" dans CoinRun). Laissez-la tomber du c\xf4t\xe9 droit, et elle roule dans la Vall\xe9e B (apprenant \xe0 "collecter des pi\xe8ces"). Les deux vall\xe9es repr\xe9sentent des solutions parfaites pendant l\'entra\xeenement, mais elles impl\xe9mentent des algorithmes compl\xe8tement diff\xe9rents.']}),"\n",(0,i.jsx)(l.A,{term:"D\xe9pendance au Chemin",source:"",number:"4",label:"7.4",children:(0,i.jsx)(s.p,{children:"La d\xe9pendance au chemin survient lorsque de petites diff\xe9rences dans le processus d'entra\xeenement m\xe8nent \xe0 la d\xe9couverte d'algorithmes fondamentalement diff\xe9rents pour r\xe9soudre la m\xeame t\xe2che. Une forte d\xe9pendance au chemin signifie une grande variance dans les algorithmes appris \xe0 travers les sessions d'entra\xeenement, tandis qu'une faible d\xe9pendance au chemin signifie la d\xe9couverte constante de solutions algorithmiques similaires."})}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"La d\xe9pendance au chemin \xe9merge de la fa\xe7on dont la descente de gradient navigue dans le paysage de perte."})," L'entra\xeenement commence \xe0 partir d'un point al\xe9atoire dans l'espace des param\xe8tres et suit le chemin descendant le plus raide vers une meilleure performance. Lorsque plusieurs vall\xe9es existent\u2014chacune correspondant \xe0 diff\xe9rentes approches algorithmiques\u2014les premi\xe8res diff\xe9rences al\xe9atoires peuvent pousser l'optimisation vers des r\xe9gions compl\xe8tement diff\xe9rentes. Une fois engag\xe9 dans la descente d'une vall\xe9e particuli\xe8re, la descente de gradient tend \xe0 continuer dans cette direction, rendant difficile l'acc\xe8s \xe0 d'autres solutions algorithmiques."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Une forte d\xe9pendance au chemin appara\xeet lorsque des configurations d'entra\xeenement identiques d\xe9couvrent des strat\xe9gies algorithmiques fondamentalement diff\xe9rentes."})," Les chercheurs ont entra\xeen\xe9 des classificateurs de texte sur des t\xe2ches d'inf\xe9rence en langage naturel et ont d\xe9couvert que des mod\xe8les avec des performances d'entra\xeenement identiques se regroupaient en clusters distincts. Les mod\xe8les au sein de chaque cluster utilisaient des approches de raisonnement similaires et pouvaient \xeatre connect\xe9s \xe0 travers le paysage de perte, mais les mod\xe8les de diff\xe9rents clusters \xe9taient s\xe9par\xe9s par d'importantes barri\xe8res de performance. Un cluster a appris des approches sac-de-mots tandis qu'un autre a d\xe9velopp\xe9 des strat\xe9gies de raisonnement syntaxique (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2205.12411",children:"Juneja et al., 2023"}),"). Une variance similaire appara\xeet dans les exp\xe9riences d'apprentissage par renforcement et les \xe9tudes de ",(0,i.jsx)(n,{term:"fine-tuning",definition:'{"definition":"Processus consistant \xe0 prendre un mod\xe8le pr\xe9-entra\xeen\xe9 et \xe0 le perfectionner pour une t\xe2che ou un ensemble de donn\xe9es sp\xe9cifique..","source":"","aliases":["Fine-tuning","fine-tune","finetuning","finetune","affinage","Affinage"]}',children:(0,i.jsx)(n,{term:"fine-tuning",definition:'{"definition":"Processus consistant \xe0 prendre un mod\xe8le pr\xe9-entra\xeen\xe9 et \xe0 le perfectionner pour une t\xe2che ou un ensemble de donn\xe9es sp\xe9cifique..","source":"","aliases":["Fine-tuning","fine-tune","finetuning","finetune","affinage","Affinage"]}',children:"fine-tuning"})})," o\xf9 des configurations identiques produisent des comportements appris radicalement diff\xe9rents."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Une faible d\xe9pendance au chemin \xe9merge lorsque des contraintes math\xe9matiques forcent la convergence vers la m\xeame solution."}),' La g\xe9n\xe9ralisation retard\xe9e est un ph\xe9nom\xe8ne o\xf9 un mod\xe8le passe brusquement du surapprentissage (performant uniquement sur les donn\xe9es d\'entra\xeenement) \xe0 la g\xe9n\xe9ralisation (aussi appel\xe9e "grokking") (',(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2502.01774v1",children:"Carvalho et al., 2025"}),"). Par exemple, les mod\xe8les apprenant l'arithm\xe9tique m\xe9morisent initialement les exemples d'entra\xeenement et obtiennent de mauvais r\xe9sultats aux tests. Mais un entra\xeenement prolong\xe9 les am\xe8ne soudainement \xe0 impl\xe9menter le bon algorithme math\xe9matique\u2014syst\xe9matiquement le m\xeame \xe0 travers diff\xe9rentes ex\xe9cutions. Cela sugg\xe8re que pour certaines t\xe2ches, la structure math\xe9matique sous-jacente contraint l'espace des solutions si s\xe9v\xe8rement qu'un seul bon algorithme existe (",(0,i.jsx)(s.a,{href:"https://towardsdatascience.com/neural-networks-are-fundamentally-bayesian-bee9a172fad8/",children:"Mingard et al., 2019"}),"). D'autres preuves incluent des \xe9tudes montrant que les r\xe9sultats de la descente de gradient corr\xe8lent avec l'\xe9chantillonnage al\xe9atoire des distributions de param\xe8tres."]}),"\n",(0,i.jsx)(d.A,{src:"./img/fuM_Image_11.png",alt:"Saisir la description alternative de l'image",number:"11",label:"7.11",caption:"Un paysage de perte en 2D o\xf9 chaque point repr\xe9sente un algorithme appris avec un ensemble diff\xe9rent de param\xe8tres sur le paysage. Les fl\xe8ches repr\xe9sentent les diff\xe9rents chemins que la descente de gradient stochastique peut emprunter \xe0 travers le paysage de perte. Si diff\xe9rents points de d\xe9part aboutissent au m\xeame algorithme appris, alors nous avons une faible d\xe9pendance au chemin (gauche), sinon si diff\xe9rents points de d\xe9part aboutissent \xe0 diff\xe9rents algorithmes appris, alors nous avons une forte d\xe9pendance au chemin (droite)."}),"\n",(0,i.jsx)(s.h2,{id:"03",children:"Biais Inductif"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les biais inductifs d\xe9crivent la forme du paysage et d\xe9terminent quels types d'algorithmes sont plus susceptibles d'\xeatre d\xe9couverts."}),' Si votre architecture a un biais inductif de simplicit\xe9, cela signifie que les solutions algorithmiquement simples sont de larges et profondes vall\xe9es qui dominent le paysage de perte. Des solutions complexes peuvent toujours exister dans le paysage, mais elles sont rel\xe9gu\xe9es \xe0 des pics minuscules et difficiles \xe0 trouver. Cela explique intuitivement pourquoi la strat\xe9gie "aller \xe0 droite" dans CoinRun occupe un immense bassin de perte s\'\xe9tendant sur de vastes r\xe9gions de l\'espace des param\xe8tres, tandis que "naviguer vers les objets en forme de pi\xe8ce" n\'existe que dans de plus petites poches. Vous \xeates plus susceptible de trouver des solutions plus simples comme aller \xe0 droite car ces bassins et vall\xe9es sont tout simplement plus faciles \xe0 trouver et \xe0 y tomber.']}),"\n",(0,i.jsx)(l.A,{term:"Biais Inductif",source:"",number:"5",label:"7.5",children:(0,i.jsx)(s.p,{children:"Les biais inductifs sont des pr\xe9f\xe9rences syst\xe9matiques des algorithmes d'apprentissage qui favorisent certains types de solutions par rapport \xe0 d'autres. Ces biais \xe9mergent de l'architecture, de la proc\xe9dure d'optimisation et de la configuration d'entra\xeenement plut\xf4t que d'\xeatre explicitement programm\xe9s."})}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Le biais de simplicit\xe9 repr\xe9sente le biais inductif le plus influent, le mieux \xe9tudi\xe9 et potentiellement le plus dangereux pour la surg\xe9n\xe9ralisation des objectifs."})," Le biais de simplicit\xe9 pose la question \"quelle est la complexit\xe9 de sp\xe9cification de l'algorithme dans les poids ?\" C'est l'\xe9quivalent en ",(0,i.jsx)(n,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:(0,i.jsx)(n,{term:"machine learning",definition:'{"definition":"Un domaine de l\'intelligence artificielle ax\xe9 sur la cr\xe9ation de syst\xe8mes qui apprennent et s\'am\xe9liorent \xe0 partir de donn\xe9es sans \xeatre explicitement programm\xe9s pour chaque t\xe2che.","source":"","aliases":["Apprentissage automatique","apprentissage automatique","Apprentisssage machine","apprentisssage machine","Machine Learning","ML"]}',children:"apprentissage automatique"})})," du rasoir d'Occam, qui sugg\xe8re que parmi les hypoth\xe8ses concurrentes, celle avec le moins d'hypoth\xe8ses devrait \xeatre s\xe9lectionn\xe9e. Le ",(0,i.jsx)(n,{term:"stochastic gradient descent",definition:'{"definition":"Une variante de la descente de gradient qui met \xe0 jour les param\xe8tres \xe0 l\'aide de gradients calcul\xe9s sur de petits lots al\xe9atoires de donn\xe9es plut\xf4t que sur l\'ensemble des donn\xe9es..","source":"","aliases":["Stochastic Gradient Descent","SGD","Descente de Gradient Stochastique"]}',children:(0,i.jsx)(n,{term:"stochastic gradient descent",definition:'{"definition":"Une variante de la descente de gradient qui met \xe0 jour les param\xe8tres \xe0 l\'aide de gradients calcul\xe9s sur de petits lots al\xe9atoires de donn\xe9es plut\xf4t que sur l\'ensemble des donn\xe9es..","source":"","aliases":["Stochastic Gradient Descent","SGD","Descente de Gradient Stochastique"]}',children:"SGD"})})," semble adh\xe9rer au rasoir d'Occam et favorise syst\xe9matiquement les algorithmes qui s'appuient sur des corr\xe9lations simples plut\xf4t que sur un raisonnement causal complexe (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2006.07710",children:"Shah et al., 2020"}),"; ",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2409.09626",children:"Ren & Sutherland, 2024"}),"; ",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2410.02348",children:"Etienne & Flammarion, 2025"}),"; ",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2405.17299",children:"Tsoy & Konstantinov, 2024"}),"; ",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2311.08379",children:"Carlsmith, 2023"}),")",(0,i.jsx)(o.A,{id:"footnote_simplicity_bias",number:"1",text:"Plus de ressources pour en apprendre sur le biais de simplicit\xe9 \xe0 ce lien -"}),'. Dans CoinRun, "aller \xe0 droite" et "naviguer vers les objets en forme de pi\xe8ce" pourraient tous deux r\xe9soudre la t\xe2che pendant l\'entra\xeenement, mais "aller \xe0 droite" est algorithmiquement plus simple\u2014n\xe9cessitant un seul mod\xe8le comportemental plut\xf4t que la reconnaissance d\'objets, le raisonnement spatial et la navigation orient\xe9e vers un but. Le processus d\'entra\xeenement favorise syst\xe9matiquement l\'explication la plus simple, m\xeame lorsque l\'algorithme complexe se g\xe9n\xe9raliserait mieux (',(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/1805.08522",children:"Valle-P\xe9rez et al., 2019"}),"; ",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2006.07710",children:"Shah et al., 2020"}),"). Ce mod\xe8le s'\xe9tend largement \xe0 diff\xe9rentes architectures : les classificateurs d'images apprennent g\xe9n\xe9ralement des strat\xe9gies bas\xe9es sur la texture plut\xf4t que sur la forme car les motifs de texture n\xe9cessitent des structures de calcul plus simples, conduisant \xe0 une fragilit\xe9 lorsque la texture et la forme fournissent des signaux contradictoires (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/1811.12231",children:"Geirhos et al., 2019"}),")."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.a,{href:"https://github.com/sadimanna/simplicity-bias-papers",children:"Github - Articles sur le Biais de Simplicit\xe9"})}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"D'autres biais inductifs peuvent cr\xe9er des pr\xe9f\xe9rences syst\xe9matiques suppl\xe9mentaires qui peuvent favoriser la d\xe9couverte d'algorithmes avec des objectifs mal align\xe9s."})," Le biais de vitesse examine \"combien de calculs l'algorithme n\xe9cessite-t-il au moment de l'inf\xe9rence ?\". Une architecture avec un biais de vitesse aurait des bassins de perte plus larges avec des algorithmes n\xe9cessitant moins d'\xe9tapes de calcul, potentiellement en conflit avec des solutions qui effectuent un raisonnement plus approfondi ou une planification \xe0 long terme. Il existe de nombreux autres exemples de biais - le biais de fr\xe9quence (apprentissage des motifs basse fr\xe9quence avant ceux de haute fr\xe9quence) (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/1806.08734",children:"Rahaman et al., 2019"}),"), le biais g\xe9om\xe9trique (solutions avec une variabilit\xe9 plus faible) (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/2209.13083",children:"Luo et al., 2019"}),"), et plus encore. Pour la plupart, nous consid\xe9rerons les biais inductifs qui sont pertinents pour la s\xe9curit\xe9 - vitesse et simplicit\xe9."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Ces biais peuvent \xe9merger \xe0 partir de remarquablement peu de donn\xe9es, modifiant fondamentalement quels algorithmes deviennent d\xe9couvrables."})," Les r\xe9seaux neuronaux simples d\xe9veloppent un biais de forme\u2014pr\xe9f\xe9rant classifier les objets par leur structure g\xe9om\xe9trique plut\xf4t que par leur texture de surface\u2014apr\xe8s avoir vu aussi peu que 3 exemples de 4 cat\xe9gories d'objets (",(0,i.jsx)(s.a,{href:"https://arxiv.org/abs/1802.02745",children:"Feinman & Lake, 2018"}),'). L\'interaction entre la g\xe9om\xe9trie du paysage et la navigation cr\xe9e des r\xe9sultats syst\xe9matiques mais impr\xe9visibles : vous savez que vous finirez probablement dans le syst\xe8me de vall\xe9es des "solutions simples" car il domine le paysage, mais que vous d\xe9couvriez l\'algorithme sp\xe9cifique "aller \xe0 droite" ou "\xe9viter les pixels sombres" d\xe9pend des d\xe9tails al\xe9atoires de votre voyage dans l\'espace des param\xe8tres.']}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Les biais inductifs cr\xe9ent des risques de surg\xe9n\xe9ralisation des objectifs car les algorithmes bas\xe9s sur la corr\xe9lation sont souvent plus simples que le raisonnement causal."})," Il est algorithmiquement plus facile d'apprendre \"les r\xe9ponses utiles obtiennent l'approbation\" que \"comprendre ce dont l'humain a r\xe9ellement besoin et le fournir.\" \xc0 mesure que les environnements d'entra\xeenement deviennent plus complexes, l'\xe9cart entre les objectifs pr\xe9vus et les proxys facilement appris s'accro\xeet, rendant les algorithmes mal align\xe9s de plus en plus susceptibles d'\xe9merger. L'interaction entre les biais inductifs et la d\xe9pendance au chemin d\xe9termine \xe0 la fois le type et l'impl\xe9mentation sp\xe9cifique des algorithmes appris\u2014les biais contraignent l'entra\xeenement \xe0 favoriser certaines classes de solutions, tandis que la d\xe9pendance au chemin d\xe9termine quelle impl\xe9mentation sp\xe9cifique au sein de cette classe est d\xe9couverte. Cette section sur la dynamique d'apprentissage et les biais inductifs sera particuli\xe8rement pertinente lorsque nous parlerons de la probabilit\xe9 d'alignement manipulateur et trompeur."]}),"\n",(0,i.jsx)(o.c,{title:"Notes de bas de page"})]})}function g(e={}){const{wrapper:s}={...(0,a.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},4768:(e,s,n)=>{n.d(s,{c:()=>u,A:()=>d});var t=n(6540),i=n(3012);const a={footnoteAnchor:"footnoteAnchor_PZpY",footnoteSection:"footnoteSection_waoz",separator:"separator_hp8y",separatorLine:"separatorLine_uVnd",separatorLogo:"separatorLogo_dMBq",footnoteRegistry:"footnoteRegistry_ieVW",registryTitle:"registryTitle_ybBb",footnoteList:"footnoteList_Kjil",footnoteItem:"footnoteItem_aLZ2",footnoteNumber:"footnoteNumber_dA3X",footnoteContent:"footnoteContent_Xfmt",backButton:"backButton_vSVm",highlighted:"highlighted_YFU0",highlight:"highlight_jxG3",highlightDark:"highlightDark_Ekom"};var r=n(4848);function o(e,s){void 0===s&&(s=!0);const n=document.getElementById(e);n&&(n.scrollIntoView({behavior:"smooth"}),s&&(n.classList.add(a.highlighted),setTimeout((()=>n.classList.remove(a.highlighted)),1500)))}function l(e){return e?e.replace(/\[([^\]]+)\]\(([^)]+)\)/g,'<a href="$2" target="_blank" rel="noopener noreferrer">$1</a>'):""}function d(e){let{id:s,text:n,number:d}=e;const u=s||`footnote-${Math.random().toString(36).substr(2,9)}`,c="string"==typeof n?l(n):n;return(0,t.useEffect)((()=>{const e=setTimeout((()=>{const e=document.getElementById(`footnote-clone-${u}`);e&&n&&(e.innerHTML="string"==typeof n?l(n):n.toString())}),100);return()=>clearTimeout(e)}),[u,n]),(0,r.jsx)(i.Mn,{content:(0,r.jsx)("div",{dangerouslySetInnerHTML:{__html:c}}),children:(0,r.jsx)("sup",{id:`footnote-ref-${u}`,className:a.footnoteAnchor,onClick:e=>{(e.ctrlKey||e.metaKey)&&(e.preventDefault(),o(`footnote-content-${u}`))},"data-footnote-number":d||"?",children:d||"*"})})}function u(e){let{title:s="References"}=e;const[n,l]=(0,t.useState)([]);return(0,t.useEffect)((()=>{const e=document.querySelectorAll('[id^="footnote-ref-"]'),s=Array.from(e).map((e=>({id:e.id.replace("footnote-ref-",""),number:e.getAttribute("data-footnote-number")||e.textContent})));l(s)}),[]),n.length?(0,r.jsxs)("div",{className:a.footnoteSection,children:[(0,r.jsxs)("div",{className:a.separator,children:[(0,r.jsx)("div",{className:a.separatorLine}),(0,r.jsx)("img",{src:"/img/logo_samples/01-test.svg",alt:"Atlas logo",className:a.separatorLogo}),(0,r.jsx)("div",{className:a.separatorLine})]}),(0,r.jsxs)("div",{className:a.footnoteRegistry,children:[(0,r.jsx)("h2",{className:a.registryTitle,children:s}),(0,r.jsx)("ol",{className:a.footnoteList,children:n.map((e=>(0,r.jsxs)("li",{id:`footnote-content-${e.id}`,className:a.footnoteItem,value:parseInt(e.number)||void 0,children:[(0,r.jsx)(i.Mn,{content:"Back to reference",children:(0,r.jsxs)("button",{className:a.footnoteNumber,onClick:()=>o(`footnote-ref-${e.id}`),"aria-label":"Back to reference",children:[e.number,"."]})}),(0,r.jsx)("div",{className:a.footnoteContent,children:(0,r.jsx)("div",{id:`footnote-clone-${e.id}`})}),(0,r.jsx)(i.Mn,{content:"Back to reference",children:(0,r.jsx)("button",{className:a.backButton,onClick:()=>o(`footnote-ref-${e.id}`),"aria-label":"Back to reference",children:"\u21a9"})})]},e.id)))})]})]}):null}},3931:(e,s,n)=>{n.d(s,{A:()=>l});var t=n(6540),i=n(6347),a=n(8444);const r={videoFigure:"videoFigure_dV9u",fullWidth:"fullWidth_Tv7O",videoContainer:"videoContainer_LWoK",aspectRatio169:"aspectRatio169_Go8b",aspectRatio43:"aspectRatio43_b3T7",aspectRatio11:"aspectRatio11_n21J",aspectRatio219:"aspectRatio219_L_3n",videoIframe:"videoIframe_QEc5",videoElement:"videoElement_uu7N",customPlayer:"customPlayer_jiC4",customPlayerPlaceholder:"customPlayerPlaceholder_aL9q",loadingOverlay:"loadingOverlay_e2pu",spinner:"spinner_tFyL",spin:"spin_saPs",errorContainer:"errorContainer_J6Pn",errorIcon:"errorIcon_cGdn",fallbackLink:"fallbackLink_WsZk"};var o=n(4848);function l(e){let{type:s="youtube",videoId:n,caption:l,title:d,startTime:u,autoplay:c=!1,controls:p=!0,aspectRatio:m="16:9",width:h,height:g,chapter:f,number:v,label:b,useCustomPlayer:x=!1,fullWidth:q=!0}=e;const[j,y]=(0,t.useState)(!0),[L,_]=(0,t.useState)(!1),C=(0,i.zy)(),w=f||(()=>{const e=C.pathname.match(/\/chapters\/(\d+)/);return e?parseInt(e[1]):null})(),k=(()=>{const e=(e=>{if(!e)return"";if("number"==typeof e)return e.toString();if("string"==typeof e){if(/^\d+$/.test(e))return e;let s=0;const n=e.match(/(\d+)h/),t=e.match(/(\d+)m/),i=e.match(/(\d+)s/);return n&&(s+=3600*parseInt(n[1])),t&&(s+=60*parseInt(t[1])),i&&(s+=parseInt(i[1])),s>0?s.toString():""}return""})(u);switch(s.toLowerCase()){case"youtube":let t=`https://www.youtube.com/embed/${n}`;const i=new URLSearchParams;e&&i.append("start",e),c&&i.append("autoplay","1"),p||x||i.append("controls","0"),i.append("rel","0"),i.append("modestbranding","1"),i.append("fs","1"),i.append("cc_load_policy","0"),i.append("iv_load_policy","3"),i.append("showinfo","0"),i.append("disablekb","1"),i.append("playsinline","1"),i.append("color","white"),i.append("theme","light"),x&&(i.append("enablejsapi","1"),i.append("origin",window.location.origin));const a=i.toString();return a?`${t}?${a}`:t;case"vimeo":let r=`https://player.vimeo.com/video/${n}`;const o=new URLSearchParams;c&&o.append("autoplay","1"),p||x||o.append("controls","0"),o.append("title","0"),o.append("byline","0"),o.append("portrait","0"),o.append("dnt","1"),o.append("transparent","0"),o.append("background","1");const l=o.toString();return l?`${r}?${l}`:r;case"mp4":case"webm":case"video":return n;default:return console.warn(`Unsupported video type: ${s}`),n}})(),A=()=>{y(!1)},N=()=>{_(!0),y(!1)},D=e=>{let{src:n,onLoad:t,onError:i}=e;return(0,o.jsx)("div",{className:r.customPlayer,children:(0,o.jsxs)("div",{className:r.customPlayerPlaceholder,children:[(0,o.jsx)("h3",{children:"Atlas Custom Player"}),(0,o.jsx)("p",{children:"Coming Soon"}),(0,o.jsxs)("a",{href:n,target:"_blank",rel:"noopener noreferrer",className:r.fallbackLink,children:["Watch on ",s.charAt(0).toUpperCase()+s.slice(1)]})]})})},S=["mp4","webm","video"].includes(s.toLowerCase());return(0,o.jsxs)("figure",{className:`${r.videoFigure} ${q?r.fullWidth:""}`,children:[(0,o.jsxs)("div",{className:`${r.videoContainer} ${(()=>{switch(m){case"4:3":return r.aspectRatio43;case"1:1":return r.aspectRatio11;case"21:9":return r.aspectRatio219;default:return r.aspectRatio169}})()}`,style:{width:q?"100%":h||"auto",maxWidth:q?"none":"800px"},children:[j&&!L&&(0,o.jsxs)("div",{className:r.loadingOverlay,children:[(0,o.jsx)("div",{className:r.spinner}),(0,o.jsx)("p",{children:"Loading video..."})]}),L&&(0,o.jsxs)("div",{className:r.errorContainer,children:[(0,o.jsxs)("svg",{className:r.errorIcon,width:"48",height:"48",viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:"2",children:[(0,o.jsx)("circle",{cx:"12",cy:"12",r:"10"}),(0,o.jsx)("line",{x1:"12",y1:"8",x2:"12",y2:"12"}),(0,o.jsx)("line",{x1:"12",y1:"16",x2:"12.01",y2:"16"})]}),(0,o.jsx)("h4",{children:"Failed to load video"}),(0,o.jsxs)("p",{children:["Video type: ",s]}),(0,o.jsxs)("p",{children:["Video ID/URL: ",n]}),(0,o.jsx)("a",{href:k,target:"_blank",rel:"noopener noreferrer",className:r.fallbackLink,children:"Try opening video directly"})]}),!L&&(S?(0,o.jsxs)("video",{className:r.videoElement,controls:p,autoPlay:c,onLoadedData:A,onError:N,title:d||l||`${s} video`,style:{width:h||"100%",height:g||"auto",display:j?"none":"block"},children:[(0,o.jsx)("source",{src:k,type:`video/${s}`}),(0,o.jsxs)("p",{children:["Your browser doesn't support video playback.",(0,o.jsx)("a",{href:k,target:"_blank",rel:"noopener noreferrer",children:"Download the video file"})]})]}):x?(0,o.jsx)(D,{src:k,onLoad:A,onError:N}):(0,o.jsx)("iframe",{className:r.videoIframe,src:k,title:d||l||`${s} video`,frameBorder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",allowFullScreen:!0,onLoad:A,onError:N,style:{width:h||"100%",height:g||"100%",opacity:j?0:1}}))]}),(0,o.jsx)(a.A,{caption:l,mediaType:"video",chapter:w,number:v,label:b})]})}}}]);