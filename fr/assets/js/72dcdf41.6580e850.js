"use strict";(self.webpackChunkatlas=self.webpackChunkatlas||[]).push([[2284],{1842:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Suivant","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"docs":[{"type":"link","label":"Manuel scolaire","href":"/fr/chapters","className":"sidebar-chapters-index","docId":"chapters/index","unlisted":false},{"type":"category","label":"1. Capacit\xe9s","items":[{"type":"category","label":"1.1 IA \xe0 l\'\xc9tat de l\'Art","items":[{"type":"link","label":"1.1.1 Langage","href":"/chapters/01/01#01"},{"type":"link","label":"1.1.2 G\xe9n\xe9ration d\'Images","href":"/chapters/01/01#02"},{"type":"link","label":"1.1.3 Multi & Cross modalit\xe9","href":"/chapters/01/01#03"},{"type":"link","label":"1.1.4 Robotique","href":"/chapters/01/01#04"},{"type":"link","label":"1.1.5 Jeux","href":"/chapters/01/01#05"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/01/01"},{"type":"category","label":"1.2 Mod\xe8les de Base","items":[{"type":"link","label":"1.2.1 Entra\xeenement","href":"/chapters/01/02#01"},{"type":"link","label":"1.2.2 Propri\xe9t\xe9s","href":"/chapters/01/02#02"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/01/02"},{"type":"category","label":"1.3 Intelligence","items":[{"type":"link","label":"1.3.1 \xc9tudes de Cas","href":"/chapters/01/03#01"},{"type":"link","label":"1.3.2 Mesure","href":"/chapters/01/03#02"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/01/03"},{"type":"category","label":"1.4 Mise \xe0 l\'\xc9chelle","items":[{"type":"link","label":"1.4.1 La Le\xe7on Am\xe8re","href":"/chapters/01/04#01"},{"type":"link","label":"1.4.2 Lois de Mise \xe0 l\'\xc9chelle","href":"/chapters/01/04#02"},{"type":"link","label":"1.4.3 Hypoth\xe8se de Mise \xe0 l\'\xc9chelle","href":"/chapters/01/04#03"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/01/04"},{"type":"category","label":"1.5 Pr\xe9visions","items":[{"type":"link","label":"1.5.1 M\xe9thodologie","href":"/chapters/01/05#01"},{"type":"category","label":"1.5.2 Pr\xe9visions Bas\xe9es sur les Tendances","items":[{"type":"link","label":"1.5.2.1 Calcul","href":"/chapters/01/05#02-01"},{"type":"link","label":"1.5.2.2 Param\xe8tres","href":"/chapters/01/05#02-02"},{"type":"link","label":"1.5.2.3 Donn\xe9es","href":"/chapters/01/05#02-03"},{"type":"link","label":"1.5.2.4 Algorithmes","href":"/chapters/01/05#02-04"},{"type":"link","label":"1.5.2.5 Co\xfbts","href":"/chapters/01/05#02-05"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/01/05#02"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/01/05"},{"type":"category","label":"1.6 D\xe9collage","items":[{"type":"link","label":"1.6.1 Vitesse","href":"/chapters/01/06#01"},{"type":"link","label":"1.6.2 Arguments sur le D\xe9collage","href":"/chapters/01/06#02"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/01/06"},{"type":"category","label":"1.7 Annexe : D\xe9collage","items":[{"type":"link","label":"1.7.1 Continuit\xe9","href":"/chapters/01/07#01"},{"type":"link","label":"1.7.2 Similarit\xe9","href":"/chapters/01/07#02"},{"type":"link","label":"1.7.3 Polarit\xe9","href":"/chapters/01/07#03"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/01/07"},{"type":"category","label":"1.8 Annexe : Opinions d\'Experts","items":[{"type":"link","label":"1.8.1 Enqu\xeates","href":"/chapters/01/08#01"},{"type":"category","label":"1.8.2 Citations","items":[{"type":"link","label":"1.8.2.1 Experts en IA","href":"/chapters/01/08#02-01"},{"type":"link","label":"1.8.2.2 Universitaires","href":"/chapters/01/08#02-02"},{"type":"link","label":"1.8.2.3 Entrepreneurs Technologiques","href":"/chapters/01/08#02-03"},{"type":"link","label":"1.8.2.4 D\xe9clarations Communes","href":"/chapters/01/08#02-04"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/01/08#02"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/01/08"},{"type":"category","label":"1.9 Annexe : Discussion sur les LLMs","items":[{"type":"link","label":"1.9.1 Insuffisance Empirique ?","href":"/chapters/01/09#01"},{"type":"link","label":"1.9.2 Compr\xe9hension Superficielle ?","href":"/chapters/01/09#02"},{"type":"link","label":"1.9.3 Inad\xe9quation Structurelle ?","href":"/chapters/01/09#03"},{"type":"link","label":"1.9.4 Diff\xe9rences avec le Cerveau","href":"/chapters/01/09#04"},{"type":"link","label":"1.9.5 Autres Raisons de Continuer \xe0 D\xe9velopper les LLMs","href":"/chapters/01/09#05"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/01/09"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/01/"},{"type":"category","label":"2. Risques","items":[{"type":"category","label":"2.1 D\xe9composition des Risques","items":[{"type":"link","label":"2.1.1 Causes des Risques","href":"/chapters/02/01#01"},{"type":"link","label":"2.1.2 Gravit\xe9 des Risques","href":"/chapters/02/01#02"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/02/01"},{"type":"category","label":"2.2 Capacit\xe9s Dangereuses","items":[{"type":"link","label":"2.2.1 Tromperie","href":"/chapters/02/02#01"},{"type":"link","label":"2.2.2 Conscience Situationnelle","href":"/chapters/02/02#02"},{"type":"link","label":"2.2.3 Recherche de Pouvoir","href":"/chapters/02/02#03"},{"type":"link","label":"2.2.4 R\xe9plication Autonome","href":"/chapters/02/02#04"},{"type":"link","label":"2.2.5 Agentivit\xe9","href":"/chapters/02/02#05"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/02/02"},{"type":"category","label":"2.3 Risques d\'Utilisation Malveillante","items":[{"type":"link","label":"2.3.1 Risque Biologique","href":"/chapters/02/03#01"},{"type":"link","label":"2.3.2 Risque Cybern\xe9tique","href":"/chapters/02/03#02"},{"type":"link","label":"2.3.3 Risque des Armes Autonomes","href":"/chapters/02/03#03"},{"type":"link","label":"2.3.4 Risque d\'IA Adversaire","href":"/chapters/02/03#04"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/02/03"},{"type":"category","label":"2.4 Risques de D\xe9salignement","items":[{"type":"link","label":"2.4.1 D\xe9tournement des Sp\xe9cifications","href":"/chapters/02/04#01"},{"type":"link","label":"2.4.2 Tournant Perfide","href":"/chapters/02/04#02"},{"type":"link","label":"2.4.3 Auto-Am\xe9lioration","href":"/chapters/02/04#03"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/02/04"},{"type":"category","label":"2.5 Risques Syst\xe9miques","items":[{"type":"link","label":"2.5.1 Risques Syst\xe9miques D\xe9cisifs","href":"/chapters/02/05#01"},{"type":"category","label":"2.5.2 Risques Syst\xe9miques Cumulatifs","items":[{"type":"link","label":"2.5.2.1 \xc9rosion \xc9pist\xe9mique","href":"/chapters/02/05#02-01"},{"type":"link","label":"2.5.2.2 Concentration du Pouvoir","href":"/chapters/02/05#02-02"},{"type":"link","label":"2.5.2.3 Ch\xf4mage de Masse","href":"/chapters/02/05#02-03"},{"type":"link","label":"2.5.2.4 Verrouillage des Valeurs","href":"/chapters/02/05#02-04"},{"type":"link","label":"2.5.2.5 Affaiblissement","href":"/chapters/02/05#02-05"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/02/05#02"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/02/05"},{"type":"category","label":"2.6 Amplificateurs de Risques","items":[{"type":"link","label":"2.6.1 Dynamiques de Course","href":"/chapters/02/06#01"},{"type":"link","label":"2.6.2 Accidents","href":"/chapters/02/06#02"},{"type":"link","label":"2.6.3 Indiff\xe9rence","href":"/chapters/02/06#03"},{"type":"link","label":"2.6.4 Probl\xe8mes d\'Action Collective","href":"/chapters/02/06#04"},{"type":"link","label":"2.6.5 Impr\xe9visibilit\xe9","href":"/chapters/02/06#05"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/02/06"},{"type":"link","label":"2.7 Conclusion","href":"/fr/chapters/02/07","docId":"chapters/02/7","unlisted":false},{"type":"link","label":"2.8 Annexe : Quantifier les risques existentiels","href":"/fr/chapters/02/08","docId":"chapters/02/8","unlisted":false},{"type":"category","label":"2.9 Annexe : Sc\xe9narios de Pr\xe9vision","items":[{"type":"link","label":"2.9.1 Le Web de Production","href":"/chapters/02/09#01"},{"type":"link","label":"2.9.2 IA 2027","href":"/chapters/02/09#02"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/02/09"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/02/"},{"type":"category","label":"3. Strat\xe9gies","items":[{"type":"category","label":"3.1 D\xe9finitions","items":[{"type":"link","label":"3.1.1 S\xe9curit\xe9 de l\'IA","href":"/chapters/03/01#01"},{"type":"link","label":"3.1.2 Alignement de l\'IA","href":"/chapters/03/01#02"},{"type":"link","label":"3.1.3 \xc9thique de l\'IA","href":"/chapters/03/01#03"},{"type":"link","label":"3.1.4 Contr\xf4le de l\'IA","href":"/chapters/03/01#04"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/03/01"},{"type":"category","label":"3.2 Strat\xe9gies de Pr\xe9vention des Utilisations Malveillantes","items":[{"type":"category","label":"3.2.1 Contr\xf4les d\'Acc\xe8s","items":[{"type":"link","label":"3.2.1.1 Contr\xf4les Externes","href":"/chapters/03/02#01-01"},{"type":"link","label":"3.2.1.2 Contr\xf4les Internes","href":"/chapters/03/02#01-02"},{"type":"link","label":"3.2.1.3 Garanties Techniques","href":"/chapters/03/02#01-03"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/03/02#01"},{"type":"link","label":"3.2.2 Strat\xe9gies Socio-techniques","href":"/chapters/03/02#02"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/03/02"},{"type":"category","label":"3.3 Strat\xe9gies de S\xe9curit\xe9 pour l\'AGI","items":[{"type":"link","label":"3.3.1 Strat\xe9gies Na\xefves","href":"/chapters/03/03#01"},{"type":"category","label":"3.3.2 R\xe9soudre l\'Alignement","items":[{"type":"link","label":"3.3.2.1 Exigences pour l\'Alignement de l\'AGI","href":"/chapters/03/03#02-01"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/03/03#02"},{"type":"link","label":"3.3.3 Contr\xf4le de l\'IA","href":"/chapters/03/03#03"},{"type":"link","label":"3.3.4 Pens\xe9es Transparentes","href":"/chapters/03/03#04"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/03/03"},{"type":"category","label":"3.4 Strat\xe9gies de S\xe9curit\xe9 pour l\'ASI","items":[{"type":"link","label":"3.4.1 Strat\xe9gies D\xe9battues","href":"/chapters/03/04#01"},{"type":"link","label":"3.4.2 Automatisation de la Recherche sur l\'Alignement","href":"/chapters/03/04#02"},{"type":"link","label":"3.4.3 S\xe9curit\xe9 par Conception","href":"/chapters/03/04#03"},{"type":"link","label":"3.4.4 Coordination Mondiale","href":"/chapters/03/04#04"},{"type":"link","label":"3.4.5 Dissuasion","href":"/chapters/03/04#05"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/03/04"},{"type":"category","label":"3.5 Strat\xe9gies Syst\xe9miques","items":[{"type":"link","label":"3.5.1 Acc\xe9l\xe9ration de la D\xe9fense (d/acc)","href":"/chapters/03/05#01"},{"type":"link","label":"3.5.2 D\xe9fense en Profondeur","href":"/chapters/03/05#02"},{"type":"link","label":"3.5.3 Gouvernance de l\'IA","href":"/chapters/03/05#03"},{"type":"link","label":"3.5.4 Gestion des Risques","href":"/chapters/03/05#04"},{"type":"link","label":"3.5.5 Culture de la S\xe9curit\xe9","href":"/chapters/03/05#05"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/03/05"},{"type":"link","label":"3.6 Combinaison des strat\xe9gies","href":"/fr/chapters/03/06","docId":"chapters/03/6","unlisted":false},{"type":"category","label":"3.7 D\xe9fis","items":[{"type":"link","label":"3.7.1 La Nature du Probl\xe8me","href":"/chapters/03/07#01"},{"type":"link","label":"3.7.2 Incertitude et D\xe9saccord","href":"/chapters/03/07#02"},{"type":"link","label":"3.7.3 Blanchiment de la S\xe9curit\xe9","href":"/chapters/03/07#03"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/03/07"},{"type":"link","label":"3.8 Conclusion","href":"/fr/chapters/03/08","docId":"chapters/03/8","unlisted":false},{"type":"link","label":"3.9 Annexe : Questions \xe0 long terme","href":"/fr/chapters/03/09","docId":"chapters/03/9","unlisted":false},{"type":"link","label":"3.10 Annexe : Exigences pour l\'alignement de l\'ASI","href":"/fr/chapters/03/10","docId":"chapters/03/10","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/03/"},{"type":"category","label":"4. Gouvernance","items":[{"type":"category","label":"4.1 Gouvernance du Calcul","items":[{"type":"link","label":"4.1.1 Suivi","href":"/chapters/04/01#01"},{"type":"link","label":"4.1.2 Surveillance","href":"/chapters/04/01#02"},{"type":"link","label":"4.1.3 Contr\xf4les sur Puce","href":"/chapters/04/01#03"},{"type":"link","label":"4.1.4 Limitations","href":"/chapters/04/01#04"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/04/01"},{"type":"category","label":"4.2 D\xe9fis Syst\xe9miques","items":[{"type":"link","label":"4.2.1 Dynamiques de Course","href":"/chapters/04/02#01"},{"type":"link","label":"4.2.2 Prolif\xe9ration","href":"/chapters/04/02#02"},{"type":"link","label":"4.2.3 Incertitude","href":"/chapters/04/02#03"},{"type":"link","label":"4.2.4 Responsabilit\xe9","href":"/chapters/04/02#04"},{"type":"link","label":"4.2.5 Distribution du Pouvoir et de la Richesse","href":"/chapters/04/02#05"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/04/02"},{"type":"category","label":"4.3 Architectures de Gouvernance","items":[{"type":"category","label":"4.3.1 Gouvernance d\'Entreprise","items":[{"type":"link","label":"4.3.1.1 Cadres de S\xe9curit\xe9 Fronti\xe8re","href":"/chapters/04/03#01-01"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/04/03#01"},{"type":"link","label":"4.3.2 Gouvernance Nationale","href":"/chapters/04/03#02"},{"type":"link","label":"4.3.3 Gouvernance Internationale","href":"/chapters/04/03#03"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/04/03"},{"type":"category","label":"4.4 Mise en \u0152uvre","items":[{"type":"link","label":"4.4.1 Normes de S\xe9curit\xe9 de l\'IA","href":"/chapters/04/04#01"},{"type":"link","label":"4.4.2 Visibilit\xe9 R\xe9glementaire","href":"/chapters/04/04#02"},{"type":"link","label":"4.4.3 Assurer la Conformit\xe9","href":"/chapters/04/04#03"},{"type":"link","label":"4.4.4 Limitations et Compromis","href":"/chapters/04/04#04"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/04/04"},{"type":"link","label":"4.5 Conclusion","href":"/fr/chapters/04/05","docId":"chapters/04/5","unlisted":false},{"type":"link","label":"4.6 Annexe : Gouvernance des donn\xe9es","href":"/fr/chapters/04/06","docId":"chapters/04/6","unlisted":false},{"type":"category","label":"4.7 Annexe : Gouvernance Nationale","items":[{"type":"link","label":"4.7.1 Union Europ\xe9enne","href":"/chapters/04/07#01"},{"type":"link","label":"4.7.2 \xc9tats-Unis","href":"/chapters/04/07#02"},{"type":"link","label":"4.7.3 Chine","href":"/chapters/04/07#03"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/04/07"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/04/"},{"type":"category","label":"5. \xc9valuations","items":[{"type":"category","label":"5.1 R\xe9f\xe9rences","items":[{"type":"link","label":"5.1.1 Histoire et \xc9volution","href":"/chapters/05/01#01"},{"type":"link","label":"5.1.2 Limitations des R\xe9f\xe9rences","href":"/chapters/05/01#02"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/05/01"},{"type":"category","label":"5.2 Propri\xe9t\xe9s \xc9valu\xe9es","items":[{"type":"link","label":"5.2.1 Capacit\xe9","href":"/chapters/05/02#01"},{"type":"link","label":"5.2.2 Propension","href":"/chapters/05/02#02"},{"type":"link","label":"5.2.3 Contr\xf4le","href":"/chapters/05/02#03"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/05/02"},{"type":"category","label":"5.3 Techniques d\'\xc9valuation","items":[{"type":"link","label":"5.3.1 Techniques Comportementales","href":"/chapters/05/03#01"},{"type":"link","label":"5.3.2 Techniques Internes","href":"/chapters/05/03#02"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/05/03"},{"type":"category","label":"5.4 Cadres d\'\xc9valuation","items":[{"type":"link","label":"5.4.1 Cadre des Organismes Mod\xe8les","href":"/chapters/05/04#01"},{"type":"category","label":"5.4.2 Cadres de Gouvernance","items":[{"type":"link","label":"5.4.2.1 Cadre RSP (Anthropic)","href":"/chapters/05/04#02-01"},{"type":"link","label":"5.4.2.2 Cadre de Pr\xe9paration (OpenAI)","href":"/chapters/05/04#02-02"},{"type":"link","label":"5.4.2.3 Cadre de S\xe9curit\xe9 Fronti\xe8re (Google DeepMind)","href":"/chapters/05/04#02-03"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/05/04#02"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/05/04"},{"type":"category","label":"5.5 \xc9valuations des Capacit\xe9s Dangereuses","items":[{"type":"link","label":"5.5.1 Cybercriminalit\xe9","href":"/chapters/05/05#01"},{"type":"link","label":"5.5.2 Tromperie (Capacit\xe9)","href":"/chapters/05/05#02"},{"type":"link","label":"5.5.3 R\xe9plication Autonome","href":"/chapters/05/05#03"},{"type":"link","label":"5.5.4 Planification \xe0 Long Terme","href":"/chapters/05/05#04"},{"type":"link","label":"5.5.5 Conscience Situationnelle","href":"/chapters/05/05#05"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/05/05"},{"type":"category","label":"5.6 \xc9valuations des Propensions Dangereuses","items":[{"type":"link","label":"5.6.1 Tromperie (Propension)","href":"/chapters/05/06#01"},{"type":"link","label":"5.6.2 Manigance","href":"/chapters/05/06#02"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/05/06"},{"type":"link","label":"5.7 \xc9valuations de contr\xf4le","href":"/fr/chapters/05/07","docId":"chapters/05/7","unlisted":false},{"type":"category","label":"5.8 Conception d\'\xc9valuation","items":[{"type":"link","label":"5.8.1 Affordances","href":"/chapters/05/08#01"},{"type":"link","label":"5.8.2 Mise \xe0 l\'\xc9chelle et Automatisation","href":"/chapters/05/08#02"},{"type":"link","label":"5.8.3 Int\xe9gration et Audits","href":"/chapters/05/08#03"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/05/08"},{"type":"category","label":"5.9 Limitations","items":[{"type":"link","label":"5.9.1 D\xe9fis Fondamentaux","href":"/chapters/05/09#01"},{"type":"link","label":"5.9.2 D\xe9fis Techniques","href":"/chapters/05/09#02"},{"type":"link","label":"5.9.3 Dissimulation","href":"/chapters/05/09#03"},{"type":"link","label":"5.9.4 Limitations Syst\xe9miques","href":"/chapters/05/09#04"},{"type":"link","label":"5.9.5 Limitations de Gouvernance","href":"/chapters/05/09#05"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/05/09"},{"type":"link","label":"5.10 Conclusion","href":"/fr/chapters/05/10","docId":"chapters/05/10","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/05/"},{"type":"category","label":"6. Mauvaise Sp\xe9cification","items":[{"type":"category","label":"6.1 Apprentissage par Renforcement","items":[{"type":"link","label":"6.1.1 Introduction","href":"/chapters/06/01#01"},{"type":"link","label":"6.1.2 Boucle Principale","href":"/chapters/06/01#02"},{"type":"link","label":"6.1.3 Politiques","href":"/chapters/06/01#03"},{"type":"link","label":"6.1.4 R\xe9compense","href":"/chapters/06/01#04"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/06/01"},{"type":"category","label":"6.2 Optimisation","items":[{"type":"link","label":"6.2.1 Loi de Goodhart","href":"/chapters/06/02#01"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/06/02"},{"type":"category","label":"6.3 D\xe9tournement des Sp\xe9cifications","items":[{"type":"link","label":"6.3.1 Conception de la R\xe9compense","href":"/chapters/06/03#01"},{"type":"link","label":"6.3.2 Mise en Forme de la R\xe9compense","href":"/chapters/06/03#02"},{"type":"link","label":"6.3.3 Piratage de la R\xe9compense","href":"/chapters/06/03#03"},{"type":"link","label":"6.3.4 Alt\xe9ration de la R\xe9compense","href":"/chapters/06/03#04"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/06/03"},{"type":"category","label":"6.4 Apprentissage par Imitation","items":[{"type":"link","label":"6.4.1 Apprentissage par Imitation (IL)","href":"/chapters/06/04#01"},{"type":"link","label":"6.4.2 Clonage Comportemental (BC)","href":"/chapters/06/04#02"},{"type":"link","label":"6.4.3 Clonage Proc\xe9dural (PC)","href":"/chapters/06/04#03"},{"type":"link","label":"6.4.4 Apprentissage par Renforcement Inverse (IRL)","href":"/chapters/06/04#04"},{"type":"link","label":"6.4.5 Apprentissage par Renforcement Inverse Coop\xe9ratif (CIRL)","href":"/chapters/06/04#05"},{"type":"link","label":"6.4.6 Probl\xe8me d\'Inf\xe9rence d\'Objectif","href":"/chapters/06/04#06"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/06/04"},{"type":"category","label":"6.5 Apprentissage par retour","items":[{"type":"link","label":"6.5.1 Mod\xe9lisation de la R\xe9compense","href":"/chapters/06/05#01"},{"type":"link","label":"6.5.2 Apprentissage par Renforcement avec Retour Humain (RLHF)","href":"/chapters/06/05#02"},{"type":"link","label":"6.5.3 Pr\xe9-entra\xeenement avec Retour Humain (PHF)","href":"/chapters/06/05#03"},{"type":"link","label":"6.5.4 Apprentissage par Renforcement avec Retour d\'IA (RLAIF)","href":"/chapters/06/05#04"},{"type":"link","label":"6.5.5 Limitations","href":"/chapters/06/05#05"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/06/05"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/06/"},{"type":"category","label":"7. G\xe9n\xe9ralisation","items":[{"type":"category","label":"7.1 Dynamiques d\'Apprentissage","items":[{"type":"link","label":"7.1.1 Paysages de Perte","href":"/chapters/07/01#01"},{"type":"link","label":"7.1.2 D\xe9pendance au Chemin","href":"/chapters/07/01#02"},{"type":"link","label":"7.1.3 Biais Inductif","href":"/chapters/07/01#03"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/07/01"},{"type":"category","label":"7.2 Orientation vers les Objectifs","items":[{"type":"link","label":"7.2.1 Heuristiques","href":"/chapters/07/02#01"},{"type":"link","label":"7.2.2 Simulateurs","href":"/chapters/07/02#02"},{"type":"link","label":"7.2.3 Optimisation Apprise","href":"/chapters/07/02#03"},{"type":"link","label":"7.2.4 Processus Agnostiques aux Agents","href":"/chapters/07/02#04"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/07/02"},{"type":"category","label":"7.3 Manigance","items":[{"type":"link","label":"7.3.1 Pr\xe9requis","href":"/chapters/07/03#01"},{"type":"category","label":"7.3.2 Dimensions","items":[{"type":"link","label":"7.3.2.1 Transparence","href":"/chapters/07/03#02-01"},{"type":"link","label":"7.3.2.2 Contexte","href":"/chapters/07/03#02-02"},{"type":"link","label":"7.3.2.3 Persistance","href":"/chapters/07/03#02-03"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/07/03#02"},{"type":"category","label":"7.3.3 Probabilit\xe9","items":[{"type":"link","label":"7.3.3.1 Arguments en faveur de la manigance","href":"/chapters/07/03#03-01"},{"type":"link","label":"7.3.3.2 Arguments contre la manigance","href":"/chapters/07/03#03-02"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/07/03#03"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/07/03"},{"type":"category","label":"7.4 D\xe9tection","items":[{"type":"category","label":"7.4.1 Techniques Comportementales (Bo\xeete Noire)","items":[{"type":"link","label":"7.4.1.1 Raisonnement Externalis\xe9","href":"/chapters/07/04#01-01"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/07/04#01"},{"type":"category","label":"7.4.2 Techniques Internes (Bo\xeete Blanche)","items":[{"type":"link","label":"7.4.2.1 Sondes Lin\xe9aires","href":"/chapters/07/04#02-01"},{"type":"link","label":"7.4.2.2 Auto-encodeurs Parcimonieux","href":"/chapters/07/04#02-02"},{"type":"link","label":"7.4.2.3 Manipulation d\'Activation","href":"/chapters/07/04#02-03"},{"type":"link","label":"7.4.2.4 Analyse de la Structure de Raisonnement","href":"/chapters/07/04#02-04"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/07/04#02"},{"type":"link","label":"7.4.3 Techniques Combin\xe9es","href":"/chapters/07/04#03"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/07/04"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/07/"},{"type":"category","label":"8. Supervision \xc9volutive","items":[{"type":"category","label":"8.1 Supervision","items":[{"type":"link","label":"8.1.1 Signaux d\'Entra\xeenement","href":"/chapters/08/01#01"},{"type":"link","label":"8.1.2 V\xe9rification vs. G\xe9n\xe9ration","href":"/chapters/08/01#02"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/08/01"},{"type":"category","label":"8.2 D\xe9composition des T\xe2ches","items":[{"type":"link","label":"8.2.1 Cognition Factoris\xe9e","href":"/chapters/08/02#01"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/08/02"},{"type":"category","label":"8.3 Supervision des Processus","items":[{"type":"link","label":"8.3.1 Supervision du Raisonnement Externalis\xe9 (ERO)","href":"/chapters/08/03#01"},{"type":"link","label":"8.3.2 Clonage Proc\xe9dural","href":"/chapters/08/03#02"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/08/03"},{"type":"category","label":"8.4 Amplification It\xe9rative","items":[{"type":"link","label":"8.4.1 Amplification","href":"/chapters/08/04#01"},{"type":"link","label":"8.4.2 Distillation","href":"/chapters/08/04#02"},{"type":"link","label":"8.4.3 Distillation et Amplification It\xe9ratives (IDA)","href":"/chapters/08/04#03"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/08/04"},{"type":"category","label":"8.5 D\xe9bat","items":[{"type":"link","label":"8.5.1 Hypoth\xe8ses","href":"/chapters/08/05#01"},{"type":"link","label":"8.5.2 \xc9cart de Critique du Discriminateur (DCG)","href":"/chapters/08/05#02"},{"type":"link","label":"8.5.3 Juges","href":"/chapters/08/05#03"},{"type":"link","label":"8.5.4 V\xe9rit\xe9","href":"/chapters/08/05#04"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/08/05"},{"type":"category","label":"8.6 G\xe9n\xe9ralisation du Faible au Fort (W2SG)","items":[{"type":"link","label":"8.6.1 \xc9valuations en Sandwich","href":"/chapters/08/06#01"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/08/06"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/08/"},{"type":"category","label":"9. Interpr\xe9tabilit\xe9","items":[{"type":"category","label":"9.1 Qu\'est-ce que l\'Interpr\xe9tabilit\xe9 ?","items":[{"type":"link","label":"9.1.1 Interpr\xe9tabilit\xe9 M\xe9caniste","href":"/chapters/09/01#01"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/09/01"},{"type":"category","label":"9.2 M\xe9thodes Observationnelles","items":[{"type":"category","label":"9.2.1 Visualisation des Caract\xe9ristiques","items":[{"type":"link","label":"9.2.1.1 Circuits","href":"/chapters/09/02#01-01"},{"type":"link","label":"9.2.1.2 Neurones Polys\xe9mantiques","href":"/chapters/09/02#01-02"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/09/02#01"},{"type":"link","label":"9.2.2 Lentille Logit","href":"/chapters/09/02#02"},{"type":"link","label":"9.2.3 Classificateurs de Sondage","href":"/chapters/09/02#03"},{"type":"link","label":"9.2.4 Superposition","href":"/chapters/09/02#04"},{"type":"link","label":"9.2.5 Auto-encodeurs Parcimonieux","href":"/chapters/09/02#05"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/09/02"},{"type":"category","label":"9.3 M\xe9thodes Interventionnelles","items":[{"type":"link","label":"9.3.1 Correction d\'Activation","href":"/chapters/09/03#01"},{"type":"link","label":"9.3.2 Pilotage d\'Activation","href":"/chapters/09/03#02"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/09/03"},{"type":"category","label":"9.4 Automatisation et Mise \xe0 l\'\xc9chelle de l\'Interpr\xe9tabilit\xe9","items":[{"type":"link","label":"9.4.1 D\xe9couverte Automatique de Circuits (ACDC)","href":"/chapters/09/04#01"}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/09/04"},{"type":"link","label":"9.5 Critiques","href":"/fr/chapters/09/05","docId":"chapters/09/5","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/fr/chapters/09/"}]},"docs":{"chapters/01/1":{"id":"chapters/01/1","title":"L\'IA \xe0 la Pointe du Progr\xe8s","description":"Au cours de la derni\xe8re d\xe9cennie, le domaine de l\'intelligence artificielle (IA) a connu une transformation profonde, largement attribu\xe9e aux succ\xe8s de l\'apprentissage profond. Ces progr\xe8s remarquables ont red\xe9fini les limites des capacit\xe9s de l\'IA, remettant en question de nombreuses id\xe9es pr\xe9con\xe7ues sur ce que les machines peuvent accomplir. Les sections suivantes d\xe9taillent certaines de ces avanc\xe9es.","sidebar":"docs"},"chapters/01/2":{"id":"chapters/01/2","title":"Mod\xe8les de fondation","description":"Que sont les mod\xe8les de fondation ? Les mod\xe8les de fondation repr\xe9sentent un changement fondamental dans la fa\xe7on dont nous d\xe9veloppons l\'IA. Plut\xf4t que de construire des mod\xe8les sp\xe9cialis\xe9s pour de nombreuses petites t\xe2ches sp\xe9cifiques, nous pouvons maintenant entra\xeener des mod\xe8les \xe0 grande \xe9chelle qui servent de \\"fondation\\" pour de nombreuses applications diff\xe9rentes. Ces mod\xe8les sont ensuite sp\xe9cialis\xe9s par un processus appel\xe9 ajustement fin pour effectuer des t\xe2ches sp\xe9cifiques. Pensez-y comme \xe0 la fa\xe7on dont nous pouvons construire diff\xe9rents types de b\xe2timents en utilisant la m\xeame structure de base (Bommasani et al., 2022). Nous pouvons construire des banques, des restaurants ou des logements mais la fondation sous-jacente reste largement la m\xeame. C\'est juste une d\xe9finition intuitive tr\xe8s rapide. Nous entrerons plus dans les d\xe9tails dans les prochaines sous-sections sur l\'entra\xeenement, les propri\xe9t\xe9s et les risques.","sidebar":"docs"},"chapters/01/3":{"id":"chapters/01/3","title":"Intelligence","description":"\xc9tudes de cas","sidebar":"docs"},"chapters/01/4":{"id":"chapters/01/4","title":"Mise \xe0 l\'\xe9chelle","description":"Dans la section pr\xe9c\xe9dente, nous avons explor\xe9 comment nous pouvons mesurer les capacit\xe9s de l\'IA selon des dimensions continues de performance et de g\xe9n\xe9ralit\xe9. Maintenant, nous allons examiner l\'un des facteurs les plus importants \xe0 l\'origine des am\xe9liorations de ces capacit\xe9s : l\'\xe9chelle.","sidebar":"docs"},"chapters/01/5":{"id":"chapters/01/5","title":"Pr\xe9visions","description":"Dans les sections pr\xe9c\xe9dentes, nous avons explor\xe9 comment les mod\xe8les fondamentaux exploitent le calcul \xe0 travers les lois d\'\xe9chelle et la le\xe7on am\xe8re. Mais comment pouvons-nous r\xe9ellement pr\xe9dire vers o\xf9 se dirigent les capacit\xe9s de l\'IA ? Cette section pr\xe9sente les principales m\xe9thodologies de pr\xe9vision qui nous aident \xe0 anticiper les progr\xe8s de l\'IA et \xe0 pr\xe9parer des mesures de s\xe9curit\xe9 appropri\xe9es.","sidebar":"docs"},"chapters/01/6":{"id":"chapters/01/6","title":"D\xe9collage","description":"La vitesse de d\xe9collage fait r\xe9f\xe9rence \xe0 la rapidit\xe9 avec laquelle les syst\xe8mes d\'IA deviennent consid\xe9rablement plus puissants qu\'aujourd\'hui et provoquent des changements soci\xe9taux majeurs. Cela est li\xe9, mais distinct, des horizons temporels de l\'IA (le temps n\xe9cessaire pour d\xe9velopper une IA avanc\xe9e). Alors que les horizons temporels nous indiquent quand l\'IA transformative pourrait arriver, les vitesses de d\xe9collage nous disent ce qui se passe apr\xe8s son arriv\xe9e - est-ce que la capacit\xe9 et l\'impact de l\'IA augmentent progressivement sur des ann\xe9es, ou de mani\xe8re explosive sur des jours ou des semaines ?","sidebar":"docs"},"chapters/01/7":{"id":"chapters/01/7","title":"Annexe : D\xe9collage","description":"Continuit\xe9","sidebar":"docs"},"chapters/01/8":{"id":"chapters/01/8","title":"Annexe : Avis d\'experts","description":"Sondages","sidebar":"docs"},"chapters/01/9":{"id":"chapters/01/9","title":"Annexe : Discussion sur les LLMs","description":"Les LLMs actuels, bien qu\'entra\xeen\xe9s sur des donn\xe9es abondantes, sont encore loin d\'\xeatre parfaits.","sidebar":"docs"},"chapters/01/index":{"id":"chapters/01/index","title":"Capacit\xe9s","description":"Le domaine de l\'intelligence artificielle a connu une transformation remarquable ces derni\xe8res ann\xe9es, et ce n\'est peut-\xeatre que le d\xe9but. Ce chapitre pose les bases de l\'ensemble du livre en \xe9tablissant ce que les syst\xe8mes d\'IA peuvent faire actuellement, comment ils atteignent ces capacit\xe9s, et comment nous pouvons anticiper leur d\xe9veloppement futur. Cette compr\xe9hension est essentielle pour tous les chapitres suivants : la discussion sur les capacit\xe9s dangereuses et les risques potentiels (Chapitre 2) d\xe9coule directement de la compr\xe9hension des capacit\xe9s. De m\xeame, les solutions techniques propos\xe9es (Chapitre 3) et les solutions de gouvernance (Chapitre 4) doivent toutes deux tenir compte des capacit\xe9s actuelles et futures projet\xe9es de l\'IA.","sidebar":"docs"},"chapters/02/1":{"id":"chapters/02/1","title":"D\xe9composition du Risque","description":"Avant de commencer \xe0 parler de sc\xe9narios de risque concrets, nous avons besoin d\'un cadre qui nous permet d\'\xe9valuer o\xf9 ils se situent sur le spectre du risque. La classification des risques est intrins\xe8quement multidimensionnelle plut\xf4t que de chercher une seule \\"meilleure\\" cat\xe9gorisation. Nous avons choisi de d\xe9composer les risques en deux facteurs - \\"pourquoi les risques surviennent\\" (cause) et \\"quel degr\xe9 de gravit\xe9 peuvent atteindre les risques\\" (s\xe9v\xe9rit\xe9). D\'autres cadres compl\xe9mentaires comme la taxonomie des risques du MIT abordent des aspects comme \\"qui les cause\\" (humains vs syst\xe8mes d\'IA), \\"quand ils \xe9mergent\\" (d\xe9veloppement vs d\xe9ploiement), ou \\"si les r\xe9sultats sont intentionnels\\" (Slattery et al., 2024). Notre approche de d\xe9composition n\'est qu\'une parmi de nombreuses perspectives possibles, mais les risques dont nous parlerons ont tendance \xe0 \xeatre communs \xe0 travers celles-ci.","sidebar":"docs"},"chapters/02/2":{"id":"chapters/02/2","title":"Capacit\xe9s Dangereuses","description":"Dans le dernier chapitre, nous avons parl\xe9 de la notion g\xe9n\xe9rale de capacit\xe9s. Dans ce chapitre, nous voulons vous pr\xe9senter certaines capacit\xe9s dangereuses concr\xe8tes. Celles que nous pr\xe9sentons ici ne sont en aucun cas les seules capacit\xe9s dangereuses. Il existe de nombreuses autres capacit\xe9s potentiellement dangereuses comme la persuasion, la capacit\xe9 \xe0 g\xe9n\xe9rer des logiciels malveillants et ainsi de suite. Nous entrons beaucoup plus dans les d\xe9tails dans le chapitre sur les \xe9valuations.","sidebar":"docs"},"chapters/02/3":{"id":"chapters/02/3","title":"Risques d\'utilisation abusive","description":"Dans les sections suivantes, nous examinerons certains \xe9tats du monde qui, nous l\'esp\xe9rons, donnent une image un peu plus claire des risques li\xe9s \xe0 l\'IA. Bien que les sections aient \xe9t\xe9 divis\xe9es en mauvaise utilisation, d\xe9salignement et syst\xe9mique, il est important de se rappeler que cette division sert uniquement \xe0 des fins d\'explication. Il est tr\xe8s probable que le futur impliquera un m\xe9lange de risques \xe9mergeant de toutes ces cat\xe9gories.","sidebar":"docs"},"chapters/02/4":{"id":"chapters/02/4","title":"Risques de d\xe9salignement","description":"Supposons maintenant, pour les besoins de l\'argumentation, que les machines [intelligentes] sont une r\xe9elle possibilit\xe9, et examinons les cons\xe9quences de leur construction... Il ne serait pas question que les machines meurent, et elles pourraient converser entre elles pour aiguiser leur esprit. \xc0 un certain stade, nous devrions donc nous attendre \xe0 ce que les machines prennent le contr\xf4le.","sidebar":"docs"},"chapters/02/5":{"id":"chapters/02/5","title":"Risques syst\xe9miques","description":"Les risques syst\xe9miques \xe9mergent des interactions entre les syst\xe8mes d\'IA et la soci\xe9t\xe9, et non des d\xe9faillances individuelles d\'IA. Contrairement aux risques de mauvaise utilisation ou de d\xe9salignement qui se concentrent sur des syst\xe8mes d\'IA sp\xe9cifiques se comportant mal, les risques syst\xe9miques proviennent de la fa\xe7on dont plusieurs syst\xe8mes d\'IA - m\xeame lorsqu\'ils fonctionnent exactement comme pr\xe9vu - interagissent entre eux et avec les structures soci\xe9tales humaines comme les march\xe9s, les institutions d\xe9mocratiques et les r\xe9seaux sociaux. Ces risques sont parall\xe8les \xe0 ceux d\'autres domaines complexes : la crise financi\xe8re de 2008 n\'a pas \xe9t\xe9 caus\xe9e par la d\xe9cision d\'une seule banque mais est n\xe9e du comportement collectif de nombreuses institutions prenant des choix individuellement raisonnables qui, combin\xe9s, ont menac\xe9 l\'ensemble du syst\xe8me financier (Haldane and May, 2011).","sidebar":"docs"},"chapters/02/6":{"id":"chapters/02/6","title":"Amplificateurs de risque","description":"Les risques li\xe9s \xe0 l\'IA n\'existent pas de mani\xe8re isol\xe9e - ils sont amplifi\xe9s par la dynamique de comp\xe9tition et de coordination entourant le d\xe9veloppement de l\'IA. Bien que les syst\xe8mes d\'IA individuels puissent pr\xe9senter des risques g\xe9rables, l\'\xe9cosyst\xe8me plus large de la fa\xe7on dont ces syst\xe8mes sont d\xe9velopp\xe9s, d\xe9ploy\xe9s et gouvern\xe9s cr\xe9e des pressions syst\xe9miques qui peuvent augmenter consid\xe9rablement la probabilit\xe9 et la gravit\xe9 des cons\xe9quences n\xe9fastes. Ces facteurs d\'amplification op\xe8rent ind\xe9pendamment de toute capacit\xe9 ou mode de d\xe9faillance sp\xe9cifique de l\'IA, ce qui les rend particuli\xe8rement importants \xe0 comprendre et \xe0 traiter.","sidebar":"docs"},"chapters/02/7":{"id":"chapters/02/7","title":"Conclusion","description":"L\'att\xe9nuation du risque d\'extinction par l\'IA devrait \xeatre une priorit\xe9 mondiale au m\xeame titre que d\'autres risques \xe0 l\'\xe9chelle soci\xe9tale comme les pand\xe9mies et la guerre nucl\xe9aire.","sidebar":"docs"},"chapters/02/8":{"id":"chapters/02/8","title":"Annexe : Quantifier les risques existentiels","description":"P(doom) repr\xe9sente la probabilit\xe9 subjective que l\'intelligence artificielle causera des cons\xe9quences existentiellement catastrophiques pour l\'humanit\xe9. Le terme a \xe9volu\xe9 pour devenir une m\xe9trique s\xe9rieuse utilis\xe9e par les chercheurs, les d\xe9cideurs politiques et les leaders de l\'industrie pour exprimer leur \xe9valuation du risque existentiel li\xe9 \xe0 l\'IA. Les sc\xe9narios exacts englob\xe9s par \\"doom\\" varient mais incluent g\xe9n\xe9ralement l\'extinction humaine, la perte permanente de pouvoir de l\'humanit\xe9, ou l\'effondrement de la civilisation (Field, 2025).","sidebar":"docs"},"chapters/02/9":{"id":"chapters/02/9","title":"Annexe : Sc\xe9narios de pr\xe9vision","description":"Le Web de Production","sidebar":"docs"},"chapters/02/index":{"id":"chapters/02/index","title":"Risques","description":"Le chapitre pr\xe9c\xe9dent a explor\xe9 les capacit\xe9s en rapide progression de l\'IA \xe0 travers les lois d\'\xe9chelle, la le\xe7on am\xe8re et les sc\xe9narios potentiels de d\xe9collage. Nous avons vu comment plus de puissance de calcul, de donn\xe9es et d\'am\xe9liorations algorithmiques entra\xeenent des gains de capacit\xe9s constants dans tous les domaines. Mais pourquoi l\'augmentation des capacit\xe9s devrait-elle nous pr\xe9occuper ? La r\xe9ponse courte est que des syst\xe8mes d\'IA plus capables cr\xe9ent des risques \xe0 plus grande \xe9chelle.","sidebar":"docs"},"chapters/03/1":{"id":"chapters/03/1","title":"D\xe9finitions","description":"Les d\xe9finitions fa\xe7onnent la s\xe9lection de la strat\xe9gie. La fa\xe7on dont nous d\xe9finissons les probl\xe8mes impacte directement les strat\xe9gies que nous adoptons pour les r\xe9soudre. Dans un domaine nouveau et en \xe9volution comme la s\xe9curit\xe9 de l\'IA, des termes clairement d\xe9finis sont essentiels pour une communication et une recherche efficaces. L\'ambigu\xeft\xe9 m\xe8ne \xe0 des malentendus, entrave la collaboration, masque les d\xe9saccords et facilite l\'\xe9coblanchiment de la s\xe9curit\xe9 (Ren et al., 2024 ; Lizka, 2023). Les termes que nous utilisons refl\xe8tent nos hypoth\xe8ses sur la nature des probl\xe8mes que nous essayons de r\xe9soudre et fa\xe7onnent les solutions que nous d\xe9veloppons. Des termes comme \\"alignement\\" et \\"s\xe9curit\xe9\\" sont utilis\xe9s avec des significations variables, refl\xe9tant diff\xe9rentes hypoth\xe8ses sous-jacentes sur la nature du probl\xe8me et les objectifs de la recherche. L\'objectif de cette section est d\'expliquer les diff\xe9rentes perspectives autour de ces mots, ce que visent exactement les strat\xe9gies de s\xe9curit\xe9 sp\xe9cifiques, et d\'\xe9tablir comment notre texte les utilisera.","sidebar":"docs"},"chapters/03/10":{"id":"chapters/03/10","title":"Annexe : Exigences pour l\'alignement de l\'ASI","description":"L\'alignement de l\'ASI h\xe9rite de toutes les exigences de l\'AGI tout en introduisant des d\xe9fis fondamentalement plus difficiles. Un syst\xe8me superintelligent qui \xe9choue aux exigences basiques de robustesse, d\'\xe9volutivit\xe9, de faisabilit\xe9 ou d\'adoption serait catastrophiquement dangereux. Cependant, satisfaire ces exigences au niveau AGI devient n\xe9cessaire mais insuffisant pour la s\xe9curit\xe9 de l\'ASI. La diff\xe9rence fondamentale est que les syst\xe8mes superintelligents fonctionneront au-del\xe0 des capacit\xe9s humaines de compr\xe9hension et de supervision, cr\xe9ant des d\xe9fis de s\xe9curit\xe9 qualitativement diff\xe9rents.","sidebar":"docs"},"chapters/03/2":{"id":"chapters/03/2","title":"Strat\xe9gies de pr\xe9vention des abus","description":"Les strat\xe9gies pour pr\xe9venir les utilisations abusives se concentrent souvent sur le contr\xf4le de l\'acc\xe8s aux capacit\xe9s dangereuses ou la mise en \u0153uvre de mesures de protection techniques pour limiter les applications nuisibles.","sidebar":"docs"},"chapters/03/3":{"id":"chapters/03/3","title":"Strat\xe9gies de s\xe9curit\xe9 pour l\'AGI","description":"Contrairement \xe0 la mauvaise utilisation, o\xf9 l\'intention humaine est le moteur du pr\xe9judice, la s\xe9curit\xe9 de l\'AGI concerne principalement le comportement du syst\xe8me d\'IA lui-m\xeame. Les probl\xe8mes fondamentaux deviennent l\'alignement et le contr\xf4le : s\'assurer que ces syst\xe8mes tr\xe8s capables et potentiellement autonomes comprennent et poursuivent de mani\xe8re fiable des objectifs coh\xe9rents avec les valeurs et intentions humaines, plut\xf4t que de d\xe9velopper et d\'agir selon des objectifs mal align\xe9s qui pourraient conduire \xe0 des r\xe9sultats catastrophiques.","sidebar":"docs"},"chapters/03/4":{"id":"chapters/03/4","title":"Strat\xe9gies de s\xe9curit\xe9 pour l\'ASI","description":"La Superintelligence Artificielle (ASI) fait r\xe9f\xe9rence aux syst\xe8mes d\'IA qui d\xe9passent significativement les capacit\xe9s cognitives humaines dans pratiquement tous les domaines d\'int\xe9r\xeat. L\'\xe9mergence potentielle de l\'ASI pr\xe9sente des d\xe9fis de s\xe9curit\xe9 qui peuvent diff\xe9rer qualitativement de ceux pos\xe9s par l\'AGI. Les strat\xe9gies de s\xe9curit\xe9 pour l\'ASI impliquent souvent des programmes plus sp\xe9culatifs.","sidebar":"docs"},"chapters/03/5":{"id":"chapters/03/5","title":"Strat\xe9gies Syst\xe9miques","description":"La s\xe9curit\xe9 de l\'IA est un probl\xe8me socio-technique qui n\xe9cessite une solution socio-technique. Assurer la s\xe9curit\xe9 de l\'IA requiert \xe9galement des approches syst\xe9miques robustes. Celles-ci englobent les structures de gouvernance, les pratiques organisationnelles et les normes culturelles qui fa\xe7onnent le d\xe9veloppement et le d\xe9ploiement de l\'IA. Les mesures de s\xe9curit\xe9 techniques peuvent \xeatre compromises par une gouvernance inad\xe9quate, de mauvaises pratiques de s\xe9curit\xe9 au sein des laboratoires, ou une culture qui privil\xe9gie la vitesse plut\xf4t que la prudence. Cette section examine les strat\xe9gies visant \xe0 int\xe9grer la s\xe9curit\xe9 dans l\'\xe9cosyst\xe8me plus large entourant l\'IA.","sidebar":"docs"},"chapters/03/6":{"id":"chapters/03/6","title":"Combinaison des strat\xe9gies","description":"L\'interaction exacte des strat\xe9gies est discutable, mais cette section d\xe9crit une s\xe9quence plausible de d\xe9pendances.","sidebar":"docs"},"chapters/03/7":{"id":"chapters/03/7","title":"D\xe9fis","description":"Le d\xe9veloppement de strat\xe9gies pour assurer la s\xe9curit\xe9 des syst\xe8mes d\'IA de plus en plus performants pr\xe9sente des d\xe9fis uniques et importants. Ces difficult\xe9s d\xe9coulent de la nature m\xeame de l\'IA, de l\'\xe9tat actuel du domaine de recherche et de la complexit\xe9 des risques impliqu\xe9s.","sidebar":"docs"},"chapters/03/8":{"id":"chapters/03/8","title":"Conclusion","description":"Le paysage strat\xe9gique pour assurer la s\xe9curit\xe9 de l\'IA est vaste, complexe et en \xe9volution rapide. Il couvre un large spectre, allant du contr\xf4le d\'acc\xe8s aux mod\xe8les actuels pour pr\xe9venir les abus, en passant par les d\xe9fis techniques complexes d\'alignement de l\'AGI, jusqu\'aux man\u0153uvres g\xe9opolitiques sp\xe9culatives et aux consid\xe9rations philosophiques concernant l\'ASI.","sidebar":"docs"},"chapters/03/9":{"id":"chapters/03/9","title":"Annexe : Questions \xe0 long terme","description":"Alignement avec quoi ?","sidebar":"docs"},"chapters/03/index":{"id":"chapters/03/index","title":"Strat\xe9gies","description":"Ce chapitre tente d\'exposer la vue d\'ensemble de la strat\xe9gie de s\xe9curit\xe9 de l\'IA pour att\xe9nuer les risques explor\xe9s dans le chapitre pr\xe9c\xe9dent.","sidebar":"docs"},"chapters/04/1":{"id":"chapters/04/1","title":"Gouvernance du calcul","description":"Le calcul est une cible de gouvernance puissante car il r\xe9pond aux trois crit\xe8res des cibles de gouvernance efficaces :","sidebar":"docs"},"chapters/04/2":{"id":"chapters/04/2","title":"D\xe9fis Syst\xe9miques","description":"Dynamiques de course","sidebar":"docs"},"chapters/04/3":{"id":"chapters/04/3","title":"Architectures de gouvernance","description":"La gouvernance de l\'IA fronti\xe8re ne peut \xeatre confi\xe9e \xe0 une seule institution ou niveau d\'autorit\xe9. Les entreprises manquent d\'incitations pour pleinement tenir compte des impacts soci\xe9taux, les nations sont en comp\xe9tition pour l\'avantage technologique, et les organismes internationaux peinent \xe0 faire respecter les r\xe8gles. Chaque niveau de gouvernance \u2013 entreprise, national et international \u2013 apporte des forces uniques et fait face \xe0 des limitations distinctes. Comprendre comment ces niveaux interagissent et se renforcent mutuellement est important pour construire des syst\xe8mes de gouvernance efficaces de l\'IA.","sidebar":"docs"},"chapters/04/4":{"id":"chapters/04/4","title":"Mise en \u0153uvre","description":"Normes de s\xe9curit\xe9 de l\'IA","sidebar":"docs"},"chapters/04/5":{"id":"chapters/04/5","title":"Conclusion","description":"Les cadres de gouvernance examin\xe9s tout au long de ce chapitre fournissent des outils essentiels pour g\xe9rer les risques li\xe9s \xe0 l\'IA, mais les outils seuls ne d\xe9terminent pas les r\xe9sultats. Le succ\xe8s n\xe9cessite de choisir les bonnes priorit\xe9s, de d\xe9velopper les capacit\xe9s n\xe9cessaires et de maintenir des cadres qui \xe9voluent avec la technologie.","sidebar":"docs"},"chapters/04/6":{"id":"chapters/04/6","title":"Annexe : Gouvernance des donn\xe9es","description":"Quel r\xf4le jouent les donn\xe9es dans les risques li\xe9s \xe0 l\'IA ? Les donn\xe9es fa\xe7onnent fondamentalement ce que les syst\xe8mes d\'IA peuvent faire et comment ils se comportent. Pour les mod\xe8les de fondation avanc\xe9s, les donn\xe9es d\'entra\xeenement influencent \xe0 la fois les capacit\xe9s et l\'alignement - ce que les syst\xe8mes peuvent faire et comment ils le font. Des donn\xe9es d\'entra\xeenement de mauvaise qualit\xe9 ou nuisibles pourraient conduire \xe0 des mod\xe8les mal align\xe9s ou dangereux (\\"les d\xe9chets entrants produisent des d\xe9chets sortants\\"), tandis que des ensembles de donn\xe9es soigneusement organis\xe9s pourraient favoriser un comportement plus s\xfbr et plus fiable (Longpre et al., 2024; Marcucci et al., 2023).","sidebar":"docs"},"chapters/04/7":{"id":"chapters/04/7","title":"Annexe : Gouvernance nationale","description":"Un r\xe9gime de gouvernance nationale complet pour la s\xe9curit\xe9 de l\'IA n\xe9cessite trois m\xe9canismes interconnect\xe9s :","sidebar":"docs"},"chapters/04/index":{"id":"chapters/04/index","title":"Gouvernance","description":"Des risques substantiels peuvent d\xe9couler d\'une mauvaise utilisation intentionnelle ou de probl\xe8mes involontaires de contr\xf4le li\xe9s \xe0 l\'alignement avec l\'intention humaine. Ces probl\xe8mes sont en partie dus au fait que ces capacit\xe9s ne sont pas enti\xe8rement comprises [...] Il existe un potentiel de pr\xe9judice grave, voire catastrophique, d\xe9lib\xe9r\xe9 ou non intentionnel, d\xe9coulant des capacit\xe9s les plus significatives de ces mod\xe8les d\'IA.","sidebar":"docs"},"chapters/05/1":{"id":"chapters/05/1","title":"R\xe9f\xe9rences","description":"Qu\'est-ce qu\'une \xe9valuation comparative ? Imaginez essayer de construire un pont sans m\xe8tre ruban. Avant les unit\xe9s standardis\xe9es comme les m\xe8tres et les grammes, diff\xe9rentes r\xe9gions utilisaient leurs propres mesures locales. Au-del\xe0 de rendre l\'ing\xe9nierie inefficace - cela la rendait aussi dangereuse. M\xeame si un pays d\xe9veloppait une conception de pont s\xfbre, sp\xe9cifier les mesures en \\"trois coud\xe9es royales\\" de mat\xe9riau signifiait que les constructeurs d\'autres pays ne pouvaient pas reproduire cette s\xe9curit\xe9 de mani\xe8re fiable. Une poutre de soutien l\xe9g\xe8rement trop courte ou un c\xe2ble trop fin pouvait conduire \xe0 une d\xe9faillance catastrophique.","sidebar":"docs"},"chapters/05/10":{"id":"chapters/05/10","title":"Conclusion","description":"L\'avenir de la s\xe9curit\xe9 de l\'IA d\xe9pend consid\xe9rablement de notre capacit\xe9 \xe0 mesurer et \xe0 v\xe9rifier avec pr\xe9cision les propri\xe9t\xe9s de syst\xe8mes de plus en plus puissants. \xc0 mesure que les mod\xe8les approchent des capacit\xe9s potentiellement transformatrices dans des domaines comme la cybers\xe9curit\xe9, le fonctionnement autonome et la planification strat\xe9gique, les enjeux des \xe9checs d\'\xe9valuation croissent de fa\xe7on exponentielle. En continuant \xe0 affiner nos approches d\'\xe9valuation\u2014en combinant les techniques comportementales et internes, en relevant les d\xe9fis d\'\xe9chelle gr\xe2ce \xe0 des m\xe9thodes automatis\xe9es, et en \xe9tablissant des dispositifs institutionnels pour une \xe9valuation v\xe9ritablement ind\xe9pendante\u2014nous pouvons contribuer \xe0 garantir que le d\xe9veloppement de l\'IA progresse dans une direction qui reste b\xe9n\xe9fique, contr\xf4lable et align\xe9e sur les valeurs humaines. Le d\xe9veloppement de m\xe9thodes d\'\xe9valuation robustes repr\xe9sente l\'un de nos outils les plus importants pour naviguer entre l\'exploitation des avantages de l\'IA et l\'att\xe9nuation de ses risques les plus graves.","sidebar":"docs"},"chapters/05/2":{"id":"chapters/05/2","title":"Propri\xe9t\xe9s \xe9valu\xe9es","description":"Une \\"\xe9valuation\\" consiste fondamentalement \xe0 mesurer ou \xe0 \xe9valuer une propri\xe9t\xe9 d\'un syst\xe8me d\'IA. Les aspects cl\xe9s qui distinguent une \xe9valuation d\'autres travaux sur l\'IA sont :","sidebar":"docs"},"chapters/05/3":{"id":"chapters/05/3","title":"Techniques d\'\xe9valuation","description":"Dans la section pr\xe9c\xe9dente, nous avons parl\xe9 des propri\xe9t\xe9s sp\xe9cifiques des syst\xe8mes d\'IA auxquelles nous pr\xeatons attention dans nos \xe9valuations - leurs capacit\xe9s, leurs propensions et notre capacit\xe9 \xe0 maintenir le contr\xf4le sur le syst\xe8me. La prochaine chose \xe0 aborder est comment mesurer r\xe9ellement ces propri\xe9t\xe9s ? C\'est ce que nous explorons dans cette section - Les techniques d\'\xe9valuation, qui sont les approches syst\xe9matiques que nous pouvons adopter pour recueillir et analyser des preuves sur les syst\xe8mes d\'IA.","sidebar":"docs"},"chapters/05/4":{"id":"chapters/05/4","title":"Cadres d\'\xe9valuation","description":"Techniques d\'\xe9valuation vs. Cadres d\'\xe9valuation. Lors de l\'\xe9valuation des syst\xe8mes d\'IA, les techniques individuelles sont comme des outils dans une bo\xeete \xe0 outils - utiles pour des t\xe2ches sp\xe9cifiques mais plus puissantes lorsqu\'elles sont combin\xe9es syst\xe9matiquement. C\'est l\xe0 qu\'interviennent les cadres d\'\xe9valuation. Alors que les techniques sont des m\xe9thodes sp\xe9cifiques d\'\xe9tude des syst\xe8mes d\'IA (comme l\'incitation \xe0 la cha\xeene de pens\xe9e ou l\'analyse des mod\xe8les d\'activation interne), les cadres fournissent des approches structur\xe9es pour combiner ces techniques afin de r\xe9pondre \xe0 des questions plus larges sur les syst\xe8mes d\'IA. Par exemple, nous pourrions utiliser des techniques comportementales comme le red teaming pour d\xe9tecter des r\xe9sultats trompeurs, des techniques internes comme l\'analyse des circuits pour comprendre comment la tromperie est mise en \u0153uvre, et combiner celles-ci dans un cadre d\'organisme mod\xe8le sp\xe9cifiquement con\xe7u pour cr\xe9er un \xe9chantillon de tromperie d\'IA. Chaque niveau - technique, type d\'analyse et cadre - joue un r\xf4le diff\xe9rent dans la construction de la compr\xe9hension et de la s\xe9curit\xe9.","sidebar":"docs"},"chapters/05/5":{"id":"chapters/05/5","title":"\xc9valuations des Capacit\xe9s Dangereuses","description":"\xc9valuation du potentiel maximal. Les \xe9valuations des capacit\xe9s dangereuses visent \xe0 \xe9tablir les limites sup\xe9rieures de ce qu\'un syst\xe8me d\'IA peut accomplir. Contrairement aux m\xe9triques de performance typiques qui mesurent le comportement moyen, les \xe9valuations des capacit\xe9s sondent sp\xe9cifiquement la capacit\xe9 maximale - ce que le syst\xe8me pourrait faire s\'il donnait son maximum. Cette distinction est cruciale pour l\'\xe9valuation de la s\xe9curit\xe9, car comprendre l\'\xe9tendue compl\xe8te des capacit\xe9s d\'un syst\xe8me aide \xe0 identifier les risques potentiels.","sidebar":"docs"},"chapters/05/6":{"id":"chapters/05/6","title":"\xc9valuations des Propensions Dangereuses","description":"Nous avons pr\xe9sent\xe9 les bases des \xe9valuations de propension dans la section sur les propri\xe9t\xe9s \xe9valu\xe9es. Cette section s\'appuiera sur cet aper\xe7u et explorera des propensions sp\xe9cifiques comme la recherche du pouvoir ou la tromperie, et examinera comment nous pourrions concevoir des \xe9valuations autour d\'elles.","sidebar":"docs"},"chapters/05/7":{"id":"chapters/05/7","title":"\xc9valuations de contr\xf4le","description":"Nous avons d\xe9j\xe0 expliqu\xe9 l\'intuition fondamentale derri\xe8re l\'agenda du contr\xf4le de l\'IA dans les sections pr\xe9c\xe9dentes et dans les chapitres pr\xe9c\xe9dents comme Strat\xe9gies. Cette section vise \xe0 approfondir sp\xe9cifiquement les \xe9valuations que nous pourrions concevoir en suivant la ligne de pens\xe9e du contr\xf4le.","sidebar":"docs"},"chapters/05/8":{"id":"chapters/05/8","title":"Conception de l\'\xe9valuation","description":"Maintenant que nous avons explor\xe9 diverses techniques et m\xe9thodologies d\'\xe9valuation, ainsi que des \xe9valuations concr\xe8tes dans diff\xe9rentes cat\xe9gories de capacit\xe9, de propension et de contr\xf4le, il faut comprendre comment les mettre en \u0153uvre efficacement \xe0 grande \xe9chelle. L\'objectif de cette section est de pr\xe9senter les meilleures pratiques pour construire une infrastructure d\'\xe9valuation robuste - de la conception des protocoles d\'\xe9valuation et des processus d\'assurance qualit\xe9, \xe0 l\'automatisation \xe0 grande \xe9chelle et l\'int\xe9gration dans l\'\xe9cosyst\xe8me plus large de la s\xe9curit\xe9 de l\'IA. Nous verrons comment les composants tels que la conception de l\'\xe9valuation, les \xe9valuations r\xe9dig\xe9es par les mod\xe8les et les m\xe9thodes de m\xe9ta-\xe9valuation fonctionnent ensemble pour rendre les IA plus s\xfbres.","sidebar":"docs"},"chapters/05/9":{"id":"chapters/05/9","title":"Limites","description":"Les sections pr\xe9c\xe9dentes ont d\xe9crit diverses techniques et m\xe9thodologies d\'\xe9valuation, mais la mise en place d\'une infrastructure de s\xe9curit\xe9 appropri\xe9e signifie que nous devons \xe9galement maintenir un niveau de scepticisme appropri\xe9 concernant les r\xe9sultats des \xe9valuations et \xe9viter un exc\xe8s de confiance dans les \xe9valuations de s\xe9curit\xe9. Ainsi, la derni\xe8re section de ce chapitre est consacr\xe9e \xe0 l\'exploration des limitations, des contraintes et des d\xe9fis li\xe9s aux \xe9valuations de l\'IA.","sidebar":"docs"},"chapters/05/index":{"id":"chapters/05/index","title":"\xc9valuations","description":"Lorsque vous pouvez mesurer ce dont vous parlez et l\'exprimer en chiffres, vous en savez quelque chose ; lorsque vous ne pouvez pas l\'exprimer en chiffres, votre connaissance est maigre et insatisfaisante ; ce peut \xeatre le d\xe9but de la connaissance, mais vous n\'avez gu\xe8re, dans votre r\xe9flexion, atteint le stade de la science.","sidebar":"docs"},"chapters/06/1":{"id":"chapters/06/1","title":"Apprentissage par renforcement","description":"Cette section fournit un rappel succinct de plusieurs concepts de l\'apprentissage par renforcement (RL). Elle permet \xe9galement de dissiper la confusion entre diff\xe9rents termes souvent confondus tels que les r\xe9compenses, les valeurs et les utilit\xe9s. La section se termine par une discussion sur la distinction entre le concept d\'objectifs qu\'un syst\xe8me d\'apprentissage par renforcement pourrait poursuivre et ce pour quoi il est r\xe9compens\xe9.","sidebar":"docs"},"chapters/06/2":{"id":"chapters/06/2","title":"Optimisation","description":"L\'optimisation est importante \xe0 comprendre pour les questions de s\xe9curit\xe9 de l\'IA car elle joue un r\xf4le central dans l\'apprentissage automatique. Les syst\xe8mes d\'IA, en particulier ceux bas\xe9s sur l\'apprentissage profond, sont entra\xeen\xe9s \xe0 l\'aide d\'algorithmes d\'optimisation pour apprendre des mod\xe8les et des associations \xe0 partir des donn\xe9es. Ces algorithmes mettent \xe0 jour les param\xe8tres du mod\xe8le pour minimiser une fonction de perte, maximisant ainsi ses performances sur la t\xe2che donn\xe9e.","sidebar":"docs"},"chapters/06/3":{"id":"chapters/06/3","title":"Contournement des Sp\xe9cifications","description":"La mauvaise sp\xe9cification de la r\xe9compense, \xe9galement appel\xe9e probl\xe8me d\'alignement externe, fait r\xe9f\xe9rence \xe0 la difficult\xe9 de fournir \xe0 l\'IA la r\xe9compense exacte \xe0 optimiser.","sidebar":"docs"},"chapters/06/4":{"id":"chapters/06/4","title":"Apprendre par imitation","description":"Les sections pr\xe9c\xe9dentes ont soulign\xe9 l\'importance de la mauvaise sp\xe9cification de la r\xe9compense pour l\'alignement de l\'intelligence artificielle future. Les prochaines sections exploreront diverses tentatives et propositions formul\xe9es pour r\xe9soudre ce probl\xe8me, en commen\xe7ant par une approche intuitive \u2013 apprendre la fonction de r\xe9compense appropri\xe9e par l\'observation et l\'imitation du comportement humain, plut\xf4t que par une cr\xe9ation manuelle par les concepteurs.","sidebar":"docs"},"chapters/06/5":{"id":"chapters/06/5","title":"Apprendre des retours","description":"Cette section aborde d\'autres tentatives pour r\xe9soudre le probl\xe8me de la mauvaise sp\xe9cification de la r\xe9compense. Parfois, le comportement souhait\xe9 est si complexe que l\'apprentissage par d\xe9monstration devient impossible. Une approche alternative consiste \xe0 offrir des retours \xe0 l\'agent plut\xf4t que de fournir des fonctions de r\xe9compense sp\xe9cifi\xe9es manuellement ou m\xeame des d\xe9monstrations d\'experts. Cette section explore les strat\xe9gies bas\xe9es sur les retours telles que la Mod\xe9lisation de R\xe9compense, l\'Apprentissage par Renforcement \xe0 partir des Retours Humains (RLHF) et l\'Apprentissage par Renforcement \xe0 partir des Retours d\'IA (RLAIF), \xe9galement connu sous le nom d\'Apprentissage par Renforcement \xe0 partir de l\'IA Constitutionnelle (RLCAI) ou simplement IA Constitutionnelle.","sidebar":"docs"},"chapters/06/index":{"id":"chapters/06/index","title":"Mauvaise sp\xe9cification","description":"Apprentissage par renforcement : Le chapitre commence par un rappel de certains concepts d\'apprentissage par renforcement. Cela inclut un aper\xe7u rapide du concept de r\xe9compenses et des fonctions de r\xe9compense. Cette section pose les bases pour expliquer pourquoi la conception des r\xe9compenses est extr\xeamement importante.","sidebar":"docs"},"chapters/07/1":{"id":"chapters/07/1","title":"Dynamique d\'apprentissage","description":"Une compr\xe9hension plus approfondie de la surg\xe9n\xe9ralisation des objectifs n\xe9cessite d\'examiner comment fonctionne r\xe9ellement le processus d\'entra\xeenement en apprentissage automatique. Lorsque nous entra\xeenons des r\xe9seaux de neurones, nous ajustons des millions ou des milliards de param\xe8tres. Mais que repr\xe9sentent ces param\xe8tres ? La meilleure fa\xe7on de concevoir l\'apprentissage automatique est de le voir comme un processus de recherche dans un vaste espace d\'algorithmes possibles (parfois aussi appel\xe9 recherche dans l\'espace des hypoth\xe8ses ou l\'espace des mod\xe8les). Chaque combinaison sp\xe9cifique de valeurs de param\xe8tres correspond \xe0 un algorithme diff\xe9rent pour traiter l\'information et prendre des d\xe9cisions. Le chemin que prend cette recherche - et les biais qui la guident - d\xe9terminent quels types d\'algorithmes sont d\xe9couverts et s\'ils poursuivent les objectifs pr\xe9vus ou simplement des indicateurs corr\xe9l\xe9s. Les intuitions que vous apprendrez dans cette section vous aideront \xe9norm\xe9ment dans ce chapitre, mais aussi dans les chapitres ult\xe9rieurs sur l\'interpr\xe9tabilit\xe9.","sidebar":"docs"},"chapters/07/2":{"id":"chapters/07/2","title":"Directionnalit\xe9 des Objectifs","description":"Les syst\xe8mes d\'apprentissage automatique peuvent \xe9voluer au-del\xe0 de la simple reconnaissance de motifs pour poursuivre syst\xe9matiquement des objectifs dans divers contextes et face \xe0 diff\xe9rents obstacles. Les sections pr\xe9c\xe9dentes ont abord\xe9 deux points - nous pouvons avoir des algorithmes comportementalement indiscernables avec diff\xe9rents m\xe9canismes internes \xe0 la fin de l\'entra\xeenement ; nous pouvons avoir des syst\xe8mes qui sont extr\xeamement capables mais dont les objectifs ne sont pas ceux que nous avions pr\xe9vus. Dans cette section, nous examinons ce qui se passe lorsque ces algorithmes appris deviennent fortement orient\xe9s vers des objectifs, le cas extr\xeame \xe9tant l\'impl\xe9mentation de l\'optimisation apprise (m\xe9sa-optimisation). Cette section examine les diff\xe9rentes fa\xe7ons dont un comportement syst\xe9matique potentiellement d\xe9salign\xe9 et orient\xe9 vers un objectif peut \xe9merger.","sidebar":"docs"},"chapters/07/3":{"id":"chapters/07/3","title":"Manigances","description":"La manigance \xe9merge lorsque les syst\xe8mes orient\xe9s vers un but font face \xe0 un choix strat\xe9gique in\xe9vitable concernant la r\xe9v\xe9lation de leurs v\xe9ritables objectifs. Lorsqu\'un syst\xe8me poursuit syst\xe9matiquement des objectifs et d\xe9veloppe une conscience de son processus d\'entra\xeenement, il reconna\xeet que l\'affichage de certains objectifs d\xe9clencherait des tentatives de modification. Cela cr\xe9e un dilemme fondamental : r\xe9v\xe9ler honn\xeatement les objectifs et accepter la modification, ou les dissimuler strat\xe9giquement tout en paraissant align\xe9. Le syst\xe8me doit choisir entre la transparence et la pr\xe9servation des objectifs.","sidebar":"docs"},"chapters/07/4":{"id":"chapters/07/4","title":"D\xe9tection","description":"La d\xe9tection de la surg\xe9n\xe9ralisation des objectifs cr\xe9e des d\xe9fis uniques qui la distinguent des autres probl\xe8mes d\'alignement. La difficult\xe9 principale est que la surg\xe9n\xe9ralisation des objectifs ressemble souvent \xe0 un succ\xe8s jusqu\'\xe0 ce que la distribution change suffisamment pour r\xe9v\xe9ler le proxy. L\'indiscernabilit\xe9 comportementale pendant l\'entra\xeenement signifie qu\'il n\'y a pas de signal d\'\xe9chec \xe9vident \xe0 d\xe9tecter. Cela la rend fondamentalement diff\xe9rente des \xe9checs de capacit\xe9 ou des probl\xe8mes de sp\xe9cification, o\xf9 nous pouvons souvent rep\xe9rer les probl\xe8mes \xe0 travers de mauvaises performances ou une mauvaise interpr\xe9tation \xe9vidente des instructions.","sidebar":"docs"},"chapters/07/index":{"id":"chapters/07/index","title":"G\xe9n\xe9ralisation","description":"CoinRun - un exemple facile \xe0 comprendre de la mauvaise g\xe9n\xe9ralisation d\'objectif. Dans ce jeu, les agents apparaissent du c\xf4t\xe9 gauche du niveau, \xe9vitent les ennemis et les obstacles, et collectent la pi\xe8ce pour une r\xe9compense de 10 points. Le mod\xe8le est entra\xeen\xe9 sur des milliers de niveaux g\xe9n\xe9r\xe9s de mani\xe8re proc\xe9durale, chacun avec diff\xe9rentes dispositions de plateformes, d\'ennemis et de dangers. \xc0 la fin de l\'entra\xeenement, les agents sont tr\xe8s comp\xe9tents. Ils peuvent esquiver les ennemis en mouvement, synchroniser les sauts au-dessus des fosses de lave, et traverser efficacement des niveaux complexes qu\'ils n\'ont jamais vus auparavant (Langosco et al., 2022). L\'entra\xeenement semble \xeatre tr\xe8s r\xe9ussi. Les agents obtiennent des r\xe9compenses \xe9lev\xe9es de mani\xe8re constante dans divers environnements de test. Mais lorsque les pi\xe8ces sont d\xe9plac\xe9es vers des emplacements al\xe9atoires pendant les tests, les agents restent tr\xe8s capables de navigation, mais ils ignorent syst\xe9matiquement les pi\xe8ces qui \xe9taient clairement visibles et continuent simplement \xe0 se d\xe9placer vers la droite vers des murs vides.","sidebar":"docs"},"chapters/08/1":{"id":"chapters/08/1","title":"Supervision","description":"Pourquoi avons-nous besoin de supervision ? \xc0 mesure que les syst\xe8mes d\'IA deviennent plus intelligents, ils commenceront \xe0 effectuer des t\xe2ches difficiles \xe0 \xe9valuer pour les humains. L\'\xe9valuation consiste \xe0 v\xe9rifier la performance de l\'IA apr\xe8s l\'accomplissement d\'une t\xe2che, tandis que le retour est l\'information que nous donnons \xe0 l\'IA pendant ou apr\xe8s son travail pour l\'aider \xe0 apprendre et s\'am\xe9liorer. Actuellement, nous pouvons encore utiliser des m\xe9thodes comme l\'Apprentissage par Renforcement \xe0 partir de Retours Humains (RLHF) pour guider l\'IA dans la bonne direction. Mais nous ne pouvons donner des retours que si nous pouvons encore \xe9valuer les r\xe9sultats. \xc0 mesure que les t\xe2ches deviennent plus complexes, m\xeame les experts pourraient avoir du mal \xe0 fournir des \xe9valuations et des retours pr\xe9cis. Nous avons donc besoin de nouvelles fa\xe7ons de donner des retours pr\xe9cis, m\xeame pour les t\xe2ches qui d\xe9passent l\'expertise humaine. C\'est l\'objectif de la supervision \xe9volutive.","sidebar":"docs"},"chapters/08/2":{"id":"chapters/08/2","title":"D\xe9composition des t\xe2ches","description":"Qu\'est-ce que la d\xe9composition des t\xe2ches ? La d\xe9composition des t\xe2ches est le processus qui consiste \xe0 diviser une t\xe2che complexe en sous-t\xe2ches plus petites et plus g\xe9rables. Cette technique permet d\'aborder des probl\xe8mes sophistiqu\xe9s en les divisant en composants plus simples qui peuvent \xeatre trait\xe9s ind\xe9pendamment. Par exemple, si vous devez r\xe9sumer un livre, vous pourriez d\xe9composer cette t\xe2che plus importante en r\xe9sumant chaque chapitre individuellement. Chaque r\xe9sum\xe9 de chapitre contribue alors au r\xe9sum\xe9 global du livre.","sidebar":"docs"},"chapters/08/3":{"id":"chapters/08/3","title":"Supervision des processus","description":"L\'apprentissage d\'une nouvelle t\xe2che peut se faire par essais et erreurs, appel\xe9 apprentissage orient\xe9 r\xe9sultat, o\xf9 la strat\xe9gie de l\'agent est enti\xe8rement d\xe9termin\xe9e par le r\xe9sultat souhait\xe9.","sidebar":"docs"},"chapters/08/4":{"id":"chapters/08/4","title":"Amplification It\xe9r\xe9e","description":"Dans les sections pr\xe9c\xe9dentes, nous avons discut\xe9 des m\xe9thodes pour d\xe9composer les t\xe2ches et potentiellement \xe9muler la prise de d\xe9cision humaine en d\xe9composant la cognition en composants plus petits. Dans cette section, nous expliquerons l\'une des principales motivations pour vouloir d\xe9composer les t\xe2ches en premier lieu - amplifier les capacit\xe9s des superviseurs. Nous voulons am\xe9liorer (amplifier) les capacit\xe9s des humains ou de l\'IA pour g\xe9n\xe9rer de meilleurs signaux d\'entra\xeenement afin d\'aider \xe0 aligner it\xe9rativement l\'IA.","sidebar":"docs"},"chapters/08/5":{"id":"chapters/08/5","title":"D\xe9bat","description":"S\'assurer que les syst\xe8mes d\'IA \\"nous disent honn\xeatement tout ce qu\'ils savent\\" est crucial pour l\'alignement. Cela signifie que si un mod\xe8le recommande un plan bas\xe9 sur certaines cons\xe9quences, il doit \xe9galement communiquer ces cons\xe9quences. C\'est un d\xe9fi car les structures d\'incitation bas\xe9es sur les retours pourraient r\xe9compenser des r\xe9ponses plausibles plut\xf4t que v\xe9ritablement pr\xe9cises. Alors comment obtenir des mod\xe8les qu\'ils nous disent tout ce qu\'ils peuvent sur leur raisonnement bien r\xe9fl\xe9chi et les cons\xe9quences de toutes leurs sorties ? Nous voulons \xe9viter les situations o\xf9 le mod\xe8le conna\xeet les cons\xe9quences d\'une action mais retient l\'information parce qu\'il sait que les humains n\'aimeront pas ces cons\xe9quences.","sidebar":"docs"},"chapters/08/6":{"id":"chapters/08/6","title":"La g\xe9n\xe9ralisation du faible au fort (W2SG)","description":"Historiquement, une grande partie du travail sur l\'alignement de l\'IA a \xe9t\xe9 hautement th\xe9orique, se concentrant sur les aspects fondamentaux du comportement des agents, l\'alignement interne et les risques li\xe9s \xe0 l\'optimisation apprise. M\xeame les techniques dont nous avons parl\xe9 dans les sections pr\xe9c\xe9dentes comme le d\xe9bat ou l\'IDA sont souvent critiqu\xe9es comme \xe9tant des cadres plut\xf4t que des solutions pratiques, ou fonctionnant principalement sur des probl\xe8mes simples sans aborder le d\xe9fi central de l\'alignement d\'une IA superintelligente dans des sc\xe9narios r\xe9els. Donc m\xeame si nous ne pouvons conduire des exp\xe9riences de s\xe9curit\xe9 que sur les mod\xe8les actuels, comment pouvons-nous \xeatre s\xfbrs que ces techniques resteront efficaces lorsque les IA approcheront des capacit\xe9s surhumaines ?","sidebar":"docs"},"chapters/08/index":{"id":"chapters/08/index","title":"Supervision \xe0 Grande \xc9chelle","description":"Supervision. \xc0 mesure que les syst\xe8mes d\'IA deviennent de plus en plus performants, s\'assurer qu\'ils restent align\xe9s avec les valeurs et les intentions humaines devient un d\xe9fi crucial. Cette section pr\xe9sente la supervision \xe9volutive comme une approche essentielle pour maintenir le contr\xf4le sur l\'IA avanc\xe9e. Elle explique les probl\xe8mes auxquels nous sommes confront\xe9s dans la g\xe9n\xe9ration de signaux d\'entra\xeenement pour des t\xe2ches complexes et \\"floues\\" et la n\xe9cessit\xe9 de nouvelles m\xe9thodes pour fournir des retours pr\xe9cis. Ceci est particuli\xe8rement important alors que les mod\xe8les d\'IA commencent \xe0 effectuer des t\xe2ches d\xe9passant l\'expertise humaine. La section explore \xe9galement le concept de la v\xe9rification \xe9tant plus simple que la g\xe9n\xe9ration, expliquant pourquoi cette propri\xe9t\xe9 est fondamentale pour les techniques de supervision \xe9volutive.","sidebar":"docs"},"chapters/09/1":{"id":"chapters/09/1","title":"Qu\'est-ce que l\'Interpr\xe9tabilit\xe9 ?","description":"L\'interpr\xe9tabilit\xe9 est l\'\xe9tude de la fa\xe7on dont les mod\xe8les d\'IA prennent des d\xe9cisions et des raisons qui les motivent. Son objectif principal est de comprendre le fonctionnement interne des mod\xe8les et les processus qui sous-tendent leurs d\xe9cisions. Il existe diverses approches de l\'interpr\xe9tabilit\xe9, mais dans ce chapitre\u2014et dans le contexte plus large de la s\xe9curit\xe9 de l\'IA\u2014l\'interpr\xe9tabilit\xe9 m\xe9caniste (mech interp) est le point central (Ras et al., 2020, Ali et al., 2023).","sidebar":"docs"},"chapters/09/2":{"id":"chapters/09/2","title":"M\xe9thodes d\'observation","description":"Visualisation des caract\xe9ristiques","sidebar":"docs"},"chapters/09/3":{"id":"chapters/09/3","title":"M\xe9thodes d\'intervention","description":"Activation Patching","sidebar":"docs"},"chapters/09/4":{"id":"chapters/09/4","title":"Automatiser et mettre \xe0 l\'\xe9chelle l\'interpr\xe9tabilit\xe9","description":"Les mod\xe8les \xe0 la pointe de la technologie contiennent maintenant des centaines de milliards de param\xe8tres et des milliers de couches interconnect\xe9es, rendant l\'inspection manuelle des composants du mod\xe8le impossible. L\'interpr\xe9tabilit\xe9 m\xe9caniste vise \xe0 analyser comment les \xe9l\xe9ments individuels \u2014 comme les t\xeates d\'attention, les neurones, les caract\xe9ristiques ou des couches enti\xe8res \u2014 interagissent pour produire des comportements sp\xe9cifiques. Cependant, \xe0 mesure que les mod\xe8les s\'\xe9tendent, les approches manuelles comme le tra\xe7age d\'activation pour la d\xe9couverte de circuits, l\'\xe9tude de sous-graphes et la g\xe9n\xe9ration d\'explications qui en d\xe9coule (Wang et al., 2023), deviennent impossibles \xe0 utiliser. C\'est pourquoi il est essentiel de d\xe9velopper des m\xe9thodes d\'interpr\xe9tabilit\xe9 m\xe9caniste qui peuvent \xeatre mises \xe0 l\'\xe9chelle.","sidebar":"docs"},"chapters/09/5":{"id":"chapters/09/5","title":"Critiques","description":"Bien que l\'interpr\xe9tabilit\xe9 offre une valeur potentielle dans la compr\xe9hension des mod\xe8les complexes d\'apprentissage automatique, elle fait face \xe0 plusieurs limitations critiques qui restreignent son impact pratique. Voici les principaux d\xe9fis qui limitent l\'utilit\xe9 de l\'interpr\xe9tabilit\xe9 pour garantir la s\xe9curit\xe9 de l\'IA :","sidebar":"docs"},"chapters/09/6":{"id":"chapters/09/6","title":"Critiques","description":"Bien que l\'interpr\xe9tabilit\xe9 offre une valeur potentielle dans la compr\xe9hension des mod\xe8les complexes d\'apprentissage automatique, elle fait face \xe0 plusieurs limitations critiques qui restreignent son impact pratique. Voici les principaux d\xe9fis qui limitent l\'utilit\xe9 de l\'interpr\xe9tabilit\xe9 pour assurer la s\xe9curit\xe9 de l\'IA :"},"chapters/09/index":{"id":"chapters/09/index","title":"Interpr\xe9tabilit\xe9","description":"Nous ne comprenons pas actuellement comment fonctionnent les mod\xe8les d\'IA. Nous savons comment les entra\xeener et les construire, c\'est-\xe0-dire que nous pouvons les concevoir et leur apprendre \xe0 effectuer des t\xe2ches, comme reconna\xeetre des objets dans des images ou g\xe9n\xe9rer du texte coh\xe9rent en r\xe9ponse \xe0 des invites. Cependant, cela ne signifie pas que nous pouvons toujours expliquer leur comportement apr\xe8s l\'entra\xeenement. Pour l\'instant, nous ne pouvons pas expliquer pourquoi un r\xe9seau a pris une d\xe9cision sp\xe9cifique ou produit une sortie particuli\xe8re. L\'objectif de l\'interpr\xe9tabilit\xe9 est de comprendre le fonctionnement interne de ces r\xe9seaux et d\'expliquer comment ils fonctionnent, ce qui pourrait nous permettre de mieux faire confiance aux mod\xe8les d\'IA et de les contr\xf4ler.","sidebar":"docs"},"chapters/index":{"id":"chapters/index","title":"Manuel scolaire","description":"Bienvenue dans le manuel de l\'Atlas de la S\xe9curit\xe9 de l\'IA. S\xe9lectionnez un chapitre dans la barre lat\xe9rale pour commencer.","sidebar":"docs"},"index":{"id":"index","title":"Atlas de la S\xe9curit\xe9 de l\'IA","description":"Cette page devrait \xeatre remplac\xe9e par la page d\'accueil personnalis\xe9e."}}}}')}}]);